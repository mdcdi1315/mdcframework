/*
 Copyright 2020 Mark Heath

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, 
copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, 
and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, 
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

 */

using System;
using System.IO;
using System.Text;
using System.Linq;
using System.Security;
using Microsoft.Win32;
using System.Threading;
using System.Reflection;
using System.Diagnostics;
using System.Globalization;
using System.Threading.Tasks;
using System.Collections.Generic;
using System.Runtime.InteropServices;
using System.Runtime.CompilerServices;

namespace NAudio.Wave
{
	using NAudio.Wave.Asio;

	/// <summary>
	/// Raised when ASIO data has been recorded.
	/// It is important to handle this as quickly as possible as it is in the buffer callback
	/// </summary>
	public class AsioAudioAvailableEventArgs : EventArgs
	{
		/// <summary>
		/// Pointer to a buffer per input channel
		/// </summary>
		public IntPtr[] InputBuffers { get; private set; }

		/// <summary>
		/// Pointer to a buffer per output channel
		/// Allows you to write directly to the output buffers
		/// If you do so, set SamplesPerBuffer = true,
		/// and make sure all buffers are written to with valid data
		/// </summary>
		public IntPtr[] OutputBuffers { get; private set; }

		/// <summary>
		/// Set to true if you have written to the output buffers
		/// If so, AsioOut will not read from its source
		/// </summary>
		public bool WrittenToOutputBuffers { get; set; }

		/// <summary>
		/// Number of samples in each buffer
		/// </summary>
		public int SamplesPerBuffer { get; private set; }

		/// <summary>
		/// Audio format within each buffer
		/// Most commonly this will be one of, Int32LSB, Int16LSB, Int24LSB or Float32LSB
		/// </summary>
		public AsioSampleType AsioSampleType { get; private set; }

		/// <summary>
		/// Initialises a new instance of AsioAudioAvailableEventArgs
		/// </summary>
		/// <param name="inputBuffers">Pointers to the ASIO buffers for each channel</param>
		/// <param name="outputBuffers">Pointers to the ASIO buffers for each channel</param>
		/// <param name="samplesPerBuffer">Number of samples in each buffer</param>
		/// <param name="asioSampleType">Audio format within each buffer</param>
		public AsioAudioAvailableEventArgs(IntPtr[] inputBuffers, IntPtr[] outputBuffers, int samplesPerBuffer, AsioSampleType asioSampleType)
		{
			InputBuffers = inputBuffers;
			OutputBuffers = outputBuffers;
			SamplesPerBuffer = samplesPerBuffer;
			AsioSampleType = asioSampleType;
		}

		/// <summary>
		/// Converts all the recorded audio into a buffer of 32 bit floating point samples, interleaved by channel
		/// </summary>
		/// <samples>The samples as 32 bit floating point, interleaved</samples>
		public unsafe int GetAsInterleavedSamples(float[] samples)
		{
			int num = InputBuffers.Length;
			if (samples.Length < SamplesPerBuffer * num)
			{
				throw new ArgumentException("Buffer not big enough");
			}
			int num2 = 0;
			if (AsioSampleType == AsioSampleType.Int32LSB)
			{
				for (int i = 0; i < SamplesPerBuffer; i++)
				{
					for (int j = 0; j < num; j++)
					{
						samples[num2++] = (float)(*(int*)((byte*)(void*)InputBuffers[j] + (nint)i * (nint)4)) / 2.1474836E+09f;
					}
				}
			}
			else if (AsioSampleType == AsioSampleType.Int16LSB)
			{
				for (int k = 0; k < SamplesPerBuffer; k++)
				{
					for (int l = 0; l < num; l++)
					{
						samples[num2++] = (float)(*(short*)((byte*)(void*)InputBuffers[l] + (nint)k * (nint)2)) / 32767f;
					}
				}
			}
			else if (AsioSampleType == AsioSampleType.Int24LSB)
			{
				for (int m = 0; m < SamplesPerBuffer; m++)
				{
					for (int n = 0; n < num; n++)
					{
						byte* ptr = (byte*)(void*)InputBuffers[n] + m * 3;
						int num3 = *ptr | (ptr[1] << 8) | ((sbyte)ptr[2] << 16);
						samples[num2++] = (float)num3 / 8388608f;
					}
				}
			}
			else
			{
				if (AsioSampleType != AsioSampleType.Float32LSB)
				{
					throw new NotImplementedException($"ASIO Sample Type {AsioSampleType} not supported");
				}
				for (int num4 = 0; num4 < SamplesPerBuffer; num4++)
				{
					for (int num5 = 0; num5 < num; num5++)
					{
						samples[num2++] = *(float*)((byte*)(void*)InputBuffers[num5] + (nint)num4 * (nint)4);
					}
				}
			}
			return SamplesPerBuffer * num;
		}

		/// <summary>
		/// Gets as interleaved samples, allocating a float array
		/// </summary>
		/// <returns>The samples as 32 bit floating point values</returns>
		[Obsolete("Better performance if you use the overload that takes an array, and reuse the same one")]
		public float[] GetAsInterleavedSamples()
		{
			int num = InputBuffers.Length;
			float[] array = new float[SamplesPerBuffer * num];
			GetAsInterleavedSamples(array);
			return array;
		}
	}

	/// <summary>
	/// ASIO Out Player. New implementation using an internal C# binding.
	///
	/// This implementation is only supporting Short16Bit and Float32Bit formats and is optimized 
	/// for 2 outputs channels .
	/// SampleRate is supported only if AsioDriver is supporting it
	///
	/// This implementation is probably the first AsioDriver binding fully implemented in C#!
	///
	/// Original Contributor: Mark Heath 
	/// New Contributor to C# binding : Alexandre Mutel - email: alexandre_mutel at yahoo.fr
	/// </summary>
	public class AsioOut : IWavePlayer, IDisposable
	{
		private AsioDriverExt driver;

		private IWaveProvider sourceStream;

		private PlaybackState playbackState;

		private int nbSamples;

		private byte[] waveBuffer;

		private AsioSampleConvertor.SampleConvertor convertor;

		private string driverName;

		private readonly SynchronizationContext syncContext;

		private bool isInitialized;

		/// <summary>
		/// Gets the latency (in samples) of the playback driver
		/// </summary>
		public int PlaybackLatency
		{
			get
			{
				driver.Driver.GetLatencies(out var _, out var outputLatency);
				return outputLatency;
			}
		}

		/// <summary>
		/// Automatically stop when the end of the input stream is reached
		/// Disable this if auto-stop is causing hanging issues
		/// </summary>
		public bool AutoStop { get; set; }

		/// <summary>
		/// A flag to let you know that we have reached the end of the input file
		/// Useful if AutoStop is set to false
		/// You can monitor this yourself and call Stop when it is true
		/// </summary>
		public bool HasReachedEnd { get; private set; }

		/// <summary>
		/// Playback State
		/// </summary>
		public PlaybackState PlaybackState => playbackState;

		/// <summary>
		/// Driver Name
		/// </summary>
		public string DriverName => driverName;

		/// <summary>
		/// The number of output channels we are currently using for playback
		/// (Must be less than or equal to DriverOutputChannelCount)
		/// </summary>
		public int NumberOfOutputChannels { get; private set; }

		/// <summary>
		/// The number of input channels we are currently recording from
		/// (Must be less than or equal to DriverInputChannelCount)
		/// </summary>
		public int NumberOfInputChannels { get; private set; }

		/// <summary>
		/// The maximum number of input channels this ASIO driver supports
		/// </summary>
		public int DriverInputChannelCount => driver.Capabilities.NbInputChannels;

		/// <summary>
		/// The maximum number of output channels this ASIO driver supports
		/// </summary>
		public int DriverOutputChannelCount => driver.Capabilities.NbOutputChannels;

		/// <summary>
		/// The number of samples per channel, per buffer.
		/// </summary>
		public int FramesPerBuffer
		{
			get
			{
				if (!isInitialized)
				{
					throw new Exception("Not initialized yet. Call this after calling Init");
				}
				return nbSamples;
			}
		}

		/// <summary>
		/// By default the first channel on the input WaveProvider is sent to the first ASIO output.
		/// This option sends it to the specified channel number.
		/// Warning: make sure you don't set it higher than the number of available output channels - 
		/// the number of source channels.
		/// n.b. Future NAudio may modify this
		/// </summary>
		public int ChannelOffset { get; set; }

		/// <summary>
		/// Input channel offset (used when recording), allowing you to choose to record from just one
		/// specific input rather than them all
		/// </summary>
		public int InputChannelOffset { get; set; }

		/// <summary>
		/// Sets the volume (1.0 is unity gain)
		/// Not supported for ASIO Out. Set the volume on the input stream instead
		/// </summary>
		[Obsolete("this function will be removed in a future NAudio as ASIO does not support setting the volume on the device")]
		public float Volume
		{
			get
			{
				return 1f;
			}
			set
			{
				if (value != 1f)
				{
					throw new InvalidOperationException("AsioOut does not support setting the device volume");
				}
			}
		}

		/// <inheritdoc />
		public WaveFormat OutputWaveFormat { get; private set; }

		/// <summary>
		/// Playback Stopped
		/// </summary>
		public event EventHandler<StoppedEventArgs> PlaybackStopped;

		/// <summary>
		/// When recording, fires whenever recorded audio is available
		/// </summary>
		public event EventHandler<AsioAudioAvailableEventArgs> AudioAvailable;

		/// <summary>
		/// Occurs when the driver settings are changed by the user, e.g. in the control panel.
		/// </summary>
		public event EventHandler DriverResetRequest;

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.AsioOut" /> class with the first 
		/// available ASIO Driver.
		/// </summary>
		public AsioOut()
			: this(0)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.AsioOut" /> class with the driver name.
		/// </summary>
		/// <param name="driverName">Name of the device.</param>
		public AsioOut(string driverName)
		{
			syncContext = SynchronizationContext.Current;
			InitFromName(driverName);
		}

		/// <summary>
		/// Opens an ASIO output device
		/// </summary>
		/// <param name="driverIndex">Device number (zero based)</param>
		public AsioOut(int driverIndex)
		{
			syncContext = SynchronizationContext.Current;
			string[] driverNames = GetDriverNames();
			if (driverNames.Length == 0)
			{
				throw new ArgumentException("There is no ASIO Driver installed on your system");
			}
			if (driverIndex < 0 || driverIndex > driverNames.Length)
			{
				throw new ArgumentException($"Invalid device number. Must be in the range [0,{driverNames.Length}]");
			}
			InitFromName(driverNames[driverIndex]);
		}

		/// <summary>
		/// Releases unmanaged resources and performs other cleanup operations before the
		/// <see cref="T:NAudio.Wave.AsioOut" /> is reclaimed by garbage collection.
		/// </summary>
		~AsioOut()
		{
			Dispose();
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (driver != null)
			{
				if (playbackState != 0)
				{
					driver.Stop();
				}
				driver.ResetRequestCallback = null;
				driver.ReleaseDriver();
				driver = null;
			}
		}

		/// <summary>
		/// Gets the names of the installed ASIO Driver.
		/// </summary>
		/// <returns>an array of driver names</returns>
		public static string[] GetDriverNames()
		{
			return AsioDriver.GetAsioDriverNames();
		}

		/// <summary>
		/// Determines whether ASIO is supported.
		/// </summary>
		/// <returns>
		///     <c>true</c> if ASIO is supported; otherwise, <c>false</c>.
		/// </returns>
		public static bool isSupported()
		{
			return GetDriverNames().Length != 0;
		}

		/// <summary>
		/// Determines whether this driver supports the specified sample rate.
		/// </summary>
		/// <param name="sampleRate">The samplerate to check.</param>
		/// <returns>
		///   <c>true</c> if the specified sample rate is supported otherwise, <c>false</c>.
		/// </returns>
		public bool IsSampleRateSupported(int sampleRate)
		{
			return driver.IsSampleRateSupported(sampleRate);
		}

		/// <summary>
		/// Inits the driver from the asio driver name.
		/// </summary>
		/// <param name="driverName">Name of the driver.</param>
		private void InitFromName(string driverName)
		{
			this.driverName = driverName;
			AsioDriver asioDriverByName = AsioDriver.GetAsioDriverByName(driverName);
			try
			{
				driver = new AsioDriverExt(asioDriverByName);
			}
			catch
			{
				ReleaseDriver(asioDriverByName);
				throw;
			}
			driver.ResetRequestCallback = OnDriverResetRequest;
			ChannelOffset = 0;
		}

		private void OnDriverResetRequest()
		{
			this.DriverResetRequest?.Invoke(this, EventArgs.Empty);
		}

		/// <summary>
		/// Release driver
		/// </summary>
		private void ReleaseDriver(AsioDriver driver)
		{
			driver.DisposeBuffers();
			driver.ReleaseComAsioDriver();
		}

		/// <summary>
		/// Shows the control panel
		/// </summary>
		public void ShowControlPanel()
		{
			driver.ShowControlPanel();
		}

		/// <summary>
		/// Starts playback
		/// </summary>
		public void Play()
		{
			if (playbackState != PlaybackState.Playing)
			{
				playbackState = PlaybackState.Playing;
				HasReachedEnd = false;
				driver.Start();
			}
		}

		/// <summary>
		/// Stops playback
		/// </summary>
		public void Stop()
		{
			playbackState = PlaybackState.Stopped;
			driver.Stop();
			HasReachedEnd = false;
			RaisePlaybackStopped(null);
		}

		/// <summary>
		/// Pauses playback
		/// </summary>
		public void Pause()
		{
			playbackState = PlaybackState.Paused;
			driver.Stop();
		}

		/// <summary>
		/// Initialises to play
		/// </summary>
		/// <param name="waveProvider">Source wave provider</param>
		public void Init(IWaveProvider waveProvider)
		{
			InitRecordAndPlayback(waveProvider, 0, -1);
		}

		/// <summary>
		/// Initialises to play, with optional recording
		/// </summary>
		/// <param name="waveProvider">Source wave provider - set to null for record only</param>
		/// <param name="recordChannels">Number of channels to record</param>
		/// <param name="recordOnlySampleRate">Specify sample rate here if only recording, ignored otherwise</param>
		public void InitRecordAndPlayback(IWaveProvider waveProvider, int recordChannels, int recordOnlySampleRate)
		{
			if (isInitialized)
			{
				throw new InvalidOperationException("Already initialised this instance of AsioOut - dispose and create a new one");
			}
			isInitialized = true;
			int num = waveProvider?.WaveFormat.SampleRate ?? recordOnlySampleRate;
			if (waveProvider != null)
			{
				sourceStream = waveProvider;
				NumberOfOutputChannels = waveProvider.WaveFormat.Channels;
				AsioSampleType type = driver.Capabilities.OutputChannelInfos[0].type;
				convertor = AsioSampleConvertor.SelectSampleConvertor(waveProvider.WaveFormat, type);
				switch (type)
				{
				case AsioSampleType.Float32LSB:
					OutputWaveFormat = WaveFormat.CreateIeeeFloatWaveFormat(waveProvider.WaveFormat.SampleRate, waveProvider.WaveFormat.Channels);
					break;
				case AsioSampleType.Int32LSB:
					OutputWaveFormat = new WaveFormat(waveProvider.WaveFormat.SampleRate, 32, waveProvider.WaveFormat.Channels);
					break;
				case AsioSampleType.Int16LSB:
					OutputWaveFormat = new WaveFormat(waveProvider.WaveFormat.SampleRate, 16, waveProvider.WaveFormat.Channels);
					break;
				case AsioSampleType.Int24LSB:
					OutputWaveFormat = new WaveFormat(waveProvider.WaveFormat.SampleRate, 24, waveProvider.WaveFormat.Channels);
					break;
				default:
					throw new NotSupportedException($"{type} not currently supported");
				}
			}
			else
			{
				NumberOfOutputChannels = 0;
			}
			if (!driver.IsSampleRateSupported(num))
			{
				throw new ArgumentException("SampleRate is not supported");
			}
			if (driver.Capabilities.SampleRate != (double)num)
			{
				driver.SetSampleRate(num);
			}
			driver.FillBufferCallback = driver_BufferUpdate;
			NumberOfInputChannels = recordChannels;
			nbSamples = driver.CreateBuffers(NumberOfOutputChannels, NumberOfInputChannels, useMaxBufferSize: false);
			driver.SetChannelOffset(ChannelOffset, InputChannelOffset);
			if (waveProvider != null)
			{
				waveBuffer = new byte[nbSamples * NumberOfOutputChannels * waveProvider.WaveFormat.BitsPerSample / 8];
			}
		}

		/// <summary>
		/// driver buffer update callback to fill the wave buffer.
		/// </summary>
		/// <param name="inputChannels">The input channels.</param>
		/// <param name="outputChannels">The output channels.</param>
		private unsafe void driver_BufferUpdate(IntPtr[] inputChannels, IntPtr[] outputChannels)
		{
			if (NumberOfInputChannels > 0)
			{
				EventHandler<AsioAudioAvailableEventArgs> audioAvailable = this.AudioAvailable;
				if (audioAvailable != null)
				{
					AsioAudioAvailableEventArgs asioAudioAvailableEventArgs = new AsioAudioAvailableEventArgs(inputChannels, outputChannels, nbSamples, driver.Capabilities.InputChannelInfos[0].type);
					audioAvailable(this, asioAudioAvailableEventArgs);
					if (asioAudioAvailableEventArgs.WrittenToOutputBuffers)
					{
						return;
					}
				}
			}
			if (NumberOfOutputChannels <= 0)
			{
				return;
			}
			int num = sourceStream.Read(waveBuffer, 0, waveBuffer.Length);
			if (num < waveBuffer.Length)
			{
				Array.Clear(waveBuffer, num, waveBuffer.Length - num);
			}
			fixed (byte* ptr = &waveBuffer[0])
			{
				void* value = ptr;
				convertor(new IntPtr(value), outputChannels, NumberOfOutputChannels, nbSamples);
			}
			if (num == 0)
			{
				if (AutoStop)
				{
					Stop();
				}
				HasReachedEnd = true;
			}
		}

		private void RaisePlaybackStopped(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.PlaybackStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		/// <summary>
		/// Get the input channel name
		/// </summary>
		/// <param name="channel">channel index (zero based)</param>
		/// <returns>channel name</returns>
		public string AsioInputChannelName(int channel)
		{
			if (channel <= DriverInputChannelCount)
			{
				return driver.Capabilities.InputChannelInfos[channel].name;
			}
			return "";
		}

		/// <summary>
		/// Get the output channel name
		/// </summary>
		/// <param name="channel">channel index (zero based)</param>
		/// <returns>channel name</returns>
		public string AsioOutputChannelName(int channel)
		{
			if (channel <= DriverOutputChannelCount)
			{
				return driver.Capabilities.OutputChannelInfos[channel].name;
			}
			return "";
		}
	}
}

namespace NAudio.Wave.Asio
{
	/// <summary>
	/// ASIO 64 bit value
	/// Unfortunately the ASIO API was implemented it before compiler supported consistently 64 bit 
	/// integer types. By using the structure the data layout on a little-endian system like the 
	/// Intel x86 architecture will result in a "non native" storage of the 64 bit data. The most 
	/// significant 32 bit are stored first in memory, the least significant bits are stored in the 
	/// higher memory space. However each 32 bit is stored in the native little-endian fashion
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	public struct Asio64Bit
	{
		/// <summary>
		/// most significant bits (Bits 32..63)
		/// </summary>
		public uint hi;

		/// <summary>
		/// least significant bits (Bits 0..31)
		/// </summary>
		public uint lo;
	}

	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	internal struct AsioBufferInfo
	{
		public bool isInput;

		public int channelNum;

		public IntPtr pBuffer0;

		public IntPtr pBuffer1;

		public IntPtr Buffer(int bufferIndex)
		{
			if (bufferIndex != 0)
			{
				return pBuffer1;
			}
			return pBuffer0;
		}
	}

	/// <summary>
	/// ASIO Callbacks
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	public struct AsioCallbacks
	{
		/// <summary>
		/// ASIO Buffer Switch Callback
		/// </summary>
		[UnmanagedFunctionPointer(CallingConvention.Cdecl)]
		public delegate void AsioBufferSwitchCallBack(int doubleBufferIndex, bool directProcess);

		/// <summary>
		/// ASIO Sample Rate Did Change Callback
		/// </summary>
		[UnmanagedFunctionPointer(CallingConvention.Cdecl)]
		public delegate void AsioSampleRateDidChangeCallBack(double sRate);

		/// <summary>
		/// ASIO Message Callback
		/// </summary>
		[UnmanagedFunctionPointer(CallingConvention.Cdecl)]
		public delegate int AsioAsioMessageCallBack(AsioMessageSelector selector, int value, IntPtr message, IntPtr opt);

		/// <summary>
		/// ASIO Buffer Switch Time Info Callback
		/// </summary>
		[UnmanagedFunctionPointer(CallingConvention.Cdecl)]
		public delegate IntPtr AsioBufferSwitchTimeInfoCallBack(IntPtr asioTimeParam, int doubleBufferIndex, bool directProcess);

		/// <summary>
		/// Buffer switch callback
		/// void (*bufferSwitch) (long doubleBufferIndex, AsioBool directProcess);
		/// </summary>
		public AsioBufferSwitchCallBack pbufferSwitch;

		/// <summary>
		/// Sample Rate Changed callback
		/// void (*sampleRateDidChange) (AsioSampleRate sRate);
		/// </summary>
		public AsioSampleRateDidChangeCallBack psampleRateDidChange;

		/// <summary>
		/// ASIO Message callback
		/// long (*asioMessage) (long selector, long value, void* message, double* opt);
		/// </summary>
		public AsioAsioMessageCallBack pasioMessage;

		/// <summary>
		/// ASIO Buffer Switch Time Info Callback
		/// AsioTime* (*bufferSwitchTimeInfo) (AsioTime* params, long doubleBufferIndex, AsioBool directProcess);
		/// </summary>
		public AsioBufferSwitchTimeInfoCallBack pbufferSwitchTimeInfo;
	}

	/// <summary>
	/// ASIO Channel Info
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	public struct AsioChannelInfo
	{
		/// <summary>
		/// on input, channel index
		/// </summary>
		public int channel;

		/// <summary>
		/// Is Input
		/// </summary>
		public bool isInput;

		/// <summary>
		/// Is Active
		/// </summary>
		public bool isActive;

		/// <summary>
		/// Channel Info
		/// </summary>
		public int channelGroup;

		/// <summary>
		/// ASIO Sample Type
		/// </summary>
		[MarshalAs(UnmanagedType.U4)]
		public AsioSampleType type;

		/// <summary>
		/// Name
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		public string name;
	}

	/// <summary>
	/// Main AsioDriver Class. To use this class, you need to query first the GetAsioDriverNames() and
	/// then use the GetAsioDriverByName to instantiate the correct AsioDriver.
	/// This is the first AsioDriver binding fully implemented in C#!
	///
	/// Contributor: Alexandre Mutel - email: alexandre_mutel at yahoo.fr
	/// </summary>
	public class AsioDriver
	{
		/// <summary>
		/// Internal VTable structure to store all the delegates to the C++ COM method.
		/// </summary>
		[StructLayout(LayoutKind.Sequential, Pack = 2)]
		private class AsioDriverVTable
		{
			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate int ASIOInit(IntPtr _pUnknown, IntPtr sysHandle);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate void ASIOgetDriverName(IntPtr _pUnknown, StringBuilder name);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate int ASIOgetDriverVersion(IntPtr _pUnknown);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate void ASIOgetErrorMessage(IntPtr _pUnknown, StringBuilder errorMessage);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOstart(IntPtr _pUnknown);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOstop(IntPtr _pUnknown);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetChannels(IntPtr _pUnknown, out int numInputChannels, out int numOutputChannels);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetLatencies(IntPtr _pUnknown, out int inputLatency, out int outputLatency);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetBufferSize(IntPtr _pUnknown, out int minSize, out int maxSize, out int preferredSize, out int granularity);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOcanSampleRate(IntPtr _pUnknown, double sampleRate);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetSampleRate(IntPtr _pUnknown, out double sampleRate);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOsetSampleRate(IntPtr _pUnknown, double sampleRate);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetClockSources(IntPtr _pUnknown, out long clocks, int numSources);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOsetClockSource(IntPtr _pUnknown, int reference);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetSamplePosition(IntPtr _pUnknown, out long samplePos, ref Asio64Bit timeStamp);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOgetChannelInfo(IntPtr _pUnknown, ref AsioChannelInfo info);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOcreateBuffers(IntPtr _pUnknown, IntPtr bufferInfos, int numChannels, int bufferSize, IntPtr callbacks);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOdisposeBuffers(IntPtr _pUnknown);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOcontrolPanel(IntPtr _pUnknown);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOfuture(IntPtr _pUnknown, int selector, IntPtr opt);

			[UnmanagedFunctionPointer(CallingConvention.ThisCall)]
			public delegate AsioError ASIOoutputReady(IntPtr _pUnknown);

			public ASIOInit init;

			public ASIOgetDriverName getDriverName;

			public ASIOgetDriverVersion getDriverVersion;

			public ASIOgetErrorMessage getErrorMessage;

			public ASIOstart start;

			public ASIOstop stop;

			public ASIOgetChannels getChannels;

			public ASIOgetLatencies getLatencies;

			public ASIOgetBufferSize getBufferSize;

			public ASIOcanSampleRate canSampleRate;

			public ASIOgetSampleRate getSampleRate;

			public ASIOsetSampleRate setSampleRate;

			public ASIOgetClockSources getClockSources;

			public ASIOsetClockSource setClockSource;

			public ASIOgetSamplePosition getSamplePosition;

			public ASIOgetChannelInfo getChannelInfo;

			public ASIOcreateBuffers createBuffers;

			public ASIOdisposeBuffers disposeBuffers;

			public ASIOcontrolPanel controlPanel;

			public ASIOfuture future;

			public ASIOoutputReady outputReady;
		}

		private IntPtr pAsioComObject;

		private IntPtr pinnedcallbacks;

		private AsioDriverVTable asioDriverVTable;

		private AsioDriver()
		{
		}

		/// <summary>
		/// Gets the ASIO driver names installed.
		/// </summary>
		/// <returns>a list of driver names. Use this name to GetAsioDriverByName</returns>
		public static string[] GetAsioDriverNames()
		{
			RegistryKey registryKey = Registry.LocalMachine.OpenSubKey("SOFTWARE\\ASIO");
			string[] result = new string[0];
			if (registryKey != null)
			{
				result = registryKey.GetSubKeyNames();
				registryKey.Close();
			}
			return result;
		}

		/// <summary>
		/// Instantiate a AsioDriver given its name.
		/// </summary>
		/// <param name="name">The name of the driver</param>
		/// <returns>an AsioDriver instance</returns>
		public static AsioDriver GetAsioDriverByName(string name)
		{
			return GetAsioDriverByGuid(new Guid((Registry.LocalMachine.OpenSubKey("SOFTWARE\\ASIO\\" + name) ?? throw new ArgumentException("Driver Name " + name + " doesn't exist")).GetValue("CLSID").ToString()));
		}

		/// <summary>
		/// Instantiate the ASIO driver by GUID.
		/// </summary>
		/// <param name="guid">The GUID.</param>
		/// <returns>an AsioDriver instance</returns>
		public static AsioDriver GetAsioDriverByGuid(Guid guid)
		{
			AsioDriver asioDriver = new AsioDriver();
			asioDriver.InitFromGuid(guid);
			return asioDriver;
		}

		/// <summary>
		/// Inits the AsioDriver..
		/// </summary>
		/// <param name="sysHandle">The sys handle.</param>
		/// <returns></returns>
		public bool Init(IntPtr sysHandle)
		{
			return asioDriverVTable.init(pAsioComObject, sysHandle) == 1;
		}

		/// <summary>
		/// Gets the name of the driver.
		/// </summary>
		/// <returns></returns>
		public string GetDriverName()
		{
			StringBuilder stringBuilder = new StringBuilder(256);
			asioDriverVTable.getDriverName(pAsioComObject, stringBuilder);
			return stringBuilder.ToString();
		}

		/// <summary>
		/// Gets the driver version.
		/// </summary>
		/// <returns></returns>
		public int GetDriverVersion()
		{
			return asioDriverVTable.getDriverVersion(pAsioComObject);
		}

		/// <summary>
		/// Gets the error message.
		/// </summary>
		/// <returns></returns>
		public string GetErrorMessage()
		{
			StringBuilder stringBuilder = new StringBuilder(256);
			asioDriverVTable.getErrorMessage(pAsioComObject, stringBuilder);
			return stringBuilder.ToString();
		}

		/// <summary>
		/// Starts this instance.
		/// </summary>
		public void Start()
		{
			HandleException(asioDriverVTable.start(pAsioComObject), "start");
		}

		/// <summary>
		/// Stops this instance.
		/// </summary>
		public AsioError Stop()
		{
			return asioDriverVTable.stop(pAsioComObject);
		}

		/// <summary>
		/// Gets the number of channels.
		/// </summary>
		/// <param name="numInputChannels">The num input channels.</param>
		/// <param name="numOutputChannels">The num output channels.</param>
		public void GetChannels(out int numInputChannels, out int numOutputChannels)
		{
			HandleException(asioDriverVTable.getChannels(pAsioComObject, out numInputChannels, out numOutputChannels), "getChannels");
		}

		/// <summary>
		/// Gets the latencies (n.b. does not throw an exception)
		/// </summary>
		/// <param name="inputLatency">The input latency.</param>
		/// <param name="outputLatency">The output latency.</param>
		public AsioError GetLatencies(out int inputLatency, out int outputLatency)
		{
			return asioDriverVTable.getLatencies(pAsioComObject, out inputLatency, out outputLatency);
		}

		/// <summary>
		/// Gets the size of the buffer.
		/// </summary>
		/// <param name="minSize">Size of the min.</param>
		/// <param name="maxSize">Size of the max.</param>
		/// <param name="preferredSize">Size of the preferred.</param>
		/// <param name="granularity">The granularity.</param>
		public void GetBufferSize(out int minSize, out int maxSize, out int preferredSize, out int granularity)
		{
			HandleException(asioDriverVTable.getBufferSize(pAsioComObject, out minSize, out maxSize, out preferredSize, out granularity), "getBufferSize");
		}

		/// <summary>
		/// Determines whether this instance can use the specified sample rate.
		/// </summary>
		/// <param name="sampleRate">The sample rate.</param>
		/// <returns>
		/// 	<c>true</c> if this instance [can sample rate] the specified sample rate; otherwise, <c>false</c>.
		/// </returns>
		public bool CanSampleRate(double sampleRate)
		{
			AsioError asioError = asioDriverVTable.canSampleRate(pAsioComObject, sampleRate);
			switch (asioError)
			{
			case AsioError.ASE_NoClock:
				return false;
			case AsioError.ASE_OK:
				return true;
			default:
				HandleException(asioError, "canSampleRate");
				return false;
			}
		}

		/// <summary>
		/// Gets the sample rate.
		/// </summary>
		/// <returns></returns>
		public double GetSampleRate()
		{
			HandleException(asioDriverVTable.getSampleRate(pAsioComObject, out var sampleRate), "getSampleRate");
			return sampleRate;
		}

		/// <summary>
		/// Sets the sample rate.
		/// </summary>
		/// <param name="sampleRate">The sample rate.</param>
		public void SetSampleRate(double sampleRate)
		{
			HandleException(asioDriverVTable.setSampleRate(pAsioComObject, sampleRate), "setSampleRate");
		}

		/// <summary>
		/// Gets the clock sources.
		/// </summary>
		/// <param name="clocks">The clocks.</param>
		/// <param name="numSources">The num sources.</param>
		public void GetClockSources(out long clocks, int numSources)
		{
			HandleException(asioDriverVTable.getClockSources(pAsioComObject, out clocks, numSources), "getClockSources");
		}

		/// <summary>
		/// Sets the clock source.
		/// </summary>
		/// <param name="reference">The reference.</param>
		public void SetClockSource(int reference)
		{
			HandleException(asioDriverVTable.setClockSource(pAsioComObject, reference), "setClockSources");
		}

		/// <summary>
		/// Gets the sample position.
		/// </summary>
		/// <param name="samplePos">The sample pos.</param>
		/// <param name="timeStamp">The time stamp.</param>
		public void GetSamplePosition(out long samplePos, ref Asio64Bit timeStamp)
		{
			HandleException(asioDriverVTable.getSamplePosition(pAsioComObject, out samplePos, ref timeStamp), "getSamplePosition");
		}

		/// <summary>
		/// Gets the channel info.
		/// </summary>
		/// <param name="channelNumber">The channel number.</param>
		/// <param name="trueForInputInfo">if set to <c>true</c> [true for input info].</param>
		/// <returns>Channel Info</returns>
		public AsioChannelInfo GetChannelInfo(int channelNumber, bool trueForInputInfo)
		{
			AsioChannelInfo asioChannelInfo = default(AsioChannelInfo);
			asioChannelInfo.channel = channelNumber;
			asioChannelInfo.isInput = trueForInputInfo;
			AsioChannelInfo info = asioChannelInfo;
			HandleException(asioDriverVTable.getChannelInfo(pAsioComObject, ref info), "getChannelInfo");
			return info;
		}

		/// <summary>
		/// Creates the buffers.
		/// </summary>
		/// <param name="bufferInfos">The buffer infos.</param>
		/// <param name="numChannels">The num channels.</param>
		/// <param name="bufferSize">Size of the buffer.</param>
		/// <param name="callbacks">The callbacks.</param>
		public void CreateBuffers(IntPtr bufferInfos, int numChannels, int bufferSize, ref AsioCallbacks callbacks)
		{
			pinnedcallbacks = Marshal.AllocHGlobal(Marshal.SizeOf(callbacks));
			Marshal.StructureToPtr(callbacks, pinnedcallbacks, fDeleteOld: false);
			HandleException(asioDriverVTable.createBuffers(pAsioComObject, bufferInfos, numChannels, bufferSize, pinnedcallbacks), "createBuffers");
		}

		/// <summary>
		/// Disposes the buffers.
		/// </summary>
		public AsioError DisposeBuffers()
		{
			AsioError result = asioDriverVTable.disposeBuffers(pAsioComObject);
			Marshal.FreeHGlobal(pinnedcallbacks);
			return result;
		}

		/// <summary>
		/// Controls the panel.
		/// </summary>
		public void ControlPanel()
		{
			HandleException(asioDriverVTable.controlPanel(pAsioComObject), "controlPanel");
		}

		/// <summary>
		/// Futures the specified selector.
		/// </summary>
		/// <param name="selector">The selector.</param>
		/// <param name="opt">The opt.</param>
		public void Future(int selector, IntPtr opt)
		{
			HandleException(asioDriverVTable.future(pAsioComObject, selector, opt), "future");
		}

		/// <summary>
		/// Notifies OutputReady to the AsioDriver.
		/// </summary>
		/// <returns></returns>
		public AsioError OutputReady()
		{
			return asioDriverVTable.outputReady(pAsioComObject);
		}

		/// <summary>
		/// Releases this instance.
		/// </summary>
		public void ReleaseComAsioDriver()
		{
			Marshal.Release(pAsioComObject);
		}

		/// <summary>
		/// Handles the exception. Throws an exception based on the error.
		/// </summary>
		/// <param name="error">The error to check.</param>
		/// <param name="methodName">Method name</param>
		private void HandleException(AsioError error, string methodName)
		{
			if (error != 0 && error != AsioError.ASE_SUCCESS)
			{
				throw new AsioException("Error code [" + AsioException.getErrorName(error) + "] while calling ASIO method <" + methodName + ">, " + GetErrorMessage())
				{
					Error = error
				};
			}
		}

		/// <summary>
		/// Inits the vTable method from GUID. This is a tricky part of this class.
		/// </summary>
		/// <param name="asioGuid">The ASIO GUID.</param>
		private void InitFromGuid(Guid asioGuid)
		{
			int num = CoCreateInstance(ref asioGuid, IntPtr.Zero, 1u, ref asioGuid, out pAsioComObject);
			if (num != 0)
			{
				throw new COMException("Unable to instantiate ASIO. Check if STAThread is set", num);
			}
			IntPtr ptr = Marshal.ReadIntPtr(pAsioComObject);
			asioDriverVTable = new AsioDriverVTable();
			FieldInfo[] fields = typeof(AsioDriverVTable).GetFields();
			for (int i = 0; i < fields.Length; i++)
			{
				FieldInfo fieldInfo = fields[i];
				object delegateForFunctionPointer = Marshal.GetDelegateForFunctionPointer(Marshal.ReadIntPtr(ptr, (i + 3) * IntPtr.Size), fieldInfo.FieldType);
				fieldInfo.SetValue(asioDriverVTable, delegateForFunctionPointer);
			}
		}

		[DllImport("ole32.dll")]
		private static extern int CoCreateInstance(ref Guid clsid, IntPtr inner, uint context, ref Guid uuid, out IntPtr rReturnedComObject);
	}

	/// <summary>
	/// AsioDriverCapability holds all the information from the AsioDriver.
	/// Use AsioDriverExt to get the Capabilities
	/// </summary>
	public class AsioDriverCapability
	{
		/// <summary>
		/// Drive Name
		/// </summary>
		public string DriverName;

		/// <summary>
		/// Number of Input Channels
		/// </summary>
		public int NbInputChannels;

		/// <summary>
		/// Number of Output Channels
		/// </summary>
		public int NbOutputChannels;

		/// <summary>
		/// Input Latency
		/// </summary>
		public int InputLatency;

		/// <summary>
		/// Output Latency
		/// </summary>
		public int OutputLatency;

		/// <summary>
		/// Buffer Minimum Size
		/// </summary>
		public int BufferMinSize;

		/// <summary>
		/// Buffer Maximum Size
		/// </summary>
		public int BufferMaxSize;

		/// <summary>
		/// Buffer Preferred Size
		/// </summary>
		public int BufferPreferredSize;

		/// <summary>
		/// Buffer Granularity
		/// </summary>
		public int BufferGranularity;

		/// <summary>
		/// Sample Rate
		/// </summary>
		public double SampleRate;

		/// <summary>
		/// Input Channel Info
		/// </summary>
		public AsioChannelInfo[] InputChannelInfos;

		/// <summary>
		/// Output Channel Info
		/// </summary>
		public AsioChannelInfo[] OutputChannelInfos;
	}

	/// <summary>
	/// AsioDriverExt is a simplified version of the AsioDriver. It provides an easier
	/// way to access the capabilities of the Driver and implement the callbacks necessary 
	/// for feeding the driver.
	/// Implementation inspired from Rob Philpot's with a managed C++ ASIO wrapper BlueWave.Interop.Asio
	/// http://www.codeproject.com/KB/mcpp/Asio.Net.aspx
	///
	/// Contributor: Alexandre Mutel - email: alexandre_mutel at yahoo.fr
	/// </summary>
	public class AsioDriverExt
	{
		private readonly AsioDriver driver;

		private AsioCallbacks callbacks;

		private AsioDriverCapability capability;

		private AsioBufferInfo[] bufferInfos;

		private bool isOutputReadySupported;

		private IntPtr[] currentOutputBuffers;

		private IntPtr[] currentInputBuffers;

		private int numberOfOutputChannels;

		private int numberOfInputChannels;

		private AsioFillBufferCallback fillBufferCallback;

		private int bufferSize;

		private int outputChannelOffset;

		private int inputChannelOffset;

		public Action ResetRequestCallback;

		/// <summary>
		/// Gets the driver used.
		/// </summary>
		/// <value>The ASIOdriver.</value>
		public AsioDriver Driver => driver;

		/// <summary>
		/// Gets or sets the fill buffer callback.
		/// </summary>
		/// <value>The fill buffer callback.</value>
		public AsioFillBufferCallback FillBufferCallback
		{
			get
			{
				return fillBufferCallback;
			}
			set
			{
				fillBufferCallback = value;
			}
		}

		/// <summary>
		/// Gets the capabilities of the AsioDriver.
		/// </summary>
		/// <value>The capabilities.</value>
		public AsioDriverCapability Capabilities => capability;

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.Asio.AsioDriverExt" /> class based on an already
		/// instantiated AsioDriver instance.
		/// </summary>
		/// <param name="driver">A AsioDriver already instantiated.</param>
		public AsioDriverExt(AsioDriver driver)
		{
			this.driver = driver;
			if (!driver.Init(IntPtr.Zero))
			{
				throw new InvalidOperationException(driver.GetErrorMessage());
			}
			callbacks = default(AsioCallbacks);
			callbacks.pasioMessage = AsioMessageCallBack;
			callbacks.pbufferSwitch = BufferSwitchCallBack;
			callbacks.pbufferSwitchTimeInfo = BufferSwitchTimeInfoCallBack;
			callbacks.psampleRateDidChange = SampleRateDidChangeCallBack;
			BuildCapabilities();
		}

		/// <summary>
		/// Allows adjustment of which is the first output channel we write to
		/// </summary>
		/// <param name="outputChannelOffset">Output Channel offset</param>
		/// <param name="inputChannelOffset">Input Channel offset</param>
		public void SetChannelOffset(int outputChannelOffset, int inputChannelOffset)
		{
			if (outputChannelOffset + numberOfOutputChannels <= Capabilities.NbOutputChannels)
			{
				this.outputChannelOffset = outputChannelOffset;
				if (inputChannelOffset + numberOfInputChannels <= Capabilities.NbInputChannels)
				{
					this.inputChannelOffset = inputChannelOffset;
					return;
				}
				throw new ArgumentException("Invalid channel offset");
			}
			throw new ArgumentException("Invalid channel offset");
		}

		/// <summary>
		/// Starts playing the buffers.
		/// </summary>
		public void Start()
		{
			driver.Start();
		}

		/// <summary>
		/// Stops playing the buffers.
		/// </summary>
		public void Stop()
		{
			driver.Stop();
		}

		/// <summary>
		/// Shows the control panel.
		/// </summary>
		public void ShowControlPanel()
		{
			driver.ControlPanel();
		}

		/// <summary>
		/// Releases this instance.
		/// </summary>
		public void ReleaseDriver()
		{
			try
			{
				driver.DisposeBuffers();
			}
			catch (Exception ex)
			{
				Console.Out.WriteLine(ex.ToString());
			}
			driver.ReleaseComAsioDriver();
		}

		/// <summary>
		/// Determines whether the specified sample rate is supported.
		/// </summary>
		/// <param name="sampleRate">The sample rate.</param>
		/// <returns>
		/// 	<c>true</c> if [is sample rate supported]; otherwise, <c>false</c>.
		/// </returns>
		public bool IsSampleRateSupported(double sampleRate)
		{
			return driver.CanSampleRate(sampleRate);
		}

		/// <summary>
		/// Sets the sample rate.
		/// </summary>
		/// <param name="sampleRate">The sample rate.</param>
		public void SetSampleRate(double sampleRate)
		{
			driver.SetSampleRate(sampleRate);
			BuildCapabilities();
		}

		/// <summary>
		/// Creates the buffers for playing.
		/// </summary>
		/// <param name="numberOfOutputChannels">The number of outputs channels.</param>
		/// <param name="numberOfInputChannels">The number of input channel.</param>
		/// <param name="useMaxBufferSize">if set to <c>true</c> [use max buffer size] else use Prefered size</param>
		public unsafe int CreateBuffers(int numberOfOutputChannels, int numberOfInputChannels, bool useMaxBufferSize)
		{
			if (numberOfOutputChannels < 0 || numberOfOutputChannels > capability.NbOutputChannels)
			{
				throw new ArgumentException($"Invalid number of channels {numberOfOutputChannels}, must be in the range [0,{capability.NbOutputChannels}]");
			}
			if (numberOfInputChannels < 0 || numberOfInputChannels > capability.NbInputChannels)
			{
				throw new ArgumentException("numberOfInputChannels", $"Invalid number of input channels {numberOfInputChannels}, must be in the range [0,{capability.NbInputChannels}]");
			}
			this.numberOfOutputChannels = numberOfOutputChannels;
			this.numberOfInputChannels = numberOfInputChannels;
			int num = capability.NbInputChannels + capability.NbOutputChannels;
			bufferInfos = new AsioBufferInfo[num];
			currentOutputBuffers = new IntPtr[numberOfOutputChannels];
			currentInputBuffers = new IntPtr[numberOfInputChannels];
			int num2 = 0;
			int num3 = 0;
			while (num3 < capability.NbInputChannels)
			{
				bufferInfos[num2].isInput = true;
				bufferInfos[num2].channelNum = num3;
				bufferInfos[num2].pBuffer0 = IntPtr.Zero;
				bufferInfos[num2].pBuffer1 = IntPtr.Zero;
				num3++;
				num2++;
			}
			int num4 = 0;
			while (num4 < capability.NbOutputChannels)
			{
				bufferInfos[num2].isInput = false;
				bufferInfos[num2].channelNum = num4;
				bufferInfos[num2].pBuffer0 = IntPtr.Zero;
				bufferInfos[num2].pBuffer1 = IntPtr.Zero;
				num4++;
				num2++;
			}
			if (useMaxBufferSize)
			{
				bufferSize = capability.BufferMaxSize;
			}
			else
			{
				bufferSize = capability.BufferPreferredSize;
			}
			fixed (AsioBufferInfo* value = &bufferInfos[0])
			{
				IntPtr intPtr = new IntPtr(value);
				driver.CreateBuffers(intPtr, num, bufferSize, ref callbacks);
			}
			isOutputReadySupported = driver.OutputReady() == AsioError.ASE_OK;
			return bufferSize;
		}

		/// <summary>
		/// Builds the capabilities internally.
		/// </summary>
		private void BuildCapabilities()
		{
			capability = new AsioDriverCapability();
			capability.DriverName = driver.GetDriverName();
			driver.GetChannels(out capability.NbInputChannels, out capability.NbOutputChannels);
			capability.InputChannelInfos = new AsioChannelInfo[capability.NbInputChannels];
			capability.OutputChannelInfos = new AsioChannelInfo[capability.NbOutputChannels];
			for (int i = 0; i < capability.NbInputChannels; i++)
			{
				capability.InputChannelInfos[i] = driver.GetChannelInfo(i, trueForInputInfo: true);
			}
			for (int j = 0; j < capability.NbOutputChannels; j++)
			{
				capability.OutputChannelInfos[j] = driver.GetChannelInfo(j, trueForInputInfo: false);
			}
			capability.SampleRate = driver.GetSampleRate();
			AsioError latencies = driver.GetLatencies(out capability.InputLatency, out capability.OutputLatency);
			if (latencies != 0 && latencies != AsioError.ASE_NotPresent)
			{
				throw new AsioException("ASIOgetLatencies")
				{
					Error = latencies
				};
			}
			driver.GetBufferSize(out capability.BufferMinSize, out capability.BufferMaxSize, out capability.BufferPreferredSize, out capability.BufferGranularity);
		}

		/// <summary>
		/// Callback called by the AsioDriver on fill buffer demand. Redirect call to external callback.
		/// </summary>
		/// <param name="doubleBufferIndex">Index of the double buffer.</param>
		/// <param name="directProcess">if set to <c>true</c> [direct process].</param>
		private void BufferSwitchCallBack(int doubleBufferIndex, bool directProcess)
		{
			for (int i = 0; i < numberOfInputChannels; i++)
			{
				currentInputBuffers[i] = bufferInfos[i + inputChannelOffset].Buffer(doubleBufferIndex);
			}
			for (int j = 0; j < numberOfOutputChannels; j++)
			{
				currentOutputBuffers[j] = bufferInfos[j + outputChannelOffset + capability.NbInputChannels].Buffer(doubleBufferIndex);
			}
			fillBufferCallback?.Invoke(currentInputBuffers, currentOutputBuffers);
			if (isOutputReadySupported)
			{
				driver.OutputReady();
			}
		}

		/// <summary>
		/// Callback called by the AsioDriver on event "Samples rate changed".
		/// </summary>
		/// <param name="sRate">The sample rate.</param>
		private void SampleRateDidChangeCallBack(double sRate)
		{
			capability.SampleRate = sRate;
		}

		/// <summary>
		/// Asio message call back.
		/// </summary>
		/// <param name="selector">The selector.</param>
		/// <param name="value">The value.</param>
		/// <param name="message">The message.</param>
		/// <param name="opt">The opt.</param>
		/// <returns></returns>
		private int AsioMessageCallBack(AsioMessageSelector selector, int value, IntPtr message, IntPtr opt)
		{
			switch (selector)
			{
			case AsioMessageSelector.kAsioSelectorSupported:
				switch ((AsioMessageSelector)Enum.ToObject(typeof(AsioMessageSelector), value))
				{
				case AsioMessageSelector.kAsioEngineVersion:
					return 1;
				case AsioMessageSelector.kAsioResetRequest:
					ResetRequestCallback?.Invoke();
					return 0;
				case AsioMessageSelector.kAsioBufferSizeChange:
					return 0;
				case AsioMessageSelector.kAsioResyncRequest:
					return 0;
				case AsioMessageSelector.kAsioLatenciesChanged:
					return 0;
				case AsioMessageSelector.kAsioSupportsTimeInfo:
					return 0;
				case AsioMessageSelector.kAsioSupportsTimeCode:
					return 0;
				}
				break;
			case AsioMessageSelector.kAsioEngineVersion:
				return 2;
			case AsioMessageSelector.kAsioResetRequest:
				ResetRequestCallback?.Invoke();
				return 1;
			case AsioMessageSelector.kAsioBufferSizeChange:
				return 0;
			case AsioMessageSelector.kAsioResyncRequest:
				return 0;
			case AsioMessageSelector.kAsioLatenciesChanged:
				return 0;
			case AsioMessageSelector.kAsioSupportsTimeInfo:
				return 0;
			case AsioMessageSelector.kAsioSupportsTimeCode:
				return 0;
			}
			return 0;
		}

		/// <summary>
		/// Buffers switch time info call back.
		/// </summary>
		/// <param name="asioTimeParam">The asio time param.</param>
		/// <param name="doubleBufferIndex">Index of the double buffer.</param>
		/// <param name="directProcess">if set to <c>true</c> [direct process].</param>
		/// <returns></returns>
		private IntPtr BufferSwitchTimeInfoCallBack(IntPtr asioTimeParam, int doubleBufferIndex, bool directProcess)
		{
			return IntPtr.Zero;
		}
	}

	/// <summary>
	/// ASIO Error Codes
	/// </summary>
	public enum AsioError
	{
		/// <summary>
		/// This value will be returned whenever the call succeeded
		/// </summary>
		ASE_OK = 0,
		/// <summary>
		/// unique success return value for ASIOFuture calls
		/// </summary>
		ASE_SUCCESS = 1061701536,
		/// <summary>
		/// hardware input or output is not present or available
		/// </summary>
		ASE_NotPresent = -1000,
		/// <summary>
		/// hardware is malfunctioning (can be returned by any ASIO function)
		/// </summary>
		ASE_HWMalfunction = -999,
		/// <summary>
		/// input parameter invalid
		/// </summary>
		ASE_InvalidParameter = -998,
		/// <summary>
		/// hardware is in a bad mode or used in a bad mode
		/// </summary>
		ASE_InvalidMode = -997,
		/// <summary>
		/// hardware is not running when sample position is inquired
		/// </summary>
		ASE_SPNotAdvancing = -996,
		/// <summary>
		/// sample clock or rate cannot be determined or is not present
		/// </summary>
		ASE_NoClock = -995,
		/// <summary>
		/// not enough memory for completing the request
		/// </summary>
		ASE_NoMemory = -994
	}

	/// <summary>
	/// ASIO common Exception.
	/// </summary>
	internal class AsioException : Exception
	{
		private AsioError error;

		public AsioError Error
		{
			get
			{
				return error;
			}
			set
			{
				error = value;
				Data["ASIOError"] = error;
			}
		}

		public AsioException()
		{
		}

		public AsioException(string message)
			: base(message)
		{
		}

		public AsioException(string message, Exception innerException)
			: base(message, innerException)
		{
		}

		/// <summary>
		/// Gets the name of the error.
		/// </summary>
		/// <param name="error">The error.</param>
		/// <returns>the name of the error</returns>
		public static string getErrorName(AsioError error)
		{
			return Enum.GetName(typeof(AsioError), error);
		}
	}

	/// <summary>
	/// Callback used by the AsioDriverExt to get wave data
	/// </summary>
	public delegate void AsioFillBufferCallback(IntPtr[] inputChannels, IntPtr[] outputChannels);

	/// <summary>
	/// ASIO Message Selector
	/// </summary>
	public enum AsioMessageSelector
	{
		/// <summary>
		/// selector in &lt;value&gt;, returns 1L if supported,
		/// </summary>
		kAsioSelectorSupported = 1,
		/// <summary>
		/// returns engine (host) asio implementation version,
		/// </summary>
		kAsioEngineVersion,
		/// <summary>
		/// request driver reset. if accepted, this
		/// </summary>
		kAsioResetRequest,
		/// <summary>
		/// not yet supported, will currently always return 0L.
		/// </summary>
		kAsioBufferSizeChange,
		/// <summary>
		/// the driver went out of sync, such that
		/// </summary>
		kAsioResyncRequest,
		/// <summary>
		/// the drivers latencies have changed. The engine
		/// </summary>
		kAsioLatenciesChanged,
		/// <summary>
		/// if host returns true here, it will expect the
		/// </summary>
		kAsioSupportsTimeInfo,
		/// <summary>
		/// supports timecode
		/// </summary>
		kAsioSupportsTimeCode,
		/// <summary>
		/// unused - value: number of commands, message points to mmc commands
		/// </summary>
		kAsioMMCCommand,
		/// <summary>
		/// kAsioSupportsXXX return 1 if host supports this
		/// </summary>
		kAsioSupportsInputMonitor,
		/// <summary>
		/// unused and undefined
		/// </summary>
		kAsioSupportsInputGain,
		/// <summary>
		/// unused and undefined
		/// </summary>
		kAsioSupportsInputMeter,
		/// <summary>
		/// unused and undefined
		/// </summary>
		kAsioSupportsOutputGain,
		/// <summary>
		/// unused and undefined
		/// </summary>
		kAsioSupportsOutputMeter,
		/// <summary>
		/// driver detected an overload
		/// </summary>
		kAsioOverload
	}

	/// <summary>
	/// This class stores convertors for different interleaved WaveFormat to ASIOSampleType separate channel
	/// format.
	/// </summary>
	internal class AsioSampleConvertor
	{
		public delegate void SampleConvertor(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples);

		/// <summary>
		/// Selects the sample convertor based on the input WaveFormat and the output ASIOSampleTtype.
		/// </summary>
		/// <param name="waveFormat">The wave format.</param>
		/// <param name="asioType">The type.</param>
		/// <returns></returns>
		public static SampleConvertor SelectSampleConvertor(WaveFormat waveFormat, AsioSampleType asioType)
		{
			SampleConvertor result = null;
			bool flag = waveFormat.Channels == 2;
			switch (asioType)
			{
			case AsioSampleType.Int32LSB:
				switch (waveFormat.BitsPerSample)
				{
				case 16:
					result = (flag ? new SampleConvertor(ConvertorShortToInt2Channels) : new SampleConvertor(ConvertorShortToIntGeneric));
					break;
				case 32:
					result = ((waveFormat.Encoding != WaveFormatEncoding.IeeeFloat) ? (flag ? new SampleConvertor(ConvertorIntToInt2Channels) : new SampleConvertor(ConvertorIntToIntGeneric)) : (flag ? new SampleConvertor(ConvertorFloatToInt2Channels) : new SampleConvertor(ConvertorFloatToIntGeneric)));
					break;
				}
				break;
			case AsioSampleType.Int16LSB:
				switch (waveFormat.BitsPerSample)
				{
				case 16:
					result = (flag ? new SampleConvertor(ConvertorShortToShort2Channels) : new SampleConvertor(ConvertorShortToShortGeneric));
					break;
				case 32:
					result = ((waveFormat.Encoding != WaveFormatEncoding.IeeeFloat) ? (flag ? new SampleConvertor(ConvertorIntToShort2Channels) : new SampleConvertor(ConvertorIntToShortGeneric)) : (flag ? new SampleConvertor(ConvertorFloatToShort2Channels) : new SampleConvertor(ConvertorFloatToShortGeneric)));
					break;
				}
				break;
			case AsioSampleType.Int24LSB:
				switch (waveFormat.BitsPerSample)
				{
				case 16:
					throw new ArgumentException("Not a supported conversion");
				case 32:
					if (waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
					{
						result = ConverterFloatTo24LSBGeneric;
						break;
					}
					throw new ArgumentException("Not a supported conversion");
				}
				break;
			case AsioSampleType.Float32LSB:
				switch (waveFormat.BitsPerSample)
				{
				case 16:
					throw new ArgumentException("Not a supported conversion");
				case 32:
					result = ((waveFormat.Encoding != WaveFormatEncoding.IeeeFloat) ? new SampleConvertor(ConvertorIntToFloatGeneric) : new SampleConvertor(ConverterFloatToFloatGeneric));
					break;
				}
				break;
			default:
				throw new ArgumentException($"ASIO Buffer Type {Enum.GetName(typeof(AsioSampleType), asioType)} is not yet supported.");
			}
			return result;
		}

		/// <summary>
		/// Optimized convertor for 2 channels SHORT
		/// </summary>
		public unsafe static void ConvertorShortToInt2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			short* ptr = (short*)(void*)inputInterleavedBuffer;
			short* ptr2 = (short*)(void*)asioOutputBuffers[0];
			short* ptr3 = (short*)(void*)asioOutputBuffers[1];
			ptr2++;
			ptr3++;
			for (int i = 0; i < nbSamples; i++)
			{
				*ptr2 = *ptr;
				*ptr3 = ptr[1];
				ptr += 2;
				ptr2 += 2;
				ptr3 += 2;
			}
		}

		/// <summary>
		/// Generic convertor for SHORT
		/// </summary>
		public unsafe static void ConvertorShortToIntGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			short* ptr = (short*)(void*)inputInterleavedBuffer;
			short*[] array = new short*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (short*)(void*)asioOutputBuffers[i];
				int num = i;
				short* ptr2 = array[num];
				array[num] = ptr2 + 1;
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					*array[k] = *(ptr++);
					short*[] array2 = array;
					int num = k;
					array2[num] += 2;
				}
			}
		}

		/// <summary>
		/// Optimized convertor for 2 channels FLOAT
		/// </summary>
		public unsafe static void ConvertorFloatToInt2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			int* ptr2 = (int*)(void*)asioOutputBuffers[0];
			int* ptr3 = (int*)(void*)asioOutputBuffers[1];
			for (int i = 0; i < nbSamples; i++)
			{
				*(ptr2++) = clampToInt(*ptr);
				*(ptr3++) = clampToInt(ptr[1]);
				ptr += 2;
			}
		}

		/// <summary>
		/// Generic convertor Float to INT
		/// </summary>
		public unsafe static void ConvertorFloatToIntGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			int*[] array = new int*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (int*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					int* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = clampToInt(*(ptr++));
				}
			}
		}

		/// <summary>
		/// Optimized convertor for 2 channels INT to INT
		/// </summary>
		public unsafe static void ConvertorIntToInt2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			int* ptr = (int*)(void*)inputInterleavedBuffer;
			int* ptr2 = (int*)(void*)asioOutputBuffers[0];
			int* ptr3 = (int*)(void*)asioOutputBuffers[1];
			for (int i = 0; i < nbSamples; i++)
			{
				*(ptr2++) = *ptr;
				*(ptr3++) = ptr[1];
				ptr += 2;
			}
		}

		/// <summary>
		/// Generic convertor INT to INT
		/// </summary>
		public unsafe static void ConvertorIntToIntGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			int* ptr = (int*)(void*)inputInterleavedBuffer;
			int*[] array = new int*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (int*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					int* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = *(ptr++);
				}
			}
		}

		/// <summary>
		/// Optimized convertor for 2 channels INT to SHORT
		/// </summary>
		public unsafe static void ConvertorIntToShort2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			int* ptr = (int*)(void*)inputInterleavedBuffer;
			short* ptr2 = (short*)(void*)asioOutputBuffers[0];
			short* ptr3 = (short*)(void*)asioOutputBuffers[1];
			for (int i = 0; i < nbSamples; i++)
			{
				*(ptr2++) = (short)(*ptr / 65536);
				*(ptr3++) = (short)(ptr[1] / 65536);
				ptr += 2;
			}
		}

		/// <summary>
		/// Generic convertor INT to SHORT
		/// </summary>
		public unsafe static void ConvertorIntToShortGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			int* ptr = (int*)(void*)inputInterleavedBuffer;
			int*[] array = new int*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (int*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					int* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = (short)(*(ptr++) / 65536);
				}
			}
		}

		/// <summary>
		/// Generic convertor INT to FLOAT
		/// </summary>
		public unsafe static void ConvertorIntToFloatGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			int* ptr = (int*)(void*)inputInterleavedBuffer;
			float*[] array = new float*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (float*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					float* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = *(ptr++) / int.MinValue;
				}
			}
		}

		/// <summary>
		/// Optimized convertor for 2 channels SHORT
		/// </summary>
		public unsafe static void ConvertorShortToShort2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			short* ptr = (short*)(void*)inputInterleavedBuffer;
			short* ptr2 = (short*)(void*)asioOutputBuffers[0];
			short* ptr3 = (short*)(void*)asioOutputBuffers[1];
			for (int i = 0; i < nbSamples; i++)
			{
				*(ptr2++) = *ptr;
				*(ptr3++) = ptr[1];
				ptr += 2;
			}
		}

		/// <summary>
		/// Generic convertor for SHORT
		/// </summary>
		public unsafe static void ConvertorShortToShortGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			short* ptr = (short*)(void*)inputInterleavedBuffer;
			short*[] array = new short*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (short*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					short* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = *(ptr++);
				}
			}
		}

		/// <summary>
		/// Optimized convertor for 2 channels FLOAT
		/// </summary>
		public unsafe static void ConvertorFloatToShort2Channels(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			short* ptr2 = (short*)(void*)asioOutputBuffers[0];
			short* ptr3 = (short*)(void*)asioOutputBuffers[1];
			for (int i = 0; i < nbSamples; i++)
			{
				*(ptr2++) = clampToShort(*ptr);
				*(ptr3++) = clampToShort(ptr[1]);
				ptr += 2;
			}
		}

		/// <summary>
		/// Generic convertor SHORT
		/// </summary>
		public unsafe static void ConvertorFloatToShortGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			short*[] array = new short*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (short*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					short* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = clampToShort(*(ptr++));
				}
			}
		}

		/// <summary>
		/// Generic converter 24 LSB
		/// </summary>
		public unsafe static void ConverterFloatTo24LSBGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			byte*[] array = new byte*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (byte*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = clampTo24Bit(*(ptr++));
					int num2 = k;
					*(array[num2]++) = (byte)num;
					num2 = k;
					*(array[num2]++) = (byte)(num >> 8);
					num2 = k;
					*(array[num2]++) = (byte)(num >> 16);
				}
			}
		}

		/// <summary>
		/// Generic convertor for float
		/// </summary>
		public unsafe static void ConverterFloatToFloatGeneric(IntPtr inputInterleavedBuffer, IntPtr[] asioOutputBuffers, int nbChannels, int nbSamples)
		{
			float* ptr = (float*)(void*)inputInterleavedBuffer;
			float*[] array = new float*[nbChannels];
			for (int i = 0; i < nbChannels; i++)
			{
				array[i] = (float*)(void*)asioOutputBuffers[i];
			}
			for (int j = 0; j < nbSamples; j++)
			{
				for (int k = 0; k < nbChannels; k++)
				{
					int num = k;
					float* ptr2 = array[num];
					array[num] = ptr2 + 1;
					*ptr2 = *(ptr++);
				}
			}
		}

		private static int clampTo24Bit(double sampleValue)
		{
			sampleValue = ((sampleValue < -1.0) ? (-1.0) : ((sampleValue > 1.0) ? 1.0 : sampleValue));
			return (int)(sampleValue * 8388607.0);
		}

		private static int clampToInt(double sampleValue)
		{
			sampleValue = ((sampleValue < -1.0) ? (-1.0) : ((sampleValue > 1.0) ? 1.0 : sampleValue));
			return (int)(sampleValue * 2147483647.0);
		}

		private static short clampToShort(double sampleValue)
		{
			sampleValue = ((sampleValue < -1.0) ? (-1.0) : ((sampleValue > 1.0) ? 1.0 : sampleValue));
			return (short)(sampleValue * 32767.0);
		}
	}

	/// <summary>
	/// ASIO Sample Type
	/// </summary>
	public enum AsioSampleType
	{
		/// <summary>
		/// Int 16 MSB
		/// </summary>
		Int16MSB = 0,
		/// <summary>
		/// Int 24 MSB (used for 20 bits as well)
		/// </summary>
		Int24MSB = 1,
		/// <summary>
		/// Int 32 MSB
		/// </summary>
		Int32MSB = 2,
		/// <summary>
		/// IEEE 754 32 bit float
		/// </summary>
		Float32MSB = 3,
		/// <summary>
		/// IEEE 754 64 bit double float
		/// </summary>
		Float64MSB = 4,
		/// <summary>
		/// 32 bit data with 16 bit alignment
		/// </summary>
		Int32MSB16 = 8,
		/// <summary>
		/// 32 bit data with 18 bit alignment
		/// </summary>
		Int32MSB18 = 9,
		/// <summary>
		/// 32 bit data with 20 bit alignment
		/// </summary>
		Int32MSB20 = 10,
		/// <summary>
		/// 32 bit data with 24 bit alignment
		/// </summary>
		Int32MSB24 = 11,
		/// <summary>
		/// Int 16 LSB
		/// </summary>
		Int16LSB = 16,
		/// <summary>
		/// Int 24 LSB
		/// used for 20 bits as well
		/// </summary>
		Int24LSB = 17,
		/// <summary>
		/// Int 32 LSB
		/// </summary>
		Int32LSB = 18,
		/// <summary>
		/// IEEE 754 32 bit float, as found on Intel x86 architecture
		/// </summary>
		Float32LSB = 19,
		/// <summary>
		/// IEEE 754 64 bit double float, as found on Intel x86 architecture
		/// </summary>
		Float64LSB = 20,
		/// <summary>
		/// 32 bit data with 16 bit alignment
		/// </summary>
		Int32LSB16 = 24,
		/// <summary>
		/// 32 bit data with 18 bit alignment
		/// </summary>
		Int32LSB18 = 25,
		/// <summary>
		/// 32 bit data with 20 bit alignment
		/// </summary>
		Int32LSB20 = 26,
		/// <summary>
		/// 32 bit data with 24 bit alignment
		/// </summary>
		Int32LSB24 = 27,
		/// <summary>
		/// DSD 1 bit data, 8 samples per byte. First sample in Least significant bit.
		/// </summary>
		DSDInt8LSB1 = 32,
		/// <summary>
		/// DSD 1 bit data, 8 samples per byte. First sample in Most significant bit.
		/// </summary>
		DSDInt8MSB1 = 33,
		/// <summary>
		/// DSD 8 bit data, 1 sample per byte. No Endianness required.
		/// </summary>
		DSDInt8NER8 = 40
	}

	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	internal struct AsioTime
	{
		public int reserved1;

		public int reserved2;

		public int reserved3;

		public int reserved4;

		public AsioTimeInfo timeInfo;

		public AsioTimeCode timeCode;
	}

	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	internal struct AsioTimeCode
	{
		public double speed;

		public Asio64Bit timeCodeSamples;

		public AsioTimeCodeFlags flags;

		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 64)]
		public string future;
	}

	[Flags]
	internal enum AsioTimeCodeFlags
	{
		kTcValid = 1,
		kTcRunning = 2,
		kTcReverse = 4,
		kTcOnspeed = 8,
		kTcStill = 0x10,
		kTcSpeedValid = 0x100
	}

	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	internal struct AsioTimeInfo
	{
		public double speed;

		public Asio64Bit systemTime;

		public Asio64Bit samplePosition;

		public double sampleRate;

		public AsioTimeInfoFlags flags;

		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 12)]
		public string reserved;
	}

	[Flags]
	internal enum AsioTimeInfoFlags
	{
		kSystemTimeValid = 1,
		kSamplePositionValid = 2,
		kSampleRateValid = 4,
		kSpeedValid = 8,
		kSampleRateChanged = 0x10,
		kClockSourceChanged = 0x20
	}
}

namespace NAudio
{
	/// <summary>
	/// Manufacturer codes from mmreg.h
	/// </summary>
	public enum Manufacturers
	{
		/// <summary>Microsoft Corporation</summary>
		Microsoft = 1,
		/// <summary>Creative Labs, Inc</summary>
		Creative = 2,
		/// <summary>Media Vision, Inc.</summary>
		Mediavision = 3,
		/// <summary>Fujitsu Corp.</summary>
		Fujitsu = 4,
		/// <summary>Artisoft, Inc.</summary>
		Artisoft = 20,
		/// <summary>Turtle Beach, Inc.</summary>
		TurtleBeach = 21,
		/// <summary>IBM Corporation</summary>
		Ibm = 22,
		/// <summary>Vocaltec LTD.</summary>
		Vocaltec = 23,
		/// <summary>Roland</summary>
		Roland = 24,
		/// <summary>DSP Solutions, Inc.</summary>
		DspSolutions = 25,
		/// <summary>NEC</summary>
		Nec = 26,
		/// <summary>ATI</summary>
		Ati = 27,
		/// <summary>Wang Laboratories, Inc</summary>
		Wanglabs = 28,
		/// <summary>Tandy Corporation</summary>
		Tandy = 29,
		/// <summary>Voyetra</summary>
		Voyetra = 30,
		/// <summary>Antex Electronics Corporation</summary>
		Antex = 31,
		/// <summary>ICL Personal Systems</summary>
		IclPS = 32,
		/// <summary>Intel Corporation</summary>
		Intel = 33,
		/// <summary>Advanced Gravis</summary>
		Gravis = 34,
		/// <summary>Video Associates Labs, Inc.</summary>
		Val = 35,
		/// <summary>InterActive Inc</summary>
		Interactive = 36,
		/// <summary>Yamaha Corporation of America</summary>
		Yamaha = 37,
		/// <summary>Everex Systems, Inc</summary>
		Everex = 38,
		/// <summary>Echo Speech Corporation</summary>
		Echo = 39,
		/// <summary>Sierra Semiconductor Corp</summary>
		Sierra = 40,
		/// <summary>Computer Aided Technologies</summary>
		Cat = 41,
		/// <summary>APPS Software International</summary>
		Apps = 42,
		/// <summary>DSP Group, Inc</summary>
		DspGroup = 43,
		/// <summary>microEngineering Labs</summary>
		Melabs = 44,
		/// <summary>Computer Friends, Inc.</summary>
		ComputerFriends = 45,
		/// <summary>ESS Technology</summary>
		Ess = 46,
		/// <summary>Audio, Inc.</summary>
		Audiofile = 47,
		/// <summary>Motorola, Inc.</summary>
		Motorola = 48,
		/// <summary>Canopus, co., Ltd.</summary>
		Canopus = 49,
		/// <summary>Seiko Epson Corporation</summary>
		Epson = 50,
		/// <summary>Truevision</summary>
		Truevision = 51,
		/// <summary>Aztech Labs, Inc.</summary>
		Aztech = 52,
		/// <summary>Videologic</summary>
		Videologic = 53,
		/// <summary>SCALACS</summary>
		Scalacs = 54,
		/// <summary>Korg Inc.</summary>
		Korg = 55,
		/// <summary>Audio Processing Technology</summary>
		Apt = 56,
		/// <summary>Integrated Circuit Systems, Inc.</summary>
		Ics = 57,
		/// <summary>Iterated Systems, Inc.</summary>
		Iteratedsys = 58,
		/// <summary>Metheus</summary>
		Metheus = 59,
		/// <summary>Logitech, Inc.</summary>
		Logitech = 60,
		/// <summary>Winnov, Inc.</summary>
		Winnov = 61,
		/// <summary>NCR Corporation</summary>
		Ncr = 62,
		/// <summary>EXAN</summary>
		Exan = 63,
		/// <summary>AST Research Inc.</summary>
		Ast = 64,
		/// <summary>Willow Pond Corporation</summary>
		Willowpond = 65,
		/// <summary>Sonic Foundry</summary>
		Sonicfoundry = 66,
		/// <summary>Vitec Multimedia</summary>
		Vitec = 67,
		/// <summary>MOSCOM Corporation</summary>
		Moscom = 68,
		/// <summary>Silicon Soft, Inc.</summary>
		Siliconsoft = 69,
		/// <summary>Supermac</summary>
		Supermac = 73,
		/// <summary>Audio Processing Technology</summary>
		Audiopt = 74,
		/// <summary>Speech Compression</summary>
		Speechcomp = 76,
		/// <summary>Ahead, Inc.</summary>
		Ahead = 77,
		/// <summary>Dolby Laboratories</summary>
		Dolby = 78,
		/// <summary>OKI</summary>
		Oki = 79,
		/// <summary>AuraVision Corporation</summary>
		Auravision = 80,
		/// <summary>Ing C. Olivetti &amp; C., S.p.A.</summary>
		Olivetti = 81,
		/// <summary>I/O Magic Corporation</summary>
		Iomagic = 82,
		/// <summary>Matsushita Electric Industrial Co., LTD.</summary>
		Matsushita = 83,
		/// <summary>Control Resources Limited</summary>
		Controlres = 84,
		/// <summary>Xebec Multimedia Solutions Limited</summary>
		Xebec = 85,
		/// <summary>New Media Corporation</summary>
		Newmedia = 86,
		/// <summary>Natural MicroSystems</summary>
		Nms = 87,
		/// <summary>Lyrrus Inc.</summary>
		Lyrrus = 88,
		/// <summary>Compusic</summary>
		Compusic = 89,
		/// <summary>OPTi Computers Inc.</summary>
		Opti = 90,
		/// <summary>Adlib Accessories Inc.</summary>
		Adlacc = 91,
		/// <summary>Compaq Computer Corp.</summary>
		Compaq = 92,
		/// <summary>Dialogic Corporation</summary>
		Dialogic = 93,
		/// <summary>InSoft, Inc.</summary>
		Insoft = 94,
		/// <summary>M.P. Technologies, Inc.</summary>
		Mptus = 95,
		/// <summary>Weitek</summary>
		Weitek = 96,
		/// <summary>Lernout &amp; Hauspie</summary>
		LernoutAndHauspie = 97,
		/// <summary>Quanta Computer Inc.</summary>
		Qciar = 98,
		/// <summary>Apple Computer, Inc.</summary>
		Apple = 99,
		/// <summary>Digital Equipment Corporation</summary>
		Digital = 100,
		/// <summary>Mark of the Unicorn</summary>
		Motu = 101,
		/// <summary>Workbit Corporation</summary>
		Workbit = 102,
		/// <summary>Ositech Communications Inc.</summary>
		Ositech = 103,
		/// <summary>miro Computer Products AG</summary>
		Miro = 104,
		/// <summary>Cirrus Logic</summary>
		Cirruslogic = 105,
		/// <summary>ISOLUTION  B.V.</summary>
		Isolution = 106,
		/// <summary>Horizons Technology, Inc</summary>
		Horizons = 107,
		/// <summary>Computer Concepts Ltd</summary>
		Concepts = 108,
		/// <summary>Voice Technologies Group, Inc.</summary>
		Vtg = 109,
		/// <summary>Radius</summary>
		Radius = 110,
		/// <summary>Rockwell International</summary>
		Rockwell = 111,
		/// <summary>Co. XYZ for testing</summary>
		Xyz = 112,
		/// <summary>Opcode Systems</summary>
		Opcode = 113,
		/// <summary>Voxware Inc</summary>
		Voxware = 114,
		/// <summary>Northern Telecom Limited</summary>
		NorthernTelecom = 115,
		/// <summary>APICOM</summary>
		Apicom = 116,
		/// <summary>Grande Software</summary>
		Grande = 117,
		/// <summary>ADDX</summary>
		Addx = 118,
		/// <summary>Wildcat Canyon Software</summary>
		Wildcat = 119,
		/// <summary>Rhetorex Inc</summary>
		Rhetorex = 120,
		/// <summary>Brooktree Corporation</summary>
		Brooktree = 121,
		/// <summary>ENSONIQ Corporation</summary>
		Ensoniq = 125,
		/// <summary>FAST Multimedia AG</summary>
		Fast = 126,
		/// <summary>NVidia Corporation</summary>
		Nvidia = 127,
		/// <summary>OKSORI Co., Ltd.</summary>
		Oksori = 128,
		/// <summary>DiAcoustics, Inc.</summary>
		Diacoustics = 129,
		/// <summary>Gulbransen, Inc.</summary>
		Gulbransen = 130,
		/// <summary>Kay Elemetrics, Inc.</summary>
		KayElemetrics = 131,
		/// <summary>Crystal Semiconductor Corporation</summary>
		Crystal = 132,
		/// <summary>Splash Studios</summary>
		SplashStudios = 133,
		/// <summary>Quarterdeck Corporation</summary>
		Quarterdeck = 134,
		/// <summary>TDK Corporation</summary>
		Tdk = 135,
		/// <summary>Digital Audio Labs, Inc.</summary>
		DigitalAudioLabs = 136,
		/// <summary>Seer Systems, Inc.</summary>
		Seersys = 137,
		/// <summary>PictureTel Corporation</summary>
		Picturetel = 138,
		/// <summary>AT&amp;T Microelectronics</summary>
		AttMicroelectronics = 139,
		/// <summary>Osprey Technologies, Inc.</summary>
		Osprey = 140,
		/// <summary>Mediatrix Peripherals</summary>
		Mediatrix = 141,
		/// <summary>SounDesignS M.C.S. Ltd.</summary>
		Soundesigns = 142,
		/// <summary>A.L. Digital Ltd.</summary>
		Aldigital = 143,
		/// <summary>Spectrum Signal Processing, Inc.</summary>
		SpectrumSignalProcessing = 144,
		/// <summary>Electronic Courseware Systems, Inc.</summary>
		Ecs = 145,
		/// <summary>AMD</summary>
		Amd = 146,
		/// <summary>Core Dynamics</summary>
		Coredynamics = 147,
		/// <summary>CANAM Computers</summary>
		Canam = 148,
		/// <summary>Softsound, Ltd.</summary>
		Softsound = 149,
		/// <summary>Norris Communications, Inc.</summary>
		Norris = 150,
		/// <summary>Danka Data Devices</summary>
		Ddd = 151,
		/// <summary>EuPhonics</summary>
		Euphonics = 152,
		/// <summary>Precept Software, Inc.</summary>
		Precept = 153,
		/// <summary>Crystal Net Corporation</summary>
		CrystalNet = 154,
		/// <summary>Chromatic Research, Inc</summary>
		Chromatic = 155,
		/// <summary>Voice Information Systems, Inc</summary>
		Voiceinfo = 156,
		/// <summary>Vienna Systems</summary>
		Viennasys = 157,
		/// <summary>Connectix Corporation</summary>
		Connectix = 158,
		/// <summary>Gadget Labs LLC</summary>
		Gadgetlabs = 159,
		/// <summary>Frontier Design Group LLC</summary>
		Frontier = 160,
		/// <summary>Viona Development GmbH</summary>
		Viona = 161,
		/// <summary>Casio Computer Co., LTD</summary>
		Casio = 162,
		/// <summary>Diamond Multimedia</summary>
		Diamondmm = 163,
		/// <summary>S3</summary>
		S3 = 164,
		/// <summary>Fraunhofer</summary>
		FraunhoferIis = 172
	}

	/// <summary>
	/// Summary description for MmException.
	/// </summary>
	public class MmException : Exception
	{
		/// <summary>
		/// Returns the Windows API result
		/// </summary>
		public MmResult Result { get; }

		/// <summary>
		/// The function being called
		/// </summary>
		public string Function { get; }

		/// <summary>
		/// Creates a new MmException
		/// </summary>
		/// <param name="result">The result returned by the Windows API call</param>
		/// <param name="function">The name of the Windows API that failed</param>
		public MmException(MmResult result, string function)
			: base(ErrorMessage(result, function))
		{
			Result = result;
			Function = function;
		}

		private static string ErrorMessage(MmResult result, string function)
		{
			return $"{result} calling {function}";
		}

		/// <summary>
		/// Helper function to automatically raise an exception on failure
		/// </summary>
		/// <param name="result">The result of the API call</param>
		/// <param name="function">The API function name</param>
		public static void Try(MmResult result, string function)
		{
			if (result != 0)
			{
				throw new MmException(result, function);
			}
		}
	}

	/// <summary>
	/// Windows multimedia error codes from mmsystem.h.
	/// </summary>
	public enum MmResult
	{
		/// <summary>no error, MMSYSERR_NOERROR</summary>
		NoError = 0,
		/// <summary>unspecified error, MMSYSERR_ERROR</summary>
		UnspecifiedError = 1,
		/// <summary>device ID out of range, MMSYSERR_BADDEVICEID</summary>
		BadDeviceId = 2,
		/// <summary>driver failed enable, MMSYSERR_NOTENABLED</summary>
		NotEnabled = 3,
		/// <summary>device already allocated, MMSYSERR_ALLOCATED</summary>
		AlreadyAllocated = 4,
		/// <summary>device handle is invalid, MMSYSERR_INVALHANDLE</summary>
		InvalidHandle = 5,
		/// <summary>no device driver present, MMSYSERR_NODRIVER</summary>
		NoDriver = 6,
		/// <summary>memory allocation error, MMSYSERR_NOMEM</summary>
		MemoryAllocationError = 7,
		/// <summary>function isn't supported, MMSYSERR_NOTSUPPORTED</summary>
		NotSupported = 8,
		/// <summary>error value out of range, MMSYSERR_BADERRNUM</summary>
		BadErrorNumber = 9,
		/// <summary>invalid flag passed, MMSYSERR_INVALFLAG</summary>
		InvalidFlag = 10,
		/// <summary>invalid parameter passed, MMSYSERR_INVALPARAM</summary>
		InvalidParameter = 11,
		/// <summary>handle being used simultaneously on another thread (eg callback),MMSYSERR_HANDLEBUSY</summary>
		HandleBusy = 12,
		/// <summary>specified alias not found, MMSYSERR_INVALIDALIAS</summary>
		InvalidAlias = 13,
		/// <summary>bad registry database, MMSYSERR_BADDB</summary>
		BadRegistryDatabase = 14,
		/// <summary>registry key not found, MMSYSERR_KEYNOTFOUND</summary>
		RegistryKeyNotFound = 15,
		/// <summary>registry read error, MMSYSERR_READERROR</summary>
		RegistryReadError = 16,
		/// <summary>registry write error, MMSYSERR_WRITEERROR</summary>
		RegistryWriteError = 17,
		/// <summary>registry delete error, MMSYSERR_DELETEERROR</summary>
		RegistryDeleteError = 18,
		/// <summary>registry value not found, MMSYSERR_VALNOTFOUND</summary>
		RegistryValueNotFound = 19,
		/// <summary>driver does not call DriverCallback, MMSYSERR_NODRIVERCB</summary>
		NoDriverCallback = 20,
		/// <summary>more data to be returned, MMSYSERR_MOREDATA</summary>
		MoreData = 21,
		/// <summary>unsupported wave format, WAVERR_BADFORMAT</summary>
		WaveBadFormat = 32,
		/// <summary>still something playing, WAVERR_STILLPLAYING</summary>
		WaveStillPlaying = 33,
		/// <summary>header not prepared, WAVERR_UNPREPARED</summary>
		WaveHeaderUnprepared = 34,
		/// <summary>device is synchronous, WAVERR_SYNC</summary>
		WaveSync = 35,
		/// <summary>Conversion not possible (ACMERR_NOTPOSSIBLE)</summary>
		AcmNotPossible = 512,
		/// <summary>Busy (ACMERR_BUSY)</summary>
		AcmBusy = 513,
		/// <summary>Header Unprepared (ACMERR_UNPREPARED)</summary>
		AcmHeaderUnprepared = 514,
		/// <summary>Cancelled (ACMERR_CANCELED)</summary>
		AcmCancelled = 515,
		/// <summary>invalid line (MIXERR_INVALLINE)</summary>
		MixerInvalidLine = 1024,
		/// <summary>invalid control (MIXERR_INVALCONTROL)</summary>
		MixerInvalidControl = 1025,
		/// <summary>invalid value (MIXERR_INVALVALUE)</summary>
		MixerInvalidValue = 1026
	}
}

namespace NAudio.Codecs
{
	/// <summary>
	/// a-law decoder
	/// based on code from:
	/// http://hazelware.luggle.com/tutorials/mulawcompression.html
	/// </summary>
	public class ALawDecoder
	{
		/// <summary>
		/// only 512 bytes required, so just use a lookup
		/// </summary>
		private static readonly short[] ALawDecompressTable = new short[256]
		{
			-5504, -5248, -6016, -5760, -4480, -4224, -4992, -4736, -7552, -7296,
			-8064, -7808, -6528, -6272, -7040, -6784, -2752, -2624, -3008, -2880,
			-2240, -2112, -2496, -2368, -3776, -3648, -4032, -3904, -3264, -3136,
			-3520, -3392, -22016, -20992, -24064, -23040, -17920, -16896, -19968, -18944,
			-30208, -29184, -32256, -31232, -26112, -25088, -28160, -27136, -11008, -10496,
			-12032, -11520, -8960, -8448, -9984, -9472, -15104, -14592, -16128, -15616,
			-13056, -12544, -14080, -13568, -344, -328, -376, -360, -280, -264,
			-312, -296, -472, -456, -504, -488, -408, -392, -440, -424,
			-88, -72, -120, -104, -24, -8, -56, -40, -216, -200,
			-248, -232, -152, -136, -184, -168, -1376, -1312, -1504, -1440,
			-1120, -1056, -1248, -1184, -1888, -1824, -2016, -1952, -1632, -1568,
			-1760, -1696, -688, -656, -752, -720, -560, -528, -624, -592,
			-944, -912, -1008, -976, -816, -784, -880, -848, 5504, 5248,
			6016, 5760, 4480, 4224, 4992, 4736, 7552, 7296, 8064, 7808,
			6528, 6272, 7040, 6784, 2752, 2624, 3008, 2880, 2240, 2112,
			2496, 2368, 3776, 3648, 4032, 3904, 3264, 3136, 3520, 3392,
			22016, 20992, 24064, 23040, 17920, 16896, 19968, 18944, 30208, 29184,
			32256, 31232, 26112, 25088, 28160, 27136, 11008, 10496, 12032, 11520,
			8960, 8448, 9984, 9472, 15104, 14592, 16128, 15616, 13056, 12544,
			14080, 13568, 344, 328, 376, 360, 280, 264, 312, 296,
			472, 456, 504, 488, 408, 392, 440, 424, 88, 72,
			120, 104, 24, 8, 56, 40, 216, 200, 248, 232,
			152, 136, 184, 168, 1376, 1312, 1504, 1440, 1120, 1056,
			1248, 1184, 1888, 1824, 2016, 1952, 1632, 1568, 1760, 1696,
			688, 656, 752, 720, 560, 528, 624, 592, 944, 912,
			1008, 976, 816, 784, 880, 848
		};

		/// <summary>
		/// Converts an a-law encoded byte to a 16 bit linear sample
		/// </summary>
		/// <param name="aLaw">a-law encoded byte</param>
		/// <returns>Linear sample</returns>
		public static short ALawToLinearSample(byte aLaw)
		{
			return ALawDecompressTable[aLaw];
		}
	}

	/// <summary>
	/// A-law encoder
	/// </summary>
	public static class ALawEncoder
	{
		private const int cBias = 132;

		private const int cClip = 32635;

		private static readonly byte[] ALawCompressTable = new byte[128]
		{
			1, 1, 2, 2, 3, 3, 3, 3, 4, 4,
			4, 4, 4, 4, 4, 4, 5, 5, 5, 5,
			5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
			5, 5, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7
		};

		/// <summary>
		/// Encodes a single 16 bit sample to a-law
		/// </summary>
		/// <param name="sample">16 bit PCM sample</param>
		/// <returns>a-law encoded byte</returns>
		public static byte LinearToALawSample(short sample)
		{
			int num = (~sample >> 8) & 0x80;
			if (num == 0)
			{
				sample = (short)(-sample);
			}
			if (sample > 32635)
			{
				sample = 32635;
			}
			byte b;
			if (sample >= 256)
			{
				int num2 = ALawCompressTable[(sample >> 8) & 0x7F];
				int num3 = (sample >> num2 + 3) & 0xF;
				b = (byte)((num2 << 4) | num3);
			}
			else
			{
				b = (byte)(sample >> 4);
			}
			return (byte)(b ^ (byte)((uint)num ^ 0x55u));
		}
	}

	/// <summary>
	/// Band data for G722 Codec
	/// </summary>
	public class Band
	{
		/// <summary>s</summary>
		public int s;

		/// <summary>sp</summary>
		public int sp;

		/// <summary>sz</summary>
		public int sz;

		/// <summary>r</summary>
		public int[] r = new int[3];

		/// <summary>a</summary>
		public int[] a = new int[3];

		/// <summary>ap</summary>
		public int[] ap = new int[3];

		/// <summary>p</summary>
		public int[] p = new int[3];

		/// <summary>d</summary>
		public int[] d = new int[7];

		/// <summary>b</summary>
		public int[] b = new int[7];

		/// <summary>bp</summary>
		public int[] bp = new int[7];

		/// <summary>sg</summary>
		public int[] sg = new int[7];

		/// <summary>nb</summary>
		public int nb;

		/// <summary>det</summary>
		public int det;
	}

	/// <summary>
	/// SpanDSP - a series of DSP components for telephony
	///
	/// g722_decode.c - The ITU G.722 codec, decode part.
	///
	/// Written by Steve Underwood &lt;steveu@coppice.org&gt;
	///
	/// Copyright (C) 2005 Steve Underwood
	/// Ported to C# by Mark Heath 2011
	///
	/// Despite my general liking of the GPL, I place my own contributions 
	/// to this code in the public domain for the benefit of all mankind -
	/// even the slimy ones who might try to proprietize my work and use it
	/// to my detriment.
	///
	/// Based in part on a single channel G.722 codec which is:
	/// Copyright (c) CMU 1993
	/// Computer Science, Speech Group
	/// Chengxiang Lu and Alex Hauptmann
	/// </summary>
	public class G722Codec
	{
		private static readonly int[] wl = new int[8] { -60, -30, 58, 172, 334, 538, 1198, 3042 };

		private static readonly int[] rl42 = new int[16]
		{
			0, 7, 6, 5, 4, 3, 2, 1, 7, 6,
			5, 4, 3, 2, 1, 0
		};

		private static readonly int[] ilb = new int[32]
		{
			2048, 2093, 2139, 2186, 2233, 2282, 2332, 2383, 2435, 2489,
			2543, 2599, 2656, 2714, 2774, 2834, 2896, 2960, 3025, 3091,
			3158, 3228, 3298, 3371, 3444, 3520, 3597, 3676, 3756, 3838,
			3922, 4008
		};

		private static readonly int[] wh = new int[3] { 0, -214, 798 };

		private static readonly int[] rh2 = new int[4] { 2, 1, 2, 1 };

		private static readonly int[] qm2 = new int[4] { -7408, -1616, 7408, 1616 };

		private static readonly int[] qm4 = new int[16]
		{
			0, -20456, -12896, -8968, -6288, -4240, -2584, -1200, 20456, 12896,
			8968, 6288, 4240, 2584, 1200, 0
		};

		private static readonly int[] qm5 = new int[32]
		{
			-280, -280, -23352, -17560, -14120, -11664, -9752, -8184, -6864, -5712,
			-4696, -3784, -2960, -2208, -1520, -880, 23352, 17560, 14120, 11664,
			9752, 8184, 6864, 5712, 4696, 3784, 2960, 2208, 1520, 880,
			280, -280
		};

		private static readonly int[] qm6 = new int[64]
		{
			-136, -136, -136, -136, -24808, -21904, -19008, -16704, -14984, -13512,
			-12280, -11192, -10232, -9360, -8576, -7856, -7192, -6576, -6000, -5456,
			-4944, -4464, -4008, -3576, -3168, -2776, -2400, -2032, -1688, -1360,
			-1040, -728, 24808, 21904, 19008, 16704, 14984, 13512, 12280, 11192,
			10232, 9360, 8576, 7856, 7192, 6576, 6000, 5456, 4944, 4464,
			4008, 3576, 3168, 2776, 2400, 2032, 1688, 1360, 1040, 728,
			432, 136, -432, -136
		};

		private static readonly int[] qmf_coeffs = new int[12]
		{
			3, -11, 12, 32, -210, 951, 3876, -805, 362, -156,
			53, -11
		};

		private static readonly int[] q6 = new int[32]
		{
			0, 35, 72, 110, 150, 190, 233, 276, 323, 370,
			422, 473, 530, 587, 650, 714, 786, 858, 940, 1023,
			1121, 1219, 1339, 1458, 1612, 1765, 1980, 2195, 2557, 2919,
			0, 0
		};

		private static readonly int[] iln = new int[32]
		{
			0, 63, 62, 31, 30, 29, 28, 27, 26, 25,
			24, 23, 22, 21, 20, 19, 18, 17, 16, 15,
			14, 13, 12, 11, 10, 9, 8, 7, 6, 5,
			4, 0
		};

		private static readonly int[] ilp = new int[32]
		{
			0, 61, 60, 59, 58, 57, 56, 55, 54, 53,
			52, 51, 50, 49, 48, 47, 46, 45, 44, 43,
			42, 41, 40, 39, 38, 37, 36, 35, 34, 33,
			32, 0
		};

		private static readonly int[] ihn = new int[3] { 0, 1, 0 };

		private static readonly int[] ihp = new int[3] { 0, 3, 2 };

		/// <summary>
		/// hard limits to 16 bit samples
		/// </summary>
		private static short Saturate(int amp)
		{
			short num = (short)amp;
			if (amp == num)
			{
				return num;
			}
			if (amp > 32767)
			{
				return short.MaxValue;
			}
			return short.MinValue;
		}

		private static void Block4(G722CodecState s, int band, int d)
		{
			s.Band[band].d[0] = d;
			s.Band[band].r[0] = Saturate(s.Band[band].s + d);
			s.Band[band].p[0] = Saturate(s.Band[band].sz + d);
			for (int i = 0; i < 3; i++)
			{
				s.Band[band].sg[i] = s.Band[band].p[i] >> 15;
			}
			int num = Saturate(s.Band[band].a[1] << 2);
			int num2 = ((s.Band[band].sg[0] == s.Band[band].sg[1]) ? (-num) : num);
			if (num2 > 32767)
			{
				num2 = 32767;
			}
			int num3 = ((s.Band[band].sg[0] == s.Band[band].sg[2]) ? 128 : (-128));
			num3 += num2 >> 7;
			num3 += s.Band[band].a[2] * 32512 >> 15;
			if (num3 > 12288)
			{
				num3 = 12288;
			}
			else if (num3 < -12288)
			{
				num3 = -12288;
			}
			s.Band[band].ap[2] = num3;
			s.Band[band].sg[0] = s.Band[band].p[0] >> 15;
			s.Band[band].sg[1] = s.Band[band].p[1] >> 15;
			num = ((s.Band[band].sg[0] == s.Band[band].sg[1]) ? 192 : (-192));
			num2 = s.Band[band].a[1] * 32640 >> 15;
			s.Band[band].ap[1] = Saturate(num + num2);
			num3 = Saturate(15360 - s.Band[band].ap[2]);
			if (s.Band[band].ap[1] > num3)
			{
				s.Band[band].ap[1] = num3;
			}
			else if (s.Band[band].ap[1] < -num3)
			{
				s.Band[band].ap[1] = -num3;
			}
			num = ((d != 0) ? 128 : 0);
			s.Band[band].sg[0] = d >> 15;
			for (int i = 1; i < 7; i++)
			{
				s.Band[band].sg[i] = s.Band[band].d[i] >> 15;
				num2 = ((s.Band[band].sg[i] == s.Band[band].sg[0]) ? num : (-num));
				num3 = s.Band[band].b[i] * 32640 >> 15;
				s.Band[band].bp[i] = Saturate(num2 + num3);
			}
			for (int i = 6; i > 0; i--)
			{
				s.Band[band].d[i] = s.Band[band].d[i - 1];
				s.Band[band].b[i] = s.Band[band].bp[i];
			}
			for (int i = 2; i > 0; i--)
			{
				s.Band[band].r[i] = s.Band[band].r[i - 1];
				s.Band[band].p[i] = s.Band[band].p[i - 1];
				s.Band[band].a[i] = s.Band[band].ap[i];
			}
			num = Saturate(s.Band[band].r[1] + s.Band[band].r[1]);
			num = s.Band[band].a[1] * num >> 15;
			num2 = Saturate(s.Band[band].r[2] + s.Band[band].r[2]);
			num2 = s.Band[band].a[2] * num2 >> 15;
			s.Band[band].sp = Saturate(num + num2);
			s.Band[band].sz = 0;
			for (int i = 6; i > 0; i--)
			{
				num = Saturate(s.Band[band].d[i] + s.Band[band].d[i]);
				s.Band[band].sz += s.Band[band].b[i] * num >> 15;
			}
			s.Band[band].sz = Saturate(s.Band[band].sz);
			s.Band[band].s = Saturate(s.Band[band].sp + s.Band[band].sz);
		}

		/// <summary>
		/// Decodes a buffer of G722
		/// </summary>
		/// <param name="state">Codec state</param>
		/// <param name="outputBuffer">Output buffer (to contain decompressed PCM samples)</param>
		/// <param name="inputG722Data"></param>
		/// <param name="inputLength">Number of bytes in input G722 data to decode</param>
		/// <returns>Number of samples written into output buffer</returns>
		public int Decode(G722CodecState state, short[] outputBuffer, byte[] inputG722Data, int inputLength)
		{
			int result = 0;
			int num = 0;
			int num2 = 0;
			while (num2 < inputLength)
			{
				int num3;
				if (state.Packed)
				{
					if (state.InBits < state.BitsPerSample)
					{
						state.InBuffer |= (uint)(inputG722Data[num2++] << state.InBits);
						state.InBits += 8;
					}
					num3 = (int)state.InBuffer & ((1 << state.BitsPerSample) - 1);
					state.InBuffer >>= state.BitsPerSample;
					state.InBits -= state.BitsPerSample;
				}
				else
				{
					num3 = inputG722Data[num2++];
				}
				int num5;
				int num4;
				int num6;
				switch (state.BitsPerSample)
				{
				default:
					num4 = num3 & 0x3F;
					num5 = (num3 >> 6) & 3;
					num6 = qm6[num4];
					num4 >>= 2;
					break;
				case 7:
					num4 = num3 & 0x1F;
					num5 = (num3 >> 5) & 3;
					num6 = qm5[num4];
					num4 >>= 1;
					break;
				case 6:
					num4 = num3 & 0xF;
					num5 = (num3 >> 4) & 3;
					num6 = qm4[num4];
					break;
				}
				num6 = state.Band[0].det * num6 >> 15;
				int num7 = state.Band[0].s + num6;
				if (num7 > 16383)
				{
					num7 = 16383;
				}
				else if (num7 < -16384)
				{
					num7 = -16384;
				}
				num6 = qm4[num4];
				int d = state.Band[0].det * num6 >> 15;
				num6 = rl42[num4];
				num4 = state.Band[0].nb * 127 >> 7;
				num4 += wl[num6];
				if (num4 < 0)
				{
					num4 = 0;
				}
				else if (num4 > 18432)
				{
					num4 = 18432;
				}
				state.Band[0].nb = num4;
				num4 = (state.Band[0].nb >> 6) & 0x1F;
				num6 = 8 - (state.Band[0].nb >> 11);
				int num8 = ((num6 < 0) ? (ilb[num4] << -num6) : (ilb[num4] >> num6));
				state.Band[0].det = num8 << 2;
				Block4(state, 0, d);
				if (!state.EncodeFrom8000Hz)
				{
					num6 = qm2[num5];
					int num9 = state.Band[1].det * num6 >> 15;
					num = num9 + state.Band[1].s;
					if (num > 16383)
					{
						num = 16383;
					}
					else if (num < -16384)
					{
						num = -16384;
					}
					num6 = rh2[num5];
					num4 = state.Band[1].nb * 127 >> 7;
					num4 += wh[num6];
					if (num4 < 0)
					{
						num4 = 0;
					}
					else if (num4 > 22528)
					{
						num4 = 22528;
					}
					state.Band[1].nb = num4;
					num4 = (state.Band[1].nb >> 6) & 0x1F;
					num6 = 10 - (state.Band[1].nb >> 11);
					num8 = ((num6 < 0) ? (ilb[num4] << -num6) : (ilb[num4] >> num6));
					state.Band[1].det = num8 << 2;
					Block4(state, 1, num9);
				}
				if (state.ItuTestMode)
				{
					outputBuffer[result++] = (short)(num7 << 1);
					outputBuffer[result++] = (short)(num << 1);
					continue;
				}
				if (state.EncodeFrom8000Hz)
				{
					outputBuffer[result++] = (short)(num7 << 1);
					continue;
				}
				for (int i = 0; i < 22; i++)
				{
					state.QmfSignalHistory[i] = state.QmfSignalHistory[i + 2];
				}
				state.QmfSignalHistory[22] = num7 + num;
				state.QmfSignalHistory[23] = num7 - num;
				int num10 = 0;
				int num11 = 0;
				for (int i = 0; i < 12; i++)
				{
					num11 += state.QmfSignalHistory[2 * i] * qmf_coeffs[i];
					num10 += state.QmfSignalHistory[2 * i + 1] * qmf_coeffs[11 - i];
				}
				outputBuffer[result++] = (short)(num10 >> 11);
				outputBuffer[result++] = (short)(num11 >> 11);
			}
			return result;
		}

		/// <summary>
		/// Encodes a buffer of G722
		/// </summary>
		/// <param name="state">Codec state</param>
		/// <param name="outputBuffer">Output buffer (to contain encoded G722)</param>
		/// <param name="inputBuffer">PCM 16 bit samples to encode</param>
		/// <param name="inputBufferCount">Number of samples in the input buffer to encode</param>
		/// <returns>Number of encoded bytes written into output buffer</returns>
		public int Encode(G722CodecState state, byte[] outputBuffer, short[] inputBuffer, int inputBufferCount)
		{
			int result = 0;
			int num = 0;
			int num2 = 0;
			while (num2 < inputBufferCount)
			{
				int num3;
				int i;
				if (state.ItuTestMode)
				{
					num3 = (num = inputBuffer[num2++] >> 1);
				}
				else if (state.EncodeFrom8000Hz)
				{
					num3 = inputBuffer[num2++] >> 1;
				}
				else
				{
					for (i = 0; i < 22; i++)
					{
						state.QmfSignalHistory[i] = state.QmfSignalHistory[i + 2];
					}
					state.QmfSignalHistory[22] = inputBuffer[num2++];
					state.QmfSignalHistory[23] = inputBuffer[num2++];
					int num4 = 0;
					int num5 = 0;
					for (i = 0; i < 12; i++)
					{
						num5 += state.QmfSignalHistory[2 * i] * qmf_coeffs[i];
						num4 += state.QmfSignalHistory[2 * i + 1] * qmf_coeffs[11 - i];
					}
					num3 = num4 + num5 >> 14;
					num = num4 - num5 >> 14;
				}
				int num6 = Saturate(num3 - state.Band[0].s);
				int num7 = ((num6 >= 0) ? num6 : (-(num6 + 1)));
				int num8;
				for (i = 1; i < 30; i++)
				{
					num8 = q6[i] * state.Band[0].det >> 12;
					if (num7 < num8)
					{
						break;
					}
				}
				int num9 = ((num6 < 0) ? iln[i] : ilp[i]);
				int num10 = num9 >> 2;
				int num11 = qm4[num10];
				int d = state.Band[0].det * num11 >> 15;
				int num12 = rl42[num10];
				num7 = state.Band[0].nb * 127 >> 7;
				state.Band[0].nb = num7 + wl[num12];
				if (state.Band[0].nb < 0)
				{
					state.Band[0].nb = 0;
				}
				else if (state.Band[0].nb > 18432)
				{
					state.Band[0].nb = 18432;
				}
				num8 = (state.Band[0].nb >> 6) & 0x1F;
				num11 = 8 - (state.Band[0].nb >> 11);
				int num13 = ((num11 < 0) ? (ilb[num8] << -num11) : (ilb[num8] >> num11));
				state.Band[0].det = num13 << 2;
				Block4(state, 0, d);
				int num14;
				if (state.EncodeFrom8000Hz)
				{
					num14 = (0xC0 | num9) >> 8 - state.BitsPerSample;
				}
				else
				{
					int num15 = Saturate(num - state.Band[1].s);
					num7 = ((num15 >= 0) ? num15 : (-(num15 + 1)));
					num8 = 564 * state.Band[1].det >> 12;
					int num16 = ((num7 < num8) ? 1 : 2);
					int num17 = ((num15 < 0) ? ihn[num16] : ihp[num16]);
					num11 = qm2[num17];
					int d2 = state.Band[1].det * num11 >> 15;
					int num18 = rh2[num17];
					num7 = state.Band[1].nb * 127 >> 7;
					state.Band[1].nb = num7 + wh[num18];
					if (state.Band[1].nb < 0)
					{
						state.Band[1].nb = 0;
					}
					else if (state.Band[1].nb > 22528)
					{
						state.Band[1].nb = 22528;
					}
					num8 = (state.Band[1].nb >> 6) & 0x1F;
					num11 = 10 - (state.Band[1].nb >> 11);
					num13 = ((num11 < 0) ? (ilb[num8] << -num11) : (ilb[num8] >> num11));
					state.Band[1].det = num13 << 2;
					Block4(state, 1, d2);
					num14 = ((num17 << 6) | num9) >> 8 - state.BitsPerSample;
				}
				if (state.Packed)
				{
					state.OutBuffer |= (uint)(num14 << state.OutBits);
					state.OutBits += state.BitsPerSample;
					if (state.OutBits >= 8)
					{
						outputBuffer[result++] = (byte)(state.OutBuffer & 0xFFu);
						state.OutBits -= 8;
						state.OutBuffer >>= 8;
					}
				}
				else
				{
					outputBuffer[result++] = (byte)num14;
				}
			}
			return result;
		}
	}

	/// <summary>
	/// Stores state to be used between calls to Encode or Decode
	/// </summary>
	public class G722CodecState
	{
		/// <summary>
		/// ITU Test Mode
		/// TRUE if the operating in the special ITU test mode, with the band split filters disabled.
		/// </summary>
		public bool ItuTestMode { get; set; }

		/// <summary>
		/// TRUE if the G.722 data is packed
		/// </summary>
		public bool Packed { get; private set; }

		/// <summary>
		/// 8kHz Sampling
		/// TRUE if encode from 8k samples/second
		/// </summary>
		public bool EncodeFrom8000Hz { get; private set; }

		/// <summary>
		/// Bits Per Sample
		/// 6 for 48000kbps, 7 for 56000kbps, or 8 for 64000kbps.
		/// </summary>
		public int BitsPerSample { get; private set; }

		/// <summary>
		/// Signal history for the QMF (x)
		/// </summary>
		public int[] QmfSignalHistory { get; private set; }

		/// <summary>
		/// Band
		/// </summary>
		public Band[] Band { get; private set; }

		/// <summary>
		/// In bit buffer
		/// </summary>
		public uint InBuffer { get; internal set; }

		/// <summary>
		/// Number of bits in InBuffer
		/// </summary>
		public int InBits { get; internal set; }

		/// <summary>
		/// Out bit buffer
		/// </summary>
		public uint OutBuffer { get; internal set; }

		/// <summary>
		/// Number of bits in OutBuffer
		/// </summary>
		public int OutBits { get; internal set; }

		/// <summary>
		/// Creates a new instance of G722 Codec State for a 
		/// new encode or decode session
		/// </summary>
		/// <param name="rate">Bitrate (typically 64000)</param>
		/// <param name="options">Special options</param>
		public G722CodecState(int rate, G722Flags options)
		{
			Band = new Band[2]
			{
				new Band(),
				new Band()
			};
			QmfSignalHistory = new int[24];
			ItuTestMode = false;
			switch (rate)
			{
			case 48000:
				BitsPerSample = 6;
				break;
			case 56000:
				BitsPerSample = 7;
				break;
			case 64000:
				BitsPerSample = 8;
				break;
			default:
				throw new ArgumentException("Invalid rate, should be 48000, 56000 or 64000");
			}
			if ((options & G722Flags.SampleRate8000) == G722Flags.SampleRate8000)
			{
				EncodeFrom8000Hz = true;
			}
			if ((options & G722Flags.Packed) == G722Flags.Packed && BitsPerSample != 8)
			{
				Packed = true;
			}
			else
			{
				Packed = false;
			}
			Band[0].det = 32;
			Band[1].det = 8;
		}
	}

	/// <summary>
	/// G722 Flags
	/// </summary>
	[Flags]
	public enum G722Flags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// Using a G722 sample rate of 8000
		/// </summary>
		SampleRate8000 = 1,
		/// <summary>
		/// Packed
		/// </summary>
		Packed = 2
	}

	/// <summary>
	/// mu-law decoder
	/// based on code from:
	/// http://hazelware.luggle.com/tutorials/mulawcompression.html
	/// </summary>
	public static class MuLawDecoder
	{
		/// <summary>
		/// only 512 bytes required, so just use a lookup
		/// </summary>
		private static readonly short[] MuLawDecompressTable = new short[256]
		{
			-32124, -31100, -30076, -29052, -28028, -27004, -25980, -24956, -23932, -22908,
			-21884, -20860, -19836, -18812, -17788, -16764, -15996, -15484, -14972, -14460,
			-13948, -13436, -12924, -12412, -11900, -11388, -10876, -10364, -9852, -9340,
			-8828, -8316, -7932, -7676, -7420, -7164, -6908, -6652, -6396, -6140,
			-5884, -5628, -5372, -5116, -4860, -4604, -4348, -4092, -3900, -3772,
			-3644, -3516, -3388, -3260, -3132, -3004, -2876, -2748, -2620, -2492,
			-2364, -2236, -2108, -1980, -1884, -1820, -1756, -1692, -1628, -1564,
			-1500, -1436, -1372, -1308, -1244, -1180, -1116, -1052, -988, -924,
			-876, -844, -812, -780, -748, -716, -684, -652, -620, -588,
			-556, -524, -492, -460, -428, -396, -372, -356, -340, -324,
			-308, -292, -276, -260, -244, -228, -212, -196, -180, -164,
			-148, -132, -120, -112, -104, -96, -88, -80, -72, -64,
			-56, -48, -40, -32, -24, -16, -8, -1, 32124, 31100,
			30076, 29052, 28028, 27004, 25980, 24956, 23932, 22908, 21884, 20860,
			19836, 18812, 17788, 16764, 15996, 15484, 14972, 14460, 13948, 13436,
			12924, 12412, 11900, 11388, 10876, 10364, 9852, 9340, 8828, 8316,
			7932, 7676, 7420, 7164, 6908, 6652, 6396, 6140, 5884, 5628,
			5372, 5116, 4860, 4604, 4348, 4092, 3900, 3772, 3644, 3516,
			3388, 3260, 3132, 3004, 2876, 2748, 2620, 2492, 2364, 2236,
			2108, 1980, 1884, 1820, 1756, 1692, 1628, 1564, 1500, 1436,
			1372, 1308, 1244, 1180, 1116, 1052, 988, 924, 876, 844,
			812, 780, 748, 716, 684, 652, 620, 588, 556, 524,
			492, 460, 428, 396, 372, 356, 340, 324, 308, 292,
			276, 260, 244, 228, 212, 196, 180, 164, 148, 132,
			120, 112, 104, 96, 88, 80, 72, 64, 56, 48,
			40, 32, 24, 16, 8, 0
		};

		/// <summary>
		/// Converts a mu-law encoded byte to a 16 bit linear sample
		/// </summary>
		/// <param name="muLaw">mu-law encoded byte</param>
		/// <returns>Linear sample</returns>
		public static short MuLawToLinearSample(byte muLaw)
		{
			return MuLawDecompressTable[muLaw];
		}
	}

	/// <summary>
	/// mu-law encoder
	/// based on code from:
	/// http://hazelware.luggle.com/tutorials/mulawcompression.html
	/// </summary>
	public static class MuLawEncoder
	{
		private const int cBias = 132;

		private const int cClip = 32635;

		private static readonly byte[] MuLawCompressTable = new byte[256]
		{
			0, 0, 1, 1, 2, 2, 2, 2, 3, 3,
			3, 3, 3, 3, 3, 3, 4, 4, 4, 4,
			4, 4, 4, 4, 4, 4, 4, 4, 4, 4,
			4, 4, 5, 5, 5, 5, 5, 5, 5, 5,
			5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
			5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
			5, 5, 5, 5, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 6, 6,
			6, 6, 6, 6, 6, 6, 6, 6, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7, 7, 7, 7, 7,
			7, 7, 7, 7, 7, 7
		};

		/// <summary>
		/// Encodes a single 16 bit sample to mu-law
		/// </summary>
		/// <param name="sample">16 bit PCM sample</param>
		/// <returns>mu-law encoded byte</returns>
		public static byte LinearToMuLawSample(short sample)
		{
			int num = (sample >> 8) & 0x80;
			if (num != 0)
			{
				sample = (short)(-sample);
			}
			if (sample > 32635)
			{
				sample = 32635;
			}
			sample = (short)(sample + 132);
			int num2 = MuLawCompressTable[(sample >> 7) & 0xFF];
			int num3 = (sample >> num2 + 3) & 0xF;
			return (byte)(~(num | (num2 << 4) | num3));
		}
	}
}

namespace NAudio.CoreAudioApi
{
	/// <summary>
	/// Represents state of a capture device
	/// </summary>
	public enum CaptureState
	{
		/// <summary>
		/// Not recording
		/// </summary>
		Stopped,
		/// <summary>
		/// Beginning to record
		/// </summary>
		Starting,
		/// <summary>
		/// Recording in progress
		/// </summary>
		Capturing,
		/// <summary>
		/// Requesting stop
		/// </summary>
		Stopping
	}
}

namespace NAudio.Dmo
{
	/// <summary>
	/// Audio Media Subtypes
	/// </summary>
	public class AudioMediaSubtypes
	{
		/// <summary>
		/// PCM
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_PCM = new Guid("00000001-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// PCM Audio obsolete
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_PCMAudioObsolete = new Guid("e436eb8a-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// MPEG1 Packet
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_MPEG1Packet = new Guid("e436eb80-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// MPEG1 Payload
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_MPEG1Payload = new Guid("e436eb81-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// MPEG2 Audio
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_MPEG2_AUDIO = new Guid("e06d802b-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// DVD audio data
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_DVD_LPCM_AUDIO = new Guid("e06d8032-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// DRM Audio
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_DRM_Audio = new Guid("00000009-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// IEEE Float
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_IEEE_FLOAT = new Guid("00000003-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby AC3
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_DOLBY_AC3 = new Guid("e06d802c-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// Dolby AC3 SPDIF
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_DOLBY_AC3_SPDIF = new Guid("00000092-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// RAW Sport
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RAW_SPORT = new Guid("00000240-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// SPDIF TAG 241h
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_SPDIF_TAG_241h = new Guid("00000241-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// I420
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_I420 = new Guid("30323449-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// IYUV
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_IYUV = new Guid("56555949-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// RGB1
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB1 = new Guid("e436eb78-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB24
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB24 = new Guid("e436eb7d-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB32
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB32 = new Guid("e436eb7e-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB4
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB4 = new Guid("e436eb79-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB555
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB555 = new Guid("e436eb7c-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB565
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB565 = new Guid("e436eb7b-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// RGB8
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_RGB8 = new Guid("e436eb7a-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// UYVY
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_UYVY = new Guid("59565955-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// Video Image
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_VIDEOIMAGE = new Guid("1d4a45f2-e5f6-4b44-8388-f0ae5c0e0c37");

		/// <summary>
		/// YUY2
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_YUY2 = new Guid("32595559-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// YV12
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_YV12 = new Guid("31313259-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// YVU9
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_YVU9 = new Guid("39555659-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// YVYU
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_YVYU = new Guid("55595659-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MPEG2 Video
		/// </summary>
		public static readonly Guid WMFORMAT_MPEG2Video = new Guid("e06d80e3-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// SCcript
		/// </summary>
		public static readonly Guid WMFORMAT_Script = new Guid("5C8510F2-DEBE-4ca7-BBA5-F07A104F8DFF");

		/// <summary>
		/// Video Info
		/// </summary>
		public static readonly Guid WMFORMAT_VideoInfo = new Guid("05589f80-c356-11ce-bf01-00aa0055595a");

		/// <summary>
		/// WAVEFORMATEX
		/// </summary>
		public static readonly Guid WMFORMAT_WaveFormatEx = new Guid("05589f81-c356-11ce-bf01-00aa0055595a");

		/// <summary>
		/// Webstream
		/// </summary>
		public static readonly Guid WMFORMAT_WebStream = new Guid("da1e6b13-8359-4050-b398-388e965bf00c");

		/// <summary>
		/// ACELP net
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_ACELPnet = new Guid("00000130-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// Base
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_Base = new Guid("00000000-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// DRM
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_DRM = new Guid("00000009-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MP3
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MP3 = new Guid("00000055-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MP43
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MP43 = new Guid("3334504D-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MP4S
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MP4S = new Guid("5334504D-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// M4S2
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_M4S2 = new Guid("3253344D-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// P422
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_P422 = new Guid("32323450-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MPEG2 Video
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MPEG2_VIDEO = new Guid("e06d8026-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// MSS1
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MSS1 = new Guid("3153534D-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// MSS2
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_MSS2 = new Guid("3253534D-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// PCM
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_PCM = new Guid("00000001-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WebStream
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WebStream = new Guid("776257d4-c627-41cb-8f81-7ac7ff1c40cc");

		/// <summary>
		/// WM Audio Lossless
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMAudio_Lossless = new Guid("00000163-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WM Audio V2
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMAudioV2 = new Guid("00000161-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WM Audio V7
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMAudioV7 = new Guid("00000161-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WM Audio V8
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMAudioV8 = new Guid("00000161-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WM Audio V9
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMAudioV9 = new Guid("00000162-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMSP1
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMSP1 = new Guid("0000000A-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMV1
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMV1 = new Guid("31564D57-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMV2
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMV2 = new Guid("32564D57-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMV3
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMV3 = new Guid("33564D57-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMVA
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMVA = new Guid("41564D57-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMVP
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WMVP = new Guid("50564D57-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// WMVP2
		/// </summary>
		public static readonly Guid WMMEDIASUBTYPE_WVP2 = new Guid("32505657-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// Audio
		/// </summary>
		public static readonly Guid WMMEDIATYPE_Audio = new Guid("73647561-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// File Transfer
		/// </summary>
		public static readonly Guid WMMEDIATYPE_FileTransfer = new Guid("D9E47579-930E-4427-ADFC-AD80F290E470");

		/// <summary>
		/// Image
		/// </summary>
		public static readonly Guid WMMEDIATYPE_Image = new Guid("34A50FD8-8AA5-4386-81FE-A0EFE0488E31");

		/// <summary>
		/// Script
		/// </summary>
		public static readonly Guid WMMEDIATYPE_Script = new Guid("73636d64-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// Text
		/// </summary>
		public static readonly Guid WMMEDIATYPE_Text = new Guid("9BBA1EA7-5AB2-4829-BA57-0940209BCF3E");

		/// <summary>
		/// Video
		/// </summary>
		public static readonly Guid WMMEDIATYPE_Video = new Guid("73646976-0000-0010-8000-00AA00389B71");

		/// <summary>
		/// Two strings
		/// </summary>
		public static readonly Guid WMSCRIPTTYPE_TwoStrings = new Guid("82f38a70-c29f-11d1-97ad-00a0c95ea850");

		/// <summary>
		/// Wave
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_WAVE = new Guid("e436eb8b-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// AU
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_AU = new Guid("e436eb8c-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// AIFF
		/// </summary>
		public static readonly Guid MEDIASUBTYPE_AIFF = new Guid("e436eb8d-524f-11ce-9f53-0020af0ba770");

		/// <summary>
		/// Audio Subtypes
		/// </summary>
		public static readonly Guid[] AudioSubTypes = new Guid[13]
		{
			MEDIASUBTYPE_PCM, MEDIASUBTYPE_PCMAudioObsolete, MEDIASUBTYPE_MPEG1Packet, MEDIASUBTYPE_MPEG1Payload, MEDIASUBTYPE_MPEG2_AUDIO, MEDIASUBTYPE_DVD_LPCM_AUDIO, MEDIASUBTYPE_DRM_Audio, MEDIASUBTYPE_IEEE_FLOAT, MEDIASUBTYPE_DOLBY_AC3, MEDIASUBTYPE_DOLBY_AC3_SPDIF,
			MEDIASUBTYPE_RAW_SPORT, MEDIASUBTYPE_SPDIF_TAG_241h, WMMEDIASUBTYPE_MP3
		};

		/// <summary>
		/// Audio subtype names
		/// </summary>
		public static readonly string[] AudioSubTypeNames = new string[13]
		{
			"PCM", "PCM Obsolete", "MPEG1Packet", "MPEG1Payload", "MPEG2_AUDIO", "DVD_LPCM_AUDIO", "DRM_Audio", "IEEE_FLOAT", "DOLBY_AC3", "DOLBY_AC3_SPDIF",
			"RAW_SPORT", "SPDIF_TAG_241h", "MP3"
		};

		/// <summary>
		/// Get Audio Subtype Name
		/// </summary>
		public static string GetAudioSubtypeName(Guid subType)
		{
			for (int i = 0; i < AudioSubTypes.Length; i++)
			{
				if (subType == AudioSubTypes[i])
				{
					return AudioSubTypeNames[i];
				}
			}
			return subType.ToString();
		}
	}

}

namespace NAudio.Dsp
{
	using NAudio.Utils;
	
	internal class AttRelEnvelope
	{
		protected const double DC_OFFSET = 1E-25;

		private readonly EnvelopeDetector attack;

		private readonly EnvelopeDetector release;

		public double Attack
		{
			get
			{
				return attack.TimeConstant;
			}
			set
			{
				attack.TimeConstant = value;
			}
		}

		public double Release
		{
			get
			{
				return release.TimeConstant;
			}
			set
			{
				release.TimeConstant = value;
			}
		}

		public double SampleRate
		{
			get
			{
				return attack.SampleRate;
			}
			set
			{
				EnvelopeDetector envelopeDetector = attack;
				double sampleRate = (release.SampleRate = value);
				envelopeDetector.SampleRate = sampleRate;
			}
		}

		public AttRelEnvelope(double attackMilliseconds, double releaseMilliseconds, double sampleRate)
		{
			attack = new EnvelopeDetector(attackMilliseconds, sampleRate);
			release = new EnvelopeDetector(releaseMilliseconds, sampleRate);
		}

		public double Run(double inValue, double state)
		{
			if (!(inValue > state))
			{
				return release.Run(inValue, state);
			}
			return attack.Run(inValue, state);
		}
	}

	/// <summary>
	/// BiQuad filter
	/// </summary>
	public class BiQuadFilter
	{
		private double a0;

		private double a1;

		private double a2;

		private double a3;

		private double a4;

		private float x1;

		private float x2;

		private float y1;

		private float y2;

		/// <summary>
		/// Passes a single sample through the filter
		/// </summary>
		/// <param name="inSample">Input sample</param>
		/// <returns>Output sample</returns>
		public float Transform(float inSample)
		{
			double num = a0 * (double)inSample + a1 * (double)x1 + a2 * (double)x2 - a3 * (double)y1 - a4 * (double)y2;
			x2 = x1;
			x1 = inSample;
			y2 = y1;
			y1 = (float)num;
			return y1;
		}

		private void SetCoefficients(double aa0, double aa1, double aa2, double b0, double b1, double b2)
		{
			a0 = b0 / aa0;
			a1 = b1 / aa0;
			a2 = b2 / aa0;
			a3 = aa1 / aa0;
			a4 = aa2 / aa0;
		}

		/// <summary>
		/// Set this up as a low pass filter
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="cutoffFrequency">Cut-off Frequency</param>
		/// <param name="q">Bandwidth</param>
		public void SetLowPassFilter(float sampleRate, float cutoffFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)cutoffFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			double b = (1.0 - num2) / 2.0;
			double b2 = 1.0 - num2;
			double b3 = (1.0 - num2) / 2.0;
			double aa = 1.0 + num3;
			double aa2 = -2.0 * num2;
			double aa3 = 1.0 - num3;
			SetCoefficients(aa, aa2, aa3, b, b2, b3);
		}

		/// <summary>
		/// Set this up as a peaking EQ
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="centreFrequency">Centre Frequency</param>
		/// <param name="q">Bandwidth (Q)</param>
		/// <param name="dbGain">Gain in decibels</param>
		public void SetPeakingEq(float sampleRate, float centreFrequency, float q, float dbGain)
		{
			double num = Math.PI * 2.0 * (double)centreFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			double num4 = Math.Pow(10.0, dbGain / 40f);
			double b = 1.0 + num3 * num4;
			double b2 = -2.0 * num2;
			double b3 = 1.0 - num3 * num4;
			double aa = 1.0 + num3 / num4;
			double aa2 = -2.0 * num2;
			double aa3 = 1.0 - num3 / num4;
			SetCoefficients(aa, aa2, aa3, b, b2, b3);
		}

		/// <summary>
		/// Set this as a high pass filter
		/// </summary>
		public void SetHighPassFilter(float sampleRate, float cutoffFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)cutoffFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			double b = (1.0 + num2) / 2.0;
			double b2 = 0.0 - (1.0 + num2);
			double b3 = (1.0 + num2) / 2.0;
			double aa = 1.0 + num3;
			double aa2 = -2.0 * num2;
			double aa3 = 1.0 - num3;
			SetCoefficients(aa, aa2, aa3, b, b2, b3);
		}

		/// <summary>
		/// Create a low pass filter
		/// </summary>
		public static BiQuadFilter LowPassFilter(float sampleRate, float cutoffFrequency, float q)
		{
			BiQuadFilter biQuadFilter = new BiQuadFilter();
			biQuadFilter.SetLowPassFilter(sampleRate, cutoffFrequency, q);
			return biQuadFilter;
		}

		/// <summary>
		/// Create a High pass filter
		/// </summary>
		public static BiQuadFilter HighPassFilter(float sampleRate, float cutoffFrequency, float q)
		{
			BiQuadFilter biQuadFilter = new BiQuadFilter();
			biQuadFilter.SetHighPassFilter(sampleRate, cutoffFrequency, q);
			return biQuadFilter;
		}

		/// <summary>
		/// Create a bandpass filter with constant skirt gain
		/// </summary>
		public static BiQuadFilter BandPassFilterConstantSkirtGain(float sampleRate, float centreFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)centreFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num);
			double num4 = num3 / (double)(2f * q);
			double b = num3 / 2.0;
			int num5 = 0;
			double b2 = (0.0 - num3) / 2.0;
			double num6 = 1.0 + num4;
			double num7 = -2.0 * num2;
			double num8 = 1.0 - num4;
			return new BiQuadFilter(num6, num7, num8, b, num5, b2);
		}

		/// <summary>
		/// Create a bandpass filter with constant peak gain
		/// </summary>
		public static BiQuadFilter BandPassFilterConstantPeakGain(float sampleRate, float centreFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)centreFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			double b = num3;
			int num4 = 0;
			double b2 = 0.0 - num3;
			double num5 = 1.0 + num3;
			double num6 = -2.0 * num2;
			double num7 = 1.0 - num3;
			return new BiQuadFilter(num5, num6, num7, b, num4, b2);
		}

		/// <summary>
		/// Creates a notch filter
		/// </summary>
		public static BiQuadFilter NotchFilter(float sampleRate, float centreFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)centreFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			int num4 = 1;
			double b = -2.0 * num2;
			int num5 = 1;
			double num6 = 1.0 + num3;
			double num7 = -2.0 * num2;
			double num8 = 1.0 - num3;
			return new BiQuadFilter(num6, num7, num8, num4, b, num5);
		}

		/// <summary>
		/// Creaes an all pass filter
		/// </summary>
		public static BiQuadFilter AllPassFilter(float sampleRate, float centreFrequency, float q)
		{
			double num = Math.PI * 2.0 * (double)centreFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num) / (double)(2f * q);
			double b = 1.0 - num3;
			double b2 = -2.0 * num2;
			double b3 = 1.0 + num3;
			double num4 = 1.0 + num3;
			double num5 = -2.0 * num2;
			double num6 = 1.0 - num3;
			return new BiQuadFilter(num4, num5, num6, b, b2, b3);
		}

		/// <summary>
		/// Create a Peaking EQ
		/// </summary>
		public static BiQuadFilter PeakingEQ(float sampleRate, float centreFrequency, float q, float dbGain)
		{
			BiQuadFilter biQuadFilter = new BiQuadFilter();
			biQuadFilter.SetPeakingEq(sampleRate, centreFrequency, q, dbGain);
			return biQuadFilter;
		}

		/// <summary>
		/// H(s) = A * (s^2 + (sqrt(A)/Q)*s + A)/(A*s^2 + (sqrt(A)/Q)*s + 1)
		/// </summary>
		/// <param name="sampleRate"></param>
		/// <param name="cutoffFrequency"></param>
		/// <param name="shelfSlope">a "shelf slope" parameter (for shelving EQ only).  
		/// When S = 1, the shelf slope is as steep as it can be and remain monotonically
		/// increasing or decreasing gain with frequency.  The shelf slope, in dB/octave, 
		/// remains proportional to S for all other values for a fixed f0/Fs and dBgain.</param>
		/// <param name="dbGain">Gain in decibels</param>
		public static BiQuadFilter LowShelf(float sampleRate, float cutoffFrequency, float shelfSlope, float dbGain)
		{
			double num = Math.PI * 2.0 * (double)cutoffFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num);
			double num4 = Math.Pow(10.0, dbGain / 40f);
			double num5 = num3 / 2.0 * Math.Sqrt((num4 + 1.0 / num4) * (double)(1f / shelfSlope - 1f) + 2.0);
			double num6 = 2.0 * Math.Sqrt(num4) * num5;
			double b = num4 * (num4 + 1.0 - (num4 - 1.0) * num2 + num6);
			double b2 = 2.0 * num4 * (num4 - 1.0 - (num4 + 1.0) * num2);
			double b3 = num4 * (num4 + 1.0 - (num4 - 1.0) * num2 - num6);
			double num7 = num4 + 1.0 + (num4 - 1.0) * num2 + num6;
			double num8 = -2.0 * (num4 - 1.0 + (num4 + 1.0) * num2);
			double num9 = num4 + 1.0 + (num4 - 1.0) * num2 - num6;
			return new BiQuadFilter(num7, num8, num9, b, b2, b3);
		}

		/// <summary>
		/// H(s) = A * (A*s^2 + (sqrt(A)/Q)*s + 1)/(s^2 + (sqrt(A)/Q)*s + A)
		/// </summary>
		/// <param name="sampleRate"></param>
		/// <param name="cutoffFrequency"></param>
		/// <param name="shelfSlope"></param>
		/// <param name="dbGain"></param>
		/// <returns></returns>
		public static BiQuadFilter HighShelf(float sampleRate, float cutoffFrequency, float shelfSlope, float dbGain)
		{
			double num = Math.PI * 2.0 * (double)cutoffFrequency / (double)sampleRate;
			double num2 = Math.Cos(num);
			double num3 = Math.Sin(num);
			double num4 = Math.Pow(10.0, dbGain / 40f);
			double num5 = num3 / 2.0 * Math.Sqrt((num4 + 1.0 / num4) * (double)(1f / shelfSlope - 1f) + 2.0);
			double num6 = 2.0 * Math.Sqrt(num4) * num5;
			double b = num4 * (num4 + 1.0 + (num4 - 1.0) * num2 + num6);
			double b2 = -2.0 * num4 * (num4 - 1.0 + (num4 + 1.0) * num2);
			double b3 = num4 * (num4 + 1.0 + (num4 - 1.0) * num2 - num6);
			double num7 = num4 + 1.0 - (num4 - 1.0) * num2 + num6;
			double num8 = 2.0 * (num4 - 1.0 - (num4 + 1.0) * num2);
			double num9 = num4 + 1.0 - (num4 - 1.0) * num2 - num6;
			return new BiQuadFilter(num7, num8, num9, b, b2, b3);
		}

		private BiQuadFilter()
		{
			x1 = (x2 = 0f);
			y1 = (y2 = 0f);
		}

		private BiQuadFilter(double a0, double a1, double a2, double b0, double b1, double b2)
		{
			SetCoefficients(a0, a1, a2, b0, b1, b2);
			x1 = (x2 = 0f);
			y1 = (y2 = 0f);
		}
	}

	/// <summary>
	/// Type to represent complex number
	/// </summary>
	public struct Complex
	{
		/// <summary>
		/// Real Part
		/// </summary>
		public float X;

		/// <summary>
		/// Imaginary Part
		/// </summary>
		public float Y;
	}

	internal class EnvelopeDetector
	{
		private double sampleRate;

		private double ms;

		private double coeff;

		public double TimeConstant
		{
			get
			{
				return ms;
			}
			set
			{
				ms = value;
				SetCoef();
			}
		}

		public double SampleRate
		{
			get
			{
				return sampleRate;
			}
			set
			{
				sampleRate = value;
				SetCoef();
			}
		}

		public EnvelopeDetector()
			: this(1.0, 44100.0)
		{
		}

		public EnvelopeDetector(double ms, double sampleRate)
		{
			this.sampleRate = sampleRate;
			this.ms = ms;
			SetCoef();
		}

		public double Run(double inValue, double state)
		{
			return inValue + coeff * (state - inValue);
		}

		private void SetCoef()
		{
			coeff = Math.Exp(-1.0 / (0.001 * ms * sampleRate));
		}
	}

	/// <summary>
	/// Envelope generator (ADSR)
	/// </summary>
	public class EnvelopeGenerator
	{
		/// <summary>
		/// Envelope State
		/// </summary>
		public enum EnvelopeState
		{
			/// <summary>
			/// Idle
			/// </summary>
			Idle,
			/// <summary>
			/// Attack
			/// </summary>
			Attack,
			/// <summary>
			/// Decay
			/// </summary>
			Decay,
			/// <summary>
			/// Sustain
			/// </summary>
			Sustain,
			/// <summary>
			/// Release
			/// </summary>
			Release
		}

		private EnvelopeState state;

		private float output;

		private float attackRate;

		private float decayRate;

		private float releaseRate;

		private float attackCoef;

		private float decayCoef;

		private float releaseCoef;

		private float sustainLevel;

		private float targetRatioAttack;

		private float targetRatioDecayRelease;

		private float attackBase;

		private float decayBase;

		private float releaseBase;

		/// <summary>
		/// Attack Rate (seconds * SamplesPerSecond)
		/// </summary>
		public float AttackRate
		{
			get
			{
				return attackRate;
			}
			set
			{
				attackRate = value;
				attackCoef = CalcCoef(value, targetRatioAttack);
				attackBase = (1f + targetRatioAttack) * (1f - attackCoef);
			}
		}

		/// <summary>
		/// Decay Rate (seconds * SamplesPerSecond)
		/// </summary>
		public float DecayRate
		{
			get
			{
				return decayRate;
			}
			set
			{
				decayRate = value;
				decayCoef = CalcCoef(value, targetRatioDecayRelease);
				decayBase = (sustainLevel - targetRatioDecayRelease) * (1f - decayCoef);
			}
		}

		/// <summary>
		/// Release Rate (seconds * SamplesPerSecond)
		/// </summary>
		public float ReleaseRate
		{
			get
			{
				return releaseRate;
			}
			set
			{
				releaseRate = value;
				releaseCoef = CalcCoef(value, targetRatioDecayRelease);
				releaseBase = (0f - targetRatioDecayRelease) * (1f - releaseCoef);
			}
		}

		/// <summary>
		/// Sustain Level (1 = 100%)
		/// </summary>
		public float SustainLevel
		{
			get
			{
				return sustainLevel;
			}
			set
			{
				sustainLevel = value;
				decayBase = (sustainLevel - targetRatioDecayRelease) * (1f - decayCoef);
			}
		}

		/// <summary>
		/// Current envelope state
		/// </summary>
		public EnvelopeState State => state;

		/// <summary>
		/// Creates and Initializes an Envelope Generator
		/// </summary>
		public EnvelopeGenerator()
		{
			Reset();
			AttackRate = 0f;
			DecayRate = 0f;
			ReleaseRate = 0f;
			SustainLevel = 1f;
			SetTargetRatioAttack(0.3f);
			SetTargetRatioDecayRelease(0.0001f);
		}

		private static float CalcCoef(float rate, float targetRatio)
		{
			return (float)Math.Exp((0.0 - Math.Log((1f + targetRatio) / targetRatio)) / (double)rate);
		}

		/// <summary>
		/// Sets the attack curve
		/// </summary>
		private void SetTargetRatioAttack(float targetRatio)
		{
			if (targetRatio < 1E-09f)
			{
				targetRatio = 1E-09f;
			}
			targetRatioAttack = targetRatio;
			attackBase = (1f + targetRatioAttack) * (1f - attackCoef);
		}

		/// <summary>
		/// Sets the decay release curve
		/// </summary>
		private void SetTargetRatioDecayRelease(float targetRatio)
		{
			if (targetRatio < 1E-09f)
			{
				targetRatio = 1E-09f;
			}
			targetRatioDecayRelease = targetRatio;
			decayBase = (sustainLevel - targetRatioDecayRelease) * (1f - decayCoef);
			releaseBase = (0f - targetRatioDecayRelease) * (1f - releaseCoef);
		}

		/// <summary>
		/// Read the next volume multiplier from the envelope generator
		/// </summary>
		/// <returns>A volume multiplier</returns>
		public float Process()
		{
			switch (state)
			{
			case EnvelopeState.Attack:
				output = attackBase + output * attackCoef;
				if (output >= 1f)
				{
					output = 1f;
					state = EnvelopeState.Decay;
				}
				break;
			case EnvelopeState.Decay:
				output = decayBase + output * decayCoef;
				if (output <= sustainLevel)
				{
					output = sustainLevel;
					state = EnvelopeState.Sustain;
				}
				break;
			case EnvelopeState.Release:
				output = releaseBase + output * releaseCoef;
				if ((double)output <= 0.0)
				{
					output = 0f;
					state = EnvelopeState.Idle;
				}
				break;
			}
			return output;
		}

		/// <summary>
		/// Trigger the gate
		/// </summary>
		/// <param name="gate">If true, enter attack phase, if false enter release phase (unless already idle)</param>
		public void Gate(bool gate)
		{
			if (gate)
			{
				state = EnvelopeState.Attack;
			}
			else if (state != 0)
			{
				state = EnvelopeState.Release;
			}
		}

		/// <summary>
		/// Reset to idle state
		/// </summary>
		public void Reset()
		{
			state = EnvelopeState.Idle;
			output = 0f;
		}

		/// <summary>
		/// Get the current output level
		/// </summary>
		public float GetOutput()
		{
			return output;
		}
	}

	/// <summary>
	/// Summary description for FastFourierTransform.
	/// </summary>
	public static class FastFourierTransform
	{
		/// <summary>
		/// This computes an in-place complex-to-complex FFT 
		/// x and y are the real and imaginary arrays of 2^m points.
		/// </summary>
		public static void FFT(bool forward, int m, Complex[] data)
		{
			int num = 1;
			for (int i = 0; i < m; i++)
			{
				num *= 2;
			}
			int num2 = num >> 1;
			int num3 = 0;
			for (int i = 0; i < num - 1; i++)
			{
				if (i < num3)
				{
					float x = data[i].X;
					float y = data[i].Y;
					data[i].X = data[num3].X;
					data[i].Y = data[num3].Y;
					data[num3].X = x;
					data[num3].Y = y;
				}
				int num4;
				for (num4 = num2; num4 <= num3; num4 >>= 1)
				{
					num3 -= num4;
				}
				num3 += num4;
			}
			float num5 = -1f;
			float num6 = 0f;
			int num7 = 1;
			for (int j = 0; j < m; j++)
			{
				int num8 = num7;
				num7 <<= 1;
				float num9 = 1f;
				float num10 = 0f;
				for (num3 = 0; num3 < num8; num3++)
				{
					for (int i = num3; i < num; i += num7)
					{
						int num11 = i + num8;
						float num12 = num9 * data[num11].X - num10 * data[num11].Y;
						float num13 = num9 * data[num11].Y + num10 * data[num11].X;
						data[num11].X = data[i].X - num12;
						data[num11].Y = data[i].Y - num13;
						data[i].X += num12;
						data[i].Y += num13;
					}
					float num14 = num9 * num5 - num10 * num6;
					num10 = num9 * num6 + num10 * num5;
					num9 = num14;
				}
				num6 = (float)Math.Sqrt((1f - num5) / 2f);
				if (forward)
				{
					num6 = 0f - num6;
				}
				num5 = (float)Math.Sqrt((1f + num5) / 2f);
			}
			if (forward)
			{
				for (int i = 0; i < num; i++)
				{
					data[i].X /= num;
					data[i].Y /= num;
				}
			}
		}

		/// <summary>
		/// Applies a Hamming Window
		/// </summary>
		/// <param name="n">Index into frame</param>
		/// <param name="frameSize">Frame size (e.g. 1024)</param>
		/// <returns>Multiplier for Hamming window</returns>
		public static double HammingWindow(int n, int frameSize)
		{
			return 0.54 - 0.46 * Math.Cos(Math.PI * 2.0 * (double)n / (double)(frameSize - 1));
		}

		/// <summary>
		/// Applies a Hann Window
		/// </summary>
		/// <param name="n">Index into frame</param>
		/// <param name="frameSize">Frame size (e.g. 1024)</param>
		/// <returns>Multiplier for Hann window</returns>
		public static double HannWindow(int n, int frameSize)
		{
			return 0.5 * (1.0 - Math.Cos(Math.PI * 2.0 * (double)n / (double)(frameSize - 1)));
		}

		/// <summary>
		/// Applies a Blackman-Harris Window
		/// </summary>
		/// <param name="n">Index into frame</param>
		/// <param name="frameSize">Frame size (e.g. 1024)</param>
		/// <returns>Multiplier for Blackmann-Harris window</returns>
		public static double BlackmannHarrisWindow(int n, int frameSize)
		{
			return 287.0 / 800.0 - 0.48829 * Math.Cos(Math.PI * 2.0 * (double)n / (double)(frameSize - 1)) + 0.14128 * Math.Cos(Math.PI * 4.0 * (double)n / (double)(frameSize - 1)) - 0.01168 * Math.Cos(Math.PI * 6.0 * (double)n / (double)(frameSize - 1));
		}
	}

	/// <summary>
	/// Summary description for ImpulseResponseConvolution.
	/// </summary>
	public class ImpulseResponseConvolution
	{
		/// <summary>
		/// A very simple mono convolution algorithm
		/// </summary>
		/// <remarks>
		/// This will be very slow
		/// </remarks>
		public float[] Convolve(float[] input, float[] impulseResponse)
		{
			float[] array = new float[input.Length + impulseResponse.Length];
			for (int i = 0; i < array.Length; i++)
			{
				for (int j = 0; j < impulseResponse.Length; j++)
				{
					if (i >= j && i - j < input.Length)
					{
						array[i] += impulseResponse[j] * input[i - j];
					}
				}
			}
			Normalize(array);
			return array;
		}

		/// <summary>
		/// This is actually a downwards normalize for data that will clip
		/// </summary>
		public void Normalize(float[] data)
		{
			float num = 0f;
			for (int i = 0; i < data.Length; i++)
			{
				num = Math.Max(num, Math.Abs(data[i]));
			}
			if ((double)num > 1.0)
			{
				for (int j = 0; j < data.Length; j++)
				{
					data[j] /= num;
				}
			}
		}
	}

	internal class SimpleCompressor : AttRelEnvelope
	{
		private double envdB;

		public double MakeUpGain { get; set; }

		public double Threshold { get; set; }

		public double Ratio { get; set; }

		public SimpleCompressor(double attackTime, double releaseTime, double sampleRate)
			: base(attackTime, releaseTime, sampleRate)
		{
			Threshold = 0.0;
			Ratio = 1.0;
			MakeUpGain = 0.0;
			envdB = 1E-25;
		}

		public SimpleCompressor()
			: this(10.0, 10.0, 44100.0)
		{
		}

		public void InitRuntime()
		{
			envdB = 1E-25;
		}

		public void Process(ref double in1, ref double in2)
		{
			double val = Math.Abs(in1);
			double val2 = Math.Abs(in2);
			double num = Decibels.LinearToDecibels(Math.Max(val, val2) + 1E-25) - Threshold;
			if (num < 0.0)
			{
				num = 0.0;
			}
			num += 1E-25;
			envdB = Run(num, envdB);
			num = envdB - 1E-25;
			double dB = num * (Ratio - 1.0);
			dB = Decibels.DecibelsToLinear(dB) * Decibels.DecibelsToLinear(MakeUpGain);
			in1 *= dB;
			in2 *= dB;
		}
	}

	internal class SimpleGate : AttRelEnvelope
	{
		private double threshdB;

		private double thresh;

		private double env;

		public double Threshold
		{
			get
			{
				return threshdB;
			}
			set
			{
				threshdB = value;
				thresh = Decibels.DecibelsToLinear(value);
			}
		}

		public SimpleGate()
			: base(10.0, 10.0, 44100.0)
		{
			threshdB = 0.0;
			thresh = 1.0;
			env = 1E-25;
		}

		public void Process(ref double in1, ref double in2)
		{
			double val = Math.Abs(in1);
			double val2 = Math.Abs(in2);
			double num = ((Math.Max(val, val2) > thresh) ? 1.0 : 0.0);
			num += 1E-25;
			env = Run(num, env);
			num = env - 1E-25;
			in1 *= num;
			in2 *= num;
		}
	}

	/// <summary>
	/// SMB Pitch Shifter
	/// </summary>
	public class SmbPitchShifter
	{
		private static int MAX_FRAME_LENGTH = 16000;

		private float[] gInFIFO = new float[MAX_FRAME_LENGTH];

		private float[] gOutFIFO = new float[MAX_FRAME_LENGTH];

		private float[] gFFTworksp = new float[2 * MAX_FRAME_LENGTH];

		private float[] gLastPhase = new float[MAX_FRAME_LENGTH / 2 + 1];

		private float[] gSumPhase = new float[MAX_FRAME_LENGTH / 2 + 1];

		private float[] gOutputAccum = new float[2 * MAX_FRAME_LENGTH];

		private float[] gAnaFreq = new float[MAX_FRAME_LENGTH];

		private float[] gAnaMagn = new float[MAX_FRAME_LENGTH];

		private float[] gSynFreq = new float[MAX_FRAME_LENGTH];

		private float[] gSynMagn = new float[MAX_FRAME_LENGTH];

		private long gRover;

		/// <summary>
		/// Pitch Shift 
		/// </summary>
		public void PitchShift(float pitchShift, long numSampsToProcess, float sampleRate, float[] indata)
		{
			PitchShift(pitchShift, numSampsToProcess, 2048L, 10L, sampleRate, indata);
		}

		/// <summary>
		/// Pitch Shift 
		/// </summary>
		public void PitchShift(float pitchShift, long numSampsToProcess, long fftFrameSize, long osamp, float sampleRate, float[] indata)
		{
			long num = fftFrameSize / 2;
			long num2 = fftFrameSize / osamp;
			double num3 = (double)sampleRate / (double)fftFrameSize;
			double num4 = Math.PI * 2.0 * (double)num2 / (double)fftFrameSize;
			long num5 = fftFrameSize - num2;
			if (gRover == 0L)
			{
				gRover = num5;
			}
			for (long num6 = 0L; num6 < numSampsToProcess; num6++)
			{
				gInFIFO[gRover] = indata[num6];
				indata[num6] = gOutFIFO[gRover - num5];
				gRover++;
				if (gRover < fftFrameSize)
				{
					continue;
				}
				gRover = num5;
				for (long num7 = 0L; num7 < fftFrameSize; num7++)
				{
					double num8 = -0.5 * Math.Cos(Math.PI * 2.0 * (double)num7 / (double)fftFrameSize) + 0.5;
					gFFTworksp[2 * num7] = (float)((double)gInFIFO[num7] * num8);
					gFFTworksp[2 * num7 + 1] = 0f;
				}
				ShortTimeFourierTransform(gFFTworksp, fftFrameSize, -1L);
				for (long num7 = 0L; num7 <= num; num7++)
				{
					double num9 = gFFTworksp[2 * num7];
					double num10 = gFFTworksp[2 * num7 + 1];
					double num11 = 2.0 * Math.Sqrt(num9 * num9 + num10 * num10);
					double num12 = Math.Atan2(num10, num9);
					double num13 = num12 - (double)gLastPhase[num7];
					gLastPhase[num7] = (float)num12;
					num13 -= (double)num7 * num4;
					long num14 = (long)(num13 / Math.PI);
					num14 = ((num14 < 0) ? (num14 - (num14 & 1)) : (num14 + (num14 & 1)));
					num13 -= Math.PI * (double)num14;
					num13 = (double)osamp * num13 / (Math.PI * 2.0);
					num13 = (double)num7 * num3 + num13 * num3;
					gAnaMagn[num7] = (float)num11;
					gAnaFreq[num7] = (float)num13;
				}
				for (int i = 0; i < fftFrameSize; i++)
				{
					gSynMagn[i] = 0f;
					gSynFreq[i] = 0f;
				}
				for (long num7 = 0L; num7 <= num; num7++)
				{
					long num15 = (long)((float)num7 * pitchShift);
					if (num15 <= num)
					{
						gSynMagn[num15] += gAnaMagn[num7];
						gSynFreq[num15] = gAnaFreq[num7] * pitchShift;
					}
				}
				for (long num7 = 0L; num7 <= num; num7++)
				{
					double num11 = gSynMagn[num7];
					double num13 = gSynFreq[num7];
					num13 -= (double)num7 * num3;
					num13 /= num3;
					num13 = Math.PI * 2.0 * num13 / (double)osamp;
					num13 += (double)num7 * num4;
					gSumPhase[num7] += (float)num13;
					double num12 = gSumPhase[num7];
					gFFTworksp[2 * num7] = (float)(num11 * Math.Cos(num12));
					gFFTworksp[2 * num7 + 1] = (float)(num11 * Math.Sin(num12));
				}
				for (long num7 = fftFrameSize + 2; num7 < 2 * fftFrameSize; num7++)
				{
					gFFTworksp[num7] = 0f;
				}
				ShortTimeFourierTransform(gFFTworksp, fftFrameSize, 1L);
				for (long num7 = 0L; num7 < fftFrameSize; num7++)
				{
					double num8 = -0.5 * Math.Cos(Math.PI * 2.0 * (double)num7 / (double)fftFrameSize) + 0.5;
					gOutputAccum[num7] += (float)(2.0 * num8 * (double)gFFTworksp[2 * num7] / (double)(num * osamp));
				}
				for (long num7 = 0L; num7 < num2; num7++)
				{
					gOutFIFO[num7] = gOutputAccum[num7];
				}
				for (long num7 = 0L; num7 < fftFrameSize; num7++)
				{
					gOutputAccum[num7] = gOutputAccum[num7 + num2];
				}
				for (long num7 = 0L; num7 < num5; num7++)
				{
					gInFIFO[num7] = gInFIFO[num7 + num2];
				}
			}
		}

		/// <summary>
		/// Short Time Fourier Transform
		/// </summary>
		public void ShortTimeFourierTransform(float[] fftBuffer, long fftFrameSize, long sign)
		{
			for (long num = 2L; num < 2 * fftFrameSize - 2; num += 2)
			{
				long num2 = 2L;
				long num3 = 0L;
				while (num2 < 2 * fftFrameSize)
				{
					if ((num & num2) != 0L)
					{
						num3++;
					}
					num3 <<= 1;
					num2 <<= 1;
				}
				if (num < num3)
				{
					float num4 = fftBuffer[num];
					fftBuffer[num] = fftBuffer[num3];
					fftBuffer[num3] = num4;
					num4 = fftBuffer[num + 1];
					fftBuffer[num + 1] = fftBuffer[num3 + 1];
					fftBuffer[num3 + 1] = num4;
				}
			}
			long num5 = (long)(Math.Log(fftFrameSize) / Math.Log(2.0) + 0.5);
			long num6 = 0L;
			long num7 = 2L;
			for (; num6 < num5; num6++)
			{
				num7 <<= 1;
				long num8 = num7 >> 1;
				float num9 = 1f;
				float num10 = 0f;
				float num11 = MathF.PI / (float)(num8 >> 1);
				float num12 = (float)Math.Cos(num11);
				float num13 = (float)((double)sign * Math.Sin(num11));
				for (long num3 = 0L; num3 < num8; num3 += 2)
				{
					float num14;
					for (long num = num3; num < 2 * fftFrameSize; num += num7)
					{
						num14 = fftBuffer[num + num8] * num9 - fftBuffer[num + num8 + 1] * num10;
						float num15 = fftBuffer[num + num8] * num10 + fftBuffer[num + num8 + 1] * num9;
						fftBuffer[num + num8] = fftBuffer[num] - num14;
						fftBuffer[num + num8 + 1] = fftBuffer[num + 1] - num15;
						fftBuffer[num] += num14;
						fftBuffer[num + 1] += num15;
					}
					num14 = num9 * num12 - num10 * num13;
					num10 = num9 * num13 + num10 * num12;
					num9 = num14;
				}
			}
		}
	}

	/// <summary>
	/// Fully managed resampler, based on Cockos WDL Resampler
	/// </summary>
	public class WdlResampler
	{
		private class WDL_Resampler_IIRFilter
		{
			private double m_fpos;

			private double m_a1;

			private double m_a2;

			private double m_b0;

			private double m_b1;

			private double m_b2;

			private double[,] m_hist;

			public WDL_Resampler_IIRFilter()
			{
				m_fpos = -1.0;
				Reset();
			}

			public void Reset()
			{
				m_hist = new double[256, 4];
			}

			public void setParms(double fpos, double Q)
			{
				if (!(Math.Abs(fpos - m_fpos) < 1E-06))
				{
					m_fpos = fpos;
					double num = fpos * Math.PI;
					double num2 = Math.Cos(num);
					double num3 = Math.Sin(num) / (2.0 * Q);
					double num4 = 1.0 / (1.0 + num3);
					m_b1 = (1.0 - num2) * num4;
					m_b2 = (m_b0 = m_b1 * 0.5);
					m_a1 = -2.0 * num2 * num4;
					m_a2 = (1.0 - num3) * num4;
				}
			}

			public void Apply(float[] inBuffer, int inIndex, float[] outBuffer, int outIndex, int ns, int span, int w)
			{
				double b = m_b0;
				double b2 = m_b1;
				double b3 = m_b2;
				double a = m_a1;
				double a2 = m_a2;
				while (ns-- != 0)
				{
					double num = inBuffer[inIndex];
					inIndex += span;
					double x = num * b + m_hist[w, 0] * b2 + m_hist[w, 1] * b3 - m_hist[w, 2] * a - m_hist[w, 3] * a2;
					m_hist[w, 1] = m_hist[w, 0];
					m_hist[w, 0] = num;
					m_hist[w, 3] = m_hist[w, 2];
					m_hist[w, 2] = denormal_filter(x);
					outBuffer[outIndex] = (float)m_hist[w, 2];
					outIndex += span;
				}
			}

			private double denormal_filter(float x)
			{
				return x;
			}

			private double denormal_filter(double x)
			{
				return x;
			}
		}

		private const int WDL_RESAMPLE_MAX_FILTERS = 4;

		private const int WDL_RESAMPLE_MAX_NCH = 64;

		private const double PI = Math.PI;

		private double m_sratein;

		private double m_srateout;

		private double m_fracpos;

		private double m_ratio;

		private double m_filter_ratio;

		private float m_filterq;

		private float m_filterpos;

		private float[] m_rsinbuf;

		private float[] m_filter_coeffs;

		private WDL_Resampler_IIRFilter m_iirfilter;

		private int m_filter_coeffs_size;

		private int m_last_requested;

		private int m_filtlatency;

		private int m_samples_in_rsinbuf;

		private int m_lp_oversize;

		private int m_sincsize;

		private int m_filtercnt;

		private int m_sincoversize;

		private bool m_interp;

		private bool m_feedmode;

		/// <summary>
		/// Creates a new Resampler
		/// </summary>
		public WdlResampler()
		{
			m_filterq = 0.707f;
			m_filterpos = 0.693f;
			m_sincoversize = 0;
			m_lp_oversize = 1;
			m_sincsize = 0;
			m_filtercnt = 1;
			m_interp = true;
			m_feedmode = false;
			m_filter_coeffs_size = 0;
			m_sratein = 44100.0;
			m_srateout = 44100.0;
			m_ratio = 1.0;
			m_filter_ratio = -1.0;
			Reset();
		}

		/// <summary>
		/// sets the mode
		/// if sinc set, it overrides interp or filtercnt
		/// </summary>
		public void SetMode(bool interp, int filtercnt, bool sinc, int sinc_size = 64, int sinc_interpsize = 32)
		{
			m_sincsize = ((sinc && sinc_size >= 4) ? ((sinc_size > 8192) ? 8192 : sinc_size) : 0);
			m_sincoversize = ((m_sincsize == 0) ? 1 : ((sinc_interpsize <= 1) ? 1 : ((sinc_interpsize >= 4096) ? 4096 : sinc_interpsize)));
			m_filtercnt = ((m_sincsize == 0) ? ((filtercnt > 0) ? ((filtercnt >= 4) ? 4 : filtercnt) : 0) : 0);
			m_interp = interp && m_sincsize == 0;
			if (m_sincsize == 0)
			{
				m_filter_coeffs = new float[0];
				m_filter_coeffs_size = 0;
			}
			if (m_filtercnt == 0)
			{
				m_iirfilter = null;
			}
		}

		/// <summary>
		/// Sets the filter parameters
		/// used for filtercnt&gt;0 but not sinc
		/// </summary>
		public void SetFilterParms(float filterpos = 0.693f, float filterq = 0.707f)
		{
			m_filterpos = filterpos;
			m_filterq = filterq;
		}

		/// <summary>
		/// Set feed mode
		/// </summary>
		/// <param name="wantInputDriven">if true, that means the first parameter to ResamplePrepare will specify however much input you have, not how much you want</param>
		public void SetFeedMode(bool wantInputDriven)
		{
			m_feedmode = wantInputDriven;
		}

		/// <summary>
		/// Reset
		/// </summary>
		public void Reset(double fracpos = 0.0)
		{
			m_last_requested = 0;
			m_filtlatency = 0;
			m_fracpos = fracpos;
			m_samples_in_rsinbuf = 0;
			if (m_iirfilter != null)
			{
				m_iirfilter.Reset();
			}
		}

		/// <summary>
		/// Set input and output rates
		/// </summary>
		public void SetRates(double rate_in, double rate_out)
		{
			if (rate_in < 1.0)
			{
				rate_in = 1.0;
			}
			if (rate_out < 1.0)
			{
				rate_out = 1.0;
			}
			if (rate_in != m_sratein || rate_out != m_srateout)
			{
				m_sratein = rate_in;
				m_srateout = rate_out;
				m_ratio = m_sratein / m_srateout;
			}
		}

		/// <summary>
		/// amount of input that has been received but not yet converted to output, in seconds
		/// </summary>
		public double GetCurrentLatency()
		{
			double num = ((double)m_samples_in_rsinbuf - (double)m_filtlatency) / m_sratein;
			if (num < 0.0)
			{
				num = 0.0;
			}
			return num;
		}

		/// <summary>
		/// Prepare
		/// note that it is safe to call ResamplePrepare without calling ResampleOut (the next call of ResamplePrepare will function as normal)
		/// nb inbuffer was WDL_ResampleSample **, returning a place to put the in buffer, so we return a buffer and offset
		/// </summary>
		/// <param name="out_samples">req_samples is output samples desired if !wantInputDriven, or if wantInputDriven is input samples that we have</param>
		/// <param name="nch"></param>
		/// <param name="inbuffer"></param>
		/// <param name="inbufferOffset"></param>
		/// <returns>returns number of samples desired (put these into *inbuffer)</returns>
		public int ResamplePrepare(int out_samples, int nch, out float[] inbuffer, out int inbufferOffset)
		{
			if (nch > 64 || nch < 1)
			{
				inbuffer = null;
				inbufferOffset = 0;
				return 0;
			}
			int num = 0;
			if (m_sincsize > 1)
			{
				num = m_sincsize;
			}
			int num2 = num / 2;
			if (num2 > 1 && m_samples_in_rsinbuf < num2 - 1)
			{
				m_filtlatency += num2 - 1 - m_samples_in_rsinbuf;
				m_samples_in_rsinbuf = num2 - 1;
				if (m_samples_in_rsinbuf > 0)
				{
					m_rsinbuf = new float[m_samples_in_rsinbuf * nch];
				}
			}
			int num3 = 0;
			num3 = (m_feedmode ? out_samples : ((int)(m_ratio * (double)out_samples) + 4 + num - m_samples_in_rsinbuf));
			if (num3 < 0)
			{
				num3 = 0;
			}
			while (true)
			{
				Array.Resize(ref m_rsinbuf, (m_samples_in_rsinbuf + num3) * nch);
				int num4 = m_rsinbuf.Length / ((nch == 0) ? 1 : nch) - m_samples_in_rsinbuf;
				if (num4 == num3)
				{
					break;
				}
				if (num3 > 4 && num4 == 0)
				{
					num3 /= 2;
					continue;
				}
				num3 = num4;
				break;
			}
			inbuffer = m_rsinbuf;
			inbufferOffset = m_samples_in_rsinbuf * nch;
			m_last_requested = num3;
			return num3;
		}

		/// <summary>
		/// if numsamples_in &lt; the value return by ResamplePrepare(), then it will be flushed to produce all remaining valid samples
		/// do NOT call with nsamples_in greater than the value returned from resamplerprpare()! the extra samples will be ignored.
		/// returns number of samples successfully outputted to out
		/// </summary>
		public int ResampleOut(float[] outBuffer, int outBufferIndex, int nsamples_in, int nsamples_out, int nch)
		{
			if (nch > 64 || nch < 1)
			{
				return 0;
			}
			if (m_filtercnt > 0 && m_ratio > 1.0 && nsamples_in > 0)
			{
				if (m_iirfilter == null)
				{
					m_iirfilter = new WDL_Resampler_IIRFilter();
				}
				int filtercnt = m_filtercnt;
				m_iirfilter.setParms(1.0 / m_ratio * (double)m_filterpos, m_filterq);
				int num = m_samples_in_rsinbuf * nch;
				int num2 = 0;
				for (int i = 0; i < nch; i++)
				{
					for (int j = 0; j < filtercnt; j++)
					{
						m_iirfilter.Apply(m_rsinbuf, num + i, m_rsinbuf, num + i, nsamples_in, nch, num2++);
					}
				}
			}
			m_samples_in_rsinbuf += Math.Min(nsamples_in, m_last_requested);
			int num3 = m_samples_in_rsinbuf;
			if (nsamples_in < m_last_requested)
			{
				int num4 = (m_last_requested - nsamples_in) * 2 + m_sincsize * 2;
				int num5 = (m_samples_in_rsinbuf + num4) * nch;
				Array.Resize(ref m_rsinbuf, num5);
				if (m_rsinbuf.Length == num5)
				{
					Array.Clear(m_rsinbuf, m_samples_in_rsinbuf * nch, num4 * nch);
					num3 = m_samples_in_rsinbuf + num4;
				}
			}
			int num6 = 0;
			double num7 = m_fracpos;
			double ratio = m_ratio;
			int num8 = 0;
			int num9 = outBufferIndex;
			int num10 = nsamples_out;
			int num11 = 0;
			if (m_sincsize != 0)
			{
				if (m_ratio > 1.0)
				{
					BuildLowPass(1.0 / (m_ratio * 1.03));
				}
				else
				{
					BuildLowPass(1.0);
				}
				int filter_coeffs_size = m_filter_coeffs_size;
				int num12 = num3 - filter_coeffs_size;
				num11 = filter_coeffs_size / 2 - 1;
				int filterIndex = 0;
				if (nch == 1)
				{
					while (num10-- != 0)
					{
						int num13 = (int)num7;
						if (num13 >= num12 - 1)
						{
							break;
						}
						SincSample1(outBuffer, num9, m_rsinbuf, num8 + num13, num7 - (double)num13, m_filter_coeffs, filterIndex, filter_coeffs_size);
						num9++;
						num7 += ratio;
						num6++;
					}
				}
				else if (nch == 2)
				{
					while (num10-- != 0)
					{
						int num14 = (int)num7;
						if (num14 >= num12 - 1)
						{
							break;
						}
						SincSample2(outBuffer, num9, m_rsinbuf, num8 + num14 * 2, num7 - (double)num14, m_filter_coeffs, filterIndex, filter_coeffs_size);
						num9 += 2;
						num7 += ratio;
						num6++;
					}
				}
				else
				{
					while (num10-- != 0)
					{
						int num15 = (int)num7;
						if (num15 >= num12 - 1)
						{
							break;
						}
						SincSample(outBuffer, num9, m_rsinbuf, num8 + num15 * nch, num7 - (double)num15, nch, m_filter_coeffs, filterIndex, filter_coeffs_size);
						num9 += nch;
						num7 += ratio;
						num6++;
					}
				}
			}
			else if (!m_interp)
			{
				if (nch == 1)
				{
					while (num10-- != 0)
					{
						int num16 = (int)num7;
						if (num16 >= num3)
						{
							break;
						}
						outBuffer[num9++] = m_rsinbuf[num8 + num16];
						num7 += ratio;
						num6++;
					}
				}
				else if (nch == 2)
				{
					while (num10-- != 0)
					{
						int num17 = (int)num7;
						if (num17 >= num3)
						{
							break;
						}
						num17 += num17;
						outBuffer[num9] = m_rsinbuf[num8 + num17];
						outBuffer[num9 + 1] = m_rsinbuf[num8 + num17 + 1];
						num9 += 2;
						num7 += ratio;
						num6++;
					}
				}
				else
				{
					while (num10-- != 0)
					{
						int num18 = (int)num7;
						if (num18 >= num3)
						{
							break;
						}
						Array.Copy(m_rsinbuf, num8 + num18 * nch, outBuffer, num9, nch);
						num9 += nch;
						num7 += ratio;
						num6++;
					}
				}
			}
			else if (nch == 1)
			{
				while (num10-- != 0)
				{
					int num19 = (int)num7;
					double num20 = num7 - (double)num19;
					if (num19 >= num3 - 1)
					{
						break;
					}
					double num21 = 1.0 - num20;
					int num22 = num8 + num19;
					outBuffer[num9++] = (float)((double)m_rsinbuf[num22] * num21 + (double)m_rsinbuf[num22 + 1] * num20);
					num7 += ratio;
					num6++;
				}
			}
			else if (nch == 2)
			{
				while (num10-- != 0)
				{
					int num23 = (int)num7;
					double num24 = num7 - (double)num23;
					if (num23 >= num3 - 1)
					{
						break;
					}
					double num25 = 1.0 - num24;
					int num26 = num8 + num23 * 2;
					outBuffer[num9] = (float)((double)m_rsinbuf[num26] * num25 + (double)m_rsinbuf[num26 + 2] * num24);
					outBuffer[num9 + 1] = (float)((double)m_rsinbuf[num26 + 1] * num25 + (double)m_rsinbuf[num26 + 3] * num24);
					num9 += 2;
					num7 += ratio;
					num6++;
				}
			}
			else
			{
				while (num10-- != 0)
				{
					int num27 = (int)num7;
					double num28 = num7 - (double)num27;
					if (num27 >= num3 - 1)
					{
						break;
					}
					double num29 = 1.0 - num28;
					int num30 = nch;
					int num31 = num8 + num27 * nch;
					while (num30-- != 0)
					{
						outBuffer[num9++] = (float)((double)m_rsinbuf[num31] * num29 + (double)m_rsinbuf[num31 + nch] * num28);
						num31++;
					}
					num7 += ratio;
					num6++;
				}
			}
			if (m_filtercnt > 0 && m_ratio < 1.0 && num6 > 0)
			{
				if (m_iirfilter == null)
				{
					m_iirfilter = new WDL_Resampler_IIRFilter();
				}
				int filtercnt2 = m_filtercnt;
				m_iirfilter.setParms(m_ratio * (double)m_filterpos, m_filterq);
				int num32 = 0;
				for (int k = 0; k < nch; k++)
				{
					for (int l = 0; l < filtercnt2; l++)
					{
						m_iirfilter.Apply(outBuffer, k, outBuffer, k, num6, nch, num32++);
					}
				}
			}
			if (num6 > 0 && num3 > m_samples_in_rsinbuf)
			{
				double num33 = (num7 - (double)m_samples_in_rsinbuf + (double)num11) / ratio;
				if (num33 > 0.0)
				{
					num6 -= (int)(num33 + 0.5);
					if (num6 < 0)
					{
						num6 = 0;
					}
				}
			}
			int num34 = (int)num7;
			m_fracpos = num7 - (double)num34;
			m_samples_in_rsinbuf -= num34;
			if (m_samples_in_rsinbuf <= 0)
			{
				m_samples_in_rsinbuf = 0;
			}
			else
			{
				Array.Copy(m_rsinbuf, num8 + num34 * nch, m_rsinbuf, num8, m_samples_in_rsinbuf * nch);
			}
			return num6;
		}

		private void BuildLowPass(double filtpos)
		{
			int sincsize = m_sincsize;
			int sincoversize = m_sincoversize;
			if (m_filter_ratio == filtpos && m_filter_coeffs_size == sincsize && m_lp_oversize == sincoversize)
			{
				return;
			}
			m_lp_oversize = sincoversize;
			m_filter_ratio = filtpos;
			int num = (sincsize + 1) * m_lp_oversize;
			Array.Resize(ref m_filter_coeffs, num);
			if (m_filter_coeffs.Length == num)
			{
				m_filter_coeffs_size = sincsize;
				int num2 = sincsize * m_lp_oversize;
				int num3 = num2 / 2;
				double num4 = 0.0;
				double num5 = 0.0;
				double num6 = Math.PI * 2.0 / (double)num2;
				double num7 = Math.PI / (double)m_lp_oversize * filtpos;
				double num8 = num7 * (double)(-num3);
				for (int i = -num3; i < num3 + m_lp_oversize; i++)
				{
					double num9 = 287.0 / 800.0 - 0.48829 * Math.Cos(num5) + 0.14128 * Math.Cos(2.0 * num5) - 0.01168 * Math.Cos(6.0 * num5);
					if (i != 0)
					{
						num9 *= Math.Sin(num8) / num8;
					}
					num5 += num6;
					num8 += num7;
					m_filter_coeffs[num3 + i] = (float)num9;
					if (i < num3)
					{
						num4 += num9;
					}
				}
				num4 = (double)m_lp_oversize / num4;
				for (int i = 0; i < num2 + m_lp_oversize; i++)
				{
					m_filter_coeffs[i] = (float)((double)m_filter_coeffs[i] * num4);
				}
			}
			else
			{
				m_filter_coeffs_size = 0;
			}
		}

		private void SincSample(float[] outBuffer, int outBufferIndex, float[] inBuffer, int inBufferIndex, double fracpos, int nch, float[] filter, int filterIndex, int filtsz)
		{
			int lp_oversize = m_lp_oversize;
			fracpos *= (double)lp_oversize;
			int num = (int)fracpos;
			filterIndex += lp_oversize - 1 - num;
			fracpos -= (double)num;
			for (int i = 0; i < nch; i++)
			{
				double num2 = 0.0;
				double num3 = 0.0;
				int num4 = filterIndex;
				int num5 = inBufferIndex + i;
				int num6 = filtsz;
				while (num6-- != 0)
				{
					num2 += (double)(filter[num4] * inBuffer[num5]);
					num3 += (double)(filter[num4 + 1] * inBuffer[num5]);
					num5 += nch;
					num4 += lp_oversize;
				}
				outBuffer[outBufferIndex + i] = (float)(num2 * fracpos + num3 * (1.0 - fracpos));
			}
		}

		private void SincSample1(float[] outBuffer, int outBufferIndex, float[] inBuffer, int inBufferIndex, double fracpos, float[] filter, int filterIndex, int filtsz)
		{
			int lp_oversize = m_lp_oversize;
			fracpos *= (double)lp_oversize;
			int num = (int)fracpos;
			filterIndex += lp_oversize - 1 - num;
			fracpos -= (double)num;
			double num2 = 0.0;
			double num3 = 0.0;
			int num4 = filterIndex;
			int num5 = inBufferIndex;
			int num6 = filtsz;
			while (num6-- != 0)
			{
				num2 += (double)(filter[num4] * inBuffer[num5]);
				num3 += (double)(filter[num4 + 1] * inBuffer[num5]);
				num5++;
				num4 += lp_oversize;
			}
			outBuffer[outBufferIndex] = (float)(num2 * fracpos + num3 * (1.0 - fracpos));
		}

		private void SincSample2(float[] outptr, int outBufferIndex, float[] inBuffer, int inBufferIndex, double fracpos, float[] filter, int filterIndex, int filtsz)
		{
			int lp_oversize = m_lp_oversize;
			fracpos *= (double)lp_oversize;
			int num = (int)fracpos;
			filterIndex += lp_oversize - 1 - num;
			fracpos -= (double)num;
			double num2 = 0.0;
			double num3 = 0.0;
			double num4 = 0.0;
			double num5 = 0.0;
			int num6 = filterIndex;
			int num7 = inBufferIndex;
			int num8 = filtsz / 2;
			while (num8-- != 0)
			{
				num2 += (double)(filter[num6] * inBuffer[num7]);
				num3 += (double)(filter[num6] * inBuffer[num7 + 1]);
				num4 += (double)(filter[num6 + 1] * inBuffer[num7]);
				num5 += (double)(filter[num6 + 1] * inBuffer[num7 + 1]);
				num2 += (double)(filter[num6 + lp_oversize] * inBuffer[num7 + 2]);
				num3 += (double)(filter[num6 + lp_oversize] * inBuffer[num7 + 3]);
				num4 += (double)(filter[num6 + lp_oversize + 1] * inBuffer[num7 + 2]);
				num5 += (double)(filter[num6 + lp_oversize + 1] * inBuffer[num7 + 3]);
				num7 += 4;
				num6 += lp_oversize * 2;
			}
			outptr[outBufferIndex] = (float)(num2 * fracpos + num4 * (1.0 - fracpos));
			outptr[outBufferIndex + 1] = (float)(num3 * fracpos + num5 * (1.0 - fracpos));
		}
	}
}

namespace NAudio.Wave.SampleProviders
{
	using NAudio.Dsp;
	using NAudio.Utils;
	
	/// <summary>
	/// ADSR sample provider allowing you to specify attack, decay, sustain and release values
	/// </summary>
	public class AdsrSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider source;

		private readonly EnvelopeGenerator adsr;

		private float attackSeconds;

		private float releaseSeconds;

		/// <summary>
		/// Attack time in seconds
		/// </summary>
		public float AttackSeconds
		{
			get
			{
				return attackSeconds;
			}
			set
			{
				attackSeconds = value;
				adsr.AttackRate = attackSeconds * (float)WaveFormat.SampleRate;
			}
		}

		/// <summary>
		/// Release time in seconds
		/// </summary>
		public float ReleaseSeconds
		{
			get
			{
				return releaseSeconds;
			}
			set
			{
				releaseSeconds = value;
				adsr.ReleaseRate = releaseSeconds * (float)WaveFormat.SampleRate;
			}
		}

		/// <summary>
		/// The output WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Creates a new AdsrSampleProvider with default values
		/// </summary>
		public AdsrSampleProvider(ISampleProvider source)
		{
			if (source.WaveFormat.Channels > 1)
			{
				throw new ArgumentException("Currently only supports mono inputs");
			}
			this.source = source;
			adsr = new EnvelopeGenerator();
			AttackSeconds = 0.01f;
			adsr.SustainLevel = 1f;
			adsr.DecayRate = 0f * (float)WaveFormat.SampleRate;
			ReleaseSeconds = 0.3f;
			adsr.Gate(gate: true);
		}

		/// <summary>
		/// Reads audio from this sample provider
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			if (adsr.State == EnvelopeGenerator.EnvelopeState.Idle)
			{
				return 0;
			}
			int num = source.Read(buffer, offset, count);
			for (int i = 0; i < num; i++)
			{
				buffer[offset++] *= adsr.Process();
			}
			return num;
		}

		/// <summary>
		/// Enters the Release phase
		/// </summary>
		public void Stop()
		{
			adsr.Gate(gate: false);
		}
	}

	/// <summary>
	/// Sample Provider to concatenate multiple sample providers together
	/// </summary>
	public class ConcatenatingSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider[] providers;

		private int currentProviderIndex;

		/// <summary>
		/// The WaveFormat of this Sample Provider
		/// </summary>
		public WaveFormat WaveFormat => providers[0].WaveFormat;

		/// <summary>
		/// Creates a new ConcatenatingSampleProvider
		/// </summary>
		/// <param name="providers">The source providers to play one after the other. Must all share the same sample rate and channel count</param>
		public ConcatenatingSampleProvider(IEnumerable<ISampleProvider> providers)
		{
			if (providers == null)
			{
				throw new ArgumentNullException("providers");
			}
			this.providers = providers.ToArray();
			if (this.providers.Length == 0)
			{
				throw new ArgumentException("Must provide at least one input", "providers");
			}
			if (this.providers.Any((ISampleProvider p) => p.WaveFormat.Channels != WaveFormat.Channels))
			{
				throw new ArgumentException("All inputs must have the same channel count", "providers");
			}
			if (this.providers.Any((ISampleProvider p) => p.WaveFormat.SampleRate != WaveFormat.SampleRate))
			{
				throw new ArgumentException("All inputs must have the same sample rate", "providers");
			}
		}

		/// <summary>
		/// Read Samples from this sample provider
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = 0;
			while (num < count && currentProviderIndex < providers.Length)
			{
				int count2 = count - num;
				int num2 = providers[currentProviderIndex].Read(buffer, offset + num, count2);
				num += num2;
				if (num2 == 0)
				{
					currentProviderIndex++;
				}
			}
			return num;
		}
	}

	/// <summary>
	/// Sample Provider to allow fading in and out
	/// </summary>
	public class FadeInOutSampleProvider : ISampleProvider
	{
		private enum FadeState
		{
			Silence,
			FadingIn,
			FullVolume,
			FadingOut
		}

		private readonly object lockObject = new object();

		private readonly ISampleProvider source;

		private int fadeSamplePosition;

		private int fadeSampleCount;

		private FadeState fadeState;

		/// <summary>
		/// WaveFormat of this SampleProvider
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Creates a new FadeInOutSampleProvider
		/// </summary>
		/// <param name="source">The source stream with the audio to be faded in or out</param>
		/// <param name="initiallySilent">If true, we start faded out</param>
		public FadeInOutSampleProvider(ISampleProvider source, bool initiallySilent = false)
		{
			this.source = source;
			fadeState = ((!initiallySilent) ? FadeState.FullVolume : FadeState.Silence);
		}

		/// <summary>
		/// Requests that a fade-in begins (will start on the next call to Read)
		/// </summary>
		/// <param name="fadeDurationInMilliseconds">Duration of fade in milliseconds</param>
		public void BeginFadeIn(double fadeDurationInMilliseconds)
		{
			lock (lockObject)
			{
				fadeSamplePosition = 0;
				fadeSampleCount = (int)(fadeDurationInMilliseconds * (double)source.WaveFormat.SampleRate / 1000.0);
				fadeState = FadeState.FadingIn;
			}
		}

		/// <summary>
		/// Requests that a fade-out begins (will start on the next call to Read)
		/// </summary>
		/// <param name="fadeDurationInMilliseconds">Duration of fade in milliseconds</param>
		public void BeginFadeOut(double fadeDurationInMilliseconds)
		{
			lock (lockObject)
			{
				fadeSamplePosition = 0;
				fadeSampleCount = (int)(fadeDurationInMilliseconds * (double)source.WaveFormat.SampleRate / 1000.0);
				fadeState = FadeState.FadingOut;
			}
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Buffer to read into</param>
		/// <param name="offset">Offset within buffer to write to</param>
		/// <param name="count">Number of samples desired</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = source.Read(buffer, offset, count);
			lock (lockObject)
			{
				if (fadeState == FadeState.FadingIn)
				{
					FadeIn(buffer, offset, num);
				}
				else if (fadeState == FadeState.FadingOut)
				{
					FadeOut(buffer, offset, num);
				}
				else if (fadeState == FadeState.Silence)
				{
					ClearBuffer(buffer, offset, count);
				}
			}
			return num;
		}

		private static void ClearBuffer(float[] buffer, int offset, int count)
		{
			for (int i = 0; i < count; i++)
			{
				buffer[i + offset] = 0f;
			}
		}

		private void FadeOut(float[] buffer, int offset, int sourceSamplesRead)
		{
			int num = 0;
			while (num < sourceSamplesRead)
			{
				float num2 = 1f - (float)fadeSamplePosition / (float)fadeSampleCount;
				for (int i = 0; i < source.WaveFormat.Channels; i++)
				{
					buffer[offset + num++] *= num2;
				}
				fadeSamplePosition++;
				if (fadeSamplePosition > fadeSampleCount)
				{
					fadeState = FadeState.Silence;
					ClearBuffer(buffer, num + offset, sourceSamplesRead - num);
					break;
				}
			}
		}

		private void FadeIn(float[] buffer, int offset, int sourceSamplesRead)
		{
			int num = 0;
			while (num < sourceSamplesRead)
			{
				float num2 = (float)fadeSamplePosition / (float)fadeSampleCount;
				for (int i = 0; i < source.WaveFormat.Channels; i++)
				{
					buffer[offset + num++] *= num2;
				}
				fadeSamplePosition++;
				if (fadeSamplePosition > fadeSampleCount)
				{
					fadeState = FadeState.FullVolume;
					break;
				}
			}
		}
	}

	/// <summary>
	/// Required Interface for a Panning Strategy
	/// </summary>
	public interface IPanStrategy
	{
		/// <summary>
		/// Gets the left and right multipliers for a given pan value
		/// </summary>
		/// <param name="pan">Pan value from -1 to 1</param>
		/// <returns>Left and right multipliers in a stereo sample pair</returns>
		StereoSamplePair GetMultipliers(float pan);
	}

	/// <summary>
	/// Sample provider interface to make WaveChannel32 extensible
	/// Still a bit ugly, hence internal at the moment - and might even make these into
	/// bit depth converting WaveProviders
	/// </summary>
	internal interface ISampleChunkConverter
	{
		bool Supports(WaveFormat format);

		void LoadNextChunk(IWaveProvider sourceProvider, int samplePairsRequired);

		bool GetNextSample(out float sampleLeft, out float sampleRight);
	}

	/// <summary>
	/// Linear Pan
	/// </summary>
	public class LinearPanStrategy : IPanStrategy
	{
		/// <summary>
		/// Gets the left and right channel multipliers for this pan value
		/// </summary>
		/// <param name="pan">Pan value, between -1 and 1</param>
		/// <returns>Left and right multipliers</returns>
		public StereoSamplePair GetMultipliers(float pan)
		{
			float num = (0f - pan + 1f) / 2f;
			float left = num;
			float right = 1f - num;
			StereoSamplePair result = default(StereoSamplePair);
			result.Left = left;
			result.Right = right;
			return result;
		}
	}

	/// <summary>
	/// Simple SampleProvider that passes through audio unchanged and raises
	/// an event every n samples with the maximum sample value from the period
	/// for metering purposes
	/// </summary>
	public class MeteringSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider source;

		private readonly float[] maxSamples;

		private int sampleCount;

		private readonly int channels;

		private readonly StreamVolumeEventArgs args;

		/// <summary>
		/// Number of Samples per notification
		/// </summary>
		public int SamplesPerNotification { get; set; }

		/// <summary>
		/// The WaveFormat of this sample provider
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Raised periodically to inform the user of the max volume
		/// </summary>
		public event EventHandler<StreamVolumeEventArgs> StreamVolume;

		/// <summary>
		/// Initialises a new instance of MeteringSampleProvider that raises 10 stream volume
		/// events per second
		/// </summary>
		/// <param name="source">Source sample provider</param>
		public MeteringSampleProvider(ISampleProvider source)
			: this(source, source.WaveFormat.SampleRate / 10)
		{
		}

		/// <summary>
		/// Initialises a new instance of MeteringSampleProvider 
		/// </summary>
		/// <param name="source">source sampler provider</param>
		/// <param name="samplesPerNotification">Number of samples between notifications</param>
		public MeteringSampleProvider(ISampleProvider source, int samplesPerNotification)
		{
			this.source = source;
			channels = source.WaveFormat.Channels;
			maxSamples = new float[channels];
			SamplesPerNotification = samplesPerNotification;
			args = new StreamVolumeEventArgs
			{
				MaxSampleValues = maxSamples
			};
		}

		/// <summary>
		/// Reads samples from this Sample Provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = source.Read(buffer, offset, count);
			if (this.StreamVolume != null)
			{
				for (int i = 0; i < num; i += channels)
				{
					for (int j = 0; j < channels; j++)
					{
						float val = Math.Abs(buffer[offset + i + j]);
						maxSamples[j] = Math.Max(maxSamples[j], val);
					}
					sampleCount++;
					if (sampleCount >= SamplesPerNotification)
					{
						this.StreamVolume(this, args);
						sampleCount = 0;
						Array.Clear(maxSamples, 0, channels);
					}
				}
			}
			return num;
		}
	}

	/// <summary>
	/// A sample provider mixer, allowing inputs to be added and removed
	/// </summary>
	public class MixingSampleProvider : ISampleProvider
	{
		private readonly List<ISampleProvider> sources;

		private float[] sourceBuffer;

		private const int MaxInputs = 1024;

		/// <summary>
		/// Returns the mixer inputs (read-only - use AddMixerInput to add an input
		/// </summary>
		public IEnumerable<ISampleProvider> MixerInputs => sources;

		/// <summary>
		/// When set to true, the Read method always returns the number
		/// of samples requested, even if there are no inputs, or if the
		/// current inputs reach their end. Setting this to true effectively
		/// makes this a never-ending sample provider, so take care if you plan
		/// to write it out to a file.
		/// </summary>
		public bool ReadFully { get; set; }

		/// <summary>
		/// The output WaveFormat of this sample provider
		/// </summary>
		public WaveFormat WaveFormat { get; private set; }

		/// <summary>
		/// Raised when a mixer input has been removed because it has ended
		/// </summary>
		public event EventHandler<SampleProviderEventArgs> MixerInputEnded;

		/// <summary>
		/// Creates a new MixingSampleProvider, with no inputs, but a specified WaveFormat
		/// </summary>
		/// <param name="waveFormat">The WaveFormat of this mixer. All inputs must be in this format</param>
		public MixingSampleProvider(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Mixer wave format must be IEEE float");
			}
			sources = new List<ISampleProvider>();
			WaveFormat = waveFormat;
		}

		/// <summary>
		/// Creates a new MixingSampleProvider, based on the given inputs
		/// </summary>
		/// <param name="sources">Mixer inputs - must all have the same waveformat, and must
		/// all be of the same WaveFormat. There must be at least one input</param>
		public MixingSampleProvider(IEnumerable<ISampleProvider> sources)
		{
			this.sources = new List<ISampleProvider>();
			foreach (ISampleProvider source in sources)
			{
				AddMixerInput(source);
			}
			if (this.sources.Count == 0)
			{
				throw new ArgumentException("Must provide at least one input in this constructor");
			}
		}

		/// <summary>
		/// Adds a WaveProvider as a Mixer input.
		/// Must be PCM or IEEE float already
		/// </summary>
		/// <param name="mixerInput">IWaveProvider mixer input</param>
		public void AddMixerInput(IWaveProvider mixerInput)
		{
			AddMixerInput(SampleProviderConverters.ConvertWaveProviderIntoSampleProvider(mixerInput));
		}

		/// <summary>
		/// Adds a new mixer input
		/// </summary>
		/// <param name="mixerInput">Mixer input</param>
		public void AddMixerInput(ISampleProvider mixerInput)
		{
			lock (sources)
			{
				if (sources.Count >= 1024)
				{
					throw new InvalidOperationException("Too many mixer inputs");
				}
				sources.Add(mixerInput);
			}
			if (WaveFormat == null)
			{
				WaveFormat = mixerInput.WaveFormat;
			}
			else if (WaveFormat.SampleRate != mixerInput.WaveFormat.SampleRate || WaveFormat.Channels != mixerInput.WaveFormat.Channels)
			{
				throw new ArgumentException("All mixer inputs must have the same WaveFormat");
			}
		}

		/// <summary>
		/// Removes a mixer input
		/// </summary>
		/// <param name="mixerInput">Mixer input to remove</param>
		public void RemoveMixerInput(ISampleProvider mixerInput)
		{
			lock (sources)
			{
				sources.Remove(mixerInput);
			}
		}

		/// <summary>
		/// Removes all mixer inputs
		/// </summary>
		public void RemoveAllMixerInputs()
		{
			lock (sources)
			{
				sources.Clear();
			}
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = 0;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, count);
			lock (sources)
			{
				for (int num2 = sources.Count - 1; num2 >= 0; num2--)
				{
					ISampleProvider sampleProvider = sources[num2];
					int num3 = sampleProvider.Read(sourceBuffer, 0, count);
					int num4 = offset;
					for (int i = 0; i < num3; i++)
					{
						if (i >= num)
						{
							buffer[num4++] = sourceBuffer[i];
						}
						else
						{
							buffer[num4++] += sourceBuffer[i];
						}
					}
					num = Math.Max(num3, num);
					if (num3 < count)
					{
						this.MixerInputEnded?.Invoke(this, new SampleProviderEventArgs(sampleProvider));
						sources.RemoveAt(num2);
					}
				}
			}
			if (ReadFully && num < count)
			{
				int num5 = offset + num;
				while (num5 < offset + count)
				{
					buffer[num5++] = 0f;
				}
				num = count;
			}
			return num;
		}
	}

	internal class Mono16SampleChunkConverter : ISampleChunkConverter
	{
		private int sourceSample;

		private byte[] sourceBuffer;

		private WaveBuffer sourceWaveBuffer;

		private int sourceSamples;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 16)
			{
				return waveFormat.Channels == 1;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 2;
			sourceSample = 0;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceWaveBuffer = new WaveBuffer(sourceBuffer);
			sourceSamples = source.Read(sourceBuffer, 0, num) / 2;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (sourceSample < sourceSamples)
			{
				sampleLeft = (float)sourceWaveBuffer.ShortBuffer[sourceSample++] / 32768f;
				sampleRight = sampleLeft;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	internal class Mono24SampleChunkConverter : ISampleChunkConverter
	{
		private int offset;

		private byte[] sourceBuffer;

		private int sourceBytes;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 24)
			{
				return waveFormat.Channels == 1;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 3;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceBytes = source.Read(sourceBuffer, 0, num);
			offset = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (offset < sourceBytes)
			{
				sampleLeft = (float)(((sbyte)sourceBuffer[offset + 2] << 16) | (sourceBuffer[offset + 1] << 8) | sourceBuffer[offset]) / 8388608f;
				offset += 3;
				sampleRight = sampleLeft;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	internal class Mono8SampleChunkConverter : ISampleChunkConverter
	{
		private int offset;

		private byte[] sourceBuffer;

		private int sourceBytes;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 8)
			{
				return waveFormat.Channels == 1;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, samplePairsRequired);
			sourceBytes = source.Read(sourceBuffer, 0, samplePairsRequired);
			offset = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (offset < sourceBytes)
			{
				sampleLeft = (float)(int)sourceBuffer[offset] / 256f;
				offset++;
				sampleRight = sampleLeft;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	internal class MonoFloatSampleChunkConverter : ISampleChunkConverter
	{
		private int sourceSample;

		private byte[] sourceBuffer;

		private WaveBuffer sourceWaveBuffer;

		private int sourceSamples;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
			{
				return waveFormat.Channels == 1;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 4;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceWaveBuffer = new WaveBuffer(sourceBuffer);
			sourceSamples = source.Read(sourceBuffer, 0, num) / 4;
			sourceSample = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (sourceSample < sourceSamples)
			{
				sampleLeft = sourceWaveBuffer.FloatBuffer[sourceSample++];
				sampleRight = sampleLeft;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	/// <summary>
	/// No nonsense mono to stereo provider, no volume adjustment,
	/// just copies input to left and right. 
	/// </summary>
	public class MonoToStereoSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider source;

		private float[] sourceBuffer;

		/// <summary>
		/// WaveFormat of this provider
		/// </summary>
		public WaveFormat WaveFormat { get; }

		/// <summary>
		/// Multiplier for left channel (default is 1.0)
		/// </summary>
		public float LeftVolume { get; set; }

		/// <summary>
		/// Multiplier for right channel (default is 1.0)
		/// </summary>
		public float RightVolume { get; set; }

		/// <summary>
		/// Initializes a new instance of MonoToStereoSampleProvider
		/// </summary>
		/// <param name="source">Source sample provider</param>
		public MonoToStereoSampleProvider(ISampleProvider source)
		{
			LeftVolume = 1f;
			RightVolume = 1f;
			if (source.WaveFormat.Channels != 1)
			{
				throw new ArgumentException("Source must be mono");
			}
			this.source = source;
			WaveFormat = WaveFormat.CreateIeeeFloatWaveFormat(source.WaveFormat.SampleRate, 2);
		}

		/// <summary>
		/// Reads samples from this provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int count2 = count / 2;
			int num = offset;
			EnsureSourceBuffer(count2);
			int num2 = source.Read(sourceBuffer, 0, count2);
			for (int i = 0; i < num2; i++)
			{
				buffer[num++] = sourceBuffer[i] * LeftVolume;
				buffer[num++] = sourceBuffer[i] * RightVolume;
			}
			return num2 * 2;
		}

		private void EnsureSourceBuffer(int count)
		{
			if (sourceBuffer == null || sourceBuffer.Length < count)
			{
				sourceBuffer = new float[count];
			}
		}
	}

	/// <summary>
	/// Allows any number of inputs to be patched to outputs
	/// Uses could include swapping left and right channels, turning mono into stereo,
	/// feeding different input sources to different soundcard outputs etc
	/// </summary>
	public class MultiplexingSampleProvider : ISampleProvider
	{
		private readonly IList<ISampleProvider> inputs;

		private readonly WaveFormat waveFormat;

		private readonly int outputChannelCount;

		private readonly int inputChannelCount;

		private readonly List<int> mappings;

		/// <summary>
		/// persistent temporary buffer to prevent creating work for garbage collector
		/// </summary>
		private float[] inputBuffer;

		/// <summary>
		/// The output WaveFormat for this SampleProvider
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// The number of input channels. Note that this is not the same as the number of input wave providers. If you pass in
		/// one stereo and one mono input provider, the number of input channels is three.
		/// </summary>
		public int InputChannelCount => inputChannelCount;

		/// <summary>
		/// The number of output channels, as specified in the constructor.
		/// </summary>
		public int OutputChannelCount => outputChannelCount;

		/// <summary>
		/// Creates a multiplexing sample provider, allowing re-patching of input channels to different
		/// output channels
		/// </summary>
		/// <param name="inputs">Input sample providers. Must all be of the same sample rate, but can have any number of channels</param>
		/// <param name="numberOfOutputChannels">Desired number of output channels.</param>
		public MultiplexingSampleProvider(IEnumerable<ISampleProvider> inputs, int numberOfOutputChannels)
		{
			this.inputs = new List<ISampleProvider>(inputs);
			outputChannelCount = numberOfOutputChannels;
			if (this.inputs.Count == 0)
			{
				throw new ArgumentException("You must provide at least one input");
			}
			if (numberOfOutputChannels < 1)
			{
				throw new ArgumentException("You must provide at least one output");
			}
			foreach (ISampleProvider input in this.inputs)
			{
				if (waveFormat == null)
				{
					if (input.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
					{
						throw new ArgumentException("Only 32 bit float is supported");
					}
					waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(input.WaveFormat.SampleRate, numberOfOutputChannels);
				}
				else
				{
					if (input.WaveFormat.BitsPerSample != waveFormat.BitsPerSample)
					{
						throw new ArgumentException("All inputs must have the same bit depth");
					}
					if (input.WaveFormat.SampleRate != waveFormat.SampleRate)
					{
						throw new ArgumentException("All inputs must have the same sample rate");
					}
				}
				inputChannelCount += input.WaveFormat.Channels;
			}
			mappings = new List<int>();
			for (int i = 0; i < outputChannelCount; i++)
			{
				mappings.Add(i % inputChannelCount);
			}
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Buffer to be filled with sample data</param>
		/// <param name="offset">Offset into buffer to start writing to, usually 0</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = count / outputChannelCount;
			int num2 = 0;
			int num3 = 0;
			foreach (ISampleProvider input in inputs)
			{
				int num4 = num * input.WaveFormat.Channels;
				inputBuffer = BufferHelpers.Ensure(inputBuffer, num4);
				int num5 = input.Read(inputBuffer, 0, num4);
				num3 = Math.Max(num3, num5 / input.WaveFormat.Channels);
				for (int i = 0; i < input.WaveFormat.Channels; i++)
				{
					int num6 = num2 + i;
					for (int j = 0; j < outputChannelCount; j++)
					{
						if (mappings[j] != num6)
						{
							continue;
						}
						int num7 = i;
						int num8 = offset + j;
						int k;
						for (k = 0; k < num; k++)
						{
							if (num7 >= num5)
							{
								break;
							}
							buffer[num8] = inputBuffer[num7];
							num8 += outputChannelCount;
							num7 += input.WaveFormat.Channels;
						}
						for (; k < num; k++)
						{
							buffer[num8] = 0f;
							num8 += outputChannelCount;
						}
					}
				}
				num2 += input.WaveFormat.Channels;
			}
			return num3 * outputChannelCount;
		}

		/// <summary>
		/// Connects a specified input channel to an output channel
		/// </summary>
		/// <param name="inputChannel">Input Channel index (zero based). Must be less than InputChannelCount</param>
		/// <param name="outputChannel">Output Channel index (zero based). Must be less than OutputChannelCount</param>
		public void ConnectInputToOutput(int inputChannel, int outputChannel)
		{
			if (inputChannel < 0 || inputChannel >= InputChannelCount)
			{
				throw new ArgumentException("Invalid input channel");
			}
			if (outputChannel < 0 || outputChannel >= OutputChannelCount)
			{
				throw new ArgumentException("Invalid output channel");
			}
			mappings[outputChannel] = inputChannel;
		}
	}

	/// <summary>
	/// Simple class that raises an event on every sample
	/// </summary>
	public class NotifyingSampleProvider : ISampleProvider, ISampleNotifier
	{
		private readonly ISampleProvider source;

		private readonly SampleEventArgs sampleArgs = new SampleEventArgs(0f, 0f);

		private readonly int channels;

		/// <summary>
		/// WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Sample notifier
		/// </summary>
		public event EventHandler<SampleEventArgs> Sample;

		/// <summary>
		/// Initializes a new instance of NotifyingSampleProvider
		/// </summary>
		/// <param name="source">Source Sample Provider</param>
		public NotifyingSampleProvider(ISampleProvider source)
		{
			this.source = source;
			channels = WaveFormat.Channels;
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="sampleCount">Number of samples desired</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int sampleCount)
		{
			int num = source.Read(buffer, offset, sampleCount);
			if (this.Sample != null)
			{
				for (int i = 0; i < num; i += channels)
				{
					sampleArgs.Left = buffer[offset + i];
					sampleArgs.Right = ((channels > 1) ? buffer[offset + i + 1] : sampleArgs.Left);
					this.Sample(this, sampleArgs);
				}
			}
			return num;
		}
	}

	/// <summary>
	/// Allows you to:
	/// 1. insert a pre-delay of silence before the source begins
	/// 2. skip over a certain amount of the beginning of the source
	/// 3. only play a set amount from the source
	/// 4. insert silence at the end after the source is complete
	/// </summary>
	public class OffsetSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider sourceProvider;

		private int phase;

		private int phasePos;

		private int delayBySamples;

		private int skipOverSamples;

		private int takeSamples;

		private int leadOutSamples;

		/// <summary>
		/// Number of samples of silence to insert before playing source
		/// </summary>
		public int DelayBySamples
		{
			get
			{
				return delayBySamples;
			}
			set
			{
				if (phase != 0)
				{
					throw new InvalidOperationException("Can't set DelayBySamples after calling Read");
				}
				if (value % WaveFormat.Channels != 0)
				{
					throw new ArgumentException("DelayBySamples must be a multiple of WaveFormat.Channels");
				}
				delayBySamples = value;
			}
		}

		/// <summary>
		/// Amount of silence to insert before playing
		/// </summary>
		public TimeSpan DelayBy
		{
			get
			{
				return SamplesToTimeSpan(delayBySamples);
			}
			set
			{
				delayBySamples = TimeSpanToSamples(value);
			}
		}

		/// <summary>
		/// Number of samples in source to discard
		/// </summary>
		public int SkipOverSamples
		{
			get
			{
				return skipOverSamples;
			}
			set
			{
				if (phase != 0)
				{
					throw new InvalidOperationException("Can't set SkipOverSamples after calling Read");
				}
				if (value % WaveFormat.Channels != 0)
				{
					throw new ArgumentException("SkipOverSamples must be a multiple of WaveFormat.Channels");
				}
				skipOverSamples = value;
			}
		}

		/// <summary>
		/// Amount of audio to skip over from the source before beginning playback
		/// </summary>
		public TimeSpan SkipOver
		{
			get
			{
				return SamplesToTimeSpan(skipOverSamples);
			}
			set
			{
				skipOverSamples = TimeSpanToSamples(value);
			}
		}

		/// <summary>
		/// Number of samples to read from source (if 0, then read it all)
		/// </summary>
		public int TakeSamples
		{
			get
			{
				return takeSamples;
			}
			set
			{
				if (phase != 0)
				{
					throw new InvalidOperationException("Can't set TakeSamples after calling Read");
				}
				if (value % WaveFormat.Channels != 0)
				{
					throw new ArgumentException("TakeSamples must be a multiple of WaveFormat.Channels");
				}
				takeSamples = value;
			}
		}

		/// <summary>
		/// Amount of audio to take from the source (TimeSpan.Zero means play to end)
		/// </summary>
		public TimeSpan Take
		{
			get
			{
				return SamplesToTimeSpan(takeSamples);
			}
			set
			{
				takeSamples = TimeSpanToSamples(value);
			}
		}

		/// <summary>
		/// Number of samples of silence to insert after playing source
		/// </summary>
		public int LeadOutSamples
		{
			get
			{
				return leadOutSamples;
			}
			set
			{
				if (phase != 0)
				{
					throw new InvalidOperationException("Can't set LeadOutSamples after calling Read");
				}
				if (value % WaveFormat.Channels != 0)
				{
					throw new ArgumentException("LeadOutSamples must be a multiple of WaveFormat.Channels");
				}
				leadOutSamples = value;
			}
		}

		/// <summary>
		/// Amount of silence to insert after playing source
		/// </summary>
		public TimeSpan LeadOut
		{
			get
			{
				return SamplesToTimeSpan(leadOutSamples);
			}
			set
			{
				leadOutSamples = TimeSpanToSamples(value);
			}
		}

		/// <summary>
		/// The WaveFormat of this SampleProvider
		/// </summary>
		public WaveFormat WaveFormat => sourceProvider.WaveFormat;

		private int TimeSpanToSamples(TimeSpan time)
		{
			return (int)(time.TotalSeconds * (double)WaveFormat.SampleRate) * WaveFormat.Channels;
		}

		private TimeSpan SamplesToTimeSpan(int samples)
		{
			return TimeSpan.FromSeconds((double)(samples / WaveFormat.Channels) / (double)WaveFormat.SampleRate);
		}

		/// <summary>
		/// Creates a new instance of offsetSampleProvider
		/// </summary>
		/// <param name="sourceProvider">The Source Sample Provider to read from</param>
		public OffsetSampleProvider(ISampleProvider sourceProvider)
		{
			this.sourceProvider = sourceProvider;
		}

		/// <summary>
		/// Reads from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset within sample buffer to read to</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = 0;
			if (phase == 0)
			{
				phase++;
			}
			if (phase == 1)
			{
				int num2 = Math.Min(count, DelayBySamples - phasePos);
				for (int i = 0; i < num2; i++)
				{
					buffer[offset + i] = 0f;
				}
				phasePos += num2;
				num += num2;
				if (phasePos >= DelayBySamples)
				{
					phase++;
					phasePos = 0;
				}
			}
			if (phase == 2)
			{
				if (SkipOverSamples > 0)
				{
					float[] array = new float[WaveFormat.SampleRate * WaveFormat.Channels];
					int num3;
					for (int j = 0; j < SkipOverSamples; j += num3)
					{
						int count2 = Math.Min(SkipOverSamples - j, array.Length);
						num3 = sourceProvider.Read(array, 0, count2);
						if (num3 == 0)
						{
							break;
						}
					}
				}
				phase++;
				phasePos = 0;
			}
			if (phase == 3)
			{
				int num4 = count - num;
				if (takeSamples != 0)
				{
					num4 = Math.Min(num4, takeSamples - phasePos);
				}
				int num5 = sourceProvider.Read(buffer, offset + num, num4);
				phasePos += num5;
				num += num5;
				if (num5 < num4 || (takeSamples > 0 && phasePos >= takeSamples))
				{
					phase++;
					phasePos = 0;
				}
			}
			if (phase == 4)
			{
				int num6 = Math.Min(count - num, LeadOutSamples - phasePos);
				for (int k = 0; k < num6; k++)
				{
					buffer[offset + num + k] = 0f;
				}
				phasePos += num6;
				num += num6;
				if (phasePos >= LeadOutSamples)
				{
					phase++;
					phasePos = 0;
				}
			}
			return num;
		}
	}

	/// <summary>
	/// Converts a mono sample provider to stereo, with a customisable pan strategy
	/// </summary>
	public class PanningSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider source;

		private float pan;

		private float leftMultiplier;

		private float rightMultiplier;

		private readonly WaveFormat waveFormat;

		private float[] sourceBuffer;

		private IPanStrategy panStrategy;

		/// <summary>
		/// Pan value, must be between -1 (left) and 1 (right)
		/// </summary>
		public float Pan
		{
			get
			{
				return pan;
			}
			set
			{
				if (value < -1f || value > 1f)
				{
					throw new ArgumentOutOfRangeException("value", "Pan must be in the range -1 to 1");
				}
				pan = value;
				UpdateMultipliers();
			}
		}

		/// <summary>
		/// The pan strategy currently in use
		/// </summary>
		public IPanStrategy PanStrategy
		{
			get
			{
				return panStrategy;
			}
			set
			{
				panStrategy = value;
				UpdateMultipliers();
			}
		}

		/// <summary>
		/// The WaveFormat of this sample provider
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Initialises a new instance of the PanningSampleProvider
		/// </summary>
		/// <param name="source">Source sample provider, must be mono</param>
		public PanningSampleProvider(ISampleProvider source)
		{
			if (source.WaveFormat.Channels != 1)
			{
				throw new ArgumentException("Source sample provider must be mono");
			}
			this.source = source;
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(source.WaveFormat.SampleRate, 2);
			panStrategy = new SinPanStrategy();
		}

		private void UpdateMultipliers()
		{
			StereoSamplePair multipliers = panStrategy.GetMultipliers(Pan);
			leftMultiplier = multipliers.Left;
			rightMultiplier = multipliers.Right;
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples desired</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = count / 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i++)
			{
				buffer[num3++] = leftMultiplier * sourceBuffer[i];
				buffer[num3++] = rightMultiplier * sourceBuffer[i];
			}
			return num2 * 2;
		}
	}

	/// <summary>
	/// Converts an IWaveProvider containing 16 bit PCM to an
	/// ISampleProvider
	/// </summary>
	public class Pcm16BitToSampleProvider : SampleProviderConverterBase
	{
		/// <summary>
		/// Initialises a new instance of Pcm16BitToSampleProvider
		/// </summary>
		/// <param name="source">Source wave provider</param>
		public Pcm16BitToSampleProvider(IWaveProvider source)
			: base(source)
		{
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Samples required</param>
		/// <returns>Number of samples read</returns>
		public override int Read(float[] buffer, int offset, int count)
		{
			int num = count * 2;
			EnsureSourceBuffer(num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i += 2)
			{
				buffer[num3++] = (float)BitConverter.ToInt16(sourceBuffer, i) / 32768f;
			}
			return num2 / 2;
		}
	}

	/// <summary>
	/// Converts an IWaveProvider containing 24 bit PCM to an
	/// ISampleProvider
	/// </summary>
	public class Pcm24BitToSampleProvider : SampleProviderConverterBase
	{
		/// <summary>
		/// Initialises a new instance of Pcm24BitToSampleProvider
		/// </summary>
		/// <param name="source">Source Wave Provider</param>
		public Pcm24BitToSampleProvider(IWaveProvider source)
			: base(source)
		{
		}

		/// <summary>
		/// Reads floating point samples from this sample provider
		/// </summary>
		/// <param name="buffer">sample buffer</param>
		/// <param name="offset">offset within sample buffer to write to</param>
		/// <param name="count">number of samples required</param>
		/// <returns>number of samples provided</returns>
		public override int Read(float[] buffer, int offset, int count)
		{
			int num = count * 3;
			EnsureSourceBuffer(num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i += 3)
			{
				buffer[num3++] = (float)(((sbyte)sourceBuffer[i + 2] << 16) | (sourceBuffer[i + 1] << 8) | sourceBuffer[i]) / 8388608f;
			}
			return num2 / 3;
		}
	}

	/// <summary>
	/// Converts an IWaveProvider containing 32 bit PCM to an
	/// ISampleProvider
	/// </summary>
	public class Pcm32BitToSampleProvider : SampleProviderConverterBase
	{
		/// <summary>
		/// Initialises a new instance of Pcm32BitToSampleProvider
		/// </summary>
		/// <param name="source">Source Wave Provider</param>
		public Pcm32BitToSampleProvider(IWaveProvider source)
			: base(source)
		{
		}

		/// <summary>
		/// Reads floating point samples from this sample provider
		/// </summary>
		/// <param name="buffer">sample buffer</param>
		/// <param name="offset">offset within sample buffer to write to</param>
		/// <param name="count">number of samples required</param>
		/// <returns>number of samples provided</returns>
		public override int Read(float[] buffer, int offset, int count)
		{
			int num = count * 4;
			EnsureSourceBuffer(num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i += 4)
			{
				buffer[num3++] = (float)(((sbyte)sourceBuffer[i + 3] << 24) | (sourceBuffer[i + 2] << 16) | (sourceBuffer[i + 1] << 8) | sourceBuffer[i]) / 2.1474836E+09f;
			}
			return num2 / 4;
		}
	}

	/// <summary>
	/// Converts an IWaveProvider containing 8 bit PCM to an
	/// ISampleProvider
	/// </summary>
	public class Pcm8BitToSampleProvider : SampleProviderConverterBase
	{
		/// <summary>
		/// Initialises a new instance of Pcm8BitToSampleProvider
		/// </summary>
		/// <param name="source">Source wave provider</param>
		public Pcm8BitToSampleProvider(IWaveProvider source)
			: base(source)
		{
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples to read</param>
		/// <returns>Number of samples read</returns>
		public override int Read(float[] buffer, int offset, int count)
		{
			EnsureSourceBuffer(count);
			int num = source.Read(sourceBuffer, 0, count);
			int num2 = offset;
			for (int i = 0; i < num; i++)
			{
				buffer[num2++] = (float)(int)sourceBuffer[i] / 128f - 1f;
			}
			return num;
		}
	}

	/// <summary>
	/// Utility class that takes an IWaveProvider input at any bit depth
	/// and exposes it as an ISampleProvider. Can turn mono inputs into stereo,
	/// and allows adjusting of volume
	/// (The eventual successor to WaveChannel32)
	/// This class also serves as an example of how you can link together several simple 
	/// Sample Providers to form a more useful class.
	/// </summary>
	public class SampleChannel : ISampleProvider
	{
		private readonly VolumeSampleProvider volumeProvider;

		private readonly MeteringSampleProvider preVolumeMeter;

		private readonly WaveFormat waveFormat;

		/// <summary>
		/// The WaveFormat of this Sample Provider
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Allows adjusting the volume, 1.0f = full volume
		/// </summary>
		public float Volume
		{
			get
			{
				return volumeProvider.Volume;
			}
			set
			{
				volumeProvider.Volume = value;
			}
		}

		/// <summary>
		/// Raised periodically to inform the user of the max volume
		/// (before the volume meter)
		/// </summary>
		public event EventHandler<StreamVolumeEventArgs> PreVolumeMeter
		{
			add
			{
				preVolumeMeter.StreamVolume += value;
			}
			remove
			{
				preVolumeMeter.StreamVolume -= value;
			}
		}

		/// <summary>
		/// Initialises a new instance of SampleChannel
		/// </summary>
		/// <param name="waveProvider">Source wave provider, must be PCM or IEEE</param>
		public SampleChannel(IWaveProvider waveProvider)
			: this(waveProvider, forceStereo: false)
		{
		}

		/// <summary>
		/// Initialises a new instance of SampleChannel
		/// </summary>
		/// <param name="waveProvider">Source wave provider, must be PCM or IEEE</param>
		/// <param name="forceStereo">force mono inputs to become stereo</param>
		public SampleChannel(IWaveProvider waveProvider, bool forceStereo)
		{
			ISampleProvider sampleProvider = SampleProviderConverters.ConvertWaveProviderIntoSampleProvider(waveProvider);
			if (sampleProvider.WaveFormat.Channels == 1 && forceStereo)
			{
				sampleProvider = new MonoToStereoSampleProvider(sampleProvider);
			}
			waveFormat = sampleProvider.WaveFormat;
			preVolumeMeter = new MeteringSampleProvider(sampleProvider);
			volumeProvider = new VolumeSampleProvider(preVolumeMeter);
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="sampleCount">Number of samples desired</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int sampleCount)
		{
			return volumeProvider.Read(buffer, offset, sampleCount);
		}
	}

	/// <summary>
	/// Helper base class for classes converting to ISampleProvider
	/// </summary>
	public abstract class SampleProviderConverterBase : ISampleProvider
	{
		/// <summary>
		/// Source Wave Provider
		/// </summary>
		protected IWaveProvider source;

		private readonly WaveFormat waveFormat;

		/// <summary>
		/// Source buffer (to avoid constantly creating small buffers during playback)
		/// </summary>
		protected byte[] sourceBuffer;

		/// <summary>
		/// Wave format of this wave provider
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Initialises a new instance of SampleProviderConverterBase
		/// </summary>
		/// <param name="source">Source Wave provider</param>
		public SampleProviderConverterBase(IWaveProvider source)
		{
			this.source = source;
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(source.WaveFormat.SampleRate, source.WaveFormat.Channels);
		}

		/// <summary>
		/// Reads samples from the source wave provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public abstract int Read(float[] buffer, int offset, int count);

		/// <summary>
		/// Ensure the source buffer exists and is big enough
		/// </summary>
		/// <param name="sourceBytesRequired">Bytes required</param>
		protected void EnsureSourceBuffer(int sourceBytesRequired)
		{
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, sourceBytesRequired);
		}
	}

	/// <summary>
	/// Utility class for converting to SampleProvider
	/// </summary>
	internal static class SampleProviderConverters
	{
		/// <summary>
		/// Helper function to go from IWaveProvider to a SampleProvider
		/// Must already be PCM or IEEE float
		/// </summary>
		/// <param name="waveProvider">The WaveProvider to convert</param>
		/// <returns>A sample provider</returns>
		public static ISampleProvider ConvertWaveProviderIntoSampleProvider(IWaveProvider waveProvider)
		{
			if (waveProvider.WaveFormat.Encoding == WaveFormatEncoding.Pcm)
			{
				if (waveProvider.WaveFormat.BitsPerSample == 8)
				{
					return new Pcm8BitToSampleProvider(waveProvider);
				}
				if (waveProvider.WaveFormat.BitsPerSample == 16)
				{
					return new Pcm16BitToSampleProvider(waveProvider);
				}
				if (waveProvider.WaveFormat.BitsPerSample == 24)
				{
					return new Pcm24BitToSampleProvider(waveProvider);
				}
				if (waveProvider.WaveFormat.BitsPerSample == 32)
				{
					return new Pcm32BitToSampleProvider(waveProvider);
				}
				throw new InvalidOperationException("Unsupported bit depth");
			}
			if (waveProvider.WaveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
			{
				if (waveProvider.WaveFormat.BitsPerSample == 64)
				{
					return new WaveToSampleProvider64(waveProvider);
				}
				return new WaveToSampleProvider(waveProvider);
			}
			throw new ArgumentException("Unsupported source encoding");
		}
	}

	/// <summary>
	/// SampleProvider event args
	/// </summary>
	public class SampleProviderEventArgs : EventArgs
	{
		/// <summary>
		/// The Sample Provider
		/// </summary>
		public ISampleProvider SampleProvider { get; private set; }

		/// <summary>
		/// Constructs a new SampleProviderEventArgs
		/// </summary>
		public SampleProviderEventArgs(ISampleProvider sampleProvider)
		{
			SampleProvider = sampleProvider;
		}
	}

	/// <summary>
	/// Helper class for when you need to convert back to an IWaveProvider from
	/// an ISampleProvider. Keeps it as IEEE float
	/// </summary>
	public class SampleToWaveProvider : IWaveProvider
	{
		private readonly ISampleProvider source;

		/// <summary>
		/// The waveformat of this WaveProvider (same as the source)
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Initializes a new instance of the WaveProviderFloatToWaveProvider class
		/// </summary>
		/// <param name="source">Source wave provider</param>
		public SampleToWaveProvider(ISampleProvider source)
		{
			if (source.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Must be already floating point");
			}
			this.source = source;
		}

		/// <summary>
		/// Reads from this provider
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			int count2 = count / 4;
			WaveBuffer waveBuffer = new WaveBuffer(buffer);
			return source.Read(waveBuffer.FloatBuffer, offset / 4, count2) * 4;
		}
	}

	/// <summary>
	/// Converts a sample provider to 16 bit PCM, optionally clipping and adjusting volume along the way
	/// </summary>
	public class SampleToWaveProvider16 : IWaveProvider
	{
		private readonly ISampleProvider sourceProvider;

		private readonly WaveFormat waveFormat;

		private volatile float volume;

		private float[] sourceBuffer;

		/// <summary>
		/// <see cref="P:NAudio.Wave.IWaveProvider.WaveFormat" />
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Volume of this channel. 1.0 = full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// Converts from an ISampleProvider (IEEE float) to a 16 bit PCM IWaveProvider.
		/// Number of channels and sample rate remain unchanged.
		/// </summary>
		/// <param name="sourceProvider">The input source provider</param>
		public SampleToWaveProvider16(ISampleProvider sourceProvider)
		{
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Input source provider must be IEEE float", "sourceProvider");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Input source provider must be 32 bit", "sourceProvider");
			}
			waveFormat = new WaveFormat(sourceProvider.WaveFormat.SampleRate, 16, sourceProvider.WaveFormat.Channels);
			this.sourceProvider = sourceProvider;
			volume = 1f;
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public int Read(byte[] destBuffer, int offset, int numBytes)
		{
			int num = numBytes / 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			int num2 = sourceProvider.Read(sourceBuffer, 0, num);
			WaveBuffer waveBuffer = new WaveBuffer(destBuffer);
			int num3 = offset / 2;
			for (int i = 0; i < num2; i++)
			{
				float num4 = sourceBuffer[i] * volume;
				if (num4 > 1f)
				{
					num4 = 1f;
				}
				if (num4 < -1f)
				{
					num4 = -1f;
				}
				waveBuffer.ShortBuffer[num3++] = (short)(num4 * 32767f);
			}
			return num2 * 2;
		}
	}

	/// <summary>
	/// Converts a sample provider to 24 bit PCM, optionally clipping and adjusting volume along the way
	/// </summary>
	public class SampleToWaveProvider24 : IWaveProvider
	{
		private readonly ISampleProvider sourceProvider;

		private readonly WaveFormat waveFormat;

		private volatile float volume;

		private float[] sourceBuffer;

		/// <summary>
		/// The Format of this IWaveProvider
		/// <see cref="P:NAudio.Wave.IWaveProvider.WaveFormat" />
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Volume of this channel. 1.0 = full scale, 0.0 to mute
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// Converts from an ISampleProvider (IEEE float) to a 16 bit PCM IWaveProvider.
		/// Number of channels and sample rate remain unchanged.
		/// </summary>
		/// <param name="sourceProvider">The input source provider</param>
		public SampleToWaveProvider24(ISampleProvider sourceProvider)
		{
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Input source provider must be IEEE float", "sourceProvider");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Input source provider must be 32 bit", "sourceProvider");
			}
			waveFormat = new WaveFormat(sourceProvider.WaveFormat.SampleRate, 24, sourceProvider.WaveFormat.Channels);
			this.sourceProvider = sourceProvider;
			volume = 1f;
		}

		/// <summary>
		/// Reads bytes from this wave stream, clipping if necessary
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public int Read(byte[] destBuffer, int offset, int numBytes)
		{
			int num = numBytes / 3;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			int num2 = sourceProvider.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i++)
			{
				float num4 = sourceBuffer[i] * volume;
				if (num4 > 1f)
				{
					num4 = 1f;
				}
				if (num4 < -1f)
				{
					num4 = -1f;
				}
				int num5 = (int)((double)num4 * 8388607.0);
				destBuffer[num3++] = (byte)num5;
				destBuffer[num3++] = (byte)(num5 >> 8);
				destBuffer[num3++] = (byte)(num5 >> 16);
			}
			return num2 * 3;
		}
	}

	/// <summary>
	/// Signal Generator
	/// Sin, Square, Triangle, SawTooth, White Noise, Pink Noise, Sweep.
	/// </summary>
	/// <remarks>
	/// Posibility to change ISampleProvider
	/// Example :
	/// ---------
	/// WaveOut _waveOutGene = new WaveOut();
	/// WaveGenerator wg = new SignalGenerator();
	/// wg.Type = ...
	/// wg.Frequency = ...
	/// wg ...
	/// _waveOutGene.Init(wg);
	/// _waveOutGene.Play();
	/// </remarks>
	public class SignalGenerator : ISampleProvider
	{
		private readonly WaveFormat waveFormat;

		private readonly Random random = new Random();

		private readonly double[] pinkNoiseBuffer = new double[7];

		private const double TwoPi = Math.PI * 2.0;

		private int nSample;

		private double phi;

		/// <summary>
		/// The waveformat of this WaveProvider (same as the source)
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Frequency for the Generator. (20.0 - 20000.0 Hz)
		/// Sin, Square, Triangle, SawTooth, Sweep (Start Frequency).
		/// </summary>
		public double Frequency { get; set; }

		/// <summary>
		/// Return Log of Frequency Start (Read only)
		/// </summary>
		public double FrequencyLog => Math.Log(Frequency);

		/// <summary>
		/// End Frequency for the Sweep Generator. (Start Frequency in Frequency)
		/// </summary>
		public double FrequencyEnd { get; set; }

		/// <summary>
		/// Return Log of Frequency End (Read only)
		/// </summary>
		public double FrequencyEndLog => Math.Log(FrequencyEnd);

		/// <summary>
		/// Gain for the Generator. (0.0 to 1.0)
		/// </summary>
		public double Gain { get; set; }

		/// <summary>
		/// Channel PhaseReverse
		/// </summary>
		public bool[] PhaseReverse { get; }

		/// <summary>
		/// Type of Generator.
		/// </summary>
		public SignalGeneratorType Type { get; set; }

		/// <summary>
		/// Length Seconds for the Sweep Generator.
		/// </summary>
		public double SweepLengthSecs { get; set; }

		/// <summary>
		/// Initializes a new instance for the Generator (Default :: 44.1Khz, 2 channels, Sinus, Frequency = 440, Gain = 1)
		/// </summary>
		public SignalGenerator()
			: this(44100, 2)
		{
		}

		/// <summary>
		/// Initializes a new instance for the Generator (UserDef SampleRate &amp; Channels)
		/// </summary>
		/// <param name="sampleRate">Desired sample rate</param>
		/// <param name="channel">Number of channels</param>
		public SignalGenerator(int sampleRate, int channel)
		{
			phi = 0.0;
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channel);
			Type = SignalGeneratorType.Sin;
			Frequency = 440.0;
			Gain = 1.0;
			PhaseReverse = new bool[channel];
			SweepLengthSecs = 2.0;
		}

		/// <summary>
		/// Reads from this provider.
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = offset;
			for (int i = 0; i < count / waveFormat.Channels; i++)
			{
				double num2;
				switch (Type)
				{
				case SignalGeneratorType.Sin:
				{
					double num4 = Math.PI * 2.0 * Frequency / (double)waveFormat.SampleRate;
					num2 = Gain * Math.Sin((double)nSample * num4);
					nSample++;
					break;
				}
				case SignalGeneratorType.Square:
				{
					double num4 = 2.0 * Frequency / (double)waveFormat.SampleRate;
					double num7 = (double)nSample * num4 % 2.0 - 1.0;
					num2 = ((num7 >= 0.0) ? Gain : (0.0 - Gain));
					nSample++;
					break;
				}
				case SignalGeneratorType.Triangle:
				{
					double num4 = 2.0 * Frequency / (double)waveFormat.SampleRate;
					double num7 = (double)nSample * num4 % 2.0;
					num2 = 2.0 * num7;
					if (num2 > 1.0)
					{
						num2 = 2.0 - num2;
					}
					if (num2 < -1.0)
					{
						num2 = -2.0 - num2;
					}
					num2 *= Gain;
					nSample++;
					break;
				}
				case SignalGeneratorType.SawTooth:
				{
					double num4 = 2.0 * Frequency / (double)waveFormat.SampleRate;
					double num7 = (double)nSample * num4 % 2.0 - 1.0;
					num2 = Gain * num7;
					nSample++;
					break;
				}
				case SignalGeneratorType.White:
					num2 = Gain * NextRandomTwo();
					break;
				case SignalGeneratorType.Pink:
				{
					double num5 = NextRandomTwo();
					pinkNoiseBuffer[0] = 0.99886 * pinkNoiseBuffer[0] + num5 * 0.0555179;
					pinkNoiseBuffer[1] = 0.99332 * pinkNoiseBuffer[1] + num5 * 0.0750759;
					pinkNoiseBuffer[2] = 0.969 * pinkNoiseBuffer[2] + num5 * 0.153852;
					pinkNoiseBuffer[3] = 0.8665 * pinkNoiseBuffer[3] + num5 * 0.3104856;
					pinkNoiseBuffer[4] = 0.55 * pinkNoiseBuffer[4] + num5 * 0.5329522;
					pinkNoiseBuffer[5] = -0.7616 * pinkNoiseBuffer[5] - num5 * 0.016898;
					double num6 = pinkNoiseBuffer[0] + pinkNoiseBuffer[1] + pinkNoiseBuffer[2] + pinkNoiseBuffer[3] + pinkNoiseBuffer[4] + pinkNoiseBuffer[5] + pinkNoiseBuffer[6] + num5 * 0.5362;
					pinkNoiseBuffer[6] = num5 * 0.115926;
					num2 = Gain * (num6 / 5.0);
					break;
				}
				case SignalGeneratorType.Sweep:
				{
					double num3 = Math.Exp(FrequencyLog + (double)nSample * (FrequencyEndLog - FrequencyLog) / (SweepLengthSecs * (double)waveFormat.SampleRate));
					double num4 = Math.PI * 2.0 * num3 / (double)waveFormat.SampleRate;
					phi += num4;
					num2 = Gain * Math.Sin(phi);
					nSample++;
					if ((double)nSample > SweepLengthSecs * (double)waveFormat.SampleRate)
					{
						nSample = 0;
						phi = 0.0;
					}
					break;
				}
				default:
					num2 = 0.0;
					break;
				}
				for (int j = 0; j < waveFormat.Channels; j++)
				{
					if (PhaseReverse[j])
					{
						buffer[num++] = (float)(0.0 - num2);
					}
					else
					{
						buffer[num++] = (float)num2;
					}
				}
			}
			return count;
		}

		/// <summary>
		/// Private :: Random for WhiteNoise &amp; Pink Noise (Value form -1 to 1)
		/// </summary>
		/// <returns>Random value from -1 to +1</returns>
		private double NextRandomTwo()
		{
			return 2.0 * random.NextDouble() - 1.0;
		}
	}

	/// <summary>
	/// Signal Generator type
	/// </summary>
	public enum SignalGeneratorType
	{
		/// <summary>
		/// Pink noise
		/// </summary>
		Pink,
		/// <summary>
		/// White noise
		/// </summary>
		White,
		/// <summary>
		/// Sweep
		/// </summary>
		Sweep,
		/// <summary>
		/// Sine wave
		/// </summary>
		Sin,
		/// <summary>
		/// Square wave
		/// </summary>
		Square,
		/// <summary>
		/// Triangle Wave
		/// </summary>
		Triangle,
		/// <summary>
		/// Sawtooth wave
		/// </summary>
		SawTooth
	}

	/// <summary>
	/// Sinus Pan, thanks to Yuval Naveh
	/// </summary>
	public class SinPanStrategy : IPanStrategy
	{
		private const float HalfPi = MathF.PI / 2f;

		/// <summary>
		/// Gets the left and right channel multipliers for this pan value
		/// </summary>
		/// <param name="pan">Pan value, between -1 and 1</param>
		/// <returns>Left and right multipliers</returns>
		public StereoSamplePair GetMultipliers(float pan)
		{
			float num = (0f - pan + 1f) / 2f;
			float left = (float)Math.Sin(num * (MathF.PI / 2f));
			float right = (float)Math.Cos(num * (MathF.PI / 2f));
			StereoSamplePair result = default(StereoSamplePair);
			result.Left = left;
			result.Right = right;
			return result;
		}
	}

	/// <summary>
	/// Author: Freefall
	/// Date: 05.08.16
	/// Based on: the port of Stephan M. Bernsee´s pitch shifting class
	/// Port site: https://sites.google.com/site/mikescoderama/pitch-shifting
	/// Test application and github site: https://github.com/Freefall63/NAudio-Pitchshifter
	///
	/// NOTE: I strongly advice to add a Limiter for post-processing.
	/// For my needs the FastAttackCompressor1175 provides acceptable results:
	/// https://github.com/Jiyuu/SkypeFX/blob/master/JSNet/FastAttackCompressor1175.cs
	///
	/// UPDATE: Added a simple Limiter based on the pydirac implementation.
	/// https://github.com/echonest/remix/blob/master/external/pydirac225/source/Dirac_LE.cpp
	///
	///             </summary>
	public class SmbPitchShiftingSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider sourceStream;

		private readonly WaveFormat waveFormat;

		private float pitch = 1f;

		private readonly int fftSize;

		private readonly long osamp;

		private readonly SmbPitchShifter shifterLeft = new SmbPitchShifter();

		private readonly SmbPitchShifter shifterRight = new SmbPitchShifter();

		private const float LIM_THRESH = 0.95f;

		private const float LIM_RANGE = 0.050000012f;

		private const float M_PI_2 = MathF.PI / 2f;

		/// <summary>
		/// WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Pitch Factor (0.5f = octave down, 1.0f = normal, 2.0f = octave up)
		/// </summary>
		public float PitchFactor
		{
			get
			{
				return pitch;
			}
			set
			{
				pitch = value;
			}
		}

		/// <summary>
		/// Creates a new SMB Pitch Shifting Sample Provider with default settings
		/// </summary>
		/// <param name="sourceProvider">Source provider</param>
		public SmbPitchShiftingSampleProvider(ISampleProvider sourceProvider)
			: this(sourceProvider, 4096, 4L, 1f)
		{
		}

		/// <summary>
		/// Creates a new SMB Pitch Shifting Sample Provider with custom settings
		/// </summary>
		/// <param name="sourceProvider">Source provider</param>
		/// <param name="fftSize">FFT Size (any power of two &lt;= 4096: 4096, 2048, 1024, 512, ...)</param>
		/// <param name="osamp">Oversampling (number of overlapping windows)</param>
		/// <param name="initialPitch">Initial pitch (0.5f = octave down, 1.0f = normal, 2.0f = octave up)</param>
		public SmbPitchShiftingSampleProvider(ISampleProvider sourceProvider, int fftSize, long osamp, float initialPitch)
		{
			sourceStream = sourceProvider;
			waveFormat = sourceProvider.WaveFormat;
			this.fftSize = fftSize;
			this.osamp = osamp;
			PitchFactor = initialPitch;
		}

		/// <summary>
		/// Read from this sample provider
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = sourceStream.Read(buffer, offset, count);
			if (pitch == 1f)
			{
				return num;
			}
			if (waveFormat.Channels == 1)
			{
				float[] array = new float[num];
				int num2 = 0;
				for (int i = offset; i <= num + offset - 1; i++)
				{
					array[num2] = buffer[i];
					num2++;
				}
				shifterLeft.PitchShift(pitch, num, fftSize, osamp, waveFormat.SampleRate, array);
				num2 = 0;
				for (int j = offset; j <= num + offset - 1; j++)
				{
					buffer[j] = Limiter(array[num2]);
					num2++;
				}
				return num;
			}
			if (waveFormat.Channels == 2)
			{
				float[] array2 = new float[num >> 1];
				float[] array3 = new float[num >> 1];
				int num3 = 0;
				for (int k = offset; k <= num + offset - 1; k += 2)
				{
					array2[num3] = buffer[k];
					array3[num3] = buffer[k + 1];
					num3++;
				}
				shifterLeft.PitchShift(pitch, num >> 1, fftSize, osamp, waveFormat.SampleRate, array2);
				shifterRight.PitchShift(pitch, num >> 1, fftSize, osamp, waveFormat.SampleRate, array3);
				num3 = 0;
				for (int l = offset; l <= num + offset - 1; l += 2)
				{
					buffer[l] = Limiter(array2[num3]);
					buffer[l + 1] = Limiter(array3[num3]);
					num3++;
				}
				return num;
			}
			throw new Exception("Shifting of more than 2 channels is currently not supported.");
		}

		private float Limiter(float sample)
		{
			if (0.95f < sample)
			{
				float num = (sample - 0.95f) / 0.050000012f;
				return (float)(Math.Atan(num) / 1.5707963705062866 * 0.050000011920928955 + 0.949999988079071);
			}
			if (sample < -0.95f)
			{
				float num = (0f - (sample + 0.95f)) / 0.050000012f;
				return 0f - (float)(Math.Atan(num) / 1.5707963705062866 * 0.050000011920928955 + 0.949999988079071);
			}
			return sample;
		}
	}

	/// <summary>
	/// Square Root Pan, thanks to Yuval Naveh
	/// </summary>
	public class SquareRootPanStrategy : IPanStrategy
	{
		/// <summary>
		/// Gets the left and right channel multipliers for this pan value
		/// </summary>
		/// <param name="pan">Pan value, between -1 and 1</param>
		/// <returns>Left and right multipliers</returns>
		public StereoSamplePair GetMultipliers(float pan)
		{
			float num = (0f - pan + 1f) / 2f;
			float left = (float)Math.Sqrt(num);
			float right = (float)Math.Sqrt(1f - num);
			StereoSamplePair result = default(StereoSamplePair);
			result.Left = left;
			result.Right = right;
			return result;
		}
	}

	internal class Stereo16SampleChunkConverter : ISampleChunkConverter
	{
		private int sourceSample;

		private byte[] sourceBuffer;

		private WaveBuffer sourceWaveBuffer;

		private int sourceSamples;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 16)
			{
				return waveFormat.Channels == 2;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 4;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceWaveBuffer = new WaveBuffer(sourceBuffer);
			sourceSamples = source.Read(sourceBuffer, 0, num) / 2;
			sourceSample = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (sourceSample < sourceSamples)
			{
				sampleLeft = (float)sourceWaveBuffer.ShortBuffer[sourceSample++] / 32768f;
				sampleRight = (float)sourceWaveBuffer.ShortBuffer[sourceSample++] / 32768f;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	internal class Stereo24SampleChunkConverter : ISampleChunkConverter
	{
		private int offset;

		private byte[] sourceBuffer;

		private int sourceBytes;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 24)
			{
				return waveFormat.Channels == 2;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 6;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceBytes = source.Read(sourceBuffer, 0, num);
			offset = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (offset < sourceBytes)
			{
				sampleLeft = (float)(((sbyte)sourceBuffer[offset + 2] << 16) | (sourceBuffer[offset + 1] << 8) | sourceBuffer[offset]) / 8388608f;
				offset += 3;
				sampleRight = (float)(((sbyte)sourceBuffer[offset + 2] << 16) | (sourceBuffer[offset + 1] << 8) | sourceBuffer[offset]) / 8388608f;
				offset += 3;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	internal class Stereo8SampleChunkConverter : ISampleChunkConverter
	{
		private int offset;

		private byte[] sourceBuffer;

		private int sourceBytes;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.Pcm && waveFormat.BitsPerSample == 8)
			{
				return waveFormat.Channels == 2;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceBytes = source.Read(sourceBuffer, 0, num);
			offset = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (offset < sourceBytes)
			{
				sampleLeft = (float)(int)sourceBuffer[offset++] / 256f;
				sampleRight = (float)(int)sourceBuffer[offset++] / 256f;
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	/// <summary>
	/// Simplistic "balance" control - treating the mono input as if it was stereo
	/// In the centre, both channels full volume. Opposite channel decays linearly 
	/// as balance is turned to to one side
	/// </summary>
	public class StereoBalanceStrategy : IPanStrategy
	{
		/// <summary>
		/// Gets the left and right channel multipliers for this pan value
		/// </summary>
		/// <param name="pan">Pan value, between -1 and 1</param>
		/// <returns>Left and right multipliers</returns>
		public StereoSamplePair GetMultipliers(float pan)
		{
			float left = ((pan <= 0f) ? 1f : ((1f - pan) / 2f));
			float right = ((pan >= 0f) ? 1f : ((pan + 1f) / 2f));
			StereoSamplePair result = default(StereoSamplePair);
			result.Left = left;
			result.Right = right;
			return result;
		}
	}

	internal class StereoFloatSampleChunkConverter : ISampleChunkConverter
	{
		private int sourceSample;

		private byte[] sourceBuffer;

		private WaveBuffer sourceWaveBuffer;

		private int sourceSamples;

		public bool Supports(WaveFormat waveFormat)
		{
			if (waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
			{
				return waveFormat.Channels == 2;
			}
			return false;
		}

		public void LoadNextChunk(IWaveProvider source, int samplePairsRequired)
		{
			int num = samplePairsRequired * 8;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			sourceWaveBuffer = new WaveBuffer(sourceBuffer);
			sourceSamples = source.Read(sourceBuffer, 0, num) / 4;
			sourceSample = 0;
		}

		public bool GetNextSample(out float sampleLeft, out float sampleRight)
		{
			if (sourceSample < sourceSamples)
			{
				sampleLeft = sourceWaveBuffer.FloatBuffer[sourceSample++];
				sampleRight = sourceWaveBuffer.FloatBuffer[sourceSample++];
				return true;
			}
			sampleLeft = 0f;
			sampleRight = 0f;
			return false;
		}
	}

	/// <summary>
	/// Pair of floating point values, representing samples or multipliers
	/// </summary>
	public struct StereoSamplePair
	{
		/// <summary>
		/// Left value
		/// </summary>
		public float Left { get; set; }

		/// <summary>
		/// Right value
		/// </summary>
		public float Right { get; set; }
	}

	/// <summary>
	/// Takes a stereo input and turns it to mono
	/// </summary>
	public class StereoToMonoSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider sourceProvider;

		private float[] sourceBuffer;

		/// <summary>
		/// 1.0 to mix the mono source entirely to the left channel
		/// </summary>
		public float LeftVolume { get; set; }

		/// <summary>
		/// 1.0 to mix the mono source entirely to the right channel
		/// </summary>
		public float RightVolume { get; set; }

		/// <summary>
		/// Output Wave Format
		/// </summary>
		public WaveFormat WaveFormat { get; }

		/// <summary>
		/// Creates a new mono ISampleProvider based on a stereo input
		/// </summary>
		/// <param name="sourceProvider">Stereo 16 bit PCM input</param>
		public StereoToMonoSampleProvider(ISampleProvider sourceProvider)
		{
			LeftVolume = 0.5f;
			RightVolume = 0.5f;
			if (sourceProvider.WaveFormat.Channels != 2)
			{
				throw new ArgumentException("Source must be stereo");
			}
			this.sourceProvider = sourceProvider;
			WaveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sourceProvider.WaveFormat.SampleRate, 1);
		}

		/// <summary>
		/// Reads bytes from this SampleProvider
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = count * 2;
			if (sourceBuffer == null || sourceBuffer.Length < num)
			{
				sourceBuffer = new float[num];
			}
			int num2 = sourceProvider.Read(sourceBuffer, 0, num);
			int num3 = offset;
			for (int i = 0; i < num2; i += 2)
			{
				float num4 = sourceBuffer[i];
				float num5 = sourceBuffer[i + 1];
				float num6 = num4 * LeftVolume + num5 * RightVolume;
				buffer[num3++] = num6;
			}
			return num2 / 2;
		}
	}

	/// <summary>
	/// Event args for aggregated stream volume
	/// </summary>
	public class StreamVolumeEventArgs : EventArgs
	{
		/// <summary>
		/// Max sample values array (one for each channel)
		/// </summary>
		public float[] MaxSampleValues { get; set; }
	}

	/// <summary>
	/// Very simple sample provider supporting adjustable gain
	/// </summary>
	public class VolumeSampleProvider : ISampleProvider
	{
		private readonly ISampleProvider source;

		/// <summary>
		/// WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Allows adjusting the volume, 1.0f = full volume
		/// </summary>
		public float Volume { get; set; }

		/// <summary>
		/// Initializes a new instance of VolumeSampleProvider
		/// </summary>
		/// <param name="source">Source Sample Provider</param>
		public VolumeSampleProvider(ISampleProvider source)
		{
			this.source = source;
			Volume = 1f;
		}

		/// <summary>
		/// Reads samples from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="sampleCount">Number of samples desired</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int sampleCount)
		{
			int result = source.Read(buffer, offset, sampleCount);
			if (Volume != 1f)
			{
				for (int i = 0; i < sampleCount; i++)
				{
					buffer[offset + i] *= Volume;
				}
			}
			return result;
		}
	}

	/// <summary>
	/// Helper class turning an already 32 bit floating point IWaveProvider
	/// into an ISampleProvider - hopefully not needed for most applications
	/// </summary>
	public class WaveToSampleProvider : SampleProviderConverterBase
	{
		/// <summary>
		/// Initializes a new instance of the WaveToSampleProvider class
		/// </summary>
		/// <param name="source">Source wave provider, must be IEEE float</param>
		public WaveToSampleProvider(IWaveProvider source)
			: base(source)
		{
			if (source.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Must be already floating point");
			}
		}

		/// <summary>
		/// Reads from this provider
		/// </summary>
		public unsafe override int Read(float[] buffer, int offset, int count)
		{
			int num = count * 4;
			EnsureSourceBuffer(num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int result = num2 / 4;
			int num3 = offset;
			fixed (byte* ptr = &sourceBuffer[0])
			{
				float* ptr2 = (float*)ptr;
				int num4 = 0;
				int num5 = 0;
				while (num4 < num2)
				{
					buffer[num3++] = ptr2[num5];
					num4 += 4;
					num5++;
				}
			}
			return result;
		}
	}

	/// <summary>
	/// Helper class turning an already 64 bit floating point IWaveProvider
	/// into an ISampleProvider - hopefully not needed for most applications
	/// </summary>
	public class WaveToSampleProvider64 : SampleProviderConverterBase
	{
		/// <summary>
		/// Initializes a new instance of the WaveToSampleProvider class
		/// </summary>
		/// <param name="source">Source wave provider, must be IEEE float</param>
		public WaveToSampleProvider64(IWaveProvider source)
			: base(source)
		{
			if (source.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Must be already floating point");
			}
		}

		/// <summary>
		/// Reads from this provider
		/// </summary>
		public override int Read(float[] buffer, int offset, int count)
		{
			int num = count * 8;
			EnsureSourceBuffer(num);
			int num2 = source.Read(sourceBuffer, 0, num);
			int result = num2 / 8;
			int num3 = offset;
			for (int i = 0; i < num2; i += 8)
			{
				long value = BitConverter.ToInt64(sourceBuffer, i);
				buffer[num3++] = (float)BitConverter.Int64BitsToDouble(value);
			}
			return result;
		}
	}

	/// <summary>
	/// Fully managed resampling sample provider, based on the WDL Resampler
	/// </summary>
	public class WdlResamplingSampleProvider : ISampleProvider
	{
		private readonly WdlResampler resampler;

		private readonly WaveFormat outFormat;

		private readonly ISampleProvider source;

		private readonly int channels;

		/// <summary>
		/// Output WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => outFormat;

		/// <summary>
		/// Constructs a new resampler
		/// </summary>
		/// <param name="source">Source to resample</param>
		/// <param name="newSampleRate">Desired output sample rate</param>
		public WdlResamplingSampleProvider(ISampleProvider source, int newSampleRate)
		{
			channels = source.WaveFormat.Channels;
			outFormat = WaveFormat.CreateIeeeFloatWaveFormat(newSampleRate, channels);
			this.source = source;
			resampler = new WdlResampler();
			resampler.SetMode(interp: true, 2, sinc: false);
			resampler.SetFilterParms();
			resampler.SetFeedMode(wantInputDriven: false);
			resampler.SetRates(source.WaveFormat.SampleRate, newSampleRate);
		}

		/// <summary>
		/// Reads from this sample provider
		/// </summary>
		public int Read(float[] buffer, int offset, int count)
		{
			int num = count / channels;
			float[] inbuffer;
			int inbufferOffset;
			int num2 = resampler.ResamplePrepare(num, outFormat.Channels, out inbuffer, out inbufferOffset);
			int nsamples_in = source.Read(inbuffer, inbufferOffset, num2 * channels) / channels;
			return resampler.ResampleOut(buffer, offset, nsamples_in, num, channels) * channels;
		}
	}

	/// <summary>
	/// The WMA wave format. 
	/// May not be much use because WMA codec is a DirectShow DMO not an ACM
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	internal class WmaWaveFormat : WaveFormat
	{
		private short wValidBitsPerSample;

		private int dwChannelMask;

		private int dwReserved1;

		private int dwReserved2;

		private short wEncodeOptions;

		private short wReserved3;

		public WmaWaveFormat(int sampleRate, int bitsPerSample, int channels)
			: base(sampleRate, bitsPerSample, channels)
		{
			wValidBitsPerSample = (short)bitsPerSample;
			switch (channels)
			{
			case 1:
				dwChannelMask = 1;
				break;
			case 2:
				dwChannelMask = 3;
				break;
			}
			waveFormatTag = WaveFormatEncoding.WindowsMediaAudio;
		}
	}
}


namespace NAudio.FileFormats.Wav
{
	using NAudio.Utils;
	using NAudio.Wave;
	
	public class WaveFileChunkReader
	{
		private WaveFormat waveFormat;

		private long dataChunkPosition;

		private long dataChunkLength;

		private List<RiffChunk> riffChunks;

		private readonly bool strictMode;

		private bool isRf64;

		private readonly bool storeAllChunks;

		private long riffSize;

		/// <summary>
		/// WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Data Chunk Position
		/// </summary>
		public long DataChunkPosition => dataChunkPosition;

		/// <summary>
		/// Data Chunk Length
		/// </summary>
		public long DataChunkLength => dataChunkLength;

		/// <summary>
		/// Riff Chunks
		/// </summary>
		public List<RiffChunk> RiffChunks => riffChunks;

		public WaveFileChunkReader()
		{
			storeAllChunks = true;
			strictMode = false;
		}

		public void ReadWaveHeader(Stream stream)
		{
			dataChunkPosition = -1L;
			waveFormat = null;
			riffChunks = new List<RiffChunk>();
			dataChunkLength = 0L;
			BinaryReader binaryReader = new BinaryReader(stream);
			ReadRiffHeader(binaryReader);
			riffSize = binaryReader.ReadUInt32();
			if (binaryReader.ReadInt32() != ChunkIdentifier.ChunkIdentifierToInt32("WAVE"))
			{
				throw new FormatException("Not a WAVE file - no WAVE header");
			}
			if (isRf64)
			{
				ReadDs64Chunk(binaryReader);
			}
			int num = ChunkIdentifier.ChunkIdentifierToInt32("data");
			int num2 = ChunkIdentifier.ChunkIdentifierToInt32("fmt ");
			long num3 = Math.Min(riffSize + 8, stream.Length);
			while (stream.Position <= num3 - 8)
			{
				int num4 = binaryReader.ReadInt32();
				uint num5 = binaryReader.ReadUInt32();
				if (num4 == num)
				{
					dataChunkPosition = stream.Position;
					if (!isRf64)
					{
						dataChunkLength = num5;
					}
					stream.Position += num5;
				}
				else if (num4 == num2)
				{
					if (num5 > int.MaxValue)
					{
						throw new InvalidDataException($"Format chunk length must be between 0 and {int.MaxValue}.");
					}
					waveFormat = WaveFormat.FromFormatChunk(binaryReader, (int)num5);
				}
				else
				{
					if (num5 > stream.Length - stream.Position)
					{
						if (!strictMode)
						{
						}
						break;
					}
					if (storeAllChunks)
					{
						if (num5 > int.MaxValue)
						{
							throw new InvalidDataException($"RiffChunk chunk length must be between 0 and {int.MaxValue}.");
						}
						riffChunks.Add(GetRiffChunk(stream, num4, (int)num5));
					}
					stream.Position += num5;
				}
				if (num5 % 2u != 0 && binaryReader.PeekChar() == 0)
				{
					stream.Position++;
				}
			}
			if (waveFormat == null)
			{
				throw new FormatException("Invalid WAV file - No fmt chunk found");
			}
			if (dataChunkPosition == -1)
			{
				throw new FormatException("Invalid WAV file - No data chunk found");
			}
		}

		/// <summary>
		/// http://tech.ebu.ch/docs/tech/tech3306-2009.pdf
		/// </summary>
		private void ReadDs64Chunk(BinaryReader reader)
		{
			int num = ChunkIdentifier.ChunkIdentifierToInt32("ds64");
			if (reader.ReadInt32() != num)
			{
				throw new FormatException("Invalid RF64 WAV file - No ds64 chunk found");
			}
			int num2 = reader.ReadInt32();
			riffSize = reader.ReadInt64();
			dataChunkLength = reader.ReadInt64();
			reader.ReadInt64();
			reader.ReadBytes(num2 - 24);
		}

		private static RiffChunk GetRiffChunk(Stream stream, int chunkIdentifier, int chunkLength)
		{
			return new RiffChunk(chunkIdentifier, chunkLength, stream.Position);
		}

		private void ReadRiffHeader(BinaryReader br)
		{
			int num = br.ReadInt32();
			if (num == ChunkIdentifier.ChunkIdentifierToInt32("RF64"))
			{
				isRf64 = true;
			}
			else if (num != ChunkIdentifier.ChunkIdentifierToInt32("RIFF"))
			{
				throw new FormatException("Not a WAVE file - no RIFF header");
			}
		}
	}
}

namespace NAudio.SoundFont
{
	using NAudio.Utils;
	
	/// <summary>
	/// Controller Sources
	/// </summary>
	public enum ControllerSourceEnum
	{
		/// <summary>
		/// No Controller
		/// </summary>
		NoController = 0,
		/// <summary>
		/// Note On Velocity
		/// </summary>
		NoteOnVelocity = 2,
		/// <summary>
		/// Note On Key Number
		/// </summary>
		NoteOnKeyNumber = 3,
		/// <summary>
		/// Poly Pressure
		/// </summary>
		PolyPressure = 10,
		/// <summary>
		/// Channel Pressure
		/// </summary>
		ChannelPressure = 13,
		/// <summary>
		/// Pitch Wheel
		/// </summary>
		PitchWheel = 14,
		/// <summary>
		/// Pitch Wheel Sensitivity
		/// </summary>
		PitchWheelSensitivity = 16
	}

	/// <summary>
	/// Soundfont generator
	/// </summary>
	public class Generator
	{
		/// <summary>
		/// Gets the generator type
		/// </summary>
		public GeneratorEnum GeneratorType { get; set; }

		/// <summary>
		/// Generator amount as an unsigned short
		/// </summary>
		public ushort UInt16Amount { get; set; }

		/// <summary>
		/// Generator amount as a signed short
		/// </summary>
		public short Int16Amount
		{
			get
			{
				return (short)UInt16Amount;
			}
			set
			{
				UInt16Amount = (ushort)value;
			}
		}

		/// <summary>
		/// Low byte amount
		/// </summary>
		public byte LowByteAmount
		{
			get
			{
				return (byte)(UInt16Amount & 0xFFu);
			}
			set
			{
				UInt16Amount &= 65280;
				UInt16Amount += value;
			}
		}

		/// <summary>
		/// High byte amount
		/// </summary>
		public byte HighByteAmount
		{
			get
			{
				return (byte)((UInt16Amount & 0xFF00) >> 8);
			}
			set
			{
				UInt16Amount &= 255;
				UInt16Amount += (ushort)(value << 8);
			}
		}

		/// <summary>
		/// Instrument
		/// </summary>
		public Instrument Instrument { get; set; }

		/// <summary>
		/// Sample Header
		/// </summary>
		public SampleHeader SampleHeader { get; set; }

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			if (GeneratorType == GeneratorEnum.Instrument)
			{
				return "Generator Instrument " + Instrument.Name;
			}
			if (GeneratorType == GeneratorEnum.SampleID)
			{
				return $"Generator SampleID {SampleHeader}";
			}
			return $"Generator {GeneratorType} {UInt16Amount}";
		}
	}

	internal class GeneratorBuilder : StructureBuilder<Generator>
	{
		public override int Length => 4;

		public Generator[] Generators => data.ToArray();

		public override Generator Read(BinaryReader br)
		{
			Generator generator = new Generator();
			generator.GeneratorType = (GeneratorEnum)br.ReadUInt16();
			generator.UInt16Amount = br.ReadUInt16();
			data.Add(generator);
			return generator;
		}

		public override void Write(BinaryWriter bw, Generator o)
		{
		}

		public void Load(Instrument[] instruments)
		{
			Generator[] generators = Generators;
			foreach (Generator generator in generators)
			{
				if (generator.GeneratorType == GeneratorEnum.Instrument)
				{
					generator.Instrument = instruments[generator.UInt16Amount];
				}
			}
		}

		public void Load(SampleHeader[] sampleHeaders)
		{
			Generator[] generators = Generators;
			foreach (Generator generator in generators)
			{
				if (generator.GeneratorType == GeneratorEnum.SampleID)
				{
					generator.SampleHeader = sampleHeaders[generator.UInt16Amount];
				}
			}
		}
	}

	/// <summary>
	/// Generator types
	/// </summary>
	public enum GeneratorEnum
	{
		/// <summary>Start address offset</summary>
		StartAddressOffset,
		/// <summary>End address offset</summary>
		EndAddressOffset,
		/// <summary>Start loop address offset</summary>
		StartLoopAddressOffset,
		/// <summary>End loop address offset</summary>
		EndLoopAddressOffset,
		/// <summary>Start address coarse offset</summary>
		StartAddressCoarseOffset,
		/// <summary>Modulation LFO to pitch</summary>
		ModulationLFOToPitch,
		/// <summary>Vibrato LFO to pitch</summary>
		VibratoLFOToPitch,
		/// <summary>Modulation envelope to pitch</summary>
		ModulationEnvelopeToPitch,
		/// <summary>Initial filter cutoff frequency</summary>
		InitialFilterCutoffFrequency,
		/// <summary>Initial filter Q</summary>
		InitialFilterQ,
		/// <summary>Modulation LFO to filter Cutoff frequency</summary>
		ModulationLFOToFilterCutoffFrequency,
		/// <summary>Modulation envelope to filter cutoff frequency</summary>
		ModulationEnvelopeToFilterCutoffFrequency,
		/// <summary>End address coarse offset</summary>
		EndAddressCoarseOffset,
		/// <summary>Modulation LFO to volume</summary>
		ModulationLFOToVolume,
		/// <summary>Unused</summary>
		Unused1,
		/// <summary>Chorus effects send</summary>
		ChorusEffectsSend,
		/// <summary>Reverb effects send</summary>
		ReverbEffectsSend,
		/// <summary>Pan</summary>
		Pan,
		/// <summary>Unused</summary>
		Unused2,
		/// <summary>Unused</summary>
		Unused3,
		/// <summary>Unused</summary>
		Unused4,
		/// <summary>Delay modulation LFO</summary>
		DelayModulationLFO,
		/// <summary>Frequency modulation LFO</summary>
		FrequencyModulationLFO,
		/// <summary>Delay vibrato LFO</summary>
		DelayVibratoLFO,
		/// <summary>Frequency vibrato LFO</summary>
		FrequencyVibratoLFO,
		/// <summary>Delay modulation envelope</summary>
		DelayModulationEnvelope,
		/// <summary>Attack modulation envelope</summary>
		AttackModulationEnvelope,
		/// <summary>Hold modulation envelope</summary>
		HoldModulationEnvelope,
		/// <summary>Decay modulation envelope</summary>
		DecayModulationEnvelope,
		/// <summary>Sustain modulation envelop</summary>
		SustainModulationEnvelope,
		/// <summary>Release modulation envelope</summary>
		ReleaseModulationEnvelope,
		/// <summary>Key number to modulation envelope hold</summary>
		KeyNumberToModulationEnvelopeHold,
		/// <summary>Key number to modulation envelope decay</summary>
		KeyNumberToModulationEnvelopeDecay,
		/// <summary>Delay volume envelope</summary>
		DelayVolumeEnvelope,
		/// <summary>Attack volume envelope</summary>
		AttackVolumeEnvelope,
		/// <summary>Hold volume envelope</summary>
		HoldVolumeEnvelope,
		/// <summary>Decay volume envelope</summary>
		DecayVolumeEnvelope,
		/// <summary>Sustain volume envelope</summary>
		SustainVolumeEnvelope,
		/// <summary>Release volume envelope</summary>
		ReleaseVolumeEnvelope,
		/// <summary>Key number to volume envelope hold</summary>
		KeyNumberToVolumeEnvelopeHold,
		/// <summary>Key number to volume envelope decay</summary>
		KeyNumberToVolumeEnvelopeDecay,
		/// <summary>Instrument</summary>
		Instrument,
		/// <summary>Reserved</summary>
		Reserved1,
		/// <summary>Key range</summary>
		KeyRange,
		/// <summary>Velocity range</summary>
		VelocityRange,
		/// <summary>Start loop address coarse offset</summary>
		StartLoopAddressCoarseOffset,
		/// <summary>Key number</summary>
		KeyNumber,
		/// <summary>Velocity</summary>
		Velocity,
		/// <summary>Initial attenuation</summary>
		InitialAttenuation,
		/// <summary>Reserved</summary>
		Reserved2,
		/// <summary>End loop address coarse offset</summary>
		EndLoopAddressCoarseOffset,
		/// <summary>Coarse tune</summary>
		CoarseTune,
		/// <summary>Fine tune</summary>
		FineTune,
		/// <summary>Sample ID</summary>
		SampleID,
		/// <summary>Sample modes</summary>
		SampleModes,
		/// <summary>Reserved</summary>
		Reserved3,
		/// <summary>Scale tuning</summary>
		ScaleTuning,
		/// <summary>Exclusive class</summary>
		ExclusiveClass,
		/// <summary>Overriding root key</summary>
		OverridingRootKey,
		/// <summary>Unused</summary>
		Unused5,
		/// <summary>Unused</summary>
		UnusedEnd
	}

	/// <summary>
	/// A soundfont info chunk
	/// </summary>
	public class InfoChunk
	{
		/// <summary>
		/// SoundFont Version
		/// </summary>
		public SFVersion SoundFontVersion { get; }

		/// <summary>
		/// WaveTable sound engine
		/// </summary>
		public string WaveTableSoundEngine { get; set; }

		/// <summary>
		/// Bank name
		/// </summary>
		public string BankName { get; set; }

		/// <summary>
		/// Data ROM
		/// </summary>
		public string DataROM { get; set; }

		/// <summary>
		/// Creation Date
		/// </summary>
		public string CreationDate { get; set; }

		/// <summary>
		/// Author
		/// </summary>
		public string Author { get; set; }

		/// <summary>
		/// Target Product
		/// </summary>
		public string TargetProduct { get; set; }

		/// <summary>
		/// Copyright
		/// </summary>
		public string Copyright { get; set; }

		/// <summary>
		/// Comments
		/// </summary>
		public string Comments { get; set; }

		/// <summary>
		/// Tools
		/// </summary>
		public string Tools { get; set; }

		/// <summary>
		/// ROM Version
		/// </summary>
		public SFVersion ROMVersion { get; set; }

		internal InfoChunk(RiffChunk chunk)
		{
			bool flag = false;
			bool flag2 = false;
			if (chunk.ReadChunkID() != "INFO")
			{
				throw new InvalidDataException("Not an INFO chunk");
			}
			RiffChunk nextSubChunk;
			while ((nextSubChunk = chunk.GetNextSubChunk()) != null)
			{
				string chunkID = nextSubChunk.ChunkID;
				if (chunkID != null)
				{
					int length = chunkID.Length;
					if (length == 4)
					{
						switch (chunkID[2])
						{
						case 'i':
							if (!(chunkID == "ifil"))
							{
								break;
							}
							flag = true;
							SoundFontVersion = nextSubChunk.GetDataAsStructure(new SFVersionBuilder());
							continue;
						case 'n':
							if (!(chunkID == "isng"))
							{
								break;
							}
							WaveTableSoundEngine = nextSubChunk.GetDataAsString();
							continue;
						case 'A':
							if (!(chunkID == "INAM"))
							{
								break;
							}
							flag2 = true;
							BankName = nextSubChunk.GetDataAsString();
							continue;
						case 'o':
							if (!(chunkID == "irom"))
							{
								break;
							}
							DataROM = nextSubChunk.GetDataAsString();
							continue;
						case 'e':
							if (!(chunkID == "iver"))
							{
								break;
							}
							ROMVersion = nextSubChunk.GetDataAsStructure(new SFVersionBuilder());
							continue;
						case 'R':
							if (!(chunkID == "ICRD"))
							{
								if (!(chunkID == "IPRD"))
								{
									break;
								}
								TargetProduct = nextSubChunk.GetDataAsString();
								continue;
							}
							CreationDate = nextSubChunk.GetDataAsString();
							continue;
						case 'N':
							if (!(chunkID == "IENG"))
							{
								break;
							}
							Author = nextSubChunk.GetDataAsString();
							continue;
						case 'O':
							if (!(chunkID == "ICOP"))
							{
								break;
							}
							Copyright = nextSubChunk.GetDataAsString();
							continue;
						case 'M':
							if (!(chunkID == "ICMT"))
							{
								break;
							}
							Comments = nextSubChunk.GetDataAsString();
							continue;
						case 'F':
							if (!(chunkID == "ISFT"))
							{
								break;
							}
							Tools = nextSubChunk.GetDataAsString();
							continue;
						}
					}
				}
				throw new InvalidDataException("Unknown chunk type " + nextSubChunk.ChunkID);
			}
			if (!flag)
			{
				throw new InvalidDataException("Missing SoundFont version information");
			}
			if (!flag2)
			{
				throw new InvalidDataException("Missing SoundFont name information");
			}
		}

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return string.Format("Bank Name: {0}\r\nAuthor: {1}\r\nCopyright: {2}\r\nCreation Date: {3}\r\nTools: {4}\r\nComments: {5}\r\nSound Engine: {6}\r\nSoundFont Version: {7}\r\nTarget Product: {8}\r\nData ROM: {9}\r\nROM Version: {10}", BankName, Author, Copyright, CreationDate, Tools, "TODO-fix comments", WaveTableSoundEngine, SoundFontVersion, TargetProduct, DataROM, ROMVersion);
		}
	}

	/// <summary>
	/// SoundFont instrument
	/// </summary>
	public class Instrument
	{
		internal ushort startInstrumentZoneIndex;

		internal ushort endInstrumentZoneIndex;

		/// <summary>
		/// instrument name
		/// </summary>
		public string Name { get; set; }

		/// <summary>
		/// Zones
		/// </summary>
		public Zone[] Zones { get; set; }

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return Name;
		}
	}

	/// <summary>
	/// Instrument Builder
	/// </summary>
	internal class InstrumentBuilder : StructureBuilder<Instrument>
	{
		private Instrument lastInstrument;

		public override int Length => 22;

		public Instrument[] Instruments => data.ToArray();

		public override Instrument Read(BinaryReader br)
		{
			Instrument instrument = new Instrument();
			string text = Encoding.UTF8.GetString(br.ReadBytes(20), 0, 20);
			if (text.IndexOf('\0') >= 0)
			{
				text = text.Substring(0, text.IndexOf('\0'));
			}
			instrument.Name = text;
			instrument.startInstrumentZoneIndex = br.ReadUInt16();
			if (lastInstrument != null)
			{
				lastInstrument.endInstrumentZoneIndex = (ushort)(instrument.startInstrumentZoneIndex - 1);
			}
			data.Add(instrument);
			lastInstrument = instrument;
			return instrument;
		}

		public override void Write(BinaryWriter bw, Instrument instrument)
		{
		}

		public void LoadZones(Zone[] zones)
		{
			for (int i = 0; i < data.Count - 1; i++)
			{
				Instrument instrument = data[i];
				instrument.Zones = new Zone[instrument.endInstrumentZoneIndex - instrument.startInstrumentZoneIndex + 1];
				Array.Copy(zones, instrument.startInstrumentZoneIndex, instrument.Zones, 0, instrument.Zones.Length);
			}
			data.RemoveAt(data.Count - 1);
		}
	}

	/// <summary>
	/// Modulator
	/// </summary>
	public class Modulator
	{
		/// <summary>
		/// Source Modulation data type
		/// </summary>
		public ModulatorType SourceModulationData { get; set; }

		/// <summary>
		/// Destination generator type
		/// </summary>
		public GeneratorEnum DestinationGenerator { get; set; }

		/// <summary>
		/// Amount
		/// </summary>
		public short Amount { get; set; }

		/// <summary>
		/// Source Modulation Amount Type
		/// </summary>
		public ModulatorType SourceModulationAmount { get; set; }

		/// <summary>
		/// Source Transform Type
		/// </summary>
		public TransformEnum SourceTransform { get; set; }

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return $"Modulator {SourceModulationData} {DestinationGenerator} {Amount} {SourceModulationAmount} {SourceTransform}";
		}
	}

	internal class ModulatorBuilder : StructureBuilder<Modulator>
	{
		public override int Length => 10;

		public Modulator[] Modulators => data.ToArray();

		public override Modulator Read(BinaryReader br)
		{
			Modulator modulator = new Modulator();
			modulator.SourceModulationData = new ModulatorType(br.ReadUInt16());
			modulator.DestinationGenerator = (GeneratorEnum)br.ReadUInt16();
			modulator.Amount = br.ReadInt16();
			modulator.SourceModulationAmount = new ModulatorType(br.ReadUInt16());
			modulator.SourceTransform = (TransformEnum)br.ReadUInt16();
			data.Add(modulator);
			return modulator;
		}

		public override void Write(BinaryWriter bw, Modulator o)
		{
		}
	}

	/// <summary>
	/// Modulator Type
	/// </summary>
	public class ModulatorType
	{
		private bool polarity;

		private bool direction;

		private bool midiContinuousController;

		private ControllerSourceEnum controllerSource;

		private SourceTypeEnum sourceType;

		private ushort midiContinuousControllerNumber;

		internal ModulatorType(ushort raw)
		{
			polarity = (raw & 0x200) == 512;
			direction = (raw & 0x100) == 256;
			midiContinuousController = (raw & 0x80) == 128;
			sourceType = (SourceTypeEnum)((raw & 0xFC00) >> 10);
			controllerSource = (ControllerSourceEnum)(raw & 0x7F);
			midiContinuousControllerNumber = (ushort)(raw & 0x7Fu);
		}

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		/// <returns></returns>
		public override string ToString()
		{
			if (midiContinuousController)
			{
				return $"{sourceType} CC{midiContinuousControllerNumber}";
			}
			return $"{sourceType} {controllerSource}";
		}
	}

	/// <summary>
	/// A SoundFont Preset
	/// </summary>
	public class Preset
	{
		internal ushort startPresetZoneIndex;

		internal ushort endPresetZoneIndex;

		internal uint library;

		internal uint genre;

		internal uint morphology;

		/// <summary>
		/// Preset name
		/// </summary>
		public string Name { get; set; }

		/// <summary>
		/// Patch Number
		/// </summary>
		public ushort PatchNumber { get; set; }

		/// <summary>
		/// Bank number
		/// 0 - 127, GM percussion bank is 128
		/// </summary>
		public ushort Bank { get; set; }

		/// <summary>
		/// Zones
		/// </summary>
		public Zone[] Zones { get; set; }

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return $"{Bank}-{PatchNumber} {Name}";
		}
	}

	internal class PresetBuilder : StructureBuilder<Preset>
	{
		private Preset lastPreset;

		public override int Length => 38;

		public Preset[] Presets => data.ToArray();

		public override Preset Read(BinaryReader br)
		{
			Preset preset = new Preset();
			string text = Encoding.UTF8.GetString(br.ReadBytes(20), 0, 20);
			if (text.IndexOf('\0') >= 0)
			{
				text = text.Substring(0, text.IndexOf('\0'));
			}
			preset.Name = text;
			preset.PatchNumber = br.ReadUInt16();
			preset.Bank = br.ReadUInt16();
			preset.startPresetZoneIndex = br.ReadUInt16();
			preset.library = br.ReadUInt32();
			preset.genre = br.ReadUInt32();
			preset.morphology = br.ReadUInt32();
			if (lastPreset != null)
			{
				lastPreset.endPresetZoneIndex = (ushort)(preset.startPresetZoneIndex - 1);
			}
			data.Add(preset);
			lastPreset = preset;
			return preset;
		}

		public override void Write(BinaryWriter bw, Preset preset)
		{
		}

		public void LoadZones(Zone[] presetZones)
		{
			for (int i = 0; i < data.Count - 1; i++)
			{
				Preset preset = data[i];
				preset.Zones = new Zone[preset.endPresetZoneIndex - preset.startPresetZoneIndex + 1];
				Array.Copy(presetZones, preset.startPresetZoneIndex, preset.Zones, 0, preset.Zones.Length);
			}
			data.RemoveAt(data.Count - 1);
		}
	}

	/// <summary>
	/// Class to read the SoundFont file presets chunk
	/// </summary>
	public class PresetsChunk
	{
		private PresetBuilder presetHeaders = new PresetBuilder();

		private ZoneBuilder presetZones = new ZoneBuilder();

		private ModulatorBuilder presetZoneModulators = new ModulatorBuilder();

		private GeneratorBuilder presetZoneGenerators = new GeneratorBuilder();

		private InstrumentBuilder instruments = new InstrumentBuilder();

		private ZoneBuilder instrumentZones = new ZoneBuilder();

		private ModulatorBuilder instrumentZoneModulators = new ModulatorBuilder();

		private GeneratorBuilder instrumentZoneGenerators = new GeneratorBuilder();

		private SampleHeaderBuilder sampleHeaders = new SampleHeaderBuilder();

		/// <summary>
		/// The Presets contained in this chunk
		/// </summary>
		public Preset[] Presets => presetHeaders.Presets;

		/// <summary>
		/// The instruments contained in this chunk
		/// </summary>
		public Instrument[] Instruments => instruments.Instruments;

		/// <summary>
		/// The sample headers contained in this chunk
		/// </summary>
		public SampleHeader[] SampleHeaders => sampleHeaders.SampleHeaders;

		internal PresetsChunk(RiffChunk chunk)
		{
			string text = chunk.ReadChunkID();
			if (text != "pdta")
			{
				throw new InvalidDataException($"Not a presets data chunk ({text})");
			}
			RiffChunk nextSubChunk;
			while ((nextSubChunk = chunk.GetNextSubChunk()) != null)
			{
				string chunkID = nextSubChunk.ChunkID;
				if (chunkID != null)
				{
					int length = chunkID.Length;
					if (length == 4)
					{
						char c = chunkID[1];
						if ((uint)c <= 78u)
						{
							if ((uint)c <= 71u)
							{
								if (c != 'B')
								{
									if (c == 'G')
									{
										if (chunkID == "PGEN")
										{
											goto IL_02a8;
										}
										if (chunkID == "IGEN")
										{
											goto IL_02e4;
										}
									}
								}
								else
								{
									if (chunkID == "PBAG")
									{
										goto IL_028a;
									}
									if (chunkID == "IBAG")
									{
										goto IL_02c6;
									}
								}
							}
							else if (c != 'H')
							{
								if (c != 'M')
								{
									if (c == 'N' && chunkID == "INST")
									{
										goto IL_02b7;
									}
								}
								else
								{
									if (chunkID == "PMOD")
									{
										goto IL_0299;
									}
									if (chunkID == "IMOD")
									{
										goto IL_02d5;
									}
								}
							}
							else
							{
								if (chunkID == "PHDR")
								{
									goto IL_0278;
								}
								if (chunkID == "SHDR")
								{
									goto IL_02f3;
								}
							}
						}
						else if ((uint)c <= 103u)
						{
							if (c != 'b')
							{
								if (c == 'g')
								{
									if (chunkID == "pgen")
									{
										goto IL_02a8;
									}
									if (chunkID == "igen")
									{
										goto IL_02e4;
									}
								}
							}
							else
							{
								if (chunkID == "pbag")
								{
									goto IL_028a;
								}
								if (chunkID == "ibag")
								{
									goto IL_02c6;
								}
							}
						}
						else if (c != 'h')
						{
							if (c != 'm')
							{
								if (c == 'n' && chunkID == "inst")
								{
									goto IL_02b7;
								}
							}
							else
							{
								if (chunkID == "pmod")
								{
									goto IL_0299;
								}
								if (chunkID == "imod")
								{
									goto IL_02d5;
								}
							}
						}
						else
						{
							if (chunkID == "phdr")
							{
								goto IL_0278;
							}
							if (chunkID == "shdr")
							{
								goto IL_02f3;
							}
						}
					}
				}
				throw new InvalidDataException($"Unknown chunk type {nextSubChunk.ChunkID}");
				IL_02b7:
				nextSubChunk.GetDataAsStructureArray(instruments);
				continue;
				IL_02e4:
				nextSubChunk.GetDataAsStructureArray(instrumentZoneGenerators);
				continue;
				IL_02a8:
				nextSubChunk.GetDataAsStructureArray(presetZoneGenerators);
				continue;
				IL_0278:
				nextSubChunk.GetDataAsStructureArray(presetHeaders);
				continue;
				IL_02c6:
				nextSubChunk.GetDataAsStructureArray(instrumentZones);
				continue;
				IL_028a:
				nextSubChunk.GetDataAsStructureArray(presetZones);
				continue;
				IL_02d5:
				nextSubChunk.GetDataAsStructureArray(instrumentZoneModulators);
				continue;
				IL_0299:
				nextSubChunk.GetDataAsStructureArray(presetZoneModulators);
				continue;
				IL_02f3:
				nextSubChunk.GetDataAsStructureArray(sampleHeaders);
			}
			instrumentZoneGenerators.Load(sampleHeaders.SampleHeaders);
			instrumentZones.Load(instrumentZoneModulators.Modulators, instrumentZoneGenerators.Generators);
			instruments.LoadZones(instrumentZones.Zones);
			presetZoneGenerators.Load(instruments.Instruments);
			presetZones.Load(presetZoneModulators.Modulators, presetZoneGenerators.Generators);
			presetHeaders.LoadZones(presetZones.Zones);
			sampleHeaders.RemoveEOS();
		}

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			StringBuilder stringBuilder = new StringBuilder();
			stringBuilder.Append("Preset Headers:\r\n");
			Preset[] presets = presetHeaders.Presets;
			foreach (Preset arg in presets)
			{
				stringBuilder.AppendFormat("{0}\r\n", arg);
			}
			stringBuilder.Append("Instruments:\r\n");
			Instrument[] array = instruments.Instruments;
			foreach (Instrument arg2 in array)
			{
				stringBuilder.AppendFormat("{0}\r\n", arg2);
			}
			return stringBuilder.ToString();
		}
	}

	internal class RiffChunk
	{
		private string chunkID;

		private BinaryReader riffFile;

		public string ChunkID
		{
			get
			{
				return chunkID;
			}
			set
			{
				if (value == null)
				{
					throw new ArgumentNullException("ChunkID may not be null");
				}
				if (value.Length != 4)
				{
					throw new ArgumentException("ChunkID must be four characters");
				}
				chunkID = value;
			}
		}

		public uint ChunkSize { get; private set; }

		public long DataOffset { get; private set; }

		public static RiffChunk GetTopLevelChunk(BinaryReader file)
		{
			RiffChunk riffChunk = new RiffChunk(file);
			riffChunk.ReadChunk();
			return riffChunk;
		}

		private RiffChunk(BinaryReader file)
		{
			riffFile = file;
			chunkID = "????";
			ChunkSize = 0u;
			DataOffset = 0L;
		}

		/// <summary>
		/// just reads a chunk ID at the current position
		/// </summary>
		/// <returns>chunk ID</returns>
		public string ReadChunkID()
		{
			byte[] array = riffFile.ReadBytes(4);
			if (array.Length != 4)
			{
				throw new InvalidDataException("Couldn't read Chunk ID");
			}
			return ByteEncoding.Instance.GetString(array, 0, array.Length);
		}

		/// <summary>
		/// reads a chunk at the current position
		/// </summary>
		private void ReadChunk()
		{
			chunkID = ReadChunkID();
			ChunkSize = riffFile.ReadUInt32();
			DataOffset = riffFile.BaseStream.Position;
		}

		/// <summary>
		/// creates a new riffchunk from current position checking that we're not
		/// at the end of this chunk first
		/// </summary>
		/// <returns>the new chunk</returns>
		public RiffChunk GetNextSubChunk()
		{
			if (riffFile.BaseStream.Position + 8 < DataOffset + ChunkSize)
			{
				RiffChunk riffChunk = new RiffChunk(riffFile);
				riffChunk.ReadChunk();
				return riffChunk;
			}
			return null;
		}

		public byte[] GetData()
		{
			riffFile.BaseStream.Position = DataOffset;
			byte[] array = riffFile.ReadBytes((int)ChunkSize);
			if (array.Length != ChunkSize)
			{
				throw new InvalidDataException($"Couldn't read chunk's data Chunk: {this}, read {array.Length} bytes");
			}
			return array;
		}

		/// <summary>
		/// useful for chunks that just contain a string
		/// </summary>
		/// <returns>chunk as string</returns>
		public string GetDataAsString()
		{
			byte[] data = GetData();
			if (data == null)
			{
				return null;
			}
			return ByteEncoding.Instance.GetString(data, 0, data.Length);
		}

		public T GetDataAsStructure<T>(StructureBuilder<T> s)
		{
			riffFile.BaseStream.Position = DataOffset;
			if (s.Length != ChunkSize)
			{
				throw new InvalidDataException($"Chunk size is: {ChunkSize} so can't read structure of: {s.Length}");
			}
			return s.Read(riffFile);
		}

		public T[] GetDataAsStructureArray<T>(StructureBuilder<T> s)
		{
			riffFile.BaseStream.Position = DataOffset;
			if ((long)ChunkSize % (long)s.Length != 0L)
			{
				throw new InvalidDataException($"Chunk size is: {ChunkSize} not a multiple of structure size: {s.Length}");
			}
			int num = (int)((long)ChunkSize / (long)s.Length);
			T[] array = new T[num];
			for (int i = 0; i < num; i++)
			{
				array[i] = s.Read(riffFile);
			}
			return array;
		}

		public override string ToString()
		{
			return $"RiffChunk ID: {ChunkID} Size: {ChunkSize} Data Offset: {DataOffset}";
		}
	}

	internal class SampleDataChunk
	{
		public byte[] SampleData { get; private set; }

		public SampleDataChunk(RiffChunk chunk)
		{
			string text = chunk.ReadChunkID();
			if (text != "sdta")
			{
				throw new InvalidDataException("Not a sample data chunk (" + text + ")");
			}
			SampleData = chunk.GetData();
		}
	}

	/// <summary>
	/// A SoundFont Sample Header
	/// </summary>
	public class SampleHeader
	{
		/// <summary>
		/// The sample name
		/// </summary>
		public string SampleName;

		/// <summary>
		/// Start offset
		/// </summary>
		public uint Start;

		/// <summary>
		/// End offset
		/// </summary>
		public uint End;

		/// <summary>
		/// Start loop point
		/// </summary>
		public uint StartLoop;

		/// <summary>
		/// End loop point
		/// </summary>
		public uint EndLoop;

		/// <summary>
		/// Sample Rate
		/// </summary>
		public uint SampleRate;

		/// <summary>
		/// Original pitch
		/// </summary>
		public byte OriginalPitch;

		/// <summary>
		/// Pitch correction
		/// </summary>
		public sbyte PitchCorrection;

		/// <summary>
		/// Sample Link
		/// </summary>
		public ushort SampleLink;

		/// <summary>
		/// SoundFont Sample Link Type
		/// </summary>
		public SFSampleLink SFSampleLink;

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return SampleName;
		}
	}

	internal class SampleHeaderBuilder : StructureBuilder<SampleHeader>
	{
		public override int Length => 46;

		public SampleHeader[] SampleHeaders => data.ToArray();

		public override SampleHeader Read(BinaryReader br)
		{
			SampleHeader sampleHeader = new SampleHeader();
			byte[] array = br.ReadBytes(20);
			sampleHeader.SampleName = ByteEncoding.Instance.GetString(array, 0, array.Length);
			sampleHeader.Start = br.ReadUInt32();
			sampleHeader.End = br.ReadUInt32();
			sampleHeader.StartLoop = br.ReadUInt32();
			sampleHeader.EndLoop = br.ReadUInt32();
			sampleHeader.SampleRate = br.ReadUInt32();
			sampleHeader.OriginalPitch = br.ReadByte();
			sampleHeader.PitchCorrection = br.ReadSByte();
			sampleHeader.SampleLink = br.ReadUInt16();
			sampleHeader.SFSampleLink = (SFSampleLink)br.ReadUInt16();
			data.Add(sampleHeader);
			return sampleHeader;
		}

		public override void Write(BinaryWriter bw, SampleHeader sampleHeader)
		{
		}

		internal void RemoveEOS()
		{
			data.RemoveAt(data.Count - 1);
		}
	}

	/// <summary>
	/// SoundFont sample modes
	/// </summary>
	public enum SampleMode
	{
		/// <summary>
		/// No loop
		/// </summary>
		NoLoop,
		/// <summary>
		/// Loop Continuously
		/// </summary>
		LoopContinuously,
		/// <summary>
		/// Reserved no loop
		/// </summary>
		ReservedNoLoop,
		/// <summary>
		/// Loop and continue
		/// </summary>
		LoopAndContinue
	}

	/// <summary>
	/// Sample Link Type
	/// </summary>
	public enum SFSampleLink : ushort
	{
		/// <summary>
		/// Mono Sample
		/// </summary>
		MonoSample = 1,
		/// <summary>
		/// Right Sample
		/// </summary>
		RightSample = 2,
		/// <summary>
		/// Left Sample
		/// </summary>
		LeftSample = 4,
		/// <summary>
		/// Linked Sample
		/// </summary>
		LinkedSample = 8,
		/// <summary>
		/// ROM Mono Sample
		/// </summary>
		RomMonoSample = 32769,
		/// <summary>
		/// ROM Right Sample
		/// </summary>
		RomRightSample = 32770,
		/// <summary>
		/// ROM Left Sample
		/// </summary>
		RomLeftSample = 32772,
		/// <summary>
		/// ROM Linked Sample
		/// </summary>
		RomLinkedSample = 32776
	}

	/// <summary>
	/// SoundFont Version Structure
	/// </summary>
	public class SFVersion
	{
		/// <summary>
		/// Major Version
		/// </summary>
		public short Major { get; set; }

		/// <summary>
		/// Minor Version
		/// </summary>
		public short Minor { get; set; }
	}

	/// <summary>
	/// Builds a SoundFont version
	/// </summary>
	internal class SFVersionBuilder : StructureBuilder<SFVersion>
	{
		/// <summary>
		/// Gets the length of this structure
		/// </summary>
		public override int Length => 4;

		/// <summary>
		/// Reads a SoundFont Version structure
		/// </summary>
		public override SFVersion Read(BinaryReader br)
		{
			SFVersion sFVersion = new SFVersion();
			sFVersion.Major = br.ReadInt16();
			sFVersion.Minor = br.ReadInt16();
			data.Add(sFVersion);
			return sFVersion;
		}

		/// <summary>
		/// Writes a SoundFont Version structure
		/// </summary>
		public override void Write(BinaryWriter bw, SFVersion v)
		{
			bw.Write(v.Major);
			bw.Write(v.Minor);
		}
	}

	/// <summary>
	/// Represents a SoundFont
	/// </summary>
	public class SoundFont
	{
		private InfoChunk info;

		private PresetsChunk presetsChunk;

		private SampleDataChunk sampleData;

		/// <summary>
		/// The File Info Chunk
		/// </summary>
		public InfoChunk FileInfo => info;

		/// <summary>
		/// The Presets
		/// </summary>
		public Preset[] Presets => presetsChunk.Presets;

		/// <summary>
		/// The Instruments
		/// </summary>
		public Instrument[] Instruments => presetsChunk.Instruments;

		/// <summary>
		/// The Sample Headers
		/// </summary>
		public SampleHeader[] SampleHeaders => presetsChunk.SampleHeaders;

		/// <summary>
		/// The Sample Data
		/// </summary>
		public byte[] SampleData => sampleData.SampleData;

		/// <summary>
		/// Loads a SoundFont from a file
		/// </summary>
		/// <param name="fileName">Filename of the SoundFont</param>
		public SoundFont(string fileName)
			: this(new FileStream(fileName, FileMode.Open, FileAccess.Read))
		{
		}

		/// <summary>
		/// Loads a SoundFont from a stream
		/// </summary>
		/// <param name="sfFile">stream</param>
		public SoundFont(Stream sfFile)
		{
			using (sfFile)
			{
				RiffChunk topLevelChunk = RiffChunk.GetTopLevelChunk(new BinaryReader(sfFile));
				if (topLevelChunk.ChunkID == "RIFF")
				{
					string text = topLevelChunk.ReadChunkID();
					if (text != "sfbk")
					{
						throw new InvalidDataException($"Not a SoundFont ({text})");
					}
					RiffChunk nextSubChunk = topLevelChunk.GetNextSubChunk();
					if (nextSubChunk.ChunkID == "LIST")
					{
						info = new InfoChunk(nextSubChunk);
						RiffChunk nextSubChunk2 = topLevelChunk.GetNextSubChunk();
						sampleData = new SampleDataChunk(nextSubChunk2);
						nextSubChunk2 = topLevelChunk.GetNextSubChunk();
						presetsChunk = new PresetsChunk(nextSubChunk2);
						return;
					}
					throw new InvalidDataException($"Not info list found ({nextSubChunk.ChunkID})");
				}
				throw new InvalidDataException("Not a RIFF file");
			}
		}

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return $"Info Chunk:\r\n{info}\r\nPresets Chunk:\r\n{presetsChunk}";
		}
	}

	/// <summary>
	/// Source Types
	/// </summary>
	public enum SourceTypeEnum
	{
		/// <summary>
		/// Linear
		/// </summary>
		Linear,
		/// <summary>
		/// Concave
		/// </summary>
		Concave,
		/// <summary>
		/// Convex
		/// </summary>
		Convex,
		/// <summary>
		/// Switch
		/// </summary>
		Switch
	}

	/// <summary>
	/// base class for structures that can read themselves
	/// </summary>
	internal abstract class StructureBuilder<T>
	{
		protected List<T> data;

		public abstract int Length { get; }

		public T[] Data => data.ToArray();

		public StructureBuilder()
		{
			Reset();
		}

		public abstract T Read(BinaryReader br);

		public abstract void Write(BinaryWriter bw, T o);

		public void Reset()
		{
			data = new List<T>();
		}
	}

	/// <summary>
	/// Transform Types
	/// </summary>
	public enum TransformEnum
	{
		/// <summary>
		/// Linear
		/// </summary>
		Linear
	}

	/// <summary>
	/// A SoundFont zone
	/// </summary>
	public class Zone
	{
		internal ushort generatorIndex;

		internal ushort modulatorIndex;

		internal ushort generatorCount;

		internal ushort modulatorCount;

		/// <summary>
		/// Modulators for this Zone
		/// </summary>
		public Modulator[] Modulators { get; set; }

		/// <summary>
		/// Generators for this Zone
		/// </summary>
		public Generator[] Generators { get; set; }

		/// <summary>
		/// <see cref="M:System.Object.ToString" />
		/// </summary>
		public override string ToString()
		{
			return $"Zone {generatorCount} Gens:{generatorIndex} {modulatorCount} Mods:{modulatorIndex}";
		}
	}

	internal class ZoneBuilder : StructureBuilder<Zone>
	{
		private Zone lastZone;

		public Zone[] Zones => data.ToArray();

		public override int Length => 4;

		public override Zone Read(BinaryReader br)
		{
			Zone zone = new Zone();
			zone.generatorIndex = br.ReadUInt16();
			zone.modulatorIndex = br.ReadUInt16();
			if (lastZone != null)
			{
				lastZone.generatorCount = (ushort)(zone.generatorIndex - lastZone.generatorIndex);
				lastZone.modulatorCount = (ushort)(zone.modulatorIndex - lastZone.modulatorIndex);
			}
			data.Add(zone);
			lastZone = zone;
			return zone;
		}

		public override void Write(BinaryWriter bw, Zone zone)
		{
		}

		public void Load(Modulator[] modulators, Generator[] generators)
		{
			for (int i = 0; i < data.Count - 1; i++)
			{
				Zone zone = data[i];
				zone.Generators = new Generator[zone.generatorCount];
				Array.Copy(generators, zone.generatorIndex, zone.Generators, 0, zone.generatorCount);
				zone.Modulators = new Modulator[zone.modulatorCount];
				Array.Copy(modulators, zone.modulatorIndex, zone.Modulators, 0, zone.modulatorCount);
			}
			data.RemoveAt(data.Count - 1);
		}
	}
}

namespace NAudio.Utils
{
	using NAudio.Wave;
	
	internal class MergeSort
	{
		/// <summary>
		/// In-place and stable implementation of MergeSort
		/// </summary>
		private static void Sort<T>(IList<T> list, int lowIndex, int highIndex, IComparer<T> comparer)
		{
			if (lowIndex >= highIndex)
			{
				return;
			}
			int num = (lowIndex + highIndex) / 2;
			Sort(list, lowIndex, num, comparer);
			Sort(list, num + 1, highIndex, comparer);
			int num2 = num;
			int num3 = num + 1;
			while (lowIndex <= num2 && num3 <= highIndex)
			{
				if (comparer.Compare(list[lowIndex], list[num3]) <= 0)
				{
					lowIndex++;
					continue;
				}
				T value = list[num3];
				for (int num4 = num3 - 1; num4 >= lowIndex; num4--)
				{
					list[num4 + 1] = list[num4];
				}
				list[lowIndex] = value;
				lowIndex++;
				num2++;
				num3++;
			}
		}

		/// <summary>
		/// MergeSort a list of comparable items
		/// </summary>
		public static void Sort<T>(IList<T> list) where T : IComparable<T>
		{
			Sort(list, 0, list.Count - 1, Comparer<T>.Default);
		}

		/// <summary>
		/// MergeSort a list 
		/// </summary>
		public static void Sort<T>(IList<T> list, IComparer<T> comparer)
		{
			Sort(list, 0, list.Count - 1, comparer);
		}
	}
	
	/// <summary>
	/// Helper methods for working with audio buffers
	/// </summary>
	public static class BufferHelpers
	{
		/// <summary>
		/// Ensures the buffer is big enough
		/// </summary>
		/// <param name="buffer"></param>
		/// <param name="bytesRequired"></param>
		/// <returns></returns>
		public static byte[] Ensure(byte[] buffer, int bytesRequired)
		{
			if (buffer == null || buffer.Length < bytesRequired)
			{
				buffer = new byte[bytesRequired];
			}
			return buffer;
		}

		/// <summary>
		/// Ensures the buffer is big enough
		/// </summary>
		/// <param name="buffer"></param>
		/// <param name="samplesRequired"></param>
		/// <returns></returns>
		public static float[] Ensure(float[] buffer, int samplesRequired)
		{
			if (buffer == null || buffer.Length < samplesRequired)
			{
				buffer = new float[samplesRequired];
			}
			return buffer;
		}
	}

	/// <summary>
	/// these will become extension methods once we move to .NET 3.5
	/// </summary>
	public static class ByteArrayExtensions
	{
		/// <summary>
		/// Checks if the buffer passed in is entirely full of nulls
		/// </summary>
		public static bool IsEntirelyNull(byte[] buffer)
		{
			for (int i = 0; i < buffer.Length; i++)
			{
				if (buffer[i] != 0)
				{
					return false;
				}
			}
			return true;
		}

		/// <summary>
		/// Converts to a string containing the buffer described in hex
		/// </summary>
		public static string DescribeAsHex(byte[] buffer, string separator, int bytesPerLine)
		{
			StringBuilder stringBuilder = new StringBuilder();
			int num = 0;
			foreach (byte b in buffer)
			{
				stringBuilder.AppendFormat("{0:X2}{1}", b, separator);
				if (++num % bytesPerLine == 0)
				{
					stringBuilder.Append("\r\n");
				}
			}
			stringBuilder.Append("\r\n");
			return stringBuilder.ToString();
		}

		/// <summary>
		/// Decodes the buffer using the specified encoding, stopping at the first null
		/// </summary>
		public static string DecodeAsString(byte[] buffer, int offset, int length, Encoding encoding)
		{
			for (int i = 0; i < length; i++)
			{
				if (buffer[offset + i] == 0)
				{
					length = i;
				}
			}
			return encoding.GetString(buffer, offset, length);
		}

		/// <summary>
		/// Concatenates the given arrays into a single array.
		/// </summary>
		/// <param name="byteArrays">The arrays to concatenate</param>
		/// <returns>The concatenated resulting array.</returns>
		public static byte[] Concat(params byte[][] byteArrays)
		{
			int num = 0;
			byte[][] array = byteArrays;
			foreach (byte[] array2 in array)
			{
				num += array2.Length;
			}
			if (num <= 0)
			{
				return new byte[0];
			}
			byte[] array3 = new byte[num];
			int num2 = 0;
			array = byteArrays;
			foreach (byte[] array4 in array)
			{
				Array.Copy(array4, 0, array3, num2, array4.Length);
				num2 += array4.Length;
			}
			return array3;
		}
	}

	/// <summary>
	/// An encoding for use with file types that have one byte per character
	/// </summary>
	public class ByteEncoding : Encoding
	{
		/// <summary>
		/// The one and only instance of this class
		/// </summary>
		public static readonly ByteEncoding Instance = new ByteEncoding();

		private ByteEncoding()
		{
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetByteCount(System.Char[],System.Int32,System.Int32)" />
		/// </summary>
		public override int GetByteCount(char[] chars, int index, int count)
		{
			return count;
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetBytes(System.Char[],System.Int32,System.Int32,System.Byte[],System.Int32)" />
		/// </summary>
		public override int GetBytes(char[] chars, int charIndex, int charCount, byte[] bytes, int byteIndex)
		{
			for (int i = 0; i < charCount; i++)
			{
				bytes[byteIndex + i] = (byte)chars[charIndex + i];
			}
			return charCount;
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetCharCount(System.Byte[],System.Int32,System.Int32)" />
		/// </summary>
		public override int GetCharCount(byte[] bytes, int index, int count)
		{
			for (int i = 0; i < count; i++)
			{
				if (bytes[index + i] == 0)
				{
					return i;
				}
			}
			return count;
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetChars(System.Byte[],System.Int32,System.Int32,System.Char[],System.Int32)" />
		/// </summary>
		public override int GetChars(byte[] bytes, int byteIndex, int byteCount, char[] chars, int charIndex)
		{
			for (int i = 0; i < byteCount; i++)
			{
				byte b = bytes[byteIndex + i];
				if (b == 0)
				{
					return i;
				}
				chars[charIndex + i] = (char)b;
			}
			return byteCount;
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetMaxCharCount(System.Int32)" />
		/// </summary>
		public override int GetMaxCharCount(int byteCount)
		{
			return byteCount;
		}

		/// <summary>
		/// <see cref="M:System.Text.Encoding.GetMaxByteCount(System.Int32)" />
		/// </summary>
		public override int GetMaxByteCount(int charCount)
		{
			return charCount;
		}
	}

	/// <summary>
	/// Chunk Identifier helpers
	/// </summary>
	public class ChunkIdentifier
	{
		/// <summary>
		/// Chunk identifier to Int32 (replaces mmioStringToFOURCC)
		/// </summary>
		/// <param name="s">four character chunk identifier</param>
		/// <returns>Chunk identifier as int 32</returns>
		public static int ChunkIdentifierToInt32(string s)
		{
			if (s.Length != 4)
			{
				throw new ArgumentException("Must be a four character string");
			}
			byte[] bytes = Encoding.UTF8.GetBytes(s);
			if (bytes.Length != 4)
			{
				throw new ArgumentException("Must encode to exactly four bytes");
			}
			return BitConverter.ToInt32(bytes, 0);
		}
	}

	/// <summary>
	/// A very basic circular buffer implementation
	/// </summary>
	public class CircularBuffer
	{
		private readonly byte[] buffer;

		private readonly object lockObject;

		private int writePosition;

		private int readPosition;

		private int byteCount;

		/// <summary>
		/// Maximum length of this circular buffer
		/// </summary>
		public int MaxLength => buffer.Length;

		/// <summary>
		/// Number of bytes currently stored in the circular buffer
		/// </summary>
		public int Count
		{
			get
			{
				lock (lockObject)
				{
					return byteCount;
				}
			}
		}

		/// <summary>
		/// Create a new circular buffer
		/// </summary>
		/// <param name="size">Max buffer size in bytes</param>
		public CircularBuffer(int size)
		{
			buffer = new byte[size];
			lockObject = new object();
		}

		/// <summary>
		/// Write data to the buffer
		/// </summary>
		/// <param name="data">Data to write</param>
		/// <param name="offset">Offset into data</param>
		/// <param name="count">Number of bytes to write</param>
		/// <returns>number of bytes written</returns>
		public int Write(byte[] data, int offset, int count)
		{
			lock (lockObject)
			{
				int num = 0;
				if (count > buffer.Length - byteCount)
				{
					count = buffer.Length - byteCount;
				}
				int num2 = Math.Min(buffer.Length - writePosition, count);
				Array.Copy(data, offset, buffer, writePosition, num2);
				writePosition += num2;
				writePosition %= buffer.Length;
				num += num2;
				if (num < count)
				{
					Array.Copy(data, offset + num, buffer, writePosition, count - num);
					writePosition += count - num;
					num = count;
				}
				byteCount += num;
				return num;
			}
		}

		/// <summary>
		/// Read from the buffer
		/// </summary>
		/// <param name="data">Buffer to read into</param>
		/// <param name="offset">Offset into read buffer</param>
		/// <param name="count">Bytes to read</param>
		/// <returns>Number of bytes actually read</returns>
		public int Read(byte[] data, int offset, int count)
		{
			lock (lockObject)
			{
				if (count > byteCount)
				{
					count = byteCount;
				}
				int num = 0;
				int num2 = Math.Min(buffer.Length - readPosition, count);
				Array.Copy(buffer, readPosition, data, offset, num2);
				num += num2;
				readPosition += num2;
				readPosition %= buffer.Length;
				if (num < count)
				{
					Array.Copy(buffer, readPosition, data, offset + num, count - num);
					readPosition += count - num;
					num = count;
				}
				byteCount -= num;
				return num;
			}
		}

		/// <summary>
		/// Resets the buffer
		/// </summary>
		public void Reset()
		{
			lock (lockObject)
			{
				ResetInner();
			}
		}

		private void ResetInner()
		{
			byteCount = 0;
			readPosition = 0;
			writePosition = 0;
		}

		/// <summary>
		/// Advances the buffer, discarding bytes
		/// </summary>
		/// <param name="count">Bytes to advance</param>
		public void Advance(int count)
		{
			lock (lockObject)
			{
				if (count >= byteCount)
				{
					ResetInner();
					return;
				}
				byteCount -= count;
				readPosition += count;
				readPosition %= MaxLength;
			}
		}
	}

	/// <summary>
	/// A util class for conversions
	/// </summary>
	public class Decibels
	{
		private const double LOG_2_DB = 8.685889638065037;

		private const double DB_2_LOG = 0.11512925464970228;

		/// <summary>
		/// linear to dB conversion
		/// </summary>
		/// <param name="lin">linear value</param>
		/// <returns>decibel value</returns>
		public static double LinearToDecibels(double lin)
		{
			return Math.Log(lin) * 8.685889638065037;
		}

		/// <summary>
		/// dB to linear conversion
		/// </summary>
		/// <param name="dB">decibel value</param>
		/// <returns>linear value</returns>
		public static double DecibelsToLinear(double dB)
		{
			return Math.Exp(dB * 0.11512925464970228);
		}
	}

	/// <summary>
	/// Allows us to add descriptions to interop members
	/// </summary>
	[AttributeUsage(AttributeTargets.Field)]
	public class FieldDescriptionAttribute : Attribute
	{
		/// <summary>
		/// The description
		/// </summary>
		public string Description { get; }

		/// <summary>
		/// Field description
		/// </summary>
		public FieldDescriptionAttribute(string description)
		{
			Description = description;
		}

		/// <summary>
		/// String representation
		/// </summary>
		/// <returns></returns>
		public override string ToString()
		{
			return Description;
		}
	}

	/// <summary>
	/// Helper to get descriptions
	/// </summary>
	public static class FieldDescriptionHelper
	{
		/// <summary>
		/// Describes the Guid  by looking for a FieldDescription attribute on the specified class
		/// </summary>
		public static string Describe(Type t, Guid guid)
		{
			FieldInfo[] fields = t.GetFields(BindingFlags.Static | BindingFlags.Public);
			foreach (FieldInfo fieldInfo in fields)
			{
				if (!fieldInfo.IsPublic || !fieldInfo.IsStatic || !(fieldInfo.FieldType == typeof(Guid)) || !((Guid)fieldInfo.GetValue(null) == guid))
				{
					continue;
				}
				object[] customAttributes = fieldInfo.GetCustomAttributes(inherit: false);
				for (int j = 0; j < customAttributes.Length; j++)
				{
					if (customAttributes[j] is FieldDescriptionAttribute fieldDescriptionAttribute)
					{
						return fieldDescriptionAttribute.Description;
					}
				}
				return fieldInfo.Name;
			}
			return guid.ToString();
		}
	}

	/// <summary>
	/// HResult
	/// </summary>
	public static class HResult
	{
		/// <summary>
		/// S_OK
		/// </summary>
		public const int S_OK = 0;

		/// <summary>
		/// S_FALSE
		/// </summary>
		public const int S_FALSE = 1;

		/// <summary>
		/// E_INVALIDARG (from winerror.h)
		/// </summary>
		public const int E_INVALIDARG = -2147483645;

		private const int FACILITY_AAF = 18;

		private const int FACILITY_ACS = 20;

		private const int FACILITY_BACKGROUNDCOPY = 32;

		private const int FACILITY_CERT = 11;

		private const int FACILITY_COMPLUS = 17;

		private const int FACILITY_CONFIGURATION = 33;

		private const int FACILITY_CONTROL = 10;

		private const int FACILITY_DISPATCH = 2;

		private const int FACILITY_DPLAY = 21;

		private const int FACILITY_HTTP = 25;

		private const int FACILITY_INTERNET = 12;

		private const int FACILITY_ITF = 4;

		private const int FACILITY_MEDIASERVER = 13;

		private const int FACILITY_MSMQ = 14;

		private const int FACILITY_NULL = 0;

		private const int FACILITY_RPC = 1;

		private const int FACILITY_SCARD = 16;

		private const int FACILITY_SECURITY = 9;

		private const int FACILITY_SETUPAPI = 15;

		private const int FACILITY_SSPI = 9;

		private const int FACILITY_STORAGE = 3;

		private const int FACILITY_SXS = 23;

		private const int FACILITY_UMI = 22;

		private const int FACILITY_URT = 19;

		private const int FACILITY_WIN32 = 7;

		private const int FACILITY_WINDOWS = 8;

		private const int FACILITY_WINDOWS_CE = 24;

		/// <summary>
		/// MAKE_HRESULT macro
		/// </summary>
		public static int MAKE_HRESULT(int sev, int fac, int code)
		{
			return (sev << 31) | (fac << 16) | code;
		}

		/// <summary>
		/// Helper to deal with the fact that in Win Store apps,
		/// the HResult property name has changed
		/// </summary>
		/// <param name="exception">COM Exception</param>
		/// <returns>The HResult</returns>
		public static int GetHResult(this COMException exception)
		{
			return exception.ErrorCode;
		}
	}

	/// <summary>
	/// Methods for converting between IEEE 80-bit extended double precision
	/// and standard C# double precision.
	/// </summary>
	public static class IEEE
	{
		private static double UnsignedToFloat(ulong u)
		{
			return (double)(long)(u - int.MaxValue - 1) + 2147483648.0;
		}

		private static double ldexp(double x, int exp)
		{
			return x * Math.Pow(2.0, exp);
		}

		private static double frexp(double x, out int exp)
		{
			exp = (int)Math.Floor(Math.Log(x) / Math.Log(2.0)) + 1;
			return 1.0 - (Math.Pow(2.0, exp) - x) / Math.Pow(2.0, exp);
		}

		private static ulong FloatToUnsigned(double f)
		{
			return (ulong)((long)(f - 2147483648.0) + int.MaxValue + 1);
		}

		/// <summary>
		/// Converts a C# double precision number to an 80-bit
		/// IEEE extended double precision number (occupying 10 bytes).
		/// </summary>
		/// <param name="num">The double precision number to convert to IEEE extended.</param>
		/// <returns>An array of 10 bytes containing the IEEE extended number.</returns>
		public static byte[] ConvertToIeeeExtended(double num)
		{
			int num2;
			if (num < 0.0)
			{
				num2 = 32768;
				num *= -1.0;
			}
			else
			{
				num2 = 0;
			}
			ulong num4;
			ulong num5;
			int num3;
			if (num == 0.0)
			{
				num3 = 0;
				num4 = 0uL;
				num5 = 0uL;
			}
			else
			{
				double num6 = frexp(num, out num3);
				if (num3 > 16384 || !(num6 < 1.0))
				{
					num3 = num2 | 0x7FFF;
					num4 = 0uL;
					num5 = 0uL;
				}
				else
				{
					num3 += 16382;
					if (num3 < 0)
					{
						num6 = ldexp(num6, num3);
						num3 = 0;
					}
					num3 |= num2;
					num6 = ldexp(num6, 32);
					double num7 = Math.Floor(num6);
					num4 = FloatToUnsigned(num7);
					num6 = ldexp(num6 - num7, 32);
					num7 = Math.Floor(num6);
					num5 = FloatToUnsigned(num7);
				}
			}
			return new byte[10]
			{
				(byte)(num3 >> 8),
				(byte)num3,
				(byte)(num4 >> 24),
				(byte)(num4 >> 16),
				(byte)(num4 >> 8),
				(byte)num4,
				(byte)(num5 >> 24),
				(byte)(num5 >> 16),
				(byte)(num5 >> 8),
				(byte)num5
			};
		}

		/// <summary>
		/// Converts an IEEE 80-bit extended precision number to a
		/// C# double precision number.
		/// </summary>
		/// <param name="bytes">The 80-bit IEEE extended number (as an array of 10 bytes).</param>
		/// <returns>A C# double precision number that is a close representation of the IEEE extended number.</returns>
		public static double ConvertFromIeeeExtended(byte[] bytes)
		{
			if (bytes.Length != 10)
			{
				throw new Exception("Incorrect length for IEEE extended.");
			}
			int num = ((bytes[0] & 0x7F) << 8) | bytes[1];
			uint num2 = (uint)((bytes[2] << 24) | (bytes[3] << 16) | (bytes[4] << 8) | bytes[5]);
			uint num3 = (uint)((bytes[6] << 24) | (bytes[7] << 16) | (bytes[8] << 8) | bytes[9]);
			double num4;
			if (num == 0 && num2 == 0 && num3 == 0)
			{
				num4 = 0.0;
			}
			else if (num == 32767)
			{
				num4 = double.NaN;
			}
			else
			{
				num -= 16383;
				num4 = ldexp(UnsignedToFloat(num2), num -= 31);
				num4 += ldexp(UnsignedToFloat(num3), num -= 32);
			}
			if ((bytes[0] & 0x80) == 128)
			{
				return 0.0 - num4;
			}
			return num4;
		}
	}

	/// <summary>
	/// Pass-through stream that ignores Dispose
	/// Useful for dealing with MemoryStreams that you want to re-use
	/// </summary>
	public class IgnoreDisposeStream : Stream
	{
		/// <summary>
		/// The source stream all other methods fall through to
		/// </summary>
		public Stream SourceStream { get; private set; }

		/// <summary>
		/// If true the Dispose will be ignored, if false, will pass through to the SourceStream
		/// Set to true by default
		/// </summary>
		public bool IgnoreDispose { get; set; }

		/// <summary>
		/// Can Read
		/// </summary>
		public override bool CanRead => SourceStream.CanRead;

		/// <summary>
		/// Can Seek
		/// </summary>
		public override bool CanSeek => SourceStream.CanSeek;

		/// <summary>
		/// Can write to the underlying stream
		/// </summary>
		public override bool CanWrite => SourceStream.CanWrite;

		/// <summary>
		/// Gets the length of the underlying stream
		/// </summary>
		public override long Length => SourceStream.Length;

		/// <summary>
		/// Gets or sets the position of the underlying stream
		/// </summary>
		public override long Position
		{
			get
			{
				return SourceStream.Position;
			}
			set
			{
				SourceStream.Position = value;
			}
		}

		/// <summary>
		/// Creates a new IgnoreDisposeStream
		/// </summary>
		/// <param name="sourceStream">The source stream</param>
		public IgnoreDisposeStream(Stream sourceStream)
		{
			SourceStream = sourceStream;
			IgnoreDispose = true;
		}

		/// <summary>
		/// Flushes the underlying stream
		/// </summary>
		public override void Flush()
		{
			SourceStream.Flush();
		}

		/// <summary>
		/// Reads from the underlying stream
		/// </summary>
		public override int Read(byte[] buffer, int offset, int count)
		{
			return SourceStream.Read(buffer, offset, count);
		}

		/// <summary>
		/// Seeks on the underlying stream
		/// </summary>
		public override long Seek(long offset, SeekOrigin origin)
		{
			return SourceStream.Seek(offset, origin);
		}

		/// <summary>
		/// Sets the length of the underlying stream
		/// </summary>
		public override void SetLength(long value)
		{
			SourceStream.SetLength(value);
		}

		/// <summary>
		/// Writes to the underlying stream
		/// </summary>
		public override void Write(byte[] buffer, int offset, int count)
		{
			SourceStream.Write(buffer, offset, count);
		}

		/// <summary>
		/// Dispose - by default (IgnoreDispose = true) will do nothing,
		/// leaving the underlying stream undisposed
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (!IgnoreDispose)
			{
				SourceStream.Dispose();
				SourceStream = null;
			}
		}
	}

	/// <summary>
	/// General purpose native methods for internal NAudio use
	/// </summary>
	public static class NativeMethods
	{
		/// <summary>
		/// Loads a DLL
		/// </summary>
		[DllImport("kernel32.dll")]
		public static extern IntPtr LoadLibrary(string dllToLoad);

		/// <summary>
		/// Get procedure address
		/// </summary>
		[DllImport("kernel32.dll")]
		public static extern IntPtr GetProcAddress(IntPtr hModule, string procedureName);

		/// <summary>
		/// Free a library
		/// </summary>
		[DllImport("kernel32.dll")]
		public static extern bool FreeLibrary(IntPtr hModule);
	}

	/// <summary>
	/// WavePosition extension methods
	/// </summary>
	public static class WavePositionExtensions
	{
		/// <summary>
		/// Get Position as timespan
		/// </summary>
		public static TimeSpan GetPositionTimeSpan(this IWavePosition @this)
		{
			return TimeSpan.FromMilliseconds((double)(@this.GetPosition() / (@this.OutputWaveFormat.Channels * @this.OutputWaveFormat.BitsPerSample / 8)) * 1000.0 / (double)@this.OutputWaveFormat.SampleRate);
		}
	}
}

namespace NAudio.Wave
{
	using NAudio.Utils;
	using NAudio.Dsp;
	using NAudio.Wave.SampleProviders;
	using NAudio.FileFormats.Wav;
	using NAudio.Dmo;
	
	/// <summary>
	/// Microsoft ADPCM
	/// See http://icculus.org/SDL_sound/downloads/external_documentation/wavecomp.htm
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class AdpcmWaveFormat : WaveFormat
	{
		private short samplesPerBlock;

		private short numCoeff;

		[MarshalAs(UnmanagedType.ByValArray, SizeConst = 14)]
		private short[] coefficients;

		/// <summary>
		/// Samples per block
		/// </summary>
		public int SamplesPerBlock => samplesPerBlock;

		/// <summary>
		/// Number of coefficients
		/// </summary>
		public int NumCoefficients => numCoeff;

		/// <summary>
		/// Coefficients
		/// </summary>
		public short[] Coefficients => coefficients;

		/// <summary>
		/// Empty constructor needed for marshalling from a pointer
		/// </summary>
		private AdpcmWaveFormat()
			: this(8000, 1)
		{
		}

		/// <summary>
		/// Microsoft ADPCM  
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Channels</param>
		public AdpcmWaveFormat(int sampleRate, int channels)
			: base(sampleRate, 0, channels)
		{
			waveFormatTag = WaveFormatEncoding.Adpcm;
			extraSize = 32;
			switch (base.sampleRate)
			{
			case 8000:
			case 11025:
				blockAlign = 256;
				break;
			case 22050:
				blockAlign = 512;
				break;
			default:
				blockAlign = 1024;
				break;
			}
			bitsPerSample = 4;
			samplesPerBlock = (short)((blockAlign - 7 * channels) * 8 / (bitsPerSample * channels) + 2);
			averageBytesPerSecond = base.SampleRate * blockAlign / samplesPerBlock;
			numCoeff = 7;
			coefficients = new short[14]
			{
				256, 0, 512, -256, 0, 0, 192, 64, 240, 0,
				460, -208, 392, -232
			};
		}

		/// <summary>
		/// Serializes this wave format
		/// </summary>
		/// <param name="writer">Binary writer</param>
		public override void Serialize(BinaryWriter writer)
		{
			base.Serialize(writer);
			writer.Write(samplesPerBlock);
			writer.Write(numCoeff);
			short[] array = coefficients;
			foreach (short value in array)
			{
				writer.Write(value);
			}
		}

		/// <summary>
		/// String Description of this WaveFormat
		/// </summary>
		public override string ToString()
		{
			return $"Microsoft ADPCM {base.SampleRate} Hz {channels} channels {bitsPerSample} bits per sample {samplesPerBlock} samples per block";
		}
	}

	/// <summary>A read-only stream of AIFF data based on an aiff file
	/// with an associated WaveFormat
	/// originally contributed to NAudio by Giawa
	/// </summary>
	public class AiffFileReader : WaveStream
	{
		/// <summary>
		/// AIFF Chunk
		/// </summary>
		public struct AiffChunk
		{
			/// <summary>
			/// Chunk Name
			/// </summary>
			public string ChunkName;

			/// <summary>
			/// Chunk Length
			/// </summary>
			public uint ChunkLength;

			/// <summary>
			/// Chunk start
			/// </summary>
			public uint ChunkStart;

			/// <summary>
			/// Creates a new AIFF Chunk
			/// </summary>
			public AiffChunk(uint start, string name, uint length)
			{
				ChunkStart = start;
				ChunkName = name;
				ChunkLength = length + ((length % 2u == 1) ? 1u : 0u);
			}
		}

		private readonly WaveFormat waveFormat;

		private readonly bool ownInput;

		private readonly long dataPosition;

		private readonly int dataChunkLength;

		private readonly List<AiffChunk> chunks = new List<AiffChunk>();

		private Stream waveStream;

		private readonly object lockObject = new object();

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override long Length => dataChunkLength;

		/// <summary>
		/// Number of Samples (if possible to calculate)
		/// </summary>
		public long SampleCount
		{
			get
			{
				if (waveFormat.Encoding == WaveFormatEncoding.Pcm || waveFormat.Encoding == WaveFormatEncoding.Extensible || waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
				{
					return dataChunkLength / BlockAlign;
				}
				throw new FormatException("Sample count is calculated only for the standard encodings");
			}
		}

		/// <summary>
		/// Position in the AIFF file
		/// <see cref="P:System.IO.Stream.Position" />
		/// </summary>
		public override long Position
		{
			get
			{
				return waveStream.Position - dataPosition;
			}
			set
			{
				lock (lockObject)
				{
					value = Math.Min(value, Length);
					value -= value % waveFormat.BlockAlign;
					waveStream.Position = value + dataPosition;
				}
			}
		}

		/// <summary>Supports opening a AIF file</summary>
		/// <remarks>The AIF is of similar nastiness to the WAV format.
		/// This supports basic reading of uncompressed PCM AIF files,
		/// with 8, 16, 24 and 32 bit PCM data.
		/// </remarks>
		public AiffFileReader(string aiffFile)
			: this(File.OpenRead(aiffFile))
		{
			ownInput = true;
		}

		/// <summary>
		/// Creates an Aiff File Reader based on an input stream
		/// </summary>
		/// <param name="inputStream">The input stream containing a AIF file including header</param>
		public AiffFileReader(Stream inputStream)
		{
			waveStream = inputStream;
			ReadAiffHeader(waveStream, out waveFormat, out dataPosition, out dataChunkLength, chunks);
			Position = 0L;
		}

		/// <summary>
		/// Ensures valid AIFF header and then finds data offset.
		/// </summary>
		/// <param name="stream">The stream, positioned at the start of audio data</param>
		/// <param name="format">The format found</param>
		/// <param name="dataChunkPosition">The position of the data chunk</param>
		/// <param name="dataChunkLength">The length of the data chunk</param>
		/// <param name="chunks">Additional chunks found</param>
		public static void ReadAiffHeader(Stream stream, out WaveFormat format, out long dataChunkPosition, out int dataChunkLength, List<AiffChunk> chunks)
		{
			dataChunkPosition = -1L;
			format = null;
			BinaryReader binaryReader = new BinaryReader(stream);
			if (ReadChunkName(binaryReader) != "FORM")
			{
				throw new FormatException("Not an AIFF file - no FORM header.");
			}
			ConvertInt(binaryReader.ReadBytes(4));
			string text = ReadChunkName(binaryReader);
			if (text != "AIFC" && text != "AIFF")
			{
				throw new FormatException("Not an AIFF file - no AIFF/AIFC header.");
			}
			dataChunkLength = 0;
			while (binaryReader.BaseStream.Position < binaryReader.BaseStream.Length)
			{
				AiffChunk item = ReadChunkHeader(binaryReader);
				if (item.ChunkName == "\0\0\0\0" || binaryReader.BaseStream.Position + item.ChunkLength > binaryReader.BaseStream.Length)
				{
					break;
				}
				if (item.ChunkName == "COMM")
				{
					short channels = ConvertShort(binaryReader.ReadBytes(2));
					ConvertInt(binaryReader.ReadBytes(4));
					short bits = ConvertShort(binaryReader.ReadBytes(2));
					double num = IEEE.ConvertFromIeeeExtended(binaryReader.ReadBytes(10));
					format = new WaveFormat((int)num, bits, channels);
					if (item.ChunkLength > 18 && text == "AIFC")
					{
						if (new string(binaryReader.ReadChars(4)).ToLower() != "none")
						{
							throw new FormatException("Compressed AIFC is not supported.");
						}
						binaryReader.ReadBytes((int)(item.ChunkLength - 22));
					}
					else
					{
						binaryReader.ReadBytes((int)(item.ChunkLength - 18));
					}
				}
				else if (item.ChunkName == "SSND")
				{
					uint num2 = ConvertInt(binaryReader.ReadBytes(4));
					ConvertInt(binaryReader.ReadBytes(4));
					dataChunkPosition = item.ChunkStart + 16 + num2;
					dataChunkLength = (int)(item.ChunkLength - 8);
					binaryReader.BaseStream.Position += item.ChunkLength - 8;
				}
				else
				{
					chunks?.Add(item);
					binaryReader.BaseStream.Position += item.ChunkLength;
				}
			}
			if (format == null)
			{
				throw new FormatException("Invalid AIFF file - No COMM chunk found.");
			}
			if (dataChunkPosition == -1)
			{
				throw new FormatException("Invalid AIFF file - No SSND chunk found.");
			}
		}

		/// <summary>
		/// Cleans up the resources associated with this AiffFileReader
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && waveStream != null)
			{
				if (ownInput)
				{
					waveStream.Dispose();
				}
				waveStream = null;
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Reads bytes from the AIFF File
		/// <see cref="M:System.IO.Stream.Read(System.Byte[],System.Int32,System.Int32)" />
		/// </summary>
		public override int Read(byte[] array, int offset, int count)
		{
			if (count % waveFormat.BlockAlign != 0)
			{
				throw new ArgumentException($"Must read complete blocks: requested {count}, block align is {WaveFormat.BlockAlign}");
			}
			lock (lockObject)
			{
				if (Position + count > dataChunkLength)
				{
					count = dataChunkLength - (int)Position;
				}
				byte[] array2 = new byte[count];
				int num = waveStream.Read(array2, offset, count);
				int num2 = WaveFormat.BitsPerSample / 8;
				for (int i = 0; i < num; i += num2)
				{
					if (WaveFormat.BitsPerSample == 8)
					{
						array[i] = array2[i];
						continue;
					}
					if (WaveFormat.BitsPerSample == 16)
					{
						array[i] = array2[i + 1];
						array[i + 1] = array2[i];
						continue;
					}
					if (WaveFormat.BitsPerSample == 24)
					{
						array[i] = array2[i + 2];
						array[i + 1] = array2[i + 1];
						array[i + 2] = array2[i];
						continue;
					}
					if (WaveFormat.BitsPerSample == 32)
					{
						array[i] = array2[i + 3];
						array[i + 1] = array2[i + 2];
						array[i + 2] = array2[i + 1];
						array[i + 3] = array2[i];
						continue;
					}
					throw new FormatException("Unsupported PCM format.");
				}
				return num;
			}
		}

		private static uint ConvertInt(byte[] buffer)
		{
			if (buffer.Length != 4)
			{
				throw new Exception("Incorrect length for long.");
			}
			return (uint)((buffer[0] << 24) | (buffer[1] << 16) | (buffer[2] << 8) | buffer[3]);
		}

		private static short ConvertShort(byte[] buffer)
		{
			if (buffer.Length != 2)
			{
				throw new Exception("Incorrect length for int.");
			}
			return (short)((buffer[0] << 8) | buffer[1]);
		}

		private static AiffChunk ReadChunkHeader(BinaryReader br)
		{
			return new AiffChunk((uint)br.BaseStream.Position, ReadChunkName(br), ConvertInt(br.ReadBytes(4)));
		}

		private static string ReadChunkName(BinaryReader br)
		{
			return new string(br.ReadChars(4));
		}
	}

	/// <summary>
	/// This class writes audio data to a .aif file on disk
	/// </summary>
	public class AiffFileWriter : Stream
	{
		private Stream outStream;

		private BinaryWriter writer;

		private long dataSizePos;

		private long commSampleCountPos;

		private long dataChunkSize = 8L;

		private WaveFormat format;

		private string filename;

		private byte[] value24 = new byte[3];

		/// <summary>
		/// The aiff file name or null if not applicable
		/// </summary>
		public string Filename => filename;

		/// <summary>
		/// Number of bytes of audio in the data chunk
		/// </summary>
		public override long Length => dataChunkSize;

		/// <summary>
		/// WaveFormat of this aiff file
		/// </summary>
		public WaveFormat WaveFormat => format;

		/// <summary>
		/// Returns false: Cannot read from a AiffFileWriter
		/// </summary>
		public override bool CanRead => false;

		/// <summary>
		/// Returns true: Can write to a AiffFileWriter
		/// </summary>
		public override bool CanWrite => true;

		/// <summary>
		/// Returns false: Cannot seek within a AiffFileWriter
		/// </summary>
		public override bool CanSeek => false;

		/// <summary>
		/// Gets the Position in the AiffFile (i.e. number of bytes written so far)
		/// </summary>
		public override long Position
		{
			get
			{
				return dataChunkSize;
			}
			set
			{
				throw new InvalidOperationException("Repositioning an AiffFileWriter is not supported");
			}
		}

		/// <summary>
		/// Creates an Aiff file by reading all the data from a WaveProvider
		/// BEWARE: the WaveProvider MUST return 0 from its Read method when it is finished,
		/// or the Aiff File will grow indefinitely.
		/// </summary>
		/// <param name="filename">The filename to use</param>
		/// <param name="sourceProvider">The source WaveProvider</param>
		public static void CreateAiffFile(string filename, WaveStream sourceProvider)
		{
			using AiffFileWriter aiffFileWriter = new AiffFileWriter(filename, sourceProvider.WaveFormat);
			byte[] array = new byte[16384];
			while (sourceProvider.Position < sourceProvider.Length)
			{
				int count = Math.Min((int)(sourceProvider.Length - sourceProvider.Position), array.Length);
				int num = sourceProvider.Read(array, 0, count);
				if (num == 0)
				{
					break;
				}
				aiffFileWriter.Write(array, 0, num);
			}
		}

		/// <summary>
		/// AiffFileWriter that actually writes to a stream
		/// </summary>
		/// <param name="outStream">Stream to be written to</param>
		/// <param name="format">Wave format to use</param>
		public AiffFileWriter(Stream outStream, WaveFormat format)
		{
			this.outStream = outStream;
			this.format = format;
			writer = new BinaryWriter(outStream, Encoding.UTF8);
			writer.Write(Encoding.UTF8.GetBytes("FORM"));
			writer.Write(0);
			writer.Write(Encoding.UTF8.GetBytes("AIFF"));
			CreateCommChunk();
			WriteSsndChunkHeader();
		}

		/// <summary>
		/// Creates a new AiffFileWriter
		/// </summary>
		/// <param name="filename">The filename to write to</param>
		/// <param name="format">The Wave Format of the output data</param>
		public AiffFileWriter(string filename, WaveFormat format)
			: this(new FileStream(filename, FileMode.Create, FileAccess.Write, FileShare.Read), format)
		{
			this.filename = filename;
		}

		private void WriteSsndChunkHeader()
		{
			writer.Write(Encoding.UTF8.GetBytes("SSND"));
			dataSizePos = outStream.Position;
			writer.Write(0);
			writer.Write(0);
			writer.Write(SwapEndian(format.BlockAlign));
		}

		private byte[] SwapEndian(short n)
		{
			return new byte[2]
			{
				(byte)(n >> 8),
				(byte)((uint)n & 0xFFu)
			};
		}

		private byte[] SwapEndian(int n)
		{
			return new byte[4]
			{
				(byte)((uint)(n >> 24) & 0xFFu),
				(byte)((uint)(n >> 16) & 0xFFu),
				(byte)((uint)(n >> 8) & 0xFFu),
				(byte)((uint)n & 0xFFu)
			};
		}

		private void CreateCommChunk()
		{
			writer.Write(Encoding.UTF8.GetBytes("COMM"));
			writer.Write(SwapEndian(18));
			writer.Write(SwapEndian((short)format.Channels));
			commSampleCountPos = outStream.Position;
			writer.Write(0);
			writer.Write(SwapEndian((short)format.BitsPerSample));
			writer.Write(IEEE.ConvertToIeeeExtended(format.SampleRate));
		}

		/// <summary>
		/// Read is not supported for a AiffFileWriter
		/// </summary>
		public override int Read(byte[] buffer, int offset, int count)
		{
			throw new InvalidOperationException("Cannot read from an AiffFileWriter");
		}

		/// <summary>
		/// Seek is not supported for a AiffFileWriter
		/// </summary>
		public override long Seek(long offset, SeekOrigin origin)
		{
			throw new InvalidOperationException("Cannot seek within an AiffFileWriter");
		}

		/// <summary>
		/// SetLength is not supported for AiffFileWriter
		/// </summary>
		/// <param name="value"></param>
		public override void SetLength(long value)
		{
			throw new InvalidOperationException("Cannot set length of an AiffFileWriter");
		}

		/// <summary>
		/// Appends bytes to the AiffFile (assumes they are already in the correct format)
		/// </summary>
		/// <param name="data">the buffer containing the wave data</param>
		/// <param name="offset">the offset from which to start writing</param>
		/// <param name="count">the number of bytes to write</param>
		public override void Write(byte[] data, int offset, int count)
		{
			byte[] array = new byte[data.Length];
			int num = format.BitsPerSample / 8;
			for (int i = 0; i < data.Length; i++)
			{
				int num2 = (int)Math.Floor((double)i / (double)num) * num + (num - i % num - 1);
				array[i] = data[num2];
			}
			outStream.Write(array, offset, count);
			dataChunkSize += count;
		}

		/// <summary>
		/// Writes a single sample to the Aiff file
		/// </summary>
		/// <param name="sample">the sample to write (assumed floating point with 1.0f as max value)</param>
		public void WriteSample(float sample)
		{
			if (WaveFormat.BitsPerSample == 16)
			{
				writer.Write(SwapEndian((short)(32767f * sample)));
				dataChunkSize += 2L;
			}
			else if (WaveFormat.BitsPerSample == 24)
			{
				byte[] bytes = BitConverter.GetBytes((int)(2.1474836E+09f * sample));
				value24[2] = bytes[1];
				value24[1] = bytes[2];
				value24[0] = bytes[3];
				writer.Write(value24);
				dataChunkSize += 3L;
			}
			else
			{
				if (WaveFormat.BitsPerSample != 32 || WaveFormat.Encoding != WaveFormatEncoding.Extensible)
				{
					throw new InvalidOperationException("Only 16, 24 or 32 bit PCM or IEEE float audio data supported");
				}
				writer.Write(SwapEndian(65535 * (int)sample));
				dataChunkSize += 4L;
			}
		}

		/// <summary>
		/// Writes 32 bit floating point samples to the Aiff file
		/// They will be converted to the appropriate bit depth depending on the WaveFormat of the AIF file
		/// </summary>
		/// <param name="samples">The buffer containing the floating point samples</param>
		/// <param name="offset">The offset from which to start writing</param>
		/// <param name="count">The number of floating point samples to write</param>
		public void WriteSamples(float[] samples, int offset, int count)
		{
			for (int i = 0; i < count; i++)
			{
				WriteSample(samples[offset + i]);
			}
		}

		/// <summary>
		/// Writes 16 bit samples to the Aiff file
		/// </summary>
		/// <param name="samples">The buffer containing the 16 bit samples</param>
		/// <param name="offset">The offset from which to start writing</param>
		/// <param name="count">The number of 16 bit samples to write</param>
		public void WriteSamples(short[] samples, int offset, int count)
		{
			if (WaveFormat.BitsPerSample == 16)
			{
				for (int i = 0; i < count; i++)
				{
					writer.Write(SwapEndian(samples[i + offset]));
				}
				dataChunkSize += count * 2;
			}
			else if (WaveFormat.BitsPerSample == 24)
			{
				for (int j = 0; j < count; j++)
				{
					byte[] bytes = BitConverter.GetBytes(65535 * samples[j + offset]);
					value24[2] = bytes[1];
					value24[1] = bytes[2];
					value24[0] = bytes[3];
					writer.Write(value24);
				}
				dataChunkSize += count * 3;
			}
			else
			{
				if (WaveFormat.BitsPerSample != 32 || WaveFormat.Encoding != WaveFormatEncoding.Extensible)
				{
					throw new InvalidOperationException("Only 16, 24 or 32 bit PCM audio data supported");
				}
				for (int k = 0; k < count; k++)
				{
					writer.Write(SwapEndian(65535 * samples[k + offset]));
				}
				dataChunkSize += count * 4;
			}
		}

		/// <summary>
		/// Ensures data is written to disk
		/// </summary>
		public override void Flush()
		{
			writer.Flush();
		}

		/// <summary>
		/// Actually performs the close,making sure the header contains the correct data
		/// </summary>
		/// <param name="disposing">True if called from <see>Dispose</see></param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && outStream != null)
			{
				try
				{
					UpdateHeader(writer);
				}
				finally
				{
					outStream.Dispose();
					outStream = null;
				}
			}
		}

		/// <summary>
		/// Updates the header with file size information
		/// </summary>
		protected virtual void UpdateHeader(BinaryWriter writer)
		{
			Flush();
			writer.Seek(4, SeekOrigin.Begin);
			writer.Write(SwapEndian((int)(outStream.Length - 8)));
			UpdateCommChunk(writer);
			UpdateSsndChunk(writer);
		}

		private void UpdateCommChunk(BinaryWriter writer)
		{
			writer.Seek((int)commSampleCountPos, SeekOrigin.Begin);
			writer.Write(SwapEndian((int)(dataChunkSize * 8 / format.BitsPerSample / format.Channels)));
		}

		private void UpdateSsndChunk(BinaryWriter writer)
		{
			writer.Seek((int)dataSizePos, SeekOrigin.Begin);
			writer.Write(SwapEndian((int)dataChunkSize));
		}

		/// <summary>
		/// Finaliser - should only be called if the user forgot to close this AiffFileWriter
		/// </summary>
		~AiffFileWriter()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// https://tech.ebu.ch/docs/tech/tech3285.pdf
	/// </summary>
	public class BextChunkInfo
	{
		/// <summary>
		/// Description (max 256 chars)
		/// </summary>
		public string Description { get; set; }

		/// <summary>
		/// Originator (max 32 chars)
		/// </summary>
		public string Originator { get; set; }

		/// <summary>
		/// Originator Reference (max 32 chars)
		/// </summary>
		public string OriginatorReference { get; set; }

		/// <summary>
		/// Originator Date Time
		/// </summary>
		public DateTime OriginationDateTime { get; set; }

		/// <summary>
		/// Origination Date as string
		/// </summary>
		public string OriginationDate => OriginationDateTime.ToString("yyyy-MM-dd");

		/// <summary>
		/// Origination as time
		/// </summary>
		public string OriginationTime => OriginationDateTime.ToString("HH:mm:ss");

		/// <summary>
		/// Time reference (first sample count since midnight)
		/// </summary>
		public long TimeReference { get; set; }

		/// <summary>
		/// version 2 has loudness stuff which we don't know so using version 1
		/// </summary>
		public ushort Version => 1;

		/// <summary>
		/// 64 bytes http://en.wikipedia.org/wiki/UMID
		/// </summary>
		public string UniqueMaterialIdentifier { get; set; }

		/// <summary>
		/// for version 2 = 180 bytes (10 before are loudness values), using version 1 = 190 bytes
		/// </summary>
		public byte[] Reserved { get; }

		/// <summary>
		/// Coding history arbitrary length string at end of structure
		/// http://www.ebu.ch/CMSimages/fr/tec_text_r98-1999_tcm7-4709.pdf
		/// A=PCM,F=48000,W=16,M=stereo,T=original,CR/LF
		/// </summary>
		public string CodingHistory { get; set; }

		/// <summary>
		/// Constructs a new BextChunkInfo
		/// </summary>
		public BextChunkInfo()
		{
			Reserved = new byte[190];
		}
	}

	/// <summary>
	/// Helper stream that lets us read from compressed audio files with large block alignment
	/// as though we could read any amount and reposition anywhere
	/// </summary>
	public class BlockAlignReductionStream : WaveStream
	{
		private WaveStream sourceStream;

		private long position;

		private readonly CircularBuffer circularBuffer;

		private long bufferStartPosition;

		private byte[] sourceBuffer;

		private readonly object lockObject = new object();

		/// <summary>
		/// Block alignment of this stream
		/// </summary>
		public override int BlockAlign => WaveFormat.BitsPerSample / 8 * WaveFormat.Channels;

		/// <summary>
		/// Wave Format
		/// </summary>
		public override WaveFormat WaveFormat => sourceStream.WaveFormat;

		/// <summary>
		/// Length of this Stream
		/// </summary>
		public override long Length => sourceStream.Length;

		/// <summary>
		/// Current position within stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (lockObject)
				{
					if (position != value)
					{
						if (position % BlockAlign != 0L)
						{
							throw new ArgumentException("Position must be block aligned");
						}
						long num = value - value % sourceStream.BlockAlign;
						if (sourceStream.Position != num)
						{
							sourceStream.Position = num;
							circularBuffer.Reset();
							bufferStartPosition = sourceStream.Position;
						}
						position = value;
					}
				}
			}
		}

		private long BufferEndPosition => bufferStartPosition + circularBuffer.Count;

		/// <summary>
		/// Creates a new BlockAlignReductionStream
		/// </summary>
		/// <param name="sourceStream">the input stream</param>
		public BlockAlignReductionStream(WaveStream sourceStream)
		{
			this.sourceStream = sourceStream;
			circularBuffer = new CircularBuffer(sourceStream.WaveFormat.AverageBytesPerSecond * 4);
		}

		private byte[] GetSourceBuffer(int size)
		{
			if (sourceBuffer == null || sourceBuffer.Length < size)
			{
				sourceBuffer = new byte[size * 2];
			}
			return sourceBuffer;
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && sourceStream != null)
			{
				sourceStream.Dispose();
				sourceStream = null;
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Reads data from this stream
		/// </summary>
		/// <param name="buffer"></param>
		/// <param name="offset"></param>
		/// <param name="count"></param>
		/// <returns></returns>
		public override int Read(byte[] buffer, int offset, int count)
		{
			lock (lockObject)
			{
				while (BufferEndPosition < position + count)
				{
					int num = count;
					if (num % sourceStream.BlockAlign != 0)
					{
						num = count + sourceStream.BlockAlign - count % sourceStream.BlockAlign;
					}
					int num2 = sourceStream.Read(GetSourceBuffer(num), 0, num);
					circularBuffer.Write(GetSourceBuffer(num), 0, num2);
					if (num2 == 0)
					{
						break;
					}
				}
				if (bufferStartPosition < position)
				{
					circularBuffer.Advance((int)(position - bufferStartPosition));
					bufferStartPosition = position;
				}
				int num3 = circularBuffer.Read(buffer, offset, count);
				position += num3;
				bufferStartPosition = position;
				return num3;
			}
		}
	}

	/// <summary>
	/// Provides a buffered store of samples
	/// Read method will return queued samples or fill buffer with zeroes
	/// Now backed by a circular buffer
	/// </summary>
	public class BufferedWaveProvider : IWaveProvider
	{
		private CircularBuffer circularBuffer;

		private readonly WaveFormat waveFormat;

		/// <summary>
		/// If true, always read the amount of data requested, padding with zeroes if necessary
		/// By default is set to true
		/// </summary>
		public bool ReadFully { get; set; }

		/// <summary>
		/// Buffer length in bytes
		/// </summary>
		public int BufferLength { get; set; }

		/// <summary>
		/// Buffer duration
		/// </summary>
		public TimeSpan BufferDuration
		{
			get
			{
				return TimeSpan.FromSeconds((double)BufferLength / (double)WaveFormat.AverageBytesPerSecond);
			}
			set
			{
				BufferLength = (int)(value.TotalSeconds * (double)WaveFormat.AverageBytesPerSecond);
			}
		}

		/// <summary>
		/// If true, when the buffer is full, start throwing away data
		/// if false, AddSamples will throw an exception when buffer is full
		/// </summary>
		public bool DiscardOnBufferOverflow { get; set; }

		/// <summary>
		/// The number of buffered bytes
		/// </summary>
		public int BufferedBytes
		{
			get
			{
				if (circularBuffer != null)
				{
					return circularBuffer.Count;
				}
				return 0;
			}
		}

		/// <summary>
		/// Buffered Duration
		/// </summary>
		public TimeSpan BufferedDuration => TimeSpan.FromSeconds((double)BufferedBytes / (double)WaveFormat.AverageBytesPerSecond);

		/// <summary>
		/// Gets the WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Creates a new buffered WaveProvider
		/// </summary>
		/// <param name="waveFormat">WaveFormat</param>
		public BufferedWaveProvider(WaveFormat waveFormat)
		{
			this.waveFormat = waveFormat;
			BufferLength = waveFormat.AverageBytesPerSecond * 5;
			ReadFully = true;
		}

		/// <summary>
		/// Adds samples. Takes a copy of buffer, so that buffer can be reused if necessary
		/// </summary>
		public void AddSamples(byte[] buffer, int offset, int count)
		{
			if (circularBuffer == null)
			{
				circularBuffer = new CircularBuffer(BufferLength);
			}
			if (circularBuffer.Write(buffer, offset, count) < count && !DiscardOnBufferOverflow)
			{
				throw new InvalidOperationException("Buffer full");
			}
		}

		/// <summary>
		/// Reads from this WaveProvider
		/// Will always return count bytes, since we will zero-fill the buffer if not enough available
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = 0;
			if (circularBuffer != null)
			{
				num = circularBuffer.Read(buffer, offset, count);
			}
			if (ReadFully && num < count)
			{
				Array.Clear(buffer, offset + num, count - num);
				num = count;
			}
			return num;
		}

		/// <summary>
		/// Discards all audio from the buffer
		/// </summary>
		public void ClearBuffer()
		{
			if (circularBuffer != null)
			{
				circularBuffer.Reset();
			}
		}
	}

	/// <summary>
	/// Broadcast WAVE File Writer
	/// </summary>
	public class BwfWriter : IDisposable
	{
		private readonly WaveFormat format;

		private readonly BinaryWriter writer;

		private readonly long dataChunkSizePosition;

		private long dataLength;

		private bool isDisposed;

		/// <summary>
		/// Createa a new BwfWriter
		/// </summary>
		/// <param name="filename">Rarget filename</param>
		/// <param name="format">WaveFormat</param>
		/// <param name="bextChunkInfo">Chunk information</param>
		public BwfWriter(string filename, WaveFormat format, BextChunkInfo bextChunkInfo)
		{
			this.format = format;
			writer = new BinaryWriter(File.OpenWrite(filename));
			writer.Write(Encoding.UTF8.GetBytes("RIFF"));
			writer.Write(0);
			writer.Write(Encoding.UTF8.GetBytes("WAVE"));
			writer.Write(Encoding.UTF8.GetBytes("JUNK"));
			writer.Write(28);
			writer.Write(0L);
			writer.Write(0L);
			writer.Write(0L);
			writer.Write(0);
			writer.Write(Encoding.UTF8.GetBytes("bext"));
			byte[] bytes = Encoding.ASCII.GetBytes(bextChunkInfo.CodingHistory ?? "");
			int num = 602 + bytes.Length;
			if (num % 2 != 0)
			{
				num++;
			}
			writer.Write(num);
			_ = writer.BaseStream.Position;
			writer.Write(GetAsBytes(bextChunkInfo.Description, 256));
			writer.Write(GetAsBytes(bextChunkInfo.Originator, 32));
			writer.Write(GetAsBytes(bextChunkInfo.OriginatorReference, 32));
			writer.Write(GetAsBytes(bextChunkInfo.OriginationDate, 10));
			writer.Write(GetAsBytes(bextChunkInfo.OriginationTime, 8));
			writer.Write(bextChunkInfo.TimeReference);
			writer.Write(bextChunkInfo.Version);
			writer.Write(GetAsBytes(bextChunkInfo.UniqueMaterialIdentifier, 64));
			writer.Write(bextChunkInfo.Reserved);
			writer.Write(bytes);
			if (bytes.Length % 2 != 0)
			{
				writer.Write((byte)0);
			}
			writer.Write(Encoding.UTF8.GetBytes("fmt "));
			format.Serialize(writer);
			writer.Write(Encoding.UTF8.GetBytes("data"));
			dataChunkSizePosition = writer.BaseStream.Position;
			writer.Write(-1);
		}

		/// <summary>
		/// Write audio data to this BWF
		/// </summary>
		public void Write(byte[] buffer, int offset, int count)
		{
			if (isDisposed)
			{
				throw new ObjectDisposedException("This BWF Writer already disposed");
			}
			writer.Write(buffer, offset, count);
			dataLength += count;
		}

		/// <summary>
		/// Flush writer, and fix up header sizes
		/// </summary>
		public void Flush()
		{
			if (isDisposed)
			{
				throw new ObjectDisposedException("This BWF Writer already disposed");
			}
			writer.Flush();
			FixUpChunkSizes(restorePosition: true);
		}

		private void FixUpChunkSizes(bool restorePosition)
		{
			long position = writer.BaseStream.Position;
			bool num = dataLength > int.MaxValue;
			long num2 = writer.BaseStream.Length - 8;
			if (num)
			{
				int num3 = format.BitsPerSample / 8 * format.Channels;
				writer.BaseStream.Position = 0L;
				writer.Write(Encoding.UTF8.GetBytes("RF64"));
				writer.Write(-1);
				writer.BaseStream.Position += 4L;
				writer.Write(Encoding.UTF8.GetBytes("ds64"));
				writer.BaseStream.Position += 4L;
				writer.Write(num2);
				writer.Write(dataLength);
				writer.Write(dataLength / num3);
			}
			else
			{
				writer.BaseStream.Position = 4L;
				writer.Write((uint)num2);
				writer.BaseStream.Position = dataChunkSizePosition;
				writer.Write((uint)dataLength);
			}
			if (restorePosition)
			{
				writer.BaseStream.Position = position;
			}
		}

		/// <summary>
		/// Disposes this writer
		/// </summary>
		public void Dispose()
		{
			if (!isDisposed)
			{
				FixUpChunkSizes(restorePosition: false);
				writer.Dispose();
				isDisposed = true;
			}
		}

		private static byte[] GetAsBytes(string message, int byteSize)
		{
			byte[] array = new byte[byteSize];
			byte[] bytes = Encoding.ASCII.GetBytes(message ?? "");
			Array.Copy(bytes, array, Math.Min(bytes.Length, byteSize));
			return array;
		}
	}

	/// <summary>
	/// Channel Mode
	/// </summary>
	public enum ChannelMode
	{
		/// <summary>
		/// Stereo
		/// </summary>
		Stereo,
		/// <summary>
		/// Joint Stereo
		/// </summary>
		JointStereo,
		/// <summary>
		/// Dual Channel
		/// </summary>
		DualChannel,
		/// <summary>
		/// Mono
		/// </summary>
		Mono
	}

	/// <summary>
	/// Holds information on a cue: a labeled position within a Wave file
	/// </summary>
	public class Cue
	{
		/// <summary>
		/// Cue position in samples
		/// </summary>
		public int Position { get; }

		/// <summary>
		/// Label of the cue
		/// </summary>
		public string Label { get; }

		/// <summary>
		/// Creates a Cue based on a sample position and label 
		/// </summary>
		/// <param name="position"></param>
		/// <param name="label"></param>
		public Cue(int position, string label)
		{
			Position = position;
			Label = label ?? string.Empty;
		}
	}

	/// <summary>
	/// Holds a list of cues
	/// </summary>
	/// <remarks>
	/// The specs for reading and writing cues from the cue and list RIFF chunks 
	/// are from http://www.sonicspot.com/guide/wavefiles.html and http://www.wotsit.org/
	/// ------------------------------
	/// The cues are stored like this:
	/// ------------------------------
	/// struct CuePoint
	/// {
	///  Int32 dwIdentifier;
	///  Int32 dwPosition;
	///  Int32 fccChunk;
	///  Int32 dwChunkStart;
	///  Int32 dwBlockStart;
	///  Int32 dwSampleOffset;
	/// } 
	///
	/// struct CueChunk
	/// {
	///  Int32 chunkID;
	///  Int32 chunkSize;
	///  Int32 dwCuePoints;
	///  CuePoint[] points;
	/// }
	/// ------------------------------
	/// Labels look like this:
	/// ------------------------------
	/// struct ListHeader 
	/// {
	///   Int32 listID;      /* 'list' */
	///   Int32 chunkSize;   /* includes the Type ID below */
	///   Int32 typeID;      /* 'adtl' */
	/// } 
	///
	/// struct LabelChunk 
	/// {
	///   Int32 chunkID;
	///   Int32 chunkSize;
	///   Int32 dwIdentifier;
	///   Char[] dwText;  /* Encoded with extended ASCII */
	/// } LabelChunk;
	/// </remarks>
	public class CueList
	{
		private readonly List<Cue> cues = new List<Cue>();

		/// <summary>
		/// Gets sample positions for the embedded cues
		/// </summary>
		/// <returns>Array containing the cue positions</returns>
		public int[] CuePositions
		{
			get
			{
				int[] array = new int[cues.Count];
				for (int i = 0; i < cues.Count; i++)
				{
					array[i] = cues[i].Position;
				}
				return array;
			}
		}

		/// <summary>
		/// Gets labels for the embedded cues
		/// </summary>
		/// <returns>Array containing the labels</returns>
		public string[] CueLabels
		{
			get
			{
				string[] array = new string[cues.Count];
				for (int i = 0; i < cues.Count; i++)
				{
					array[i] = cues[i].Label;
				}
				return array;
			}
		}

		/// <summary>
		/// Number of cues
		/// </summary>
		public int Count => cues.Count;

		/// <summary>
		/// Accesses the cue at the specified index
		/// </summary>
		/// <param name="index"></param>
		/// <returns></returns>
		public Cue this[int index] => cues[index];

		/// <summary>
		/// Creates an empty cue list
		/// </summary>
		public CueList()
		{
		}

		/// <summary>
		/// Adds an item to the list
		/// </summary>
		/// <param name="cue">Cue</param>
		public void Add(Cue cue)
		{
			cues.Add(cue);
		}

		/// <summary>
		/// Creates a cue list from the cue RIFF chunk and the list RIFF chunk
		/// </summary>
		/// <param name="cueChunkData">The data contained in the cue chunk</param>
		/// <param name="listChunkData">The data contained in the list chunk</param>
		internal CueList(byte[] cueChunkData, byte[] listChunkData)
		{
			int num = BitConverter.ToInt32(cueChunkData, 0);
			Dictionary<int, int> dictionary = new Dictionary<int, int>();
			int[] array = new int[num];
			int num2 = 0;
			int num3 = 4;
			while (cueChunkData.Length - num3 >= 24)
			{
				dictionary[BitConverter.ToInt32(cueChunkData, num3)] = num2;
				array[num2] = BitConverter.ToInt32(cueChunkData, num3 + 20);
				num3 += 24;
				num2++;
			}
			string[] array2 = new string[num];
			int num4 = 0;
			int num5 = ChunkIdentifier.ChunkIdentifierToInt32("labl");
			for (int i = 4; listChunkData.Length - i >= 16; i += num4 + num4 % 2 + 12)
			{
				if (BitConverter.ToInt32(listChunkData, i) == num5)
				{
					num4 = BitConverter.ToInt32(listChunkData, i + 4) - 4;
					int key = BitConverter.ToInt32(listChunkData, i + 8);
					num2 = dictionary[key];
					array2[num2] = Encoding.UTF8.GetString(listChunkData, i + 12, num4 - 1);
				}
			}
			for (int j = 0; j < num; j++)
			{
				cues.Add(new Cue(array[j], array2[j]));
			}
		}

		/// <summary>
		/// Gets the cues as the concatenated cue and list RIFF chunks.
		/// </summary>
		/// <returns>RIFF chunks containing the cue data</returns>
		internal byte[] GetRiffChunks()
		{
			if (Count == 0)
			{
				return null;
			}
			int num = 12 + 24 * Count;
			int num2 = 12;
			for (int i = 0; i < Count; i++)
			{
				int num3 = Encoding.UTF8.GetBytes(this[i].Label).Length + 1;
				num2 += num3 + num3 % 2 + 12;
			}
			byte[] array = new byte[num + num2];
			int value = ChunkIdentifier.ChunkIdentifierToInt32("cue ");
			int value2 = ChunkIdentifier.ChunkIdentifierToInt32("data");
			int value3 = ChunkIdentifier.ChunkIdentifierToInt32("LIST");
			int value4 = ChunkIdentifier.ChunkIdentifierToInt32("adtl");
			int value5 = ChunkIdentifier.ChunkIdentifierToInt32("labl");
			using MemoryStream output = new MemoryStream(array);
			using BinaryWriter binaryWriter = new BinaryWriter(output);
			binaryWriter.Write(value);
			binaryWriter.Write(num - 8);
			binaryWriter.Write(Count);
			for (int j = 0; j < Count; j++)
			{
				int position = this[j].Position;
				binaryWriter.Write(j);
				binaryWriter.Write(position);
				binaryWriter.Write(value2);
				binaryWriter.Seek(8, SeekOrigin.Current);
				binaryWriter.Write(position);
			}
			binaryWriter.Write(value3);
			binaryWriter.Write(num2 - 8);
			binaryWriter.Write(value4);
			for (int k = 0; k < Count; k++)
			{
				byte[] bytes = Encoding.UTF8.GetBytes(this[k].Label);
				binaryWriter.Write(value5);
				binaryWriter.Write(bytes.Length + 1 + 4);
				binaryWriter.Write(k);
				binaryWriter.Write(bytes);
				if (bytes.Length % 2 == 0)
				{
					binaryWriter.Seek(2, SeekOrigin.Current);
				}
				else
				{
					binaryWriter.Seek(1, SeekOrigin.Current);
				}
			}
			return array;
		}

		/// <summary>
		/// Checks if the cue and list chunks exist and if so, creates a cue list
		/// </summary>
		internal static CueList FromChunks(WaveFileReader reader)
		{
			CueList result = null;
			byte[] array = null;
			byte[] array2 = null;
			foreach (RiffChunk extraChunk in reader.ExtraChunks)
			{
				if (extraChunk.IdentifierAsString.ToLower() == "cue ")
				{
					array = reader.GetChunkData(extraChunk);
				}
				else if (extraChunk.IdentifierAsString.ToLower() == "list")
				{
					array2 = reader.GetChunkData(extraChunk);
				}
			}
			if (array != null && array2 != null)
			{
				result = new CueList(array, array2);
			}
			return result;
		}
	}

	/// <summary>
	/// A wave file reader supporting cue reading
	/// </summary>
	public class CueWaveFileReader : WaveFileReader
	{
		private CueList cues;

		/// <summary>
		/// Cue List (can be null if cues not present)
		/// </summary>
		public CueList Cues
		{
			get
			{
				if (cues == null)
				{
					cues = CueList.FromChunks(this);
				}
				return cues;
			}
		}

		/// <summary>
		/// Loads a wavefile and supports reading cues
		/// </summary>
		/// <param name="fileName"></param>
		public CueWaveFileReader(string fileName)
			: base(fileName)
		{
		}

		/// <summary>
		/// Loads a wave from a stream and supports reading cues
		/// </summary>
		/// <param name="inputStream"></param>
		public CueWaveFileReader(Stream inputStream)
			: base(inputStream)
		{
		}
	}

	/// <summary>
	/// A wave file writer that adds cue support
	/// </summary>
	public class CueWaveFileWriter : WaveFileWriter
	{
		private CueList cues;

		/// <summary>
		/// Writes a wave file, including a cues chunk
		/// </summary>
		public CueWaveFileWriter(string fileName, WaveFormat waveFormat)
			: base(fileName, waveFormat)
		{
		}

		/// <summary>
		/// Adds a cue to the Wave file
		/// </summary>
		/// <param name="position">Sample position</param>
		/// <param name="label">Label text</param>
		public void AddCue(int position, string label)
		{
			if (cues == null)
			{
				cues = new CueList();
			}
			cues.Add(new Cue(position, label));
		}

		private void WriteCues(BinaryWriter w)
		{
			if (cues != null)
			{
				int count = cues.GetRiffChunks().Length;
				w.Seek(0, SeekOrigin.End);
				if (w.BaseStream.Length % 2 == 1)
				{
					w.Write((byte)0);
				}
				w.Write(cues.GetRiffChunks(), 0, count);
				w.Seek(4, SeekOrigin.Begin);
				w.Write((int)(w.BaseStream.Length - 8));
			}
		}

		/// <summary>
		/// Updates the header, and writes the cues out
		/// </summary>
		protected override void UpdateHeader(BinaryWriter writer)
		{
			base.UpdateHeader(writer);
			WriteCues(writer);
		}
	}

	/// <summary>
	/// Class for enumerating DirectSound devices
	/// </summary>
	public class DirectSoundDeviceInfo
	{
		/// <summary>
		/// The device identifier
		/// </summary>
		public Guid Guid { get; set; }

		/// <summary>
		/// Device description
		/// </summary>
		public string Description { get; set; }

		/// <summary>
		/// Device module name
		/// </summary>
		public string ModuleName { get; set; }
	}

	/// <summary>
	/// NativeDirectSoundOut using DirectSound COM interop.
	/// Contact author: Alexandre Mutel - alexandre_mutel at yahoo.fr
	/// Modified by: Graham "Gee" Plumb
	/// </summary>
	public class DirectSoundOut : IWavePlayer, IDisposable
	{
		[StructLayout(LayoutKind.Sequential, Pack = 2)]
		internal class BufferDescription
		{
			public int dwSize;

			[MarshalAs(UnmanagedType.U4)]
			public DirectSoundBufferCaps dwFlags;

			public uint dwBufferBytes;

			public int dwReserved;

			public IntPtr lpwfxFormat;

			public Guid guidAlgo;
		}

		[StructLayout(LayoutKind.Sequential, Pack = 2)]
		internal class BufferCaps
		{
			public int dwSize;

			public int dwFlags;

			public int dwBufferBytes;

			public int dwUnlockTransferRate;

			public int dwPlayCpuOverhead;
		}

		internal enum DirectSoundCooperativeLevel : uint
		{
			DSSCL_NORMAL = 1u,
			DSSCL_PRIORITY,
			DSSCL_EXCLUSIVE,
			DSSCL_WRITEPRIMARY
		}

		[Flags]
		internal enum DirectSoundPlayFlags : uint
		{
			DSBPLAY_LOOPING = 1u,
			DSBPLAY_LOCHARDWARE = 2u,
			DSBPLAY_LOCSOFTWARE = 4u,
			DSBPLAY_TERMINATEBY_TIME = 8u,
			DSBPLAY_TERMINATEBY_DISTANCE = 0x10u,
			DSBPLAY_TERMINATEBY_PRIORITY = 0x20u
		}

		internal enum DirectSoundBufferLockFlag : uint
		{
			None,
			FromWriteCursor,
			EntireBuffer
		}

		[Flags]
		internal enum DirectSoundBufferStatus : uint
		{
			DSBSTATUS_PLAYING = 1u,
			DSBSTATUS_BUFFERLOST = 2u,
			DSBSTATUS_LOOPING = 4u,
			DSBSTATUS_LOCHARDWARE = 8u,
			DSBSTATUS_LOCSOFTWARE = 0x10u,
			DSBSTATUS_TERMINATED = 0x20u
		}

		[Flags]
		internal enum DirectSoundBufferCaps : uint
		{
			DSBCAPS_PRIMARYBUFFER = 1u,
			DSBCAPS_STATIC = 2u,
			DSBCAPS_LOCHARDWARE = 4u,
			DSBCAPS_LOCSOFTWARE = 8u,
			DSBCAPS_CTRL3D = 0x10u,
			DSBCAPS_CTRLFREQUENCY = 0x20u,
			DSBCAPS_CTRLPAN = 0x40u,
			DSBCAPS_CTRLVOLUME = 0x80u,
			DSBCAPS_CTRLPOSITIONNOTIFY = 0x100u,
			DSBCAPS_CTRLFX = 0x200u,
			DSBCAPS_STICKYFOCUS = 0x4000u,
			DSBCAPS_GLOBALFOCUS = 0x8000u,
			DSBCAPS_GETCURRENTPOSITION2 = 0x10000u,
			DSBCAPS_MUTE3DATMAXDISTANCE = 0x20000u,
			DSBCAPS_LOCDEFER = 0x40000u
		}

		internal struct DirectSoundBufferPositionNotify
		{
			public uint dwOffset;

			public IntPtr hEventNotify;
		}

		/// <summary>
		/// IDirectSound interface
		/// </summary>
		[ComImport]
		[Guid("279AFA83-4981-11CE-A521-0020AF0BE560")]
		[SuppressUnmanagedCodeSecurity]
		[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
		internal interface IDirectSound
		{
			void CreateSoundBuffer([In] BufferDescription desc, [MarshalAs(UnmanagedType.Interface)] out object dsDSoundBuffer, IntPtr pUnkOuter);

			void GetCaps(IntPtr caps);

			void DuplicateSoundBuffer([In][MarshalAs(UnmanagedType.Interface)] IDirectSoundBuffer bufferOriginal, [In][MarshalAs(UnmanagedType.Interface)] IDirectSoundBuffer bufferDuplicate);

			void SetCooperativeLevel(IntPtr HWND, [In][MarshalAs(UnmanagedType.U4)] DirectSoundCooperativeLevel dwLevel);

			void Compact();

			void GetSpeakerConfig(IntPtr pdwSpeakerConfig);

			void SetSpeakerConfig(uint pdwSpeakerConfig);

			void Initialize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guid);
		}

		/// <summary>
		/// IDirectSoundBuffer interface
		/// </summary>
		[ComImport]
		[Guid("279AFA85-4981-11CE-A521-0020AF0BE560")]
		[SuppressUnmanagedCodeSecurity]
		[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
		internal interface IDirectSoundBuffer
		{
			void GetCaps([MarshalAs(UnmanagedType.LPStruct)] BufferCaps pBufferCaps);

			void GetCurrentPosition(out uint currentPlayCursor, out uint currentWriteCursor);

			void GetFormat();

			[return: MarshalAs(UnmanagedType.I4)]
			int GetVolume();

			void GetPan(out uint pan);

			[return: MarshalAs(UnmanagedType.I4)]
			int GetFrequency();

			[return: MarshalAs(UnmanagedType.U4)]
			DirectSoundBufferStatus GetStatus();

			void Initialize([In][MarshalAs(UnmanagedType.Interface)] IDirectSound directSound, [In] BufferDescription desc);

			void Lock(int dwOffset, uint dwBytes, out IntPtr audioPtr1, out int audioBytes1, out IntPtr audioPtr2, out int audioBytes2, [MarshalAs(UnmanagedType.U4)] DirectSoundBufferLockFlag dwFlags);

			void Play(uint dwReserved1, uint dwPriority, [In][MarshalAs(UnmanagedType.U4)] DirectSoundPlayFlags dwFlags);

			void SetCurrentPosition(uint dwNewPosition);

			void SetFormat([In] WaveFormat pcfxFormat);

			void SetVolume(int volume);

			void SetPan(uint pan);

			void SetFrequency(uint frequency);

			void Stop();

			void Unlock(IntPtr pvAudioPtr1, int dwAudioBytes1, IntPtr pvAudioPtr2, int dwAudioBytes2);

			void Restore();
		}

		/// <summary>
		/// IDirectSoundNotify interface
		/// </summary>
		[ComImport]
		[Guid("b0210783-89cd-11d0-af08-00a0c925cd16")]
		[SuppressUnmanagedCodeSecurity]
		[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
		internal interface IDirectSoundNotify
		{
			void SetNotificationPositions(uint dwPositionNotifies, [In][MarshalAs(UnmanagedType.LPArray)] DirectSoundBufferPositionNotify[] pcPositionNotifies);
		}

		/// <summary>
		/// The DSEnumCallback function is an application-defined callback function that enumerates the DirectSound drivers. 
		/// The system calls this function in response to the application's call to the DirectSoundEnumerate or DirectSoundCaptureEnumerate function.
		/// </summary>
		/// <param name="lpGuid">Address of the GUID that identifies the device being enumerated, or NULL for the primary device. This value can be passed to the DirectSoundCreate8 or DirectSoundCaptureCreate8 function to create a device object for that driver. </param>
		/// <param name="lpcstrDescription">Address of a null-terminated string that provides a textual description of the DirectSound device. </param>
		/// <param name="lpcstrModule">Address of a null-terminated string that specifies the module name of the DirectSound driver corresponding to this device. </param>
		/// <param name="lpContext">Address of application-defined data. This is the pointer passed to DirectSoundEnumerate or DirectSoundCaptureEnumerate as the lpContext parameter. </param>
		/// <returns>Returns TRUE to continue enumerating drivers, or FALSE to stop.</returns>
		private delegate bool DSEnumCallback(IntPtr lpGuid, IntPtr lpcstrDescription, IntPtr lpcstrModule, IntPtr lpContext);

		private PlaybackState playbackState;

		private WaveFormat waveFormat;

		private int samplesTotalSize;

		private int samplesFrameSize;

		private int nextSamplesWriteIndex;

		private int desiredLatency;

		private Guid device;

		private byte[] samples;

		private IWaveProvider waveStream;

		private IDirectSound directSound;

		private IDirectSoundBuffer primarySoundBuffer;

		private IDirectSoundBuffer secondaryBuffer;

		private EventWaitHandle frameEventWaitHandle1;

		private EventWaitHandle frameEventWaitHandle2;

		private EventWaitHandle endEventWaitHandle;

		private Thread notifyThread;

		private SynchronizationContext syncContext;

		private long bytesPlayed;

		private object m_LockObject = new object();

		private static List<DirectSoundDeviceInfo> devices;

		/// <summary>
		/// DirectSound default playback device GUID 
		/// </summary>
		public static readonly Guid DSDEVID_DefaultPlayback = new Guid("DEF00000-9C6D-47ED-AAF1-4DDA8F2B5C03");

		/// <summary>
		/// DirectSound default capture device GUID
		/// </summary>
		public static readonly Guid DSDEVID_DefaultCapture = new Guid("DEF00001-9C6D-47ED-AAF1-4DDA8F2B5C03");

		/// <summary>
		/// DirectSound default device for voice playback
		/// </summary>
		public static readonly Guid DSDEVID_DefaultVoicePlayback = new Guid("DEF00002-9C6D-47ED-AAF1-4DDA8F2B5C03");

		/// <summary>
		/// DirectSound default device for voice capture
		/// </summary>
		public static readonly Guid DSDEVID_DefaultVoiceCapture = new Guid("DEF00003-9C6D-47ED-AAF1-4DDA8F2B5C03");

		/// <summary>
		/// Gets the DirectSound output devices in the system
		/// </summary>
		public static IEnumerable<DirectSoundDeviceInfo> Devices
		{
			get
			{
				devices = new List<DirectSoundDeviceInfo>();
				DirectSoundEnumerate(EnumCallback, IntPtr.Zero);
				return devices;
			}
		}

		/// <summary>
		/// Gets the current position from the wave output device.
		/// </summary>
		public TimeSpan PlaybackPosition => TimeSpan.FromMilliseconds((double)(GetPosition() / (waveFormat.Channels * waveFormat.BitsPerSample / 8)) * 1000.0 / (double)waveFormat.SampleRate);

		/// <summary>
		/// Current playback state
		/// </summary>
		/// <value></value>
		public PlaybackState PlaybackState => playbackState;

		/// <summary>
		/// The volume 1.0 is full scale
		/// </summary>
		/// <value></value>
		public float Volume
		{
			get
			{
				return 1f;
			}
			set
			{
				if (value != 1f)
				{
					throw new InvalidOperationException("Setting volume not supported on DirectSoundOut, adjust the volume on your WaveProvider instead");
				}
			}
		}

		/// <inheritdoc />
		public WaveFormat OutputWaveFormat => waveFormat;

		/// <summary>
		/// Playback Stopped
		/// </summary>
		public event EventHandler<StoppedEventArgs> PlaybackStopped;

		private static bool EnumCallback(IntPtr lpGuid, IntPtr lpcstrDescription, IntPtr lpcstrModule, IntPtr lpContext)
		{
			DirectSoundDeviceInfo directSoundDeviceInfo = new DirectSoundDeviceInfo();
			if (lpGuid == IntPtr.Zero)
			{
				directSoundDeviceInfo.Guid = Guid.Empty;
			}
			else
			{
				byte[] array = new byte[16];
				Marshal.Copy(lpGuid, array, 0, 16);
				directSoundDeviceInfo.Guid = new Guid(array);
			}
			directSoundDeviceInfo.Description = Marshal.PtrToStringAnsi(lpcstrDescription);
			directSoundDeviceInfo.ModuleName = Marshal.PtrToStringAnsi(lpcstrModule);
			devices.Add(directSoundDeviceInfo);
			return true;
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.DirectSoundOut" /> class.
		/// </summary>
		public DirectSoundOut()
			: this(DSDEVID_DefaultPlayback)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.DirectSoundOut" /> class.
		/// </summary>
		public DirectSoundOut(Guid device)
			: this(device, 40)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.DirectSoundOut" /> class.
		/// </summary>
		public DirectSoundOut(int latency)
			: this(DSDEVID_DefaultPlayback, latency)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.DirectSoundOut" /> class.
		/// (40ms seems to work under Vista).
		/// </summary>
		/// <param name="latency">The latency.</param>
		/// <param name="device">Selected device</param>
		public DirectSoundOut(Guid device, int latency)
		{
			if (device == Guid.Empty)
			{
				device = DSDEVID_DefaultPlayback;
			}
			this.device = device;
			desiredLatency = latency;
			syncContext = SynchronizationContext.Current;
		}

		/// <summary>
		/// Releases unmanaged resources and performs other cleanup operations before the
		/// <see cref="T:NAudio.Wave.DirectSoundOut" /> is reclaimed by garbage collection.
		/// </summary>
		~DirectSoundOut()
		{
			Dispose();
		}

		/// <summary>
		/// Begin playback
		/// </summary>
		public void Play()
		{
			if (playbackState == PlaybackState.Stopped)
			{
				notifyThread = new Thread(PlaybackThreadFunc);
				notifyThread.Priority = ThreadPriority.Normal;
				notifyThread.IsBackground = true;
				notifyThread.Start();
			}
			lock (m_LockObject)
			{
				playbackState = PlaybackState.Playing;
			}
		}

		/// <summary>
		/// Stop playback
		/// </summary>
		public void Stop()
		{
			if (Monitor.TryEnter(m_LockObject, 50))
			{
				playbackState = PlaybackState.Stopped;
				Monitor.Exit(m_LockObject);
			}
			else if (notifyThread != null)
			{
				notifyThread.Abort();
				notifyThread = null;
			}
		}

		/// <summary>
		/// Pause Playback
		/// </summary>
		public void Pause()
		{
			lock (m_LockObject)
			{
				playbackState = PlaybackState.Paused;
			}
		}

		/// <summary>
		/// Gets the current position in bytes from the wave output device.
		/// (n.b. this is not the same thing as the position within your reader
		/// stream)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			if (playbackState != 0)
			{
				IDirectSoundBuffer directSoundBuffer = secondaryBuffer;
				if (directSoundBuffer != null)
				{
					directSoundBuffer.GetCurrentPosition(out var currentPlayCursor, out var _);
					return currentPlayCursor + bytesPlayed;
				}
			}
			return 0L;
		}

		/// <summary>
		/// Initialise playback
		/// </summary>
		/// <param name="waveProvider">The waveprovider to be played</param>
		public void Init(IWaveProvider waveProvider)
		{
			waveStream = waveProvider;
			waveFormat = waveProvider.WaveFormat;
		}

		private void InitializeDirectSound()
		{
			lock (m_LockObject)
			{
				DirectSoundCreate(ref device, out directSound, IntPtr.Zero);
				if (directSound != null)
				{
					directSound.SetCooperativeLevel(GetDesktopWindow(), DirectSoundCooperativeLevel.DSSCL_PRIORITY);
					BufferDescription bufferDescription = new BufferDescription();
					bufferDescription.dwSize = Marshal.SizeOf(bufferDescription);
					bufferDescription.dwBufferBytes = 0u;
					bufferDescription.dwFlags = DirectSoundBufferCaps.DSBCAPS_PRIMARYBUFFER;
					bufferDescription.dwReserved = 0;
					bufferDescription.lpwfxFormat = IntPtr.Zero;
					bufferDescription.guidAlgo = Guid.Empty;
					directSound.CreateSoundBuffer(bufferDescription, out var dsDSoundBuffer, IntPtr.Zero);
					primarySoundBuffer = (IDirectSoundBuffer)dsDSoundBuffer;
					primarySoundBuffer.Play(0u, 0u, DirectSoundPlayFlags.DSBPLAY_LOOPING);
					samplesFrameSize = MsToBytes(desiredLatency);
					BufferDescription bufferDescription2 = new BufferDescription();
					bufferDescription2.dwSize = Marshal.SizeOf(bufferDescription2);
					bufferDescription2.dwBufferBytes = (uint)(samplesFrameSize * 2);
					bufferDescription2.dwFlags = DirectSoundBufferCaps.DSBCAPS_CTRLVOLUME | DirectSoundBufferCaps.DSBCAPS_CTRLPOSITIONNOTIFY | DirectSoundBufferCaps.DSBCAPS_STICKYFOCUS | DirectSoundBufferCaps.DSBCAPS_GLOBALFOCUS | DirectSoundBufferCaps.DSBCAPS_GETCURRENTPOSITION2;
					bufferDescription2.dwReserved = 0;
					GCHandle gCHandle = GCHandle.Alloc(waveFormat, GCHandleType.Pinned);
					bufferDescription2.lpwfxFormat = gCHandle.AddrOfPinnedObject();
					bufferDescription2.guidAlgo = Guid.Empty;
					directSound.CreateSoundBuffer(bufferDescription2, out dsDSoundBuffer, IntPtr.Zero);
					secondaryBuffer = (IDirectSoundBuffer)dsDSoundBuffer;
					gCHandle.Free();
					BufferCaps bufferCaps = new BufferCaps();
					bufferCaps.dwSize = Marshal.SizeOf(bufferCaps);
					secondaryBuffer.GetCaps(bufferCaps);
					nextSamplesWriteIndex = 0;
					samplesTotalSize = bufferCaps.dwBufferBytes;
					samples = new byte[samplesTotalSize];
					IDirectSoundNotify obj = (IDirectSoundNotify)dsDSoundBuffer;
					frameEventWaitHandle1 = new EventWaitHandle(initialState: false, EventResetMode.AutoReset);
					frameEventWaitHandle2 = new EventWaitHandle(initialState: false, EventResetMode.AutoReset);
					endEventWaitHandle = new EventWaitHandle(initialState: false, EventResetMode.AutoReset);
					DirectSoundBufferPositionNotify[] array = new DirectSoundBufferPositionNotify[3]
					{
						default(DirectSoundBufferPositionNotify),
						default(DirectSoundBufferPositionNotify),
						default(DirectSoundBufferPositionNotify)
					};
					array[0].dwOffset = 0u;
					array[0].hEventNotify = frameEventWaitHandle1.SafeWaitHandle.DangerousGetHandle();
					array[1] = default(DirectSoundBufferPositionNotify);
					array[1].dwOffset = (uint)samplesFrameSize;
					array[1].hEventNotify = frameEventWaitHandle2.SafeWaitHandle.DangerousGetHandle();
					array[2] = default(DirectSoundBufferPositionNotify);
					array[2].dwOffset = uint.MaxValue;
					array[2].hEventNotify = endEventWaitHandle.SafeWaitHandle.DangerousGetHandle();
					obj.SetNotificationPositions(3u, array);
				}
			}
		}

		/// <summary>
		/// Performs application-defined tasks associated with freeing, releasing, or resetting unmanaged resources.
		/// </summary>
		public void Dispose()
		{
			Stop();
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Determines whether the SecondaryBuffer is lost.
		/// </summary>
		/// <returns>
		/// 	<c>true</c> if [is buffer lost]; otherwise, <c>false</c>.
		/// </returns>
		private bool IsBufferLost()
		{
			return (secondaryBuffer.GetStatus() & DirectSoundBufferStatus.DSBSTATUS_BUFFERLOST) != 0;
		}

		/// <summary>
		/// Convert ms to bytes size according to WaveFormat
		/// </summary>
		/// <param name="ms">The ms</param>
		/// <returns>number of byttes</returns>
		private int MsToBytes(int ms)
		{
			int num = ms * (waveFormat.AverageBytesPerSecond / 1000);
			return num - num % waveFormat.BlockAlign;
		}

		/// <summary>
		/// Processes the samples in a separate thread.
		/// </summary>
		private void PlaybackThreadFunc()
		{
			bool flag = false;
			bool flag2 = false;
			bytesPlayed = 0L;
			Exception ex = null;
			try
			{
				InitializeDirectSound();
				int num = 1;
				if (PlaybackState == PlaybackState.Stopped)
				{
					secondaryBuffer.SetCurrentPosition(0u);
					nextSamplesWriteIndex = 0;
					num = Feed(samplesTotalSize);
				}
				if (num <= 0)
				{
					return;
				}
				lock (m_LockObject)
				{
					playbackState = PlaybackState.Playing;
				}
				secondaryBuffer.Play(0u, 0u, DirectSoundPlayFlags.DSBPLAY_LOOPING);
				WaitHandle[] waitHandles = new WaitHandle[3] { frameEventWaitHandle1, frameEventWaitHandle2, endEventWaitHandle };
				bool flag3 = true;
				while (PlaybackState != PlaybackState.Stopped && flag3)
				{
					int num2 = WaitHandle.WaitAny(waitHandles, 3 * desiredLatency, exitContext: false);
					if (num2 != 258)
					{
						switch (num2)
						{
						case 2:
							StopPlayback();
							flag = true;
							flag3 = false;
							continue;
						case 0:
							if (flag2)
							{
								bytesPlayed += samplesFrameSize * 2;
							}
							break;
						default:
							flag2 = true;
							break;
						}
						num2 = ((num2 == 0) ? 1 : 0);
						nextSamplesWriteIndex = num2 * samplesFrameSize;
						if (Feed(samplesFrameSize) == 0)
						{
							StopPlayback();
							flag = true;
							flag3 = false;
						}
						continue;
					}
					StopPlayback();
					flag = true;
					flag3 = false;
					throw new Exception("DirectSound buffer timeout");
				}
			}
			catch (Exception ex2)
			{
				ex = ex2;
			}
			finally
			{
				if (!flag)
				{
					try
					{
						StopPlayback();
					}
					catch (Exception ex3)
					{
						if (ex == null)
						{
							ex = ex3;
						}
					}
				}
				lock (m_LockObject)
				{
					playbackState = PlaybackState.Stopped;
				}
				bytesPlayed = 0L;
				RaisePlaybackStopped(ex);
			}
		}

		private void RaisePlaybackStopped(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.PlaybackStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		/// <summary>
		/// Stop playback
		/// </summary>
		private void StopPlayback()
		{
			lock (m_LockObject)
			{
				if (secondaryBuffer != null)
				{
					CleanUpSecondaryBuffer();
					secondaryBuffer.Stop();
					Marshal.ReleaseComObject(secondaryBuffer);
					secondaryBuffer = null;
				}
				if (primarySoundBuffer != null)
				{
					primarySoundBuffer.Stop();
					Marshal.ReleaseComObject(primarySoundBuffer);
					primarySoundBuffer = null;
				}
				if (directSound != null)
				{
					Marshal.ReleaseComObject(directSound);
					directSound = null;
				}
			}
		}

		/// <summary>
		/// Clean up the SecondaryBuffer
		/// </summary>
		/// <remarks>
		/// <para>
		/// In DirectSound, when playback is started,
		/// the rest of the sound that was played last time is played back as noise.
		/// This happens even if the secondary buffer is completely silenced,
		/// so it seems that the buffer in the primary buffer or higher is not cleared.
		/// </para>
		/// <para>
		/// To solve this problem fill the secondary buffer with silence data when stop playback.
		/// </para>
		/// </remarks>
		private void CleanUpSecondaryBuffer()
		{
			if (secondaryBuffer == null)
			{
				return;
			}
			byte[] source = new byte[samplesTotalSize];
			secondaryBuffer.Lock(0, (uint)samplesTotalSize, out var audioPtr, out var audioBytes, out var audioPtr2, out var audioBytes2, DirectSoundBufferLockFlag.None);
			if (audioPtr != IntPtr.Zero)
			{
				Marshal.Copy(source, 0, audioPtr, audioBytes);
				if (audioPtr2 != IntPtr.Zero)
				{
					Marshal.Copy(source, 0, audioPtr, audioBytes);
				}
			}
			secondaryBuffer.Unlock(audioPtr, audioBytes, audioPtr2, audioBytes2);
		}

		/// <summary>
		/// Feeds the SecondaryBuffer with the WaveStream
		/// </summary>
		/// <param name="bytesToCopy">number of bytes to feed</param>
		private int Feed(int bytesToCopy)
		{
			int num = bytesToCopy;
			if (IsBufferLost())
			{
				secondaryBuffer.Restore();
			}
			if (playbackState == PlaybackState.Paused)
			{
				Array.Clear(samples, 0, samples.Length);
			}
			else
			{
				num = waveStream.Read(samples, 0, bytesToCopy);
				if (num == 0)
				{
					Array.Clear(samples, 0, samples.Length);
					return 0;
				}
			}
			secondaryBuffer.Lock(nextSamplesWriteIndex, (uint)num, out var audioPtr, out var audioBytes, out var audioPtr2, out var audioBytes2, DirectSoundBufferLockFlag.None);
			if (audioPtr != IntPtr.Zero)
			{
				Marshal.Copy(samples, 0, audioPtr, audioBytes);
				if (audioPtr2 != IntPtr.Zero)
				{
					Marshal.Copy(samples, 0, audioPtr, audioBytes);
				}
			}
			secondaryBuffer.Unlock(audioPtr, audioBytes, audioPtr2, audioBytes2);
			return num;
		}

		/// <summary>
		/// Instanciate DirectSound from the DLL
		/// </summary>
		/// <param name="GUID">The GUID.</param>
		/// <param name="directSound">The direct sound.</param>
		/// <param name="pUnkOuter">The p unk outer.</param>
		[DllImport("dsound.dll", CallingConvention = CallingConvention.StdCall, CharSet = CharSet.Unicode, ExactSpelling = true, SetLastError = true)]
		private static extern void DirectSoundCreate(ref Guid GUID, [MarshalAs(UnmanagedType.Interface)] out IDirectSound directSound, IntPtr pUnkOuter);

		/// <summary>
		/// The DirectSoundEnumerate function enumerates the DirectSound drivers installed in the system.
		/// </summary>
		/// <param name="lpDSEnumCallback">callback function</param>
		/// <param name="lpContext">User context</param>
		[DllImport("dsound.dll", CallingConvention = CallingConvention.StdCall, CharSet = CharSet.Unicode, EntryPoint = "DirectSoundEnumerateA", ExactSpelling = true, SetLastError = true)]
		private static extern void DirectSoundEnumerate(DSEnumCallback lpDSEnumCallback, IntPtr lpContext);

		/// <summary>
		/// Gets the HANDLE of the desktop window.
		/// </summary>
		/// <returns>HANDLE of the Desktop window</returns>
		[DllImport("user32.dll")]
		private static extern IntPtr GetDesktopWindow();
	}

	/// <summary>
	/// GSM 610
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class Gsm610WaveFormat : WaveFormat
	{
		private readonly short samplesPerBlock;

		/// <summary>
		/// Samples per block
		/// </summary>
		public short SamplesPerBlock => samplesPerBlock;

		/// <summary>
		/// Creates a GSM 610 WaveFormat
		/// For now hardcoded to 13kbps
		/// </summary>
		public Gsm610WaveFormat()
		{
			waveFormatTag = WaveFormatEncoding.Gsm610;
			channels = 1;
			averageBytesPerSecond = 1625;
			bitsPerSample = 0;
			blockAlign = 65;
			sampleRate = 8000;
			extraSize = 2;
			samplesPerBlock = 320;
		}

		/// <summary>
		/// Writes this structure to a BinaryWriter
		/// </summary>
		public override void Serialize(BinaryWriter writer)
		{
			base.Serialize(writer);
			writer.Write(samplesPerBlock);
		}
	}

	/// <summary>
	/// An ID3v2 Tag
	/// </summary>
	public class Id3v2Tag
	{
		private long tagStartPosition;

		private long tagEndPosition;

		private byte[] rawData;

		/// <summary>
		/// Raw data from this tag
		/// </summary>
		public byte[] RawData => rawData;

		/// <summary>
		/// Reads an ID3v2 tag from a stream
		/// </summary>
		public static Id3v2Tag ReadTag(Stream input)
		{
			try
			{
				return new Id3v2Tag(input);
			}
			catch (FormatException)
			{
				return null;
			}
		}

		/// <summary>
		/// Creates a new ID3v2 tag from a collection of key-value pairs.
		/// </summary>
		/// <param name="tags">A collection of key-value pairs containing the tags to include in the ID3v2 tag.</param>
		/// <returns>A new ID3v2 tag</returns>
		public static Id3v2Tag Create(IEnumerable<KeyValuePair<string, string>> tags)
		{
			return ReadTag(CreateId3v2TagStream(tags));
		}

		/// <summary>
		/// Convert the frame size to a byte array.
		/// </summary>
		/// <param name="n">The frame body size.</param>
		/// <returns></returns>
		private static byte[] FrameSizeToBytes(int n)
		{
			byte[] bytes = BitConverter.GetBytes(n);
			Array.Reverse((Array)bytes);
			return bytes;
		}

		/// <summary>
		/// Creates an ID3v2 frame for the given key-value pair.
		/// </summary>
		/// <param name="key"></param>
		/// <param name="value"></param>
		/// <returns></returns>
		private static byte[] CreateId3v2Frame(string key, string value)
		{
			if (string.IsNullOrEmpty(key))
			{
				throw new ArgumentNullException("key");
			}
			if (string.IsNullOrEmpty(value))
			{
				throw new ArgumentNullException("value");
			}
			if (key.Length != 4)
			{
				throw new ArgumentOutOfRangeException("key", "key " + key + " must be 4 characters long");
			}
			byte[] array = new byte[2] { 255, 254 };
			byte[] array2 = new byte[3];
			byte[] array3 = new byte[2];
			byte[] array4 = ((!(key == "COMM")) ? ByteArrayExtensions.Concat(new byte[1] { 1 }, array, Encoding.Unicode.GetBytes(value)) : ByteArrayExtensions.Concat(new byte[1] { 1 }, array2, array3, array, Encoding.Unicode.GetBytes(value)));
			return ByteArrayExtensions.Concat(Encoding.UTF8.GetBytes(key), FrameSizeToBytes(array4.Length), new byte[2], array4);
		}

		/// <summary>
		/// Gets the Id3v2 Header size. The size is encoded so that only 7 bits per byte are actually used.
		/// </summary>
		/// <param name="size"></param>
		/// <returns></returns>
		private static byte[] GetId3TagHeaderSize(int size)
		{
			byte[] array = new byte[4];
			for (int num = array.Length - 1; num >= 0; num--)
			{
				array[num] = (byte)(size % 128);
				size /= 128;
			}
			return array;
		}

		/// <summary>
		/// Creates the Id3v2 tag header and returns is as a byte array.
		/// </summary>
		/// <param name="frames">The Id3v2 frames that will be included in the file. This is used to calculate the ID3v2 tag size.</param>
		/// <returns></returns>
		private static byte[] CreateId3v2TagHeader(IEnumerable<byte[]> frames)
		{
			int num = 0;
			foreach (byte[] frame in frames)
			{
				num += frame.Length;
			}
			return ByteArrayExtensions.Concat(Encoding.UTF8.GetBytes("ID3"), new byte[2] { 3, 0 }, new byte[1], GetId3TagHeaderSize(num));
		}

		/// <summary>
		/// Creates the Id3v2 tag for the given key-value pairs and returns it in the a stream.
		/// </summary>
		/// <param name="tags"></param>
		/// <returns></returns>
		private static Stream CreateId3v2TagStream(IEnumerable<KeyValuePair<string, string>> tags)
		{
			List<byte[]> list = new List<byte[]>();
			foreach (KeyValuePair<string, string> tag in tags)
			{
				list.Add(CreateId3v2Frame(tag.Key, tag.Value));
			}
			byte[] array = CreateId3v2TagHeader(list);
			MemoryStream memoryStream = new MemoryStream();
			memoryStream.Write(array, 0, array.Length);
			foreach (byte[] item in list)
			{
				memoryStream.Write(item, 0, item.Length);
			}
			memoryStream.Position = 0L;
			return memoryStream;
		}

		private Id3v2Tag(Stream input)
		{
			tagStartPosition = input.Position;
			BinaryReader binaryReader = new BinaryReader(input);
			byte[] array = binaryReader.ReadBytes(10);
			if (array.Length >= 3 && array[0] == 73 && array[1] == 68 && array[2] == 51)
			{
				if ((array[5] & 0x40) == 64)
				{
					byte[] array2 = binaryReader.ReadBytes(4);
					_ = array2[0] * 2097152 + array2[1] * 16384 + array2[2] * 128;
					_ = array2[3];
				}
				int num = array[6] * 2097152;
				num += array[7] * 16384;
				num += array[8] * 128;
				num += array[9];
				binaryReader.ReadBytes(num);
				if ((array[5] & 0x10) == 16)
				{
					binaryReader.ReadBytes(10);
				}
				tagEndPosition = input.Position;
				input.Position = tagStartPosition;
				rawData = binaryReader.ReadBytes((int)(tagEndPosition - tagStartPosition));
				return;
			}
			input.Position = tagStartPosition;
			throw new FormatException("Not an ID3v2 tag");
		}
	}

	/// <summary>
	/// IMA/DVI ADPCM Wave Format
	/// Work in progress
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class ImaAdpcmWaveFormat : WaveFormat
	{
		private short samplesPerBlock;

		/// <summary>
		/// parameterless constructor for Marshalling
		/// </summary>
		private ImaAdpcmWaveFormat()
		{
		}

		/// <summary>
		/// Creates a new IMA / DVI ADPCM Wave Format
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Number of channels</param>
		/// <param name="bitsPerSample">Bits Per Sample</param>
		public ImaAdpcmWaveFormat(int sampleRate, int channels, int bitsPerSample)
		{
			waveFormatTag = WaveFormatEncoding.DviAdpcm;
			base.sampleRate = sampleRate;
			base.channels = (short)channels;
			base.bitsPerSample = (short)bitsPerSample;
			extraSize = 2;
			blockAlign = 0;
			averageBytesPerSecond = 0;
			samplesPerBlock = 0;
		}
	}

	/// <summary>
	/// Interface for MP3 frame by frame decoder
	/// </summary>
	public interface IMp3FrameDecompressor : IDisposable
	{
		/// <summary>
		/// PCM format that we are converting into
		/// </summary>
		WaveFormat OutputFormat { get; }

		/// <summary>
		/// Decompress a single MP3 frame
		/// </summary>
		/// <param name="frame">Frame to decompress</param>
		/// <param name="dest">Output buffer</param>
		/// <param name="destOffset">Offset within output buffer</param>
		/// <returns>Bytes written to output buffer</returns>
		int DecompressFrame(Mp3Frame frame, byte[] dest, int destOffset);

		/// <summary>
		/// Tell the decoder that we have repositioned
		/// </summary>
		void Reset();
	}

	/// <summary>
	/// An interface for WaveStreams which can report notification of individual samples
	/// </summary>
	public interface ISampleNotifier
	{
		/// <summary>
		/// A sample has been detected
		/// </summary>
		event EventHandler<SampleEventArgs> Sample;
	}

	/// <summary>
	/// Like IWaveProvider, but makes it much simpler to put together a 32 bit floating
	/// point mixing engine
	/// </summary>
	public interface ISampleProvider
	{
		/// <summary>
		/// Gets the WaveFormat of this Sample Provider.
		/// </summary>
		/// <value>The wave format.</value>
		WaveFormat WaveFormat { get; }

		/// <summary>
		/// Fill the specified buffer with 32 bit floating point samples
		/// </summary>
		/// <param name="buffer">The buffer to fill with samples.</param>
		/// <param name="offset">Offset into buffer</param>
		/// <param name="count">The number of samples to read</param>
		/// <returns>the number of samples written to the buffer.</returns>
		int Read(float[] buffer, int offset, int count);
	}

	/// <summary>
	/// IWaveBuffer interface use to store wave datas. 
	/// Data can be manipulated with arrays (<see cref="P:NAudio.Wave.IWaveBuffer.ByteBuffer" />,<see cref="P:NAudio.Wave.IWaveBuffer.FloatBuffer" />,
	/// <see cref="P:NAudio.Wave.IWaveBuffer.ShortBuffer" />,<see cref="P:NAudio.Wave.IWaveBuffer.IntBuffer" /> ) that are pointing to the same memory buffer.
	/// This is a requirement for all subclasses.
	///
	/// Use the associated Count property based on the type of buffer to get the number of data in the 
	/// buffer.
	///
	/// <see cref="T:NAudio.Wave.WaveBuffer" /> for the standard implementation using C# unions.
	/// </summary>
	public interface IWaveBuffer
	{
		/// <summary>
		/// Gets the byte buffer.
		/// </summary>
		/// <value>The byte buffer.</value>
		byte[] ByteBuffer { get; }

		/// <summary>
		/// Gets the float buffer.
		/// </summary>
		/// <value>The float buffer.</value>
		float[] FloatBuffer { get; }

		/// <summary>
		/// Gets the short buffer.
		/// </summary>
		/// <value>The short buffer.</value>
		short[] ShortBuffer { get; }

		/// <summary>
		/// Gets the int buffer.
		/// </summary>
		/// <value>The int buffer.</value>
		int[] IntBuffer { get; }

		/// <summary>
		/// Gets the max size in bytes of the byte buffer..
		/// </summary>
		/// <value>Maximum number of bytes in the buffer.</value>
		int MaxSize { get; }

		/// <summary>
		/// Gets the byte buffer count.
		/// </summary>
		/// <value>The byte buffer count.</value>
		int ByteBufferCount { get; }

		/// <summary>
		/// Gets the float buffer count.
		/// </summary>
		/// <value>The float buffer count.</value>
		int FloatBufferCount { get; }

		/// <summary>
		/// Gets the short buffer count.
		/// </summary>
		/// <value>The short buffer count.</value>
		int ShortBufferCount { get; }

		/// <summary>
		/// Gets the int buffer count.
		/// </summary>
		/// <value>The int buffer count.</value>
		int IntBufferCount { get; }
	}

	/// <summary>
	/// Generic interface for wave recording
	/// </summary>
	public interface IWaveIn : IDisposable
	{
		/// <summary>
		/// Recording WaveFormat
		/// </summary>
		WaveFormat WaveFormat { get; set; }

		/// <summary>
		/// Indicates recorded data is available 
		/// </summary>
		event EventHandler<WaveInEventArgs> DataAvailable;

		/// <summary>
		/// Indicates that all recorded data has now been received.
		/// </summary>
		event EventHandler<StoppedEventArgs> RecordingStopped;

		/// <summary>
		/// Start Recording
		/// </summary>
		void StartRecording();

		/// <summary>
		/// Stop Recording
		/// </summary>
		void StopRecording();
	}

	/// <summary>
	/// Represents the interface to a device that can play a WaveFile
	/// </summary>
	public interface IWavePlayer : IDisposable
	{
		/// <summary>
		/// The volume 
		/// 1.0f is full scale
		/// Note that not all implementations necessarily support volume changes
		/// </summary>
		float Volume { get; set; }

		/// <summary>
		/// Current playback state
		/// </summary>
		PlaybackState PlaybackState { get; }

		/// <summary>
		/// The WaveFormat this device is using for playback
		/// </summary>
		WaveFormat OutputWaveFormat { get; }

		/// <summary>
		/// Indicates that playback has gone into a stopped state due to 
		/// reaching the end of the input stream or an error has been encountered during playback
		/// </summary>
		event EventHandler<StoppedEventArgs> PlaybackStopped;

		/// <summary>
		/// Begin playback
		/// </summary>
		void Play();

		/// <summary>
		/// Stop playback
		/// </summary>
		void Stop();

		/// <summary>
		/// Pause Playback
		/// </summary>
		void Pause();

		/// <summary>
		/// Initialise playback
		/// </summary>
		/// <param name="waveProvider">The waveprovider to be played</param>
		void Init(IWaveProvider waveProvider);
	}

	/// <summary>
	/// Interface for IWavePlayers that can report position
	/// </summary>
	public interface IWavePosition
	{
		/// <summary>
		/// Gets a <see cref="T:NAudio.Wave.WaveFormat" /> instance indicating the format the hardware is using.
		/// </summary>
		WaveFormat OutputWaveFormat { get; }

		/// <summary>
		/// Position (in terms of bytes played - does not necessarily translate directly to the position within the source audio file)
		/// </summary>
		/// <returns>Position in bytes</returns>
		long GetPosition();
	}

	/// <summary>
	/// Generic interface for all WaveProviders.
	/// </summary>
	public interface IWaveProvider
	{
		/// <summary>
		/// Gets the WaveFormat of this WaveProvider.
		/// </summary>
		/// <value>The wave format.</value>
		WaveFormat WaveFormat { get; }

		/// <summary>
		/// Fill the specified buffer with wave data.
		/// </summary>
		/// <param name="buffer">The buffer to fill of wave data.</param>
		/// <param name="offset">Offset into buffer</param>
		/// <param name="count">The number of bytes to read</param>
		/// <returns>the number of bytes written to the buffer.</returns>
		int Read(byte[] buffer, int offset, int count);
	}

	/// <summary>
	/// WaveProvider that can mix together multiple 32 bit floating point input provider
	/// All channels must have the same number of inputs and same sample rate
	/// n.b. Work in Progress - not tested yet
	/// </summary>
	public class MixingWaveProvider32 : IWaveProvider
	{
		private List<IWaveProvider> inputs;

		private WaveFormat waveFormat;

		private int bytesPerSample;

		/// <summary>
		/// The number of inputs to this mixer
		/// </summary>
		public int InputCount => inputs.Count;

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Creates a new MixingWaveProvider32
		/// </summary>
		public MixingWaveProvider32()
		{
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(44100, 2);
			bytesPerSample = 4;
			inputs = new List<IWaveProvider>();
		}

		/// <summary>
		/// Creates a new 32 bit MixingWaveProvider32
		/// </summary>
		/// <param name="inputs">inputs - must all have the same format.</param>
		/// <exception cref="T:System.ArgumentException">Thrown if the input streams are not 32 bit floating point,
		/// or if they have different formats to each other</exception>
		public MixingWaveProvider32(IEnumerable<IWaveProvider> inputs)
			: this()
		{
			foreach (IWaveProvider input in inputs)
			{
				AddInputStream(input);
			}
		}

		/// <summary>
		/// Add a new input to the mixer
		/// </summary>
		/// <param name="waveProvider">The wave input to add</param>
		public void AddInputStream(IWaveProvider waveProvider)
		{
			if (waveProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Must be IEEE floating point", "waveProvider.WaveFormat");
			}
			if (waveProvider.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Only 32 bit audio currently supported", "waveProvider.WaveFormat");
			}
			if (inputs.Count == 0)
			{
				int sampleRate = waveProvider.WaveFormat.SampleRate;
				int channels = waveProvider.WaveFormat.Channels;
				waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channels);
			}
			else if (!waveProvider.WaveFormat.Equals(waveFormat))
			{
				throw new ArgumentException("All incoming channels must have the same format", "waveProvider.WaveFormat");
			}
			lock (inputs)
			{
				inputs.Add(waveProvider);
			}
		}

		/// <summary>
		/// Remove an input from the mixer
		/// </summary>
		/// <param name="waveProvider">waveProvider to remove</param>
		public void RemoveInputStream(IWaveProvider waveProvider)
		{
			lock (inputs)
			{
				inputs.Remove(waveProvider);
			}
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="buffer">buffer to read into</param>
		/// <param name="offset">offset into buffer</param>
		/// <param name="count">number of bytes required</param>
		/// <returns>Number of bytes read.</returns>
		/// <exception cref="T:System.ArgumentException">Thrown if an invalid number of bytes requested</exception>
		public int Read(byte[] buffer, int offset, int count)
		{
			if (count % bytesPerSample != 0)
			{
				throw new ArgumentException("Must read an whole number of samples", "count");
			}
			Array.Clear(buffer, offset, count);
			int num = 0;
			byte[] array = new byte[count];
			lock (inputs)
			{
				foreach (IWaveProvider input in inputs)
				{
					int num2 = input.Read(array, 0, count);
					num = Math.Max(num, num2);
					if (num2 > 0)
					{
						Sum32BitAudio(buffer, offset, array, num2);
					}
				}
				return num;
			}
		}

		/// <summary>
		/// Actually performs the mixing
		/// </summary>
		private unsafe static void Sum32BitAudio(byte[] destBuffer, int offset, byte[] sourceBuffer, int bytesRead)
		{
			fixed (byte* ptr = &destBuffer[offset])
			{
				fixed (byte* ptr3 = &sourceBuffer[0])
				{
					float* ptr2 = (float*)ptr;
					float* ptr4 = (float*)ptr3;
					int num = bytesRead / 4;
					for (int i = 0; i < num; i++)
					{
						ptr2[i] += ptr4[i];
					}
				}
			}
		}
	}

	/// <summary>
	/// Converts from mono to stereo, allowing freedom to route all, some, or none of the incoming signal to left or right channels
	/// </summary>
	public class MonoToStereoProvider16 : IWaveProvider
	{
		private readonly IWaveProvider sourceProvider;

		private byte[] sourceBuffer;

		/// <summary>
		/// 1.0 to copy the mono stream to the left channel without adjusting volume
		/// </summary>
		public float LeftVolume { get; set; }

		/// <summary>
		/// 1.0 to copy the mono stream to the right channel without adjusting volume
		/// </summary>
		public float RightVolume { get; set; }

		/// <summary>
		/// Output Wave Format
		/// </summary>
		public WaveFormat WaveFormat { get; }

		/// <summary>
		/// Creates a new stereo waveprovider based on a mono input
		/// </summary>
		/// <param name="sourceProvider">Mono 16 bit PCM input</param>
		public MonoToStereoProvider16(IWaveProvider sourceProvider)
		{
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm)
			{
				throw new ArgumentException("Source must be PCM");
			}
			if (sourceProvider.WaveFormat.Channels != 1)
			{
				throw new ArgumentException("Source must be Mono");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 16)
			{
				throw new ArgumentException("Source must be 16 bit");
			}
			this.sourceProvider = sourceProvider;
			WaveFormat = new WaveFormat(sourceProvider.WaveFormat.SampleRate, 2);
			RightVolume = 1f;
			LeftVolume = 1f;
		}

		/// <summary>
		/// Reads bytes from this WaveProvider
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = count / 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			WaveBuffer waveBuffer = new WaveBuffer(sourceBuffer);
			WaveBuffer waveBuffer2 = new WaveBuffer(buffer);
			int num2 = sourceProvider.Read(sourceBuffer, 0, num) / 2;
			int num3 = offset / 2;
			for (int i = 0; i < num2; i++)
			{
				short num4 = waveBuffer.ShortBuffer[i];
				waveBuffer2.ShortBuffer[num3++] = (short)(LeftVolume * (float)num4);
				waveBuffer2.ShortBuffer[num3++] = (short)(RightVolume * (float)num4);
			}
			return num2 * 4;
		}
	}

	/// <summary>
	/// Class for reading from MP3 files
	/// </summary>
	public class Mp3FileReaderBase : WaveStream
	{
		/// <summary>
		/// Function that can create an MP3 Frame decompressor
		/// </summary>
		/// <param name="mp3Format">A WaveFormat object describing the MP3 file format</param>
		/// <returns>An MP3 Frame decompressor</returns>
		public delegate IMp3FrameDecompressor FrameDecompressorBuilder(WaveFormat mp3Format);

		private readonly WaveFormat waveFormat;

		private Stream mp3Stream;

		private readonly long mp3DataLength;

		private readonly long dataStartPosition;

		private readonly XingHeader xingHeader;

		private readonly bool ownInputStream;

		private List<Mp3Index> tableOfContents;

		private int tocIndex;

		private long totalSamples;

		private readonly int bytesPerSample;

		private readonly int bytesPerDecodedFrame;

		private IMp3FrameDecompressor decompressor;

		private readonly byte[] decompressBuffer;

		private int decompressBufferOffset;

		private int decompressLeftovers;

		private bool repositionedFlag;

		private long position;

		private readonly object repositionLock = new object();

		/// <summary>
		/// The MP3 wave format (n.b. NOT the output format of this stream - see the WaveFormat property)
		/// </summary>
		public Mp3WaveFormat Mp3WaveFormat { get; private set; }

		/// <summary>
		/// ID3v2 tag if present
		/// </summary>
		public Id3v2Tag Id3v2Tag { get; }

		/// <summary>
		/// ID3v1 tag if present
		/// </summary>
		public byte[] Id3v1Tag { get; }

		/// <summary>
		/// This is the length in bytes of data available to be read out from the Read method
		/// (i.e. the decompressed MP3 length)
		/// n.b. this may return 0 for files whose length is unknown
		/// </summary>
		public override long Length => totalSamples * bytesPerSample;

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// <see cref="P:System.IO.Stream.Position" />
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (repositionLock)
				{
					value = Math.Max(Math.Min(value, Length), 0L);
					long num = value / bytesPerSample;
					Mp3Index mp3Index = null;
					for (int i = 0; i < tableOfContents.Count; i++)
					{
						if (tableOfContents[i].SamplePosition + tableOfContents[i].SampleCount > num)
						{
							mp3Index = tableOfContents[i];
							tocIndex = i;
							break;
						}
					}
					decompressBufferOffset = 0;
					decompressLeftovers = 0;
					repositionedFlag = true;
					if (mp3Index != null)
					{
						mp3Stream.Position = mp3Index.FilePosition;
						long num2 = num - mp3Index.SamplePosition;
						if (num2 > 0)
						{
							decompressBufferOffset = (int)num2 * bytesPerSample;
						}
					}
					else
					{
						mp3Stream.Position = mp3DataLength + dataStartPosition;
					}
					position = value;
				}
			}
		}

		/// <summary>
		/// Xing header if present
		/// </summary>
		public XingHeader XingHeader => xingHeader;

		/// <summary>Supports opening a MP3 file</summary>
		/// <param name="mp3FileName">MP3 File name</param>
		/// <param name="frameDecompressorBuilder">Factory method to build a frame decompressor</param>
		public Mp3FileReaderBase(string mp3FileName, FrameDecompressorBuilder frameDecompressorBuilder)
			: this(File.OpenRead(mp3FileName), frameDecompressorBuilder, ownInputStream: true)
		{
		}

		/// <summary>
		/// Opens MP3 from a stream rather than a file
		/// Will not dispose of this stream itself
		/// </summary>
		/// <param name="inputStream">The incoming stream containing MP3 data</param>
		/// <param name="frameDecompressorBuilder">Factory method to build a frame decompressor</param>
		public Mp3FileReaderBase(Stream inputStream, FrameDecompressorBuilder frameDecompressorBuilder)
			: this(inputStream, frameDecompressorBuilder, ownInputStream: false)
		{
		}

		protected Mp3FileReaderBase(Stream inputStream, FrameDecompressorBuilder frameDecompressorBuilder, bool ownInputStream)
		{
			if (inputStream == null)
			{
				throw new ArgumentNullException("inputStream");
			}
			if (frameDecompressorBuilder == null)
			{
				throw new ArgumentNullException("frameDecompressorBuilder");
			}
			this.ownInputStream = ownInputStream;
			try
			{
				mp3Stream = inputStream;
				Id3v2Tag = Id3v2Tag.ReadTag(mp3Stream);
				dataStartPosition = mp3Stream.Position;
				Mp3Frame mp3Frame = Mp3Frame.LoadFromStream(mp3Stream);
				if (mp3Frame == null)
				{
					throw new InvalidDataException("Invalid MP3 file - no MP3 Frames Detected");
				}
				double num = mp3Frame.BitRate;
				xingHeader = XingHeader.LoadXingHeader(mp3Frame);
				if (xingHeader != null)
				{
					dataStartPosition = mp3Stream.Position;
				}
				Mp3Frame mp3Frame2 = Mp3Frame.LoadFromStream(mp3Stream);
				if (mp3Frame2 != null && (mp3Frame2.SampleRate != mp3Frame.SampleRate || mp3Frame2.ChannelMode != mp3Frame.ChannelMode))
				{
					dataStartPosition = mp3Frame2.FileOffset;
					mp3Frame = mp3Frame2;
				}
				mp3DataLength = mp3Stream.Length - dataStartPosition;
				mp3Stream.Position = mp3Stream.Length - 128;
				byte[] array = new byte[128];
				mp3Stream.Read(array, 0, 128);
				if (array[0] == 84 && array[1] == 65 && array[2] == 71)
				{
					Id3v1Tag = array;
					mp3DataLength -= 128L;
				}
				mp3Stream.Position = dataStartPosition;
				Mp3WaveFormat = new Mp3WaveFormat(mp3Frame.SampleRate, (mp3Frame.ChannelMode == ChannelMode.Mono) ? 1 : 2, mp3Frame.FrameLength, (int)num);
				CreateTableOfContents();
				tocIndex = 0;
				num = (double)mp3DataLength * 8.0 / TotalSeconds();
				mp3Stream.Position = dataStartPosition;
				Mp3WaveFormat = new Mp3WaveFormat(mp3Frame.SampleRate, (mp3Frame.ChannelMode == ChannelMode.Mono) ? 1 : 2, mp3Frame.FrameLength, (int)num);
				decompressor = frameDecompressorBuilder(Mp3WaveFormat);
				waveFormat = decompressor.OutputFormat;
				bytesPerSample = decompressor.OutputFormat.BitsPerSample / 8 * decompressor.OutputFormat.Channels;
				bytesPerDecodedFrame = 1152 * bytesPerSample;
				decompressBuffer = new byte[bytesPerDecodedFrame * 2];
			}
			catch (Exception)
			{
				if (ownInputStream)
				{
					inputStream.Dispose();
				}
				throw;
			}
		}

		private void CreateTableOfContents()
		{
			try
			{
				tableOfContents = new List<Mp3Index>((int)(mp3DataLength / 400));
				Mp3Frame mp3Frame;
				do
				{
					Mp3Index mp3Index = new Mp3Index();
					mp3Index.FilePosition = mp3Stream.Position;
					mp3Index.SamplePosition = totalSamples;
					mp3Frame = ReadNextFrame(readData: false);
					if (mp3Frame != null)
					{
						ValidateFrameFormat(mp3Frame);
						totalSamples += mp3Frame.SampleCount;
						mp3Index.SampleCount = mp3Frame.SampleCount;
						mp3Index.ByteCount = (int)(mp3Stream.Position - mp3Index.FilePosition);
						tableOfContents.Add(mp3Index);
					}
				}
				while (mp3Frame != null);
			}
			catch (EndOfStreamException)
			{
			}
		}

		private void ValidateFrameFormat(Mp3Frame frame)
		{
			if (frame.SampleRate != Mp3WaveFormat.SampleRate)
			{
				throw new InvalidOperationException($"Got a frame at sample rate {frame.SampleRate}, in an MP3 with sample rate {Mp3WaveFormat.SampleRate}. Mp3FileReader does not support sample rate changes.");
			}
			if (((frame.ChannelMode == ChannelMode.Mono) ? 1 : 2) != Mp3WaveFormat.Channels)
			{
				throw new InvalidOperationException($"Got a frame with channel mode {frame.ChannelMode}, in an MP3 with {Mp3WaveFormat.Channels} channels. Mp3FileReader does not support changes to channel count.");
			}
		}

		/// <summary>
		/// Gets the total length of this file in milliseconds.
		/// </summary>
		private double TotalSeconds()
		{
			return (double)totalSamples / (double)Mp3WaveFormat.SampleRate;
		}

		/// <summary>
		/// Reads the next mp3 frame
		/// </summary>
		/// <returns>Next mp3 frame, or null if EOF</returns>
		public Mp3Frame ReadNextFrame()
		{
			Mp3Frame mp3Frame = ReadNextFrame(readData: true);
			if (mp3Frame != null)
			{
				position += mp3Frame.SampleCount * bytesPerSample;
			}
			return mp3Frame;
		}

		/// <summary>
		/// Reads the next mp3 frame
		/// </summary>
		/// <returns>Next mp3 frame, or null if EOF</returns>
		private Mp3Frame ReadNextFrame(bool readData)
		{
			Mp3Frame mp3Frame = null;
			try
			{
				mp3Frame = Mp3Frame.LoadFromStream(mp3Stream, readData);
				if (mp3Frame != null)
				{
					tocIndex++;
				}
			}
			catch (EndOfStreamException)
			{
			}
			return mp3Frame;
		}

		/// <summary>
		/// Reads decompressed PCM data from our MP3 file.
		/// </summary>
		public override int Read(byte[] sampleBuffer, int offset, int numBytes)
		{
			int num = 0;
			lock (repositionLock)
			{
				if (decompressLeftovers != 0)
				{
					int num2 = Math.Min(decompressLeftovers, numBytes);
					Array.Copy(decompressBuffer, decompressBufferOffset, sampleBuffer, offset, num2);
					decompressLeftovers -= num2;
					if (decompressLeftovers == 0)
					{
						decompressBufferOffset = 0;
					}
					else
					{
						decompressBufferOffset += num2;
					}
					num += num2;
					offset += num2;
				}
				int num3 = tocIndex;
				if (repositionedFlag)
				{
					decompressor.Reset();
					tocIndex = Math.Max(0, tocIndex - 3);
					mp3Stream.Position = tableOfContents[tocIndex].FilePosition;
					repositionedFlag = false;
				}
				while (num < numBytes)
				{
					Mp3Frame mp3Frame = ReadNextFrame(readData: true);
					if (mp3Frame == null)
					{
						break;
					}
					int num4 = decompressor.DecompressFrame(mp3Frame, decompressBuffer, 0);
					if (tocIndex > num3 && num4 != 0)
					{
						if (tocIndex == num3 + 1 && num4 == bytesPerDecodedFrame * 2)
						{
							Array.Copy(decompressBuffer, bytesPerDecodedFrame, decompressBuffer, 0, bytesPerDecodedFrame);
							num4 = bytesPerDecodedFrame;
						}
						int num5 = Math.Min(num4 - decompressBufferOffset, numBytes - num);
						Array.Copy(decompressBuffer, decompressBufferOffset, sampleBuffer, offset, num5);
						if (num5 + decompressBufferOffset < num4)
						{
							decompressBufferOffset = num5 + decompressBufferOffset;
							decompressLeftovers = num4 - decompressBufferOffset;
						}
						else
						{
							decompressBufferOffset = 0;
							decompressLeftovers = 0;
						}
						offset += num5;
						num += num5;
					}
				}
			}
			position += num;
			return num;
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing)
			{
				if (mp3Stream != null)
				{
					if (ownInputStream)
					{
						mp3Stream.Dispose();
					}
					mp3Stream = null;
				}
				if (decompressor != null)
				{
					decompressor.Dispose();
					decompressor = null;
				}
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// Represents an MP3 Frame
	/// </summary>
	public class Mp3Frame
	{
		private static readonly int[,,] bitRates = new int[2, 3, 15]
		{
			{
				{
					0, 32, 64, 96, 128, 160, 192, 224, 256, 288,
					320, 352, 384, 416, 448
				},
				{
					0, 32, 48, 56, 64, 80, 96, 112, 128, 160,
					192, 224, 256, 320, 384
				},
				{
					0, 32, 40, 48, 56, 64, 80, 96, 112, 128,
					160, 192, 224, 256, 320
				}
			},
			{
				{
					0, 32, 48, 56, 64, 80, 96, 112, 128, 144,
					160, 176, 192, 224, 256
				},
				{
					0, 8, 16, 24, 32, 40, 48, 56, 64, 80,
					96, 112, 128, 144, 160
				},
				{
					0, 8, 16, 24, 32, 40, 48, 56, 64, 80,
					96, 112, 128, 144, 160
				}
			}
		};

		private static readonly int[,] samplesPerFrame = new int[2, 3]
		{
			{ 384, 1152, 1152 },
			{ 384, 1152, 576 }
		};

		private static readonly int[] sampleRatesVersion1 = new int[3] { 44100, 48000, 32000 };

		private static readonly int[] sampleRatesVersion2 = new int[3] { 22050, 24000, 16000 };

		private static readonly int[] sampleRatesVersion25 = new int[3] { 11025, 12000, 8000 };

		private const int MaxFrameLength = 16384;

		/// <summary>
		/// Sample rate of this frame
		/// </summary>
		public int SampleRate { get; private set; }

		/// <summary>
		/// Frame length in bytes
		/// </summary>
		public int FrameLength { get; private set; }

		/// <summary>
		/// Bit Rate
		/// </summary>
		public int BitRate { get; private set; }

		/// <summary>
		/// Raw frame data (includes header bytes)
		/// </summary>
		public byte[] RawData { get; private set; }

		/// <summary>
		/// MPEG Version
		/// </summary>
		public MpegVersion MpegVersion { get; private set; }

		/// <summary>
		/// MPEG Layer
		/// </summary>
		public MpegLayer MpegLayer { get; private set; }

		/// <summary>
		/// Channel Mode
		/// </summary>
		public ChannelMode ChannelMode { get; private set; }

		/// <summary>
		/// The number of samples in this frame
		/// </summary>
		public int SampleCount { get; private set; }

		/// <summary>
		/// The channel extension bits
		/// </summary>
		public int ChannelExtension { get; private set; }

		/// <summary>
		/// The bitrate index (directly from the header)
		/// </summary>
		public int BitRateIndex { get; private set; }

		/// <summary>
		/// Whether the Copyright bit is set
		/// </summary>
		public bool Copyright { get; private set; }

		/// <summary>
		/// Whether a CRC is present
		/// </summary>
		public bool CrcPresent { get; private set; }

		/// <summary>
		/// Not part of the MP3 frame itself - indicates where in the stream we found this header
		/// </summary>
		public long FileOffset { get; private set; }

		/// <summary>
		/// Reads an MP3 frame from a stream
		/// </summary>
		/// <param name="input">input stream</param>
		/// <returns>A valid MP3 frame, or null if none found</returns>
		public static Mp3Frame LoadFromStream(Stream input)
		{
			return LoadFromStream(input, readData: true);
		}

		/// <summary>Reads an MP3Frame from a stream</summary>
		/// <remarks>http://mpgedit.org/mpgedit/mpeg_format/mpeghdr.htm has some good info
		/// also see http://www.codeproject.com/KB/audio-video/mpegaudioinfo.aspx
		/// </remarks>
		/// <returns>A valid MP3 frame, or null if none found</returns>
		public static Mp3Frame LoadFromStream(Stream input, bool readData)
		{
			Mp3Frame mp3Frame = new Mp3Frame();
			mp3Frame.FileOffset = input.Position;
			byte[] array = new byte[4];
			if (input.Read(array, 0, array.Length) < array.Length)
			{
				return null;
			}
			while (!IsValidHeader(array, mp3Frame))
			{
				array[0] = array[1];
				array[1] = array[2];
				array[2] = array[3];
				if (input.Read(array, 3, 1) < 1)
				{
					return null;
				}
				mp3Frame.FileOffset++;
			}
			int num = mp3Frame.FrameLength - 4;
			if (readData)
			{
				mp3Frame.RawData = new byte[mp3Frame.FrameLength];
				Array.Copy(array, mp3Frame.RawData, 4);
				if (input.Read(mp3Frame.RawData, 4, num) < num)
				{
					throw new EndOfStreamException("Unexpected end of stream before frame complete");
				}
			}
			else
			{
				input.Position += num;
			}
			return mp3Frame;
		}

		/// <summary>
		/// Constructs an MP3 frame
		/// </summary>
		private Mp3Frame()
		{
		}

		/// <summary>
		/// checks if the four bytes represent a valid header,
		/// if they are, will parse the values into Mp3Frame
		/// </summary>
		private static bool IsValidHeader(byte[] headerBytes, Mp3Frame frame)
		{
			if (headerBytes[0] == byte.MaxValue && (headerBytes[1] & 0xE0) == 224)
			{
				frame.MpegVersion = (MpegVersion)((headerBytes[1] & 0x18) >> 3);
				if (frame.MpegVersion == MpegVersion.Reserved)
				{
					return false;
				}
				frame.MpegLayer = (MpegLayer)((headerBytes[1] & 6) >> 1);
				if (frame.MpegLayer == MpegLayer.Reserved)
				{
					return false;
				}
				int num = ((frame.MpegLayer != MpegLayer.Layer1) ? ((frame.MpegLayer == MpegLayer.Layer2) ? 1 : 2) : 0);
				frame.CrcPresent = (headerBytes[1] & 1) == 0;
				frame.BitRateIndex = (headerBytes[2] & 0xF0) >> 4;
				if (frame.BitRateIndex == 15)
				{
					return false;
				}
				int num2 = ((frame.MpegVersion != MpegVersion.Version1) ? 1 : 0);
				frame.BitRate = bitRates[num2, num, frame.BitRateIndex] * 1000;
				if (frame.BitRate == 0)
				{
					return false;
				}
				int num3 = (headerBytes[2] & 0xC) >> 2;
				if (num3 == 3)
				{
					return false;
				}
				if (frame.MpegVersion == MpegVersion.Version1)
				{
					frame.SampleRate = sampleRatesVersion1[num3];
				}
				else if (frame.MpegVersion == MpegVersion.Version2)
				{
					frame.SampleRate = sampleRatesVersion2[num3];
				}
				else
				{
					frame.SampleRate = sampleRatesVersion25[num3];
				}
				bool flag = (headerBytes[2] & 2) == 2;
				_ = headerBytes[2];
				frame.ChannelMode = (ChannelMode)((headerBytes[3] & 0xC0) >> 6);
				frame.ChannelExtension = (headerBytes[3] & 0x30) >> 4;
				if (frame.ChannelExtension != 0 && frame.ChannelMode != ChannelMode.JointStereo)
				{
					return false;
				}
				frame.Copyright = (headerBytes[3] & 8) == 8;
				_ = headerBytes[3];
				_ = headerBytes[3];
				int num4 = (flag ? 1 : 0);
				frame.SampleCount = samplesPerFrame[num2, num];
				int num5 = frame.SampleCount / 8;
				if (frame.MpegLayer == MpegLayer.Layer1)
				{
					frame.FrameLength = (num5 * frame.BitRate / frame.SampleRate + num4) * 4;
				}
				else
				{
					frame.FrameLength = num5 * frame.BitRate / frame.SampleRate + num4;
				}
				if (frame.FrameLength > 16384)
				{
					return false;
				}
				return true;
			}
			return false;
		}
	}

	internal class Mp3Index
	{
		public long FilePosition { get; set; }

		public long SamplePosition { get; set; }

		public int SampleCount { get; set; }

		public int ByteCount { get; set; }
	}

	/// <summary>
	/// MP3 WaveFormat, MPEGLAYER3WAVEFORMAT from mmreg.h
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class Mp3WaveFormat : WaveFormat
	{
		/// <summary>
		/// Wave format ID (wID)
		/// </summary>
		public Mp3WaveFormatId id;

		/// <summary>
		/// Padding flags (fdwFlags)
		/// </summary>
		public Mp3WaveFormatFlags flags;

		/// <summary>
		/// Block Size (nBlockSize)
		/// </summary>
		public ushort blockSize;

		/// <summary>
		/// Frames per block (nFramesPerBlock)
		/// </summary>
		public ushort framesPerBlock;

		/// <summary>
		/// Codec Delay (nCodecDelay)
		/// </summary>
		public ushort codecDelay;

		private const short Mp3WaveFormatExtraBytes = 12;

		/// <summary>
		/// Creates a new MP3 WaveFormat
		/// </summary>
		public Mp3WaveFormat(int sampleRate, int channels, int blockSize, int bitRate)
		{
			waveFormatTag = WaveFormatEncoding.MpegLayer3;
			base.channels = (short)channels;
			averageBytesPerSecond = bitRate / 8;
			bitsPerSample = 0;
			blockAlign = 1;
			base.sampleRate = sampleRate;
			extraSize = 12;
			id = Mp3WaveFormatId.Mpeg;
			flags = Mp3WaveFormatFlags.PaddingIso;
			this.blockSize = (ushort)blockSize;
			framesPerBlock = 1;
			codecDelay = 0;
		}
	}

	/// <summary>
	/// Wave Format Padding Flags
	/// </summary>
	[Flags]
	public enum Mp3WaveFormatFlags
	{
		/// <summary>
		/// MPEGLAYER3_FLAG_PADDING_ISO
		/// </summary>
		PaddingIso = 0,
		/// <summary>
		/// MPEGLAYER3_FLAG_PADDING_ON
		/// </summary>
		PaddingOn = 1,
		/// <summary>
		/// MPEGLAYER3_FLAG_PADDING_OFF
		/// </summary>
		PaddingOff = 2
	}

	/// <summary>
	/// Wave Format ID
	/// </summary>
	public enum Mp3WaveFormatId : ushort
	{
		/// <summary>MPEGLAYER3_ID_UNKNOWN</summary>
		Unknown,
		/// <summary>MPEGLAYER3_ID_MPEG</summary>
		Mpeg,
		/// <summary>MPEGLAYER3_ID_CONSTANTFRAMESIZE</summary>
		ConstantFrameSize
	}

	/// <summary>
	/// MPEG Layer flags
	/// </summary>
	public enum MpegLayer
	{
		/// <summary>
		/// Reserved
		/// </summary>
		Reserved,
		/// <summary>
		/// Layer 3
		/// </summary>
		Layer3,
		/// <summary>
		/// Layer 2
		/// </summary>
		Layer2,
		/// <summary>
		/// Layer 1
		/// </summary>
		Layer1
	}

	/// <summary>
	/// MPEG Version Flags
	/// </summary>
	public enum MpegVersion
	{
		/// <summary>
		/// Version 2.5
		/// </summary>
		Version25,
		/// <summary>
		/// Reserved
		/// </summary>
		Reserved,
		/// <summary>
		/// Version 2
		/// </summary>
		Version2,
		/// <summary>
		/// Version 1
		/// </summary>
		Version1
	}

	/// <summary>
	/// Allows any number of inputs to be patched to outputs
	/// Uses could include swapping left and right channels, turning mono into stereo,
	/// feeding different input sources to different soundcard outputs etc
	/// </summary>
	public class MultiplexingWaveProvider : IWaveProvider
	{
		private readonly IList<IWaveProvider> inputs;

		private readonly int outputChannelCount;

		private readonly int inputChannelCount;

		private readonly List<int> mappings;

		private readonly int bytesPerSample;

		/// <summary>
		/// persistent temporary buffer to prevent creating work for garbage collector
		/// </summary>
		private byte[] inputBuffer;

		/// <summary>
		/// The WaveFormat of this WaveProvider
		/// </summary>
		public WaveFormat WaveFormat { get; }

		/// <summary>
		/// The number of input channels. Note that this is not the same as the number of input wave providers. If you pass in
		/// one stereo and one mono input provider, the number of input channels is three.
		/// </summary>
		public int InputChannelCount => inputChannelCount;

		/// <summary>
		/// The number of output channels, as specified in the constructor.
		/// </summary>
		public int OutputChannelCount => outputChannelCount;

		/// <summary>
		/// Creates a multiplexing wave provider, allowing re-patching of input channels to different
		/// output channels. Number of outputs is equal to total number of channels in inputs
		/// </summary>
		/// <param name="inputs">Input wave providers. Must all be of the same format, but can have any number of channels</param>
		public MultiplexingWaveProvider(IEnumerable<IWaveProvider> inputs)
			: this(inputs, -1)
		{
		}

		/// <summary>
		/// Creates a multiplexing wave provider, allowing re-patching of input channels to different
		/// output channels
		/// </summary>
		/// <param name="inputs">Input wave providers. Must all be of the same format, but can have any number of channels</param>
		/// <param name="numberOfOutputChannels">Desired number of output channels. (-1 means use total number of input channels)</param>
		public MultiplexingWaveProvider(IEnumerable<IWaveProvider> inputs, int numberOfOutputChannels)
		{
			this.inputs = new List<IWaveProvider>(inputs);
			outputChannelCount = ((numberOfOutputChannels == -1) ? this.inputs.Sum((IWaveProvider i) => i.WaveFormat.Channels) : numberOfOutputChannels);
			if (this.inputs.Count == 0)
			{
				throw new ArgumentException("You must provide at least one input");
			}
			if (outputChannelCount < 1)
			{
				throw new ArgumentException("You must provide at least one output");
			}
			foreach (IWaveProvider input in this.inputs)
			{
				if (WaveFormat == null)
				{
					if (input.WaveFormat.Encoding == WaveFormatEncoding.Pcm)
					{
						WaveFormat = new WaveFormat(input.WaveFormat.SampleRate, input.WaveFormat.BitsPerSample, outputChannelCount);
					}
					else
					{
						if (input.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
						{
							throw new ArgumentException("Only PCM and 32 bit float are supported");
						}
						WaveFormat = WaveFormat.CreateIeeeFloatWaveFormat(input.WaveFormat.SampleRate, outputChannelCount);
					}
				}
				else
				{
					if (input.WaveFormat.BitsPerSample != WaveFormat.BitsPerSample)
					{
						throw new ArgumentException("All inputs must have the same bit depth");
					}
					if (input.WaveFormat.SampleRate != WaveFormat.SampleRate)
					{
						throw new ArgumentException("All inputs must have the same sample rate");
					}
				}
				inputChannelCount += input.WaveFormat.Channels;
			}
			bytesPerSample = WaveFormat.BitsPerSample / 8;
			mappings = new List<int>();
			for (int j = 0; j < outputChannelCount; j++)
			{
				mappings.Add(j % inputChannelCount);
			}
		}

		/// <summary>
		/// Reads data from this WaveProvider
		/// </summary>
		/// <param name="buffer">Buffer to be filled with sample data</param>
		/// <param name="offset">Offset to write to within buffer, usually 0</param>
		/// <param name="count">Number of bytes required</param>
		/// <returns>Number of bytes read</returns>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = bytesPerSample * outputChannelCount;
			int num2 = count / num;
			int num3 = 0;
			int num4 = 0;
			foreach (IWaveProvider input in inputs)
			{
				int num5 = bytesPerSample * input.WaveFormat.Channels;
				int num6 = num2 * num5;
				inputBuffer = BufferHelpers.Ensure(inputBuffer, num6);
				int num7 = input.Read(inputBuffer, 0, num6);
				num4 = Math.Max(num4, num7 / num5);
				for (int i = 0; i < input.WaveFormat.Channels; i++)
				{
					int num8 = num3 + i;
					for (int j = 0; j < outputChannelCount; j++)
					{
						if (mappings[j] != num8)
						{
							continue;
						}
						int num9 = i * bytesPerSample;
						int num10 = offset + j * bytesPerSample;
						int k;
						for (k = 0; k < num2; k++)
						{
							if (num9 >= num7)
							{
								break;
							}
							Array.Copy(inputBuffer, num9, buffer, num10, bytesPerSample);
							num10 += num;
							num9 += num5;
						}
						for (; k < num2; k++)
						{
							Array.Clear(buffer, num10, bytesPerSample);
							num10 += num;
						}
					}
				}
				num3 += input.WaveFormat.Channels;
			}
			return num4 * num;
		}

		/// <summary>
		/// Connects a specified input channel to an output channel
		/// </summary>
		/// <param name="inputChannel">Input Channel index (zero based). Must be less than InputChannelCount</param>
		/// <param name="outputChannel">Output Channel index (zero based). Must be less than OutputChannelCount</param>
		public void ConnectInputToOutput(int inputChannel, int outputChannel)
		{
			if (inputChannel < 0 || inputChannel >= InputChannelCount)
			{
				throw new ArgumentException("Invalid input channel");
			}
			if (outputChannel < 0 || outputChannel >= OutputChannelCount)
			{
				throw new ArgumentException("Invalid output channel");
			}
			mappings[outputChannel] = inputChannel;
		}
	}

	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	internal class OggWaveFormat : WaveFormat
	{
		public uint dwVorbisACMVersion;

		public uint dwLibVorbisVersion;
	}

	/// <summary>
	/// Playback State
	/// </summary>
	public enum PlaybackState
	{
		/// <summary>
		/// Stopped
		/// </summary>
		Stopped,
		/// <summary>
		/// Playing
		/// </summary>
		Playing,
		/// <summary>
		/// Paused
		/// </summary>
		Paused
	}

	/// <summary>
	/// WaveStream that simply passes on data from its source stream
	/// (e.g. a MemoryStream)
	/// </summary>
	public class RawSourceWaveStream : WaveStream
	{
		private readonly Stream sourceStream;

		private readonly WaveFormat waveFormat;

		/// <summary>
		/// The WaveFormat of this stream
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// The length in bytes of this stream (if supported)
		/// </summary>
		public override long Length => sourceStream.Length;

		/// <summary>
		/// The current position in this stream
		/// </summary>
		public override long Position
		{
			get
			{
				return sourceStream.Position;
			}
			set
			{
				sourceStream.Position = value - value % waveFormat.BlockAlign;
			}
		}

		/// <summary>
		/// Initialises a new instance of RawSourceWaveStream
		/// </summary>
		/// <param name="sourceStream">The source stream containing raw audio</param>
		/// <param name="waveFormat">The waveformat of the audio in the source stream</param>
		public RawSourceWaveStream(Stream sourceStream, WaveFormat waveFormat)
		{
			this.sourceStream = sourceStream;
			this.waveFormat = waveFormat;
		}

		/// <summary>
		/// Initialises a new instance of RawSourceWaveStream
		/// </summary>
		/// <param name="byteStream">The buffer containing raw audio</param>
		/// <param name="offset">Offset in the source buffer to read from</param>
		/// <param name="count">Number of bytes to read in the buffer</param>
		/// <param name="waveFormat">The waveformat of the audio in the source stream</param>
		public RawSourceWaveStream(byte[] byteStream, int offset, int count, WaveFormat waveFormat)
		{
			sourceStream = new MemoryStream(byteStream, offset, count);
			this.waveFormat = waveFormat;
		}

		/// <summary>
		/// Reads data from the stream
		/// </summary>
		public override int Read(byte[] buffer, int offset, int count)
		{
			try
			{
				return sourceStream.Read(buffer, offset, count);
			}
			catch (EndOfStreamException)
			{
				return 0;
			}
		}
	}

	/// <summary>
	/// Holds information about a RIFF file chunk
	/// </summary>
	public class RiffChunk
	{
		/// <summary>
		/// The chunk identifier
		/// </summary>
		public int Identifier { get; }

		/// <summary>
		/// The chunk identifier converted to a string
		/// </summary>
		public string IdentifierAsString => Encoding.UTF8.GetString(BitConverter.GetBytes(Identifier));

		/// <summary>
		/// The chunk length
		/// </summary>
		public int Length { get; private set; }

		/// <summary>
		/// The stream position this chunk is located at
		/// </summary>
		public long StreamPosition { get; private set; }

		/// <summary>
		/// Creates a RiffChunk object
		/// </summary>
		public RiffChunk(int identifier, int length, long streamPosition)
		{
			Identifier = identifier;
			Length = length;
			StreamPosition = streamPosition;
		}
	}

	/// <summary>
	/// Sample event arguments
	/// </summary>
	public class SampleEventArgs : EventArgs
	{
		/// <summary>
		/// Left sample
		/// </summary>
		public float Left { get; set; }

		/// <summary>
		/// Right sample
		/// </summary>
		public float Right { get; set; }

		/// <summary>
		/// Constructor
		/// </summary>
		public SampleEventArgs(float left, float right)
		{
			Left = left;
			Right = right;
		}
	}

	/// <summary>
	/// Silence producing wave provider
	/// Useful for playing silence when doing a WASAPI Loopback Capture
	/// </summary>
	public class SilenceProvider : IWaveProvider
	{
		/// <summary>
		/// WaveFormat of this silence producing wave provider
		/// </summary>
		public WaveFormat WaveFormat { get; private set; }

		/// <summary>
		/// Creates a new silence producing wave provider
		/// </summary>
		/// <param name="wf">Desired WaveFormat (should be PCM / IEE float</param>
		public SilenceProvider(WaveFormat wf)
		{
			WaveFormat = wf;
		}

		/// <summary>
		/// Read silence from into the buffer
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			Array.Clear(buffer, offset, count);
			return count;
		}
	}

	/// <summary>
	/// A simple compressor
	/// </summary>
	public class SimpleCompressorEffect : ISampleProvider
	{
		private readonly ISampleProvider sourceStream;

		private readonly SimpleCompressor simpleCompressor;

		private readonly int channels;

		private readonly object lockObject = new object();

		/// <summary>
		/// Make-up Gain
		/// </summary>
		public double MakeUpGain
		{
			get
			{
				return simpleCompressor.MakeUpGain;
			}
			set
			{
				lock (lockObject)
				{
					simpleCompressor.MakeUpGain = value;
				}
			}
		}

		/// <summary>
		/// Threshold
		/// </summary>
		public double Threshold
		{
			get
			{
				return simpleCompressor.Threshold;
			}
			set
			{
				lock (lockObject)
				{
					simpleCompressor.Threshold = value;
				}
			}
		}

		/// <summary>
		/// Ratio
		/// </summary>
		public double Ratio
		{
			get
			{
				return simpleCompressor.Ratio;
			}
			set
			{
				lock (lockObject)
				{
					simpleCompressor.Ratio = value;
				}
			}
		}

		/// <summary>
		/// Attack time
		/// </summary>
		public double Attack
		{
			get
			{
				return simpleCompressor.Attack;
			}
			set
			{
				lock (lockObject)
				{
					simpleCompressor.Attack = value;
				}
			}
		}

		/// <summary>
		/// Release time
		/// </summary>
		public double Release
		{
			get
			{
				return simpleCompressor.Release;
			}
			set
			{
				lock (lockObject)
				{
					simpleCompressor.Release = value;
				}
			}
		}

		/// <summary>
		/// Turns gain on or off
		/// </summary>
		public bool Enabled { get; set; }

		/// <summary>
		/// Gets the WaveFormat of this stream
		/// </summary>
		public WaveFormat WaveFormat => sourceStream.WaveFormat;

		/// <summary>
		/// Create a new simple compressor stream
		/// </summary>
		/// <param name="sourceStream">Source stream</param>
		public SimpleCompressorEffect(ISampleProvider sourceStream)
		{
			this.sourceStream = sourceStream;
			channels = sourceStream.WaveFormat.Channels;
			simpleCompressor = new SimpleCompressor(5.0, 10.0, sourceStream.WaveFormat.SampleRate);
			simpleCompressor.Threshold = 16.0;
			simpleCompressor.Ratio = 6.0;
			simpleCompressor.MakeUpGain = 16.0;
		}

		/// <summary>
		/// Reads bytes from this stream
		/// </summary>
		/// <param name="array">Buffer to read into</param>
		/// <param name="offset">Offset in array to read into</param>
		/// <param name="count">Number of bytes to read</param>
		/// <returns>Number of bytes read</returns>
		public int Read(float[] array, int offset, int count)
		{
			lock (lockObject)
			{
				int num = sourceStream.Read(array, offset, count);
				if (Enabled)
				{
					for (int i = 0; i < num; i += channels)
					{
						double @in = array[offset + i];
						double in2 = ((channels == 1) ? 0f : array[offset + i + 1]);
						simpleCompressor.Process(ref @in, ref in2);
						array[offset + i] = (float)@in;
						if (channels > 1)
						{
							array[offset + i + 1] = (float)in2;
						}
					}
				}
				return num;
			}
		}
	}

	/// <summary>
	/// Takes a stereo 16 bit input and turns it mono, allowing you to select left or right channel only or mix them together
	/// </summary>
	public class StereoToMonoProvider16 : IWaveProvider
	{
		private readonly IWaveProvider sourceProvider;

		private byte[] sourceBuffer;

		/// <summary>
		/// 1.0 to mix the mono source entirely to the left channel
		/// </summary>
		public float LeftVolume { get; set; }

		/// <summary>
		/// 1.0 to mix the mono source entirely to the right channel
		/// </summary>
		public float RightVolume { get; set; }

		/// <summary>
		/// Output Wave Format
		/// </summary>
		public WaveFormat WaveFormat { get; private set; }

		/// <summary>
		/// Creates a new mono waveprovider based on a stereo input
		/// </summary>
		/// <param name="sourceProvider">Stereo 16 bit PCM input</param>
		public StereoToMonoProvider16(IWaveProvider sourceProvider)
		{
			LeftVolume = 0.5f;
			RightVolume = 0.5f;
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm)
			{
				throw new ArgumentException("Source must be PCM");
			}
			if (sourceProvider.WaveFormat.Channels != 2)
			{
				throw new ArgumentException("Source must be stereo");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 16)
			{
				throw new ArgumentException("Source must be 16 bit");
			}
			this.sourceProvider = sourceProvider;
			WaveFormat = new WaveFormat(sourceProvider.WaveFormat.SampleRate, 1);
		}

		/// <summary>
		/// Reads bytes from this WaveProvider
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = count * 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			WaveBuffer waveBuffer = new WaveBuffer(sourceBuffer);
			WaveBuffer waveBuffer2 = new WaveBuffer(buffer);
			int num2 = sourceProvider.Read(sourceBuffer, 0, num);
			int num3 = num2 / 2;
			int num4 = offset / 2;
			for (int i = 0; i < num3; i += 2)
			{
				short num5 = waveBuffer.ShortBuffer[i];
				short num6 = waveBuffer.ShortBuffer[i + 1];
				float num7 = (float)num5 * LeftVolume + (float)num6 * RightVolume;
				if (num7 > 32767f)
				{
					num7 = 32767f;
				}
				if (num7 < -32768f)
				{
					num7 = -32768f;
				}
				waveBuffer2.ShortBuffer[num4++] = (short)num7;
			}
			return num2 / 2;
		}
	}

	/// <summary>
	/// Stopped Event Args
	/// </summary>
	public class StoppedEventArgs : EventArgs
	{
		private readonly Exception exception;

		/// <summary>
		/// An exception. Will be null if the playback or record operation stopped due to 
		/// the user requesting stop or reached the end of the input audio
		/// </summary>
		public Exception Exception => exception;

		/// <summary>
		/// Initializes a new instance of StoppedEventArgs
		/// </summary>
		/// <param name="exception">An exception to report (null if no exception)</param>
		public StoppedEventArgs(Exception exception = null)
		{
			this.exception = exception;
		}
	}

	/// <summary>
	/// DSP Group TrueSpeech
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class TrueSpeechWaveFormat : WaveFormat
	{
		[MarshalAs(UnmanagedType.ByValArray, SizeConst = 16)]
		private short[] unknown;

		/// <summary>
		/// DSP Group TrueSpeech WaveFormat
		/// </summary>
		public TrueSpeechWaveFormat()
		{
			waveFormatTag = WaveFormatEncoding.DspGroupTrueSpeech;
			channels = 1;
			averageBytesPerSecond = 1067;
			bitsPerSample = 1;
			blockAlign = 32;
			sampleRate = 8000;
			extraSize = 32;
			unknown = new short[16];
			unknown[0] = 1;
			unknown[1] = 240;
		}

		/// <summary>
		/// Writes this structure to a BinaryWriter
		/// </summary>
		public override void Serialize(BinaryWriter writer)
		{
			base.Serialize(writer);
			short[] array = unknown;
			foreach (short value in array)
			{
				writer.Write(value);
			}
		}
	}

	/// <summary>
	/// Helper class allowing us to modify the volume of a 16 bit stream without converting to IEEE float
	/// </summary>
	public class VolumeWaveProvider16 : IWaveProvider
	{
		private readonly IWaveProvider sourceProvider;

		private float volume;

		/// <summary>
		/// Gets or sets volume. 
		/// 1.0 is full scale, 0.0 is silence, anything over 1.0 will amplify but potentially clip
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// WaveFormat of this WaveProvider
		/// </summary>
		public WaveFormat WaveFormat => sourceProvider.WaveFormat;

		/// <summary>
		/// Constructs a new VolumeWaveProvider16
		/// </summary>
		/// <param name="sourceProvider">Source provider, must be 16 bit PCM</param>
		public VolumeWaveProvider16(IWaveProvider sourceProvider)
		{
			Volume = 1f;
			this.sourceProvider = sourceProvider;
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm)
			{
				throw new ArgumentException("Expecting PCM input");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 16)
			{
				throw new ArgumentException("Expecting 16 bit");
			}
		}

		/// <summary>
		/// Read bytes from this WaveProvider
		/// </summary>
		/// <param name="buffer">Buffer to read into</param>
		/// <param name="offset">Offset within buffer to read to</param>
		/// <param name="count">Bytes desired</param>
		/// <returns>Bytes read</returns>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = sourceProvider.Read(buffer, offset, count);
			if (volume == 0f)
			{
				for (int i = 0; i < num; i++)
				{
					buffer[offset++] = 0;
				}
			}
			else if (volume != 1f)
			{
				for (int j = 0; j < num; j += 2)
				{
					short num2 = (short)((buffer[offset + 1] << 8) | buffer[offset]);
					float num3 = (float)num2 * volume;
					num2 = (short)num3;
					if (Volume > 1f)
					{
						if (num3 > 32767f)
						{
							num2 = short.MaxValue;
						}
						else if (num3 < -32768f)
						{
							num2 = short.MinValue;
						}
					}
					buffer[offset++] = (byte)((uint)num2 & 0xFFu);
					buffer[offset++] = (byte)(num2 >> 8);
				}
			}
			return num;
		}
	}

	/// <summary>
	/// Converts 16 bit PCM to IEEE float, optionally adjusting volume along the way
	/// </summary>
	public class Wave16ToFloatProvider : IWaveProvider
	{
		private IWaveProvider sourceProvider;

		private readonly WaveFormat waveFormat;

		private volatile float volume;

		private byte[] sourceBuffer;

		/// <summary>
		/// <see cref="P:NAudio.Wave.IWaveProvider.WaveFormat" />
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Volume of this channel. 1.0 = full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// Creates a new Wave16toFloatProvider
		/// </summary>
		/// <param name="sourceProvider">the source provider</param>
		public Wave16ToFloatProvider(IWaveProvider sourceProvider)
		{
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm)
			{
				throw new ArgumentException("Only PCM supported");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 16)
			{
				throw new ArgumentException("Only 16 bit audio supported");
			}
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sourceProvider.WaveFormat.SampleRate, sourceProvider.WaveFormat.Channels);
			this.sourceProvider = sourceProvider;
			volume = 1f;
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public int Read(byte[] destBuffer, int offset, int numBytes)
		{
			int num = numBytes / 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			int num2 = sourceProvider.Read(sourceBuffer, offset, num);
			WaveBuffer waveBuffer = new WaveBuffer(sourceBuffer);
			WaveBuffer waveBuffer2 = new WaveBuffer(destBuffer);
			int num3 = num2 / 2;
			int num4 = offset / 4;
			for (int i = 0; i < num3; i++)
			{
				waveBuffer2.FloatBuffer[num4++] = (float)waveBuffer.ShortBuffer[i] / 32768f * volume;
			}
			return num3 * 4;
		}
	}

	/// <summary>
	/// WaveStream that converts 32 bit audio back down to 16 bit, clipping if necessary
	/// </summary>
	public class Wave32To16Stream : WaveStream
	{
		private WaveStream sourceStream;

		private readonly WaveFormat waveFormat;

		private readonly long length;

		private long position;

		private bool clip;

		private float volume;

		private readonly object lockObject = new object();

		/// <summary>
		/// The <see cref="M:NAudio.Wave.Wave32To16Stream.Read(System.Byte[],System.Int32,System.Int32)" /> method reuses the same buffer to prevent
		/// unnecessary allocations.
		/// </summary>
		private byte[] sourceBuffer;

		/// <summary>
		/// Sets the volume for this stream. 1.0f is full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.BlockAlign" />
		/// </summary>
		public override int BlockAlign => sourceStream.BlockAlign / 2;

		/// <summary>
		/// Returns the stream length
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Gets or sets the current position in the stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (lockObject)
				{
					value -= value % BlockAlign;
					sourceStream.Position = value * 2;
					position = value;
				}
			}
		}

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Clip indicator. Can be reset.
		/// </summary>
		public bool Clip
		{
			get
			{
				return clip;
			}
			set
			{
				clip = value;
			}
		}

		/// <summary>
		/// Creates a new Wave32To16Stream
		/// </summary>
		/// <param name="sourceStream">the source stream</param>
		public Wave32To16Stream(WaveStream sourceStream)
		{
			if (sourceStream.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Only 32 bit Floating point supported");
			}
			if (sourceStream.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Only 32 bit Floating point supported");
			}
			waveFormat = new WaveFormat(sourceStream.WaveFormat.SampleRate, 16, sourceStream.WaveFormat.Channels);
			volume = 1f;
			this.sourceStream = sourceStream;
			length = sourceStream.Length / 2;
			position = sourceStream.Position / 2;
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">Destination buffer</param>
		/// <param name="offset">Offset into destination buffer</param>
		/// <param name="numBytes"></param>
		/// <returns>Number of bytes read.</returns>
		public override int Read(byte[] destBuffer, int offset, int numBytes)
		{
			lock (lockObject)
			{
				int num = numBytes * 2;
				sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
				int num2 = sourceStream.Read(sourceBuffer, 0, num);
				Convert32To16(destBuffer, offset, sourceBuffer, num2);
				position += num2 / 2;
				return num2 / 2;
			}
		}

		/// <summary>
		/// Conversion to 16 bit and clipping
		/// </summary>
		private unsafe void Convert32To16(byte[] destBuffer, int offset, byte[] source, int bytesRead)
		{
			fixed (byte* ptr = &destBuffer[offset])
			{
				fixed (byte* ptr3 = &source[0])
				{
					short* ptr2 = (short*)ptr;
					float* ptr4 = (float*)ptr3;
					int num = bytesRead / 4;
					for (int i = 0; i < num; i++)
					{
						float num2 = ptr4[i] * volume;
						if (num2 > 1f)
						{
							ptr2[i] = short.MaxValue;
							clip = true;
						}
						else if (num2 < -1f)
						{
							ptr2[i] = short.MinValue;
							clip = true;
						}
						else
						{
							ptr2[i] = (short)(num2 * 32767f);
						}
					}
				}
			}
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && sourceStream != null)
			{
				sourceStream.Dispose();
				sourceStream = null;
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// WaveBuffer class use to store wave datas. Data can be manipulated with arrays
	/// (<see cref="P:NAudio.Wave.WaveBuffer.ByteBuffer" />,<see cref="P:NAudio.Wave.WaveBuffer.FloatBuffer" />,<see cref="P:NAudio.Wave.WaveBuffer.ShortBuffer" />,<see cref="P:NAudio.Wave.WaveBuffer.IntBuffer" /> ) that are pointing to the
	/// same memory buffer. Use the associated Count property based on the type of buffer to get the number of 
	/// data in the buffer.
	/// Implicit casting is now supported to float[], byte[], int[], short[].
	/// You must not use Length on returned arrays.
	///
	/// n.b. FieldOffset is 8 now to allow it to work natively on 64 bit
	/// </summary>
	[StructLayout(LayoutKind.Explicit, Pack = 2)]
	public class WaveBuffer : IWaveBuffer
	{
		/// <summary>
		/// Number of Bytes
		/// </summary>
		[FieldOffset(0)]
		public int numberOfBytes;

		[FieldOffset(8)]
		private byte[] byteBuffer;

		[FieldOffset(8)]
		private float[] floatBuffer;

		[FieldOffset(8)]
		private short[] shortBuffer;

		[FieldOffset(8)]
		private int[] intBuffer;

		/// <summary>
		/// Gets the byte buffer.
		/// </summary>
		/// <value>The byte buffer.</value>
		public byte[] ByteBuffer => byteBuffer;

		/// <summary>
		/// Gets the float buffer.
		/// </summary>
		/// <value>The float buffer.</value>
		public float[] FloatBuffer => floatBuffer;

		/// <summary>
		/// Gets the short buffer.
		/// </summary>
		/// <value>The short buffer.</value>
		public short[] ShortBuffer => shortBuffer;

		/// <summary>
		/// Gets the int buffer.
		/// </summary>
		/// <value>The int buffer.</value>
		public int[] IntBuffer => intBuffer;

		/// <summary>
		/// Gets the max size in bytes of the byte buffer..
		/// </summary>
		/// <value>Maximum number of bytes in the buffer.</value>
		public int MaxSize => byteBuffer.Length;

		/// <summary>
		/// Gets or sets the byte buffer count.
		/// </summary>
		/// <value>The byte buffer count.</value>
		public int ByteBufferCount
		{
			get
			{
				return numberOfBytes;
			}
			set
			{
				numberOfBytes = CheckValidityCount("ByteBufferCount", value, 1);
			}
		}

		/// <summary>
		/// Gets or sets the float buffer count.
		/// </summary>
		/// <value>The float buffer count.</value>
		public int FloatBufferCount
		{
			get
			{
				return numberOfBytes / 4;
			}
			set
			{
				numberOfBytes = CheckValidityCount("FloatBufferCount", value, 4);
			}
		}

		/// <summary>
		/// Gets or sets the short buffer count.
		/// </summary>
		/// <value>The short buffer count.</value>
		public int ShortBufferCount
		{
			get
			{
				return numberOfBytes / 2;
			}
			set
			{
				numberOfBytes = CheckValidityCount("ShortBufferCount", value, 2);
			}
		}

		/// <summary>
		/// Gets or sets the int buffer count.
		/// </summary>
		/// <value>The int buffer count.</value>
		public int IntBufferCount
		{
			get
			{
				return numberOfBytes / 4;
			}
			set
			{
				numberOfBytes = CheckValidityCount("IntBufferCount", value, 4);
			}
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.WaveBuffer" /> class.
		/// </summary>
		/// <param name="sizeToAllocateInBytes">The number of bytes. The size of the final buffer will be aligned on 4 Bytes (upper bound)</param>
		public WaveBuffer(int sizeToAllocateInBytes)
		{
			int num = sizeToAllocateInBytes % 4;
			sizeToAllocateInBytes = ((num == 0) ? sizeToAllocateInBytes : (sizeToAllocateInBytes + 4 - num));
			byteBuffer = new byte[sizeToAllocateInBytes];
			numberOfBytes = 0;
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.Wave.WaveBuffer" /> class binded to a specific byte buffer.
		/// </summary>
		/// <param name="bufferToBoundTo">A byte buffer to bound the WaveBuffer to.</param>
		public WaveBuffer(byte[] bufferToBoundTo)
		{
			BindTo(bufferToBoundTo);
		}

		/// <summary>
		/// Binds this WaveBuffer instance to a specific byte buffer.
		/// </summary>
		/// <param name="bufferToBoundTo">A byte buffer to bound the WaveBuffer to.</param>
		public void BindTo(byte[] bufferToBoundTo)
		{
			byteBuffer = bufferToBoundTo;
			numberOfBytes = 0;
		}

		/// <summary>
		/// Performs an implicit conversion from <see cref="T:NAudio.Wave.WaveBuffer" /> to <see cref="T:System.Byte" />.
		/// </summary>
		/// <param name="waveBuffer">The wave buffer.</param>
		/// <returns>The result of the conversion.</returns>
		public static implicit operator byte[](WaveBuffer waveBuffer)
		{
			return waveBuffer.byteBuffer;
		}

		/// <summary>
		/// Performs an implicit conversion from <see cref="T:NAudio.Wave.WaveBuffer" /> to <see cref="T:System.Single" />.
		/// </summary>
		/// <param name="waveBuffer">The wave buffer.</param>
		/// <returns>The result of the conversion.</returns>
		public static implicit operator float[](WaveBuffer waveBuffer)
		{
			return waveBuffer.floatBuffer;
		}

		/// <summary>
		/// Performs an implicit conversion from <see cref="T:NAudio.Wave.WaveBuffer" /> to <see cref="T:System.Int32" />.
		/// </summary>
		/// <param name="waveBuffer">The wave buffer.</param>
		/// <returns>The result of the conversion.</returns>
		public static implicit operator int[](WaveBuffer waveBuffer)
		{
			return waveBuffer.intBuffer;
		}

		/// <summary>
		/// Performs an implicit conversion from <see cref="T:NAudio.Wave.WaveBuffer" /> to <see cref="T:System.Int16" />.
		/// </summary>
		/// <param name="waveBuffer">The wave buffer.</param>
		/// <returns>The result of the conversion.</returns>
		public static implicit operator short[](WaveBuffer waveBuffer)
		{
			return waveBuffer.shortBuffer;
		}

		/// <summary>
		/// Clears the associated buffer.
		/// </summary>
		public void Clear()
		{
			Array.Clear(byteBuffer, 0, byteBuffer.Length);
		}

		/// <summary>
		/// Copy this WaveBuffer to a destination buffer up to ByteBufferCount bytes.
		/// </summary>
		public void Copy(Array destinationArray)
		{
			Array.Copy(byteBuffer, destinationArray, numberOfBytes);
		}

		/// <summary>
		/// Checks the validity of the count parameters.
		/// </summary>
		/// <param name="argName">Name of the arg.</param>
		/// <param name="value">The value.</param>
		/// <param name="sizeOfValue">The size of value.</param>
		private int CheckValidityCount(string argName, int value, int sizeOfValue)
		{
			int num = value * sizeOfValue;
			if (num % 4 != 0)
			{
				throw new ArgumentOutOfRangeException(argName, $"{argName} cannot set a count ({num}) that is not 4 bytes aligned ");
			}
			if (value < 0 || value > byteBuffer.Length / sizeOfValue)
			{
				throw new ArgumentOutOfRangeException(argName, $"{argName} cannot set a count that exceed max count {byteBuffer.Length / sizeOfValue}");
			}
			return num;
		}
	}

	/// <summary>
	/// Represents Channel for the WaveMixerStream
	/// 32 bit output and 16 bit input
	/// It's output is always stereo
	/// The input stream can be panned
	/// </summary>
	public class WaveChannel32 : WaveStream, ISampleNotifier
	{
		private WaveStream sourceStream;

		private readonly WaveFormat waveFormat;

		private readonly long length;

		private readonly int destBytesPerSample;

		private readonly int sourceBytesPerSample;

		private volatile float volume;

		private volatile float pan;

		private long position;

		private readonly ISampleChunkConverter sampleProvider;

		private readonly object lockObject = new object();

		private SampleEventArgs sampleEventArgs = new SampleEventArgs(0f, 0f);

		/// <summary>
		/// Gets the block alignment for this WaveStream
		/// </summary>
		public override int BlockAlign => (int)SourceToDest(sourceStream.BlockAlign);

		/// <summary>
		/// Returns the stream length
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Gets or sets the current position in the stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (lockObject)
				{
					value -= value % BlockAlign;
					if (value < 0)
					{
						sourceStream.Position = 0L;
					}
					else
					{
						sourceStream.Position = DestToSource(value);
					}
					position = SourceToDest(sourceStream.Position);
				}
			}
		}

		/// <summary>
		/// If true, Read always returns the number of bytes requested
		/// </summary>
		public bool PadWithZeroes { get; set; }

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Volume of this channel. 1.0 = full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// Pan of this channel (from -1 to 1)
		/// </summary>
		public float Pan
		{
			get
			{
				return pan;
			}
			set
			{
				pan = value;
			}
		}

		/// <summary>
		/// Sample
		/// </summary>
		public event EventHandler<SampleEventArgs> Sample;

		/// <summary>
		/// Creates a new WaveChannel32
		/// </summary>
		/// <param name="sourceStream">the source stream</param>
		/// <param name="volume">stream volume (1 is 0dB)</param>
		/// <param name="pan">pan control (-1 to 1)</param>
		public WaveChannel32(WaveStream sourceStream, float volume, float pan)
		{
			PadWithZeroes = true;
			ISampleChunkConverter[] array = new ISampleChunkConverter[8]
			{
				new Mono8SampleChunkConverter(),
				new Stereo8SampleChunkConverter(),
				new Mono16SampleChunkConverter(),
				new Stereo16SampleChunkConverter(),
				new Mono24SampleChunkConverter(),
				new Stereo24SampleChunkConverter(),
				new MonoFloatSampleChunkConverter(),
				new StereoFloatSampleChunkConverter()
			};
			foreach (ISampleChunkConverter sampleChunkConverter in array)
			{
				if (sampleChunkConverter.Supports(sourceStream.WaveFormat))
				{
					sampleProvider = sampleChunkConverter;
					break;
				}
			}
			if (sampleProvider == null)
			{
				throw new ArgumentException("Unsupported sourceStream format");
			}
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sourceStream.WaveFormat.SampleRate, 2);
			destBytesPerSample = 8;
			this.sourceStream = sourceStream;
			this.volume = volume;
			this.pan = pan;
			sourceBytesPerSample = sourceStream.WaveFormat.Channels * sourceStream.WaveFormat.BitsPerSample / 8;
			length = SourceToDest(sourceStream.Length);
			position = 0L;
		}

		private long SourceToDest(long sourceBytes)
		{
			return sourceBytes / sourceBytesPerSample * destBytesPerSample;
		}

		private long DestToSource(long destBytes)
		{
			return destBytes / destBytesPerSample * sourceBytesPerSample;
		}

		/// <summary>
		/// Creates a WaveChannel32 with default settings
		/// </summary>
		/// <param name="sourceStream">The source stream</param>
		public WaveChannel32(WaveStream sourceStream)
			: this(sourceStream, 1f, 0f)
		{
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public override int Read(byte[] destBuffer, int offset, int numBytes)
		{
			lock (lockObject)
			{
				int num = 0;
				WaveBuffer waveBuffer = new WaveBuffer(destBuffer);
				if (position < 0)
				{
					num = (int)Math.Min(numBytes, -position);
					for (int i = 0; i < num; i++)
					{
						destBuffer[i + offset] = 0;
					}
				}
				if (num < numBytes)
				{
					sampleProvider.LoadNextChunk(sourceStream, (numBytes - num) / 8);
					int num2 = offset / 4 + num / 4;
					float sampleLeft;
					float sampleRight;
					while (sampleProvider.GetNextSample(out sampleLeft, out sampleRight) && num < numBytes)
					{
						sampleLeft = ((pan <= 0f) ? sampleLeft : (sampleLeft * (1f - pan) / 2f));
						sampleRight = ((pan >= 0f) ? sampleRight : (sampleRight * (pan + 1f) / 2f));
						sampleLeft *= volume;
						sampleRight *= volume;
						waveBuffer.FloatBuffer[num2++] = sampleLeft;
						waveBuffer.FloatBuffer[num2++] = sampleRight;
						num += 8;
						if (this.Sample != null)
						{
							RaiseSample(sampleLeft, sampleRight);
						}
					}
				}
				if (PadWithZeroes && num < numBytes)
				{
					Array.Clear(destBuffer, offset + num, numBytes - num);
					num = numBytes;
				}
				position += num;
				return num;
			}
		}

		/// <summary>
		/// Determines whether this channel has any data to play
		/// to allow optimisation to not read, but bump position forward
		/// </summary>
		public override bool HasData(int count)
		{
			if (sourceStream.HasData(count))
			{
				if (position + count < 0)
				{
					return false;
				}
				if (position < length)
				{
					return volume != 0f;
				}
				return false;
			}
			return false;
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && sourceStream != null)
			{
				sourceStream.Dispose();
				sourceStream = null;
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Raise the sample event (no check for null because it has already been done)
		/// </summary>
		private void RaiseSample(float left, float right)
		{
			sampleEventArgs.Left = left;
			sampleEventArgs.Right = right;
			this.Sample(this, sampleEventArgs);
		}
	}

	/// <summary>
	/// Useful extension methods to make switching between WaveAndSampleProvider easier
	/// </summary>
	public static class WaveExtensionMethods
	{
		/// <summary>
		/// Converts a WaveProvider into a SampleProvider (only works for PCM)
		/// </summary>
		/// <param name="waveProvider">WaveProvider to convert</param>
		/// <returns></returns>
		public static ISampleProvider ToSampleProvider(this IWaveProvider waveProvider)
		{
			return SampleProviderConverters.ConvertWaveProviderIntoSampleProvider(waveProvider);
		}

		/// <summary>
		/// Allows sending a SampleProvider directly to an IWavePlayer without needing to convert
		/// back to an IWaveProvider
		/// </summary>
		/// <param name="wavePlayer">The WavePlayer</param>
		/// <param name="sampleProvider"></param>
		/// <param name="convertTo16Bit"></param>
		public static void Init(this IWavePlayer wavePlayer, ISampleProvider sampleProvider, bool convertTo16Bit = false)
		{
			IWaveProvider waveProvider2;
			if (!convertTo16Bit)
			{
				IWaveProvider waveProvider = new SampleToWaveProvider(sampleProvider);
				waveProvider2 = waveProvider;
			}
			else
			{
				IWaveProvider waveProvider = new SampleToWaveProvider16(sampleProvider);
				waveProvider2 = waveProvider;
			}
			IWaveProvider waveProvider3 = waveProvider2;
			wavePlayer.Init(waveProvider3);
		}

		/// <summary>
		/// Turns WaveFormatExtensible into a standard waveformat if possible
		/// </summary>
		/// <param name="waveFormat">Input wave format</param>
		/// <returns>A standard PCM or IEEE waveformat, or the original waveformat</returns>
		public static WaveFormat AsStandardWaveFormat(this WaveFormat waveFormat)
		{
			if (!(waveFormat is WaveFormatExtensible waveFormatExtensible))
			{
				return waveFormat;
			}
			return waveFormatExtensible.ToStandardWaveFormat();
		}

		/// <summary>
		/// Converts a ISampleProvider to a IWaveProvider but still 32 bit float
		/// </summary>
		/// <param name="sampleProvider">SampleProvider to convert</param>
		/// <returns>An IWaveProvider</returns>
		public static IWaveProvider ToWaveProvider(this ISampleProvider sampleProvider)
		{
			return new SampleToWaveProvider(sampleProvider);
		}

		/// <summary>
		/// Converts a ISampleProvider to a IWaveProvider but and convert to 16 bit
		/// </summary>
		/// <param name="sampleProvider">SampleProvider to convert</param>
		/// <returns>A 16 bit IWaveProvider</returns>
		public static IWaveProvider ToWaveProvider16(this ISampleProvider sampleProvider)
		{
			return new SampleToWaveProvider16(sampleProvider);
		}

		/// <summary>
		/// Concatenates one Sample Provider on the end of another
		/// </summary>
		/// <param name="sampleProvider">The sample provider to play first</param>
		/// <param name="next">The sample provider to play next</param>
		/// <returns>A single sampleprovider to play one after the other</returns>
		public static ISampleProvider FollowedBy(this ISampleProvider sampleProvider, ISampleProvider next)
		{
			return new ConcatenatingSampleProvider(new ISampleProvider[2] { sampleProvider, next });
		}

		/// <summary>
		/// Concatenates one Sample Provider on the end of another with silence inserted
		/// </summary>
		/// <param name="sampleProvider">The sample provider to play first</param>
		/// <param name="silenceDuration">Silence duration to insert between the two</param>
		/// <param name="next">The sample provider to play next</param>
		/// <returns>A single sample provider</returns>
		public static ISampleProvider FollowedBy(this ISampleProvider sampleProvider, TimeSpan silenceDuration, ISampleProvider next)
		{
			OffsetSampleProvider offsetSampleProvider = new OffsetSampleProvider(sampleProvider)
			{
				LeadOut = silenceDuration
			};
			return new ConcatenatingSampleProvider(new ISampleProvider[2] { offsetSampleProvider, next });
		}

		/// <summary>
		/// Skips over a specified amount of time (by consuming source stream)
		/// </summary>
		/// <param name="sampleProvider">Source sample provider</param>
		/// <param name="skipDuration">Duration to skip over</param>
		/// <returns>A sample provider that skips over the specified amount of time</returns>
		public static ISampleProvider Skip(this ISampleProvider sampleProvider, TimeSpan skipDuration)
		{
			return new OffsetSampleProvider(sampleProvider)
			{
				SkipOver = skipDuration
			};
		}

		/// <summary>
		/// Takes a specified amount of time from the source stream
		/// </summary>
		/// <param name="sampleProvider">Source sample provider</param>
		/// <param name="takeDuration">Duration to take</param>
		/// <returns>A sample provider that reads up to the specified amount of time</returns>
		public static ISampleProvider Take(this ISampleProvider sampleProvider, TimeSpan takeDuration)
		{
			return new OffsetSampleProvider(sampleProvider)
			{
				Take = takeDuration
			};
		}

		/// <summary>
		/// Converts a Stereo Sample Provider to mono, allowing mixing of channel volume
		/// </summary>
		/// <param name="sourceProvider">Stereo Source Provider</param>
		/// <param name="leftVol">Amount of left channel to mix in (0 = mute, 1 = full, 0.5 for mixing half from each channel)</param>
		/// <param name="rightVol">Amount of right channel to mix in (0 = mute, 1 = full, 0.5 for mixing half from each channel)</param>
		/// <returns>A mono SampleProvider</returns>
		public static ISampleProvider ToMono(this ISampleProvider sourceProvider, float leftVol = 0.5f, float rightVol = 0.5f)
		{
			if (sourceProvider.WaveFormat.Channels == 1)
			{
				return sourceProvider;
			}
			return new StereoToMonoSampleProvider(sourceProvider)
			{
				LeftVolume = leftVol,
				RightVolume = rightVol
			};
		}

		/// <summary>
		/// Converts a Mono ISampleProvider to stereo
		/// </summary>
		/// <param name="sourceProvider">Mono Source Provider</param>
		/// <param name="leftVol">Amount to mix to left channel (1.0 is full volume)</param>
		/// <param name="rightVol">Amount to mix to right channel (1.0 is full volume)</param>
		/// <returns></returns>
		public static ISampleProvider ToStereo(this ISampleProvider sourceProvider, float leftVol = 1f, float rightVol = 1f)
		{
			if (sourceProvider.WaveFormat.Channels == 2)
			{
				return sourceProvider;
			}
			return new MonoToStereoSampleProvider(sourceProvider)
			{
				LeftVolume = leftVol,
				RightVolume = rightVol
			};
		}
	}

	/// <summary>This class supports the reading of WAV files,
	/// providing a repositionable WaveStream that returns the raw data
	/// contained in the WAV file
	/// </summary>
	public class WaveFileReader : WaveStream
	{
		private readonly WaveFormat waveFormat;

		private readonly bool ownInput;

		private readonly long dataPosition;

		private readonly long dataChunkLength;

		private readonly object lockObject = new object();

		private Stream waveStream;

		/// <summary>
		/// Gets a list of the additional chunks found in this file
		/// </summary>
		public List<RiffChunk> ExtraChunks { get; }

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// This is the length of audio data contained in this WAV file, in bytes
		/// (i.e. the byte length of the data chunk, not the length of the WAV file itself)
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override long Length => dataChunkLength;

		/// <summary>
		/// Number of Sample Frames  (if possible to calculate)
		/// This currently does not take into account number of channels
		/// Multiply number of channels if you want the total number of samples
		/// </summary>
		public long SampleCount
		{
			get
			{
				if (waveFormat.Encoding == WaveFormatEncoding.Pcm || waveFormat.Encoding == WaveFormatEncoding.Extensible || waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
				{
					return dataChunkLength / BlockAlign;
				}
				throw new InvalidOperationException("Sample count is calculated only for the standard encodings");
			}
		}

		/// <summary>
		/// Position in the WAV data chunk.
		/// <see cref="P:System.IO.Stream.Position" />
		/// </summary>
		public override long Position
		{
			get
			{
				return waveStream.Position - dataPosition;
			}
			set
			{
				lock (lockObject)
				{
					value = Math.Min(value, Length);
					value -= value % waveFormat.BlockAlign;
					waveStream.Position = value + dataPosition;
				}
			}
		}

		/// <summary>Supports opening a WAV file</summary>
		/// <remarks>The WAV file format is a real mess, but we will only
		/// support the basic WAV file format which actually covers the vast
		/// majority of WAV files out there. For more WAV file format information
		/// visit www.wotsit.org. If you have a WAV file that can't be read by
		/// this class, email it to the NAudio project and we will probably
		/// fix this reader to support it
		/// </remarks>
		public WaveFileReader(string waveFile)
			: this(File.OpenRead(waveFile), ownInput: true)
		{
		}

		/// <summary>
		/// Creates a Wave File Reader based on an input stream
		/// </summary>
		/// <param name="inputStream">The input stream containing a WAV file including header</param>
		public WaveFileReader(Stream inputStream)
			: this(inputStream, ownInput: false)
		{
		}

		private WaveFileReader(Stream inputStream, bool ownInput)
		{
			waveStream = inputStream;
			WaveFileChunkReader waveFileChunkReader = new WaveFileChunkReader();
			try
			{
				waveFileChunkReader.ReadWaveHeader(inputStream);
				waveFormat = waveFileChunkReader.WaveFormat;
				dataPosition = waveFileChunkReader.DataChunkPosition;
				dataChunkLength = waveFileChunkReader.DataChunkLength;
				ExtraChunks = waveFileChunkReader.RiffChunks;
			}
			catch
			{
				if (ownInput)
				{
					inputStream.Dispose();
				}
				throw;
			}
			Position = 0L;
			this.ownInput = ownInput;
		}

		/// <summary>
		/// Gets the data for the specified chunk
		/// </summary>
		public byte[] GetChunkData(RiffChunk chunk)
		{
			long position = waveStream.Position;
			waveStream.Position = chunk.StreamPosition;
			byte[] array = new byte[chunk.Length];
			waveStream.Read(array, 0, array.Length);
			waveStream.Position = position;
			return array;
		}

		/// <summary>
		/// Cleans up the resources associated with this WaveFileReader
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && waveStream != null)
			{
				if (ownInput)
				{
					waveStream.Dispose();
				}
				waveStream = null;
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Reads bytes from the Wave File
		/// <see cref="M:System.IO.Stream.Read(System.Byte[],System.Int32,System.Int32)" />
		/// </summary>
		public override int Read(byte[] array, int offset, int count)
		{
			if (count % waveFormat.BlockAlign != 0)
			{
				throw new ArgumentException($"Must read complete blocks: requested {count}, block align is {WaveFormat.BlockAlign}");
			}
			lock (lockObject)
			{
				if (Position + count > dataChunkLength)
				{
					count = (int)(dataChunkLength - Position);
				}
				return waveStream.Read(array, offset, count);
			}
		}

		/// <summary>
		/// Attempts to read the next sample or group of samples as floating point normalised into the range -1.0f to 1.0f
		/// </summary>
		/// <returns>An array of samples, 1 for mono, 2 for stereo etc. Null indicates end of file reached
		/// </returns>
		public float[] ReadNextSampleFrame()
		{
			WaveFormatEncoding encoding = waveFormat.Encoding;
			if (encoding != WaveFormatEncoding.Pcm && encoding != WaveFormatEncoding.IeeeFloat && encoding != WaveFormatEncoding.Extensible)
			{
				throw new InvalidOperationException("Only 16, 24 or 32 bit PCM or IEEE float audio data supported");
			}
			float[] array = new float[waveFormat.Channels];
			int num = waveFormat.Channels * (waveFormat.BitsPerSample / 8);
			byte[] array2 = new byte[num];
			int num2 = Read(array2, 0, num);
			if (num2 == 0)
			{
				return null;
			}
			if (num2 < num)
			{
				throw new InvalidDataException("Unexpected end of file");
			}
			int num3 = 0;
			for (int i = 0; i < waveFormat.Channels; i++)
			{
				if (waveFormat.BitsPerSample == 16)
				{
					array[i] = (float)BitConverter.ToInt16(array2, num3) / 32768f;
					num3 += 2;
					continue;
				}
				if (waveFormat.BitsPerSample == 24)
				{
					array[i] = (float)(((sbyte)array2[num3 + 2] << 16) | (array2[num3 + 1] << 8) | array2[num3]) / 8388608f;
					num3 += 3;
					continue;
				}
				if (waveFormat.BitsPerSample == 32 && waveFormat.Encoding == WaveFormatEncoding.IeeeFloat)
				{
					array[i] = BitConverter.ToSingle(array2, num3);
					num3 += 4;
					continue;
				}
				if (waveFormat.BitsPerSample == 32)
				{
					array[i] = (float)BitConverter.ToInt32(array2, num3) / 2.1474836E+09f;
					num3 += 4;
					continue;
				}
				throw new InvalidOperationException("Unsupported bit depth");
			}
			return array;
		}

		/// <summary>
		/// Attempts to read a sample into a float. n.b. only applicable for uncompressed formats
		/// Will normalise the value read into the range -1.0f to 1.0f if it comes from a PCM encoding
		/// </summary>
		/// <returns>False if the end of the WAV data chunk was reached</returns>
		[Obsolete("Use ReadNextSampleFrame instead (this version does not support stereo properly)")]
		public bool TryReadFloat(out float sampleValue)
		{
			float[] array = ReadNextSampleFrame();
			sampleValue = ((array != null) ? array[0] : 0f);
			return array != null;
		}
	}

	/// <summary>
	/// This class writes WAV data to a .wav file on disk
	/// </summary>
	public class WaveFileWriter : Stream
	{
		private Stream outStream;

		private readonly BinaryWriter writer;

		private long dataSizePos;

		private long factSampleCountPos;

		private long dataChunkSize;

		private readonly WaveFormat format;

		private readonly string filename;

		private readonly byte[] value24 = new byte[3];

		/// <summary>
		/// The wave file name or null if not applicable
		/// </summary>
		public string Filename => filename;

		/// <summary>
		/// Number of bytes of audio in the data chunk
		/// </summary>
		public override long Length => dataChunkSize;

		/// <summary>
		/// Total time (calculated from Length and average bytes per second)
		/// </summary>
		public TimeSpan TotalTime => TimeSpan.FromSeconds((double)Length / (double)WaveFormat.AverageBytesPerSecond);

		/// <summary>
		/// WaveFormat of this wave file
		/// </summary>
		public WaveFormat WaveFormat => format;

		/// <summary>
		/// Returns false: Cannot read from a WaveFileWriter
		/// </summary>
		public override bool CanRead => false;

		/// <summary>
		/// Returns true: Can write to a WaveFileWriter
		/// </summary>
		public override bool CanWrite => true;

		/// <summary>
		/// Returns false: Cannot seek within a WaveFileWriter
		/// </summary>
		public override bool CanSeek => false;

		/// <summary>
		/// Gets the Position in the WaveFile (i.e. number of bytes written so far)
		/// </summary>
		public override long Position
		{
			get
			{
				return dataChunkSize;
			}
			set
			{
				throw new InvalidOperationException("Repositioning a WaveFileWriter is not supported");
			}
		}

		/// <summary>
		/// Creates a 16 bit Wave File from an ISampleProvider
		/// BEWARE: the source provider must not return data indefinitely
		/// </summary>
		/// <param name="filename">The filename to write to</param>
		/// <param name="sourceProvider">The source sample provider</param>
		public static void CreateWaveFile16(string filename, ISampleProvider sourceProvider)
		{
			CreateWaveFile(filename, new SampleToWaveProvider16(sourceProvider));
		}

		/// <summary>
		/// Creates a Wave file by reading all the data from a WaveProvider
		/// BEWARE: the WaveProvider MUST return 0 from its Read method when it is finished,
		/// or the Wave File will grow indefinitely.
		/// </summary>
		/// <param name="filename">The filename to use</param>
		/// <param name="sourceProvider">The source WaveProvider</param>
		public static void CreateWaveFile(string filename, IWaveProvider sourceProvider)
		{
			using WaveFileWriter waveFileWriter = new WaveFileWriter(filename, sourceProvider.WaveFormat);
			byte[] array = new byte[sourceProvider.WaveFormat.AverageBytesPerSecond * 4];
			while (true)
			{
				int num = sourceProvider.Read(array, 0, array.Length);
				if (num == 0)
				{
					break;
				}
				waveFileWriter.Write(array, 0, num);
			}
		}

		/// <summary>
		/// Writes to a stream by reading all the data from a WaveProvider
		/// BEWARE: the WaveProvider MUST return 0 from its Read method when it is finished,
		/// or the Wave File will grow indefinitely.
		/// </summary>
		/// <param name="outStream">The stream the method will output to</param>
		/// <param name="sourceProvider">The source WaveProvider</param>
		public static void WriteWavFileToStream(Stream outStream, IWaveProvider sourceProvider)
		{
			using WaveFileWriter waveFileWriter = new WaveFileWriter(new IgnoreDisposeStream(outStream), sourceProvider.WaveFormat);
			byte[] array = new byte[sourceProvider.WaveFormat.AverageBytesPerSecond * 4];
			while (true)
			{
				int num = sourceProvider.Read(array, 0, array.Length);
				if (num == 0)
				{
					break;
				}
				waveFileWriter.Write(array, 0, num);
			}
			outStream.Flush();
		}

		/// <summary>
		/// WaveFileWriter that actually writes to a stream
		/// </summary>
		/// <param name="outStream">Stream to be written to</param>
		/// <param name="format">Wave format to use</param>
		public WaveFileWriter(Stream outStream, WaveFormat format)
		{
			this.outStream = outStream;
			this.format = format;
			writer = new BinaryWriter(outStream, Encoding.UTF8);
			writer.Write(Encoding.UTF8.GetBytes("RIFF"));
			writer.Write(0);
			writer.Write(Encoding.UTF8.GetBytes("WAVE"));
			writer.Write(Encoding.UTF8.GetBytes("fmt "));
			format.Serialize(writer);
			CreateFactChunk();
			WriteDataChunkHeader();
		}

		/// <summary>
		/// Creates a new WaveFileWriter
		/// </summary>
		/// <param name="filename">The filename to write to</param>
		/// <param name="format">The Wave Format of the output data</param>
		public WaveFileWriter(string filename, WaveFormat format)
			: this(new FileStream(filename, FileMode.Create, FileAccess.Write, FileShare.Read), format)
		{
			this.filename = filename;
		}

		private void WriteDataChunkHeader()
		{
			writer.Write(Encoding.UTF8.GetBytes("data"));
			dataSizePos = outStream.Position;
			writer.Write(0);
		}

		private void CreateFactChunk()
		{
			if (HasFactChunk())
			{
				writer.Write(Encoding.UTF8.GetBytes("fact"));
				writer.Write(4);
				factSampleCountPos = outStream.Position;
				writer.Write(0);
			}
		}

		private bool HasFactChunk()
		{
			if (format.Encoding != WaveFormatEncoding.Pcm)
			{
				return format.BitsPerSample != 0;
			}
			return false;
		}

		/// <summary>
		/// Read is not supported for a WaveFileWriter
		/// </summary>
		public override int Read(byte[] buffer, int offset, int count)
		{
			throw new InvalidOperationException("Cannot read from a WaveFileWriter");
		}

		/// <summary>
		/// Seek is not supported for a WaveFileWriter
		/// </summary>
		public override long Seek(long offset, SeekOrigin origin)
		{
			throw new InvalidOperationException("Cannot seek within a WaveFileWriter");
		}

		/// <summary>
		/// SetLength is not supported for WaveFileWriter
		/// </summary>
		/// <param name="value"></param>
		public override void SetLength(long value)
		{
			throw new InvalidOperationException("Cannot set length of a WaveFileWriter");
		}

		/// <summary>
		/// Appends bytes to the WaveFile (assumes they are already in the correct format)
		/// </summary>
		/// <param name="data">the buffer containing the wave data</param>
		/// <param name="offset">the offset from which to start writing</param>
		/// <param name="count">the number of bytes to write</param>
		[Obsolete("Use Write instead")]
		public void WriteData(byte[] data, int offset, int count)
		{
			Write(data, offset, count);
		}

		/// <summary>
		/// Appends bytes to the WaveFile (assumes they are already in the correct format)
		/// </summary>
		/// <param name="data">the buffer containing the wave data</param>
		/// <param name="offset">the offset from which to start writing</param>
		/// <param name="count">the number of bytes to write</param>
		public override void Write(byte[] data, int offset, int count)
		{
			if (outStream.Length + count > uint.MaxValue)
			{
				throw new ArgumentException("WAV file too large", "count");
			}
			outStream.Write(data, offset, count);
			dataChunkSize += count;
		}

		/// <summary>
		/// Writes a single sample to the Wave file
		/// </summary>
		/// <param name="sample">the sample to write (assumed floating point with 1.0f as max value)</param>
		public void WriteSample(float sample)
		{
			if (WaveFormat.BitsPerSample == 16)
			{
				writer.Write((short)(32767f * sample));
				dataChunkSize += 2L;
			}
			else if (WaveFormat.BitsPerSample == 24)
			{
				byte[] bytes = BitConverter.GetBytes((int)(2.1474836E+09f * sample));
				value24[0] = bytes[1];
				value24[1] = bytes[2];
				value24[2] = bytes[3];
				writer.Write(value24);
				dataChunkSize += 3L;
			}
			else if (WaveFormat.BitsPerSample == 32 && WaveFormat.Encoding == WaveFormatEncoding.Extensible)
			{
				writer.Write(65535 * (int)sample);
				dataChunkSize += 4L;
			}
			else
			{
				if (WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
				{
					throw new InvalidOperationException("Only 16, 24 or 32 bit PCM or IEEE float audio data supported");
				}
				writer.Write(sample);
				dataChunkSize += 4L;
			}
		}

		/// <summary>
		/// Writes 32 bit floating point samples to the Wave file
		/// They will be converted to the appropriate bit depth depending on the WaveFormat of the WAV file
		/// </summary>
		/// <param name="samples">The buffer containing the floating point samples</param>
		/// <param name="offset">The offset from which to start writing</param>
		/// <param name="count">The number of floating point samples to write</param>
		public void WriteSamples(float[] samples, int offset, int count)
		{
			for (int i = 0; i < count; i++)
			{
				WriteSample(samples[offset + i]);
			}
		}

		/// <summary>
		/// Writes 16 bit samples to the Wave file
		/// </summary>
		/// <param name="samples">The buffer containing the 16 bit samples</param>
		/// <param name="offset">The offset from which to start writing</param>
		/// <param name="count">The number of 16 bit samples to write</param>
		[Obsolete("Use WriteSamples instead")]
		public void WriteData(short[] samples, int offset, int count)
		{
			WriteSamples(samples, offset, count);
		}

		/// <summary>
		/// Writes 16 bit samples to the Wave file
		/// </summary>
		/// <param name="samples">The buffer containing the 16 bit samples</param>
		/// <param name="offset">The offset from which to start writing</param>
		/// <param name="count">The number of 16 bit samples to write</param>
		public void WriteSamples(short[] samples, int offset, int count)
		{
			if (WaveFormat.BitsPerSample == 16)
			{
				for (int i = 0; i < count; i++)
				{
					writer.Write(samples[i + offset]);
				}
				dataChunkSize += count * 2;
			}
			else if (WaveFormat.BitsPerSample == 24)
			{
				for (int j = 0; j < count; j++)
				{
					byte[] bytes = BitConverter.GetBytes(65535 * samples[j + offset]);
					value24[0] = bytes[1];
					value24[1] = bytes[2];
					value24[2] = bytes[3];
					writer.Write(value24);
				}
				dataChunkSize += count * 3;
			}
			else if (WaveFormat.BitsPerSample == 32 && WaveFormat.Encoding == WaveFormatEncoding.Extensible)
			{
				for (int k = 0; k < count; k++)
				{
					writer.Write(65535 * samples[k + offset]);
				}
				dataChunkSize += count * 4;
			}
			else
			{
				if (WaveFormat.BitsPerSample != 32 || WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
				{
					throw new InvalidOperationException("Only 16, 24 or 32 bit PCM or IEEE float audio data supported");
				}
				for (int l = 0; l < count; l++)
				{
					writer.Write((float)samples[l + offset] / 32768f);
				}
				dataChunkSize += count * 4;
			}
		}

		/// <summary>
		/// Ensures data is written to disk
		/// Also updates header, so that WAV file will be valid up to the point currently written
		/// </summary>
		public override void Flush()
		{
			long position = writer.BaseStream.Position;
			UpdateHeader(writer);
			writer.BaseStream.Position = position;
		}

		/// <summary>
		/// Actually performs the close,making sure the header contains the correct data
		/// </summary>
		/// <param name="disposing">True if called from <see>Dispose</see></param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && outStream != null)
			{
				try
				{
					UpdateHeader(writer);
				}
				finally
				{
					outStream.Dispose();
					outStream = null;
				}
			}
		}

		/// <summary>
		/// Updates the header with file size information
		/// </summary>
		protected virtual void UpdateHeader(BinaryWriter writer)
		{
			writer.Flush();
			UpdateRiffChunk(writer);
			UpdateFactChunk(writer);
			UpdateDataChunk(writer);
		}

		private void UpdateDataChunk(BinaryWriter writer)
		{
			writer.Seek((int)dataSizePos, SeekOrigin.Begin);
			writer.Write((uint)dataChunkSize);
		}

		private void UpdateRiffChunk(BinaryWriter writer)
		{
			writer.Seek(4, SeekOrigin.Begin);
			writer.Write((uint)(outStream.Length - 8));
		}

		private void UpdateFactChunk(BinaryWriter writer)
		{
			if (HasFactChunk())
			{
				int num = format.BitsPerSample * format.Channels;
				if (num != 0)
				{
					writer.Seek((int)factSampleCountPos, SeekOrigin.Begin);
					writer.Write((int)(dataChunkSize * 8 / num));
				}
			}
		}

		/// <summary>
		/// Finaliser - should only be called if the user forgot to close this WaveFileWriter
		/// </summary>
		~WaveFileWriter()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// Converts IEEE float to 16 bit PCM, optionally clipping and adjusting volume along the way
	/// </summary>
	public class WaveFloatTo16Provider : IWaveProvider
	{
		private readonly IWaveProvider sourceProvider;

		private readonly WaveFormat waveFormat;

		private volatile float volume;

		private byte[] sourceBuffer;

		/// <summary>
		/// <see cref="P:NAudio.Wave.IWaveProvider.WaveFormat" />
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Volume of this channel. 1.0 = full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				volume = value;
			}
		}

		/// <summary>
		/// Creates a new WaveFloatTo16Provider
		/// </summary>
		/// <param name="sourceProvider">the source provider</param>
		public WaveFloatTo16Provider(IWaveProvider sourceProvider)
		{
			if (sourceProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Input wave provider must be IEEE float", "sourceProvider");
			}
			if (sourceProvider.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Input wave provider must be 32 bit", "sourceProvider");
			}
			waveFormat = new WaveFormat(sourceProvider.WaveFormat.SampleRate, 16, sourceProvider.WaveFormat.Channels);
			this.sourceProvider = sourceProvider;
			volume = 1f;
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public int Read(byte[] destBuffer, int offset, int numBytes)
		{
			int num = numBytes * 2;
			sourceBuffer = BufferHelpers.Ensure(sourceBuffer, num);
			int num2 = sourceProvider.Read(sourceBuffer, 0, num);
			WaveBuffer waveBuffer = new WaveBuffer(sourceBuffer);
			WaveBuffer waveBuffer2 = new WaveBuffer(destBuffer);
			int num3 = num2 / 4;
			int num4 = offset / 2;
			for (int i = 0; i < num3; i++)
			{
				float num5 = waveBuffer.FloatBuffer[i] * volume;
				if (num5 > 1f)
				{
					num5 = 1f;
				}
				if (num5 < -1f)
				{
					num5 = -1f;
				}
				waveBuffer2.ShortBuffer[num4++] = (short)(num5 * 32767f);
			}
			return num3 * 2;
		}
	}

	/// <summary>
	/// Represents a Wave file format
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class WaveFormat
	{
		/// <summary>format type</summary>
		protected WaveFormatEncoding waveFormatTag;

		/// <summary>number of channels</summary>
		protected short channels;

		/// <summary>sample rate</summary>
		protected int sampleRate;

		/// <summary>for buffer estimation</summary>
		protected int averageBytesPerSecond;

		/// <summary>block size of data</summary>
		protected short blockAlign;

		/// <summary>number of bits per sample of mono data</summary>
		protected short bitsPerSample;

		/// <summary>number of following bytes</summary>
		protected short extraSize;

		/// <summary>
		/// Returns the encoding type used
		/// </summary>
		public WaveFormatEncoding Encoding => waveFormatTag;

		/// <summary>
		/// Returns the number of channels (1=mono,2=stereo etc)
		/// </summary>
		public int Channels => channels;

		/// <summary>
		/// Returns the sample rate (samples per second)
		/// </summary>
		public int SampleRate => sampleRate;

		/// <summary>
		/// Returns the average number of bytes used per second
		/// </summary>
		public int AverageBytesPerSecond => averageBytesPerSecond;

		/// <summary>
		/// Returns the block alignment
		/// </summary>
		public virtual int BlockAlign => blockAlign;

		/// <summary>
		/// Returns the number of bits per sample (usually 16 or 32, sometimes 24 or 8)
		/// Can be 0 for some codecs
		/// </summary>
		public int BitsPerSample => bitsPerSample;

		/// <summary>
		/// Returns the number of extra bytes used by this waveformat. Often 0,
		/// except for compressed formats which store extra data after the WAVEFORMATEX header
		/// </summary>
		public int ExtraSize => extraSize;

		/// <summary>
		/// Creates a new PCM 44.1Khz stereo 16 bit format
		/// </summary>
		public WaveFormat()
			: this(44100, 16, 2)
		{
		}

		/// <summary>
		/// Creates a new 16 bit wave format with the specified sample
		/// rate and channel count
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Number of channels</param>
		public WaveFormat(int sampleRate, int channels)
			: this(sampleRate, 16, channels)
		{
		}

		/// <summary>
		/// Gets the size of a wave buffer equivalent to the latency in milliseconds.
		/// </summary>
		/// <param name="milliseconds">The milliseconds.</param>
		/// <returns></returns>
		public int ConvertLatencyToByteSize(int milliseconds)
		{
			int num = (int)((double)AverageBytesPerSecond / 1000.0 * (double)milliseconds);
			if (num % BlockAlign != 0)
			{
				num = num + BlockAlign - num % BlockAlign;
			}
			return num;
		}

		/// <summary>
		/// Creates a WaveFormat with custom members
		/// </summary>
		/// <param name="tag">The encoding</param>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Number of channels</param>
		/// <param name="averageBytesPerSecond">Average Bytes Per Second</param>
		/// <param name="blockAlign">Block Align</param>
		/// <param name="bitsPerSample">Bits Per Sample</param>
		/// <returns></returns>
		public static WaveFormat CreateCustomFormat(WaveFormatEncoding tag, int sampleRate, int channels, int averageBytesPerSecond, int blockAlign, int bitsPerSample)
		{
			return new WaveFormat
			{
				waveFormatTag = tag,
				channels = (short)channels,
				sampleRate = sampleRate,
				averageBytesPerSecond = averageBytesPerSecond,
				blockAlign = (short)blockAlign,
				bitsPerSample = (short)bitsPerSample,
				extraSize = 0
			};
		}

		/// <summary>
		/// Creates an A-law wave format
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Number of Channels</param>
		/// <returns>Wave Format</returns>
		public static WaveFormat CreateALawFormat(int sampleRate, int channels)
		{
			return CreateCustomFormat(WaveFormatEncoding.ALaw, sampleRate, channels, sampleRate * channels, channels, 8);
		}

		/// <summary>
		/// Creates a Mu-law wave format
		/// </summary>
		/// <param name="sampleRate">Sample Rate</param>
		/// <param name="channels">Number of Channels</param>
		/// <returns>Wave Format</returns>
		public static WaveFormat CreateMuLawFormat(int sampleRate, int channels)
		{
			return CreateCustomFormat(WaveFormatEncoding.MuLaw, sampleRate, channels, sampleRate * channels, channels, 8);
		}

		/// <summary>
		/// Creates a new PCM format with the specified sample rate, bit depth and channels
		/// </summary>
		public WaveFormat(int rate, int bits, int channels)
		{
			if (channels < 1)
			{
				throw new ArgumentOutOfRangeException("channels", "Channels must be 1 or greater");
			}
			waveFormatTag = WaveFormatEncoding.Pcm;
			this.channels = (short)channels;
			sampleRate = rate;
			bitsPerSample = (short)bits;
			extraSize = 0;
			blockAlign = (short)(channels * (bits / 8));
			averageBytesPerSecond = sampleRate * blockAlign;
		}

		/// <summary>
		/// Creates a new 32 bit IEEE floating point wave format
		/// </summary>
		/// <param name="sampleRate">sample rate</param>
		/// <param name="channels">number of channels</param>
		public static WaveFormat CreateIeeeFloatWaveFormat(int sampleRate, int channels)
		{
			WaveFormat waveFormat = new WaveFormat();
			waveFormat.waveFormatTag = WaveFormatEncoding.IeeeFloat;
			waveFormat.channels = (short)channels;
			waveFormat.bitsPerSample = 32;
			waveFormat.sampleRate = sampleRate;
			waveFormat.blockAlign = (short)(4 * channels);
			waveFormat.averageBytesPerSecond = sampleRate * waveFormat.blockAlign;
			waveFormat.extraSize = 0;
			return waveFormat;
		}

		/// <summary>
		/// Helper function to retrieve a WaveFormat structure from a pointer
		/// </summary>
		/// <param name="pointer">WaveFormat structure</param>
		/// <returns></returns>
		public static WaveFormat MarshalFromPtr(IntPtr pointer)
		{
			WaveFormat waveFormat = Marshal.PtrToStructure<WaveFormat>(pointer);
			switch (waveFormat.Encoding)
			{
			case WaveFormatEncoding.Pcm:
				waveFormat.extraSize = 0;
				break;
			case WaveFormatEncoding.Extensible:
				waveFormat = Marshal.PtrToStructure<WaveFormatExtensible>(pointer);
				break;
			case WaveFormatEncoding.Adpcm:
				waveFormat = Marshal.PtrToStructure<AdpcmWaveFormat>(pointer);
				break;
			case WaveFormatEncoding.Gsm610:
				waveFormat = Marshal.PtrToStructure<Gsm610WaveFormat>(pointer);
				break;
			default:
				if (waveFormat.ExtraSize > 0)
				{
					waveFormat = Marshal.PtrToStructure<WaveFormatExtraData>(pointer);
				}
				break;
			}
			return waveFormat;
		}

		/// <summary>
		/// Helper function to marshal WaveFormat to an IntPtr
		/// </summary>
		/// <param name="format">WaveFormat</param>
		/// <returns>IntPtr to WaveFormat structure (needs to be freed by callee)</returns>
		public static IntPtr MarshalToPtr(WaveFormat format)
		{
			IntPtr intPtr = Marshal.AllocHGlobal(Marshal.SizeOf(format));
			Marshal.StructureToPtr(format, intPtr, fDeleteOld: false);
			return intPtr;
		}

		/// <summary>
		/// Reads in a WaveFormat (with extra data) from a fmt chunk (chunk identifier and
		/// length should already have been read)
		/// </summary>
		/// <param name="br">Binary reader</param>
		/// <param name="formatChunkLength">Format chunk length</param>
		/// <returns>A WaveFormatExtraData</returns>
		public static WaveFormat FromFormatChunk(BinaryReader br, int formatChunkLength)
		{
			WaveFormatExtraData waveFormatExtraData = new WaveFormatExtraData();
			waveFormatExtraData.ReadWaveFormat(br, formatChunkLength);
			waveFormatExtraData.ReadExtraData(br);
			return waveFormatExtraData;
		}

		private void ReadWaveFormat(BinaryReader br, int formatChunkLength)
		{
			if (formatChunkLength < 16)
			{
				throw new InvalidDataException("Invalid WaveFormat Structure");
			}
			waveFormatTag = (WaveFormatEncoding)br.ReadUInt16();
			channels = br.ReadInt16();
			sampleRate = br.ReadInt32();
			averageBytesPerSecond = br.ReadInt32();
			blockAlign = br.ReadInt16();
			bitsPerSample = br.ReadInt16();
			if (formatChunkLength > 16)
			{
				extraSize = br.ReadInt16();
				if (extraSize != formatChunkLength - 18)
				{
					extraSize = (short)(formatChunkLength - 18);
				}
			}
		}

		/// <summary>
		/// Reads a new WaveFormat object from a stream
		/// </summary>
		/// <param name="br">A binary reader that wraps the stream</param>
		public WaveFormat(BinaryReader br)
		{
			int formatChunkLength = br.ReadInt32();
			ReadWaveFormat(br, formatChunkLength);
		}

		/// <summary>
		/// Reports this WaveFormat as a string
		/// </summary>
		/// <returns>String describing the wave format</returns>
		public override string ToString()
		{
			switch (waveFormatTag)
			{
			case WaveFormatEncoding.Pcm:
			case WaveFormatEncoding.Extensible:
				return $"{bitsPerSample} bit PCM: {sampleRate}Hz {channels} channels";
			case WaveFormatEncoding.IeeeFloat:
				return $"{bitsPerSample} bit IEEFloat: {sampleRate}Hz {channels} channels";
			default:
				return waveFormatTag.ToString();
			}
		}

		/// <summary>
		/// Compares with another WaveFormat object
		/// </summary>
		/// <param name="obj">Object to compare to</param>
		/// <returns>True if the objects are the same</returns>
		public override bool Equals(object obj)
		{
			if (obj is WaveFormat waveFormat)
			{
				if (waveFormatTag == waveFormat.waveFormatTag && channels == waveFormat.channels && sampleRate == waveFormat.sampleRate && averageBytesPerSecond == waveFormat.averageBytesPerSecond && blockAlign == waveFormat.blockAlign)
				{
					return bitsPerSample == waveFormat.bitsPerSample;
				}
				return false;
			}
			return false;
		}

		/// <summary>
		/// Provides a Hashcode for this WaveFormat
		/// </summary>
		/// <returns>A hashcode</returns>
		public override int GetHashCode()
		{
			return (int)waveFormatTag ^ (int)channels ^ sampleRate ^ averageBytesPerSecond ^ blockAlign ^ bitsPerSample;
		}

		/// <summary>
		/// Writes this WaveFormat object to a stream
		/// </summary>
		/// <param name="writer">the output stream</param>
		public virtual void Serialize(BinaryWriter writer)
		{
			writer.Write(18 + extraSize);
			writer.Write((short)Encoding);
			writer.Write((short)Channels);
			writer.Write(SampleRate);
			writer.Write(AverageBytesPerSecond);
			writer.Write((short)BlockAlign);
			writer.Write((short)BitsPerSample);
			writer.Write(extraSize);
		}
	}

	/// <summary>
	/// Custom marshaller for WaveFormat structures
	/// </summary>
	public sealed class WaveFormatCustomMarshaler : ICustomMarshaler
	{
		private static WaveFormatCustomMarshaler marshaler;

		/// <summary>
		/// Gets the instance of this marshaller
		/// </summary>
		/// <param name="cookie"></param>
		/// <returns></returns>
		public static ICustomMarshaler GetInstance(string cookie)
		{
			if (marshaler == null)
			{
				marshaler = new WaveFormatCustomMarshaler();
			}
			return marshaler;
		}

		/// <summary>
		/// Clean up managed data
		/// </summary>
		public void CleanUpManagedData(object ManagedObj)
		{
		}

		/// <summary>
		/// Clean up native data
		/// </summary>
		/// <param name="pNativeData"></param>
		public void CleanUpNativeData(IntPtr pNativeData)
		{
			Marshal.FreeHGlobal(pNativeData);
		}

		/// <summary>
		/// Get native data size
		/// </summary>        
		public int GetNativeDataSize()
		{
			throw new NotImplementedException();
		}

		/// <summary>
		/// Marshal managed to native
		/// </summary>
		public IntPtr MarshalManagedToNative(object ManagedObj)
		{
			return WaveFormat.MarshalToPtr((WaveFormat)ManagedObj);
		}

		/// <summary>
		/// Marshal Native to Managed
		/// </summary>
		public object MarshalNativeToManaged(IntPtr pNativeData)
		{
			return WaveFormat.MarshalFromPtr(pNativeData);
		}
	}

	/// <summary>
	/// Summary description for WaveFormatEncoding.
	/// </summary>
	public enum WaveFormatEncoding : ushort
	{
		/// <summary>WAVE_FORMAT_UNKNOWN,	Microsoft Corporation</summary>
		Unknown = 0,
		/// <summary>WAVE_FORMAT_PCM		Microsoft Corporation</summary>
		Pcm = 1,
		/// <summary>WAVE_FORMAT_ADPCM		Microsoft Corporation</summary>
		Adpcm = 2,
		/// <summary>WAVE_FORMAT_IEEE_FLOAT Microsoft Corporation</summary>
		IeeeFloat = 3,
		/// <summary>WAVE_FORMAT_VSELP		Compaq Computer Corp.</summary>
		Vselp = 4,
		/// <summary>WAVE_FORMAT_IBM_CVSD	IBM Corporation</summary>
		IbmCvsd = 5,
		/// <summary>WAVE_FORMAT_ALAW		Microsoft Corporation</summary>
		ALaw = 6,
		/// <summary>WAVE_FORMAT_MULAW		Microsoft Corporation</summary>
		MuLaw = 7,
		/// <summary>WAVE_FORMAT_DTS		Microsoft Corporation</summary>
		Dts = 8,
		/// <summary>WAVE_FORMAT_DRM		Microsoft Corporation</summary>
		Drm = 9,
		/// <summary>WAVE_FORMAT_WMAVOICE9 </summary>
		WmaVoice9 = 10,
		/// <summary>WAVE_FORMAT_OKI_ADPCM	OKI</summary>
		OkiAdpcm = 16,
		/// <summary>WAVE_FORMAT_DVI_ADPCM	Intel Corporation</summary>
		DviAdpcm = 17,
		/// <summary>WAVE_FORMAT_IMA_ADPCM  Intel Corporation</summary>
		ImaAdpcm = 17,
		/// <summary>WAVE_FORMAT_MEDIASPACE_ADPCM Videologic</summary>
		MediaspaceAdpcm = 18,
		/// <summary>WAVE_FORMAT_SIERRA_ADPCM Sierra Semiconductor Corp </summary>
		SierraAdpcm = 19,
		/// <summary>WAVE_FORMAT_G723_ADPCM Antex Electronics Corporation </summary>
		G723Adpcm = 20,
		/// <summary>WAVE_FORMAT_DIGISTD DSP Solutions, Inc.</summary>
		DigiStd = 21,
		/// <summary>WAVE_FORMAT_DIGIFIX DSP Solutions, Inc.</summary>
		DigiFix = 22,
		/// <summary>WAVE_FORMAT_DIALOGIC_OKI_ADPCM Dialogic Corporation</summary>
		DialogicOkiAdpcm = 23,
		/// <summary>WAVE_FORMAT_MEDIAVISION_ADPCM Media Vision, Inc.</summary>
		MediaVisionAdpcm = 24,
		/// <summary>WAVE_FORMAT_CU_CODEC Hewlett-Packard Company </summary>
		CUCodec = 25,
		/// <summary>WAVE_FORMAT_YAMAHA_ADPCM Yamaha Corporation of America</summary>
		YamahaAdpcm = 32,
		/// <summary>WAVE_FORMAT_SONARC Speech Compression</summary>
		SonarC = 33,
		/// <summary>WAVE_FORMAT_DSPGROUP_TRUESPEECH DSP Group, Inc </summary>
		DspGroupTrueSpeech = 34,
		/// <summary>WAVE_FORMAT_ECHOSC1 Echo Speech Corporation</summary>
		EchoSpeechCorporation1 = 35,
		/// <summary>WAVE_FORMAT_AUDIOFILE_AF36, Virtual Music, Inc.</summary>
		AudioFileAf36 = 36,
		/// <summary>WAVE_FORMAT_APTX Audio Processing Technology</summary>
		Aptx = 37,
		/// <summary>WAVE_FORMAT_AUDIOFILE_AF10, Virtual Music, Inc.</summary>
		AudioFileAf10 = 38,
		/// <summary>WAVE_FORMAT_PROSODY_1612, Aculab plc</summary>
		Prosody1612 = 39,
		/// <summary>WAVE_FORMAT_LRC, Merging Technologies S.A. </summary>
		Lrc = 40,
		/// <summary>WAVE_FORMAT_DOLBY_AC2, Dolby Laboratories</summary>
		DolbyAc2 = 48,
		/// <summary>WAVE_FORMAT_GSM610, Microsoft Corporation</summary>
		Gsm610 = 49,
		/// <summary>WAVE_FORMAT_MSNAUDIO, Microsoft Corporation</summary>
		MsnAudio = 50,
		/// <summary>WAVE_FORMAT_ANTEX_ADPCME, Antex Electronics Corporation</summary>
		AntexAdpcme = 51,
		/// <summary>WAVE_FORMAT_CONTROL_RES_VQLPC, Control Resources Limited </summary>
		ControlResVqlpc = 52,
		/// <summary>WAVE_FORMAT_DIGIREAL, DSP Solutions, Inc. </summary>
		DigiReal = 53,
		/// <summary>WAVE_FORMAT_DIGIADPCM, DSP Solutions, Inc.</summary>
		DigiAdpcm = 54,
		/// <summary>WAVE_FORMAT_CONTROL_RES_CR10, Control Resources Limited</summary>
		ControlResCr10 = 55,
		/// <summary></summary>
		WAVE_FORMAT_NMS_VBXADPCM = 56,
		/// <summary></summary>
		WAVE_FORMAT_CS_IMAADPCM = 57,
		/// <summary></summary>
		WAVE_FORMAT_ECHOSC3 = 58,
		/// <summary></summary>
		WAVE_FORMAT_ROCKWELL_ADPCM = 59,
		/// <summary></summary>
		WAVE_FORMAT_ROCKWELL_DIGITALK = 60,
		/// <summary></summary>
		WAVE_FORMAT_XEBEC = 61,
		/// <summary></summary>
		WAVE_FORMAT_G721_ADPCM = 64,
		/// <summary></summary>
		WAVE_FORMAT_G728_CELP = 65,
		/// <summary></summary>
		WAVE_FORMAT_MSG723 = 66,
		/// <summary>WAVE_FORMAT_MPEG, Microsoft Corporation </summary>
		Mpeg = 80,
		/// <summary></summary>
		WAVE_FORMAT_RT24 = 82,
		/// <summary></summary>
		WAVE_FORMAT_PAC = 83,
		/// <summary>WAVE_FORMAT_MPEGLAYER3, ISO/MPEG Layer3 Format Tag </summary>
		MpegLayer3 = 85,
		/// <summary></summary>
		WAVE_FORMAT_LUCENT_G723 = 89,
		/// <summary></summary>
		WAVE_FORMAT_CIRRUS = 96,
		/// <summary></summary>
		WAVE_FORMAT_ESPCM = 97,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE = 98,
		/// <summary></summary>
		WAVE_FORMAT_CANOPUS_ATRAC = 99,
		/// <summary></summary>
		WAVE_FORMAT_G726_ADPCM = 100,
		/// <summary></summary>
		WAVE_FORMAT_G722_ADPCM = 101,
		/// <summary></summary>
		WAVE_FORMAT_DSAT_DISPLAY = 103,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_BYTE_ALIGNED = 105,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_AC8 = 112,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_AC10 = 113,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_AC16 = 114,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_AC20 = 115,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_RT24 = 116,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_RT29 = 117,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_RT29HW = 118,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_VR12 = 119,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_VR18 = 120,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_TQ40 = 121,
		/// <summary></summary>
		WAVE_FORMAT_SOFTSOUND = 128,
		/// <summary></summary>
		WAVE_FORMAT_VOXWARE_TQ60 = 129,
		/// <summary></summary>
		WAVE_FORMAT_MSRT24 = 130,
		/// <summary></summary>
		WAVE_FORMAT_G729A = 131,
		/// <summary></summary>
		WAVE_FORMAT_MVI_MVI2 = 132,
		/// <summary></summary>
		WAVE_FORMAT_DF_G726 = 133,
		/// <summary></summary>
		WAVE_FORMAT_DF_GSM610 = 134,
		/// <summary></summary>
		WAVE_FORMAT_ISIAUDIO = 136,
		/// <summary></summary>
		WAVE_FORMAT_ONLIVE = 137,
		/// <summary></summary>
		WAVE_FORMAT_SBC24 = 145,
		/// <summary></summary>
		WAVE_FORMAT_DOLBY_AC3_SPDIF = 146,
		/// <summary></summary>
		WAVE_FORMAT_MEDIASONIC_G723 = 147,
		/// <summary></summary>
		WAVE_FORMAT_PROSODY_8KBPS = 148,
		/// <summary></summary>
		WAVE_FORMAT_ZYXEL_ADPCM = 151,
		/// <summary></summary>
		WAVE_FORMAT_PHILIPS_LPCBB = 152,
		/// <summary></summary>
		WAVE_FORMAT_PACKED = 153,
		/// <summary></summary>
		WAVE_FORMAT_MALDEN_PHONYTALK = 160,
		/// <summary>WAVE_FORMAT_GSM</summary>
		Gsm = 161,
		/// <summary>WAVE_FORMAT_G729</summary>
		G729 = 162,
		/// <summary>WAVE_FORMAT_G723</summary>
		G723 = 163,
		/// <summary>WAVE_FORMAT_ACELP</summary>
		Acelp = 164,
		/// <summary>
		/// WAVE_FORMAT_RAW_AAC1
		/// </summary>
		RawAac = 255,
		/// <summary></summary>
		WAVE_FORMAT_RHETOREX_ADPCM = 256,
		/// <summary></summary>
		WAVE_FORMAT_IRAT = 257,
		/// <summary></summary>
		WAVE_FORMAT_VIVO_G723 = 273,
		/// <summary></summary>
		WAVE_FORMAT_VIVO_SIREN = 274,
		/// <summary></summary>
		WAVE_FORMAT_DIGITAL_G723 = 291,
		/// <summary></summary>
		WAVE_FORMAT_SANYO_LD_ADPCM = 293,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_ACEPLNET = 304,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_ACELP4800 = 305,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_ACELP8V3 = 306,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_G729 = 307,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_G729A = 308,
		/// <summary></summary>
		WAVE_FORMAT_SIPROLAB_KELVIN = 309,
		/// <summary></summary>
		WAVE_FORMAT_G726ADPCM = 320,
		/// <summary></summary>
		WAVE_FORMAT_QUALCOMM_PUREVOICE = 336,
		/// <summary></summary>
		WAVE_FORMAT_QUALCOMM_HALFRATE = 337,
		/// <summary></summary>
		WAVE_FORMAT_TUBGSM = 341,
		/// <summary></summary>
		WAVE_FORMAT_MSAUDIO1 = 352,
		/// <summary>
		/// Windows Media Audio, WAVE_FORMAT_WMAUDIO2, Microsoft Corporation
		/// </summary>
		WindowsMediaAudio = 353,
		/// <summary>
		/// Windows Media Audio Professional WAVE_FORMAT_WMAUDIO3, Microsoft Corporation
		/// </summary>
		WindowsMediaAudioProfessional = 354,
		/// <summary>
		/// Windows Media Audio Lossless, WAVE_FORMAT_WMAUDIO_LOSSLESS
		/// </summary>
		WindowsMediaAudioLosseless = 355,
		/// <summary>
		/// Windows Media Audio Professional over SPDIF WAVE_FORMAT_WMASPDIF (0x0164)
		/// </summary>
		WindowsMediaAudioSpdif = 356,
		/// <summary></summary>
		WAVE_FORMAT_UNISYS_NAP_ADPCM = 368,
		/// <summary></summary>
		WAVE_FORMAT_UNISYS_NAP_ULAW = 369,
		/// <summary></summary>
		WAVE_FORMAT_UNISYS_NAP_ALAW = 370,
		/// <summary></summary>
		WAVE_FORMAT_UNISYS_NAP_16K = 371,
		/// <summary></summary>
		WAVE_FORMAT_CREATIVE_ADPCM = 512,
		/// <summary></summary>
		WAVE_FORMAT_CREATIVE_FASTSPEECH8 = 514,
		/// <summary></summary>
		WAVE_FORMAT_CREATIVE_FASTSPEECH10 = 515,
		/// <summary></summary>
		WAVE_FORMAT_UHER_ADPCM = 528,
		/// <summary></summary>
		WAVE_FORMAT_QUARTERDECK = 544,
		/// <summary></summary>
		WAVE_FORMAT_ILINK_VC = 560,
		/// <summary></summary>
		WAVE_FORMAT_RAW_SPORT = 576,
		/// <summary></summary>
		WAVE_FORMAT_ESST_AC3 = 577,
		/// <summary></summary>
		WAVE_FORMAT_IPI_HSX = 592,
		/// <summary></summary>
		WAVE_FORMAT_IPI_RPELP = 593,
		/// <summary></summary>
		WAVE_FORMAT_CS2 = 608,
		/// <summary></summary>
		WAVE_FORMAT_SONY_SCX = 624,
		/// <summary></summary>
		WAVE_FORMAT_FM_TOWNS_SND = 768,
		/// <summary></summary>
		WAVE_FORMAT_BTV_DIGITAL = 1024,
		/// <summary></summary>
		WAVE_FORMAT_QDESIGN_MUSIC = 1104,
		/// <summary></summary>
		WAVE_FORMAT_VME_VMPCM = 1664,
		/// <summary></summary>
		WAVE_FORMAT_TPC = 1665,
		/// <summary></summary>
		WAVE_FORMAT_OLIGSM = 4096,
		/// <summary></summary>
		WAVE_FORMAT_OLIADPCM = 4097,
		/// <summary></summary>
		WAVE_FORMAT_OLICELP = 4098,
		/// <summary></summary>
		WAVE_FORMAT_OLISBC = 4099,
		/// <summary></summary>
		WAVE_FORMAT_OLIOPR = 4100,
		/// <summary></summary>
		WAVE_FORMAT_LH_CODEC = 4352,
		/// <summary></summary>
		WAVE_FORMAT_NORRIS = 5120,
		/// <summary></summary>
		WAVE_FORMAT_SOUNDSPACE_MUSICOMPRESS = 5376,
		/// <summary>
		/// Advanced Audio Coding (AAC) audio in Audio Data Transport Stream (ADTS) format.
		/// The format block is a WAVEFORMATEX structure with wFormatTag equal to WAVE_FORMAT_MPEG_ADTS_AAC.
		/// </summary>
		/// <remarks>
		/// The WAVEFORMATEX structure specifies the core AAC-LC sample rate and number of channels, 
		/// prior to applying spectral band replication (SBR) or parametric stereo (PS) tools, if present.
		/// No additional data is required after the WAVEFORMATEX structure.
		/// </remarks>
		/// <see>http://msdn.microsoft.com/en-us/library/dd317599%28VS.85%29.aspx</see>
		MPEG_ADTS_AAC = 5632,
		/// <summary></summary>
		/// <remarks>Source wmCodec.h</remarks>
		MPEG_RAW_AAC = 5633,
		/// <summary>
		/// MPEG-4 audio transport stream with a synchronization layer (LOAS) and a multiplex layer (LATM).
		/// The format block is a WAVEFORMATEX structure with wFormatTag equal to WAVE_FORMAT_MPEG_LOAS.
		/// </summary>
		/// <remarks>
		/// The WAVEFORMATEX structure specifies the core AAC-LC sample rate and number of channels, 
		/// prior to applying spectral SBR or PS tools, if present.
		/// No additional data is required after the WAVEFORMATEX structure.
		/// </remarks>
		/// <see>http://msdn.microsoft.com/en-us/library/dd317599%28VS.85%29.aspx</see>
		MPEG_LOAS = 5634,
		/// <summary>NOKIA_MPEG_ADTS_AAC</summary>
		/// <remarks>Source wmCodec.h</remarks>
		NOKIA_MPEG_ADTS_AAC = 5640,
		/// <summary>NOKIA_MPEG_RAW_AAC</summary>
		/// <remarks>Source wmCodec.h</remarks>
		NOKIA_MPEG_RAW_AAC = 5641,
		/// <summary>VODAFONE_MPEG_ADTS_AAC</summary>
		/// <remarks>Source wmCodec.h</remarks>
		VODAFONE_MPEG_ADTS_AAC = 5642,
		/// <summary>VODAFONE_MPEG_RAW_AAC</summary>
		/// <remarks>Source wmCodec.h</remarks>
		VODAFONE_MPEG_RAW_AAC = 5643,
		/// <summary>
		/// High-Efficiency Advanced Audio Coding (HE-AAC) stream.
		/// The format block is an HEAACWAVEFORMAT structure.
		/// </summary>
		/// <see>http://msdn.microsoft.com/en-us/library/dd317599%28VS.85%29.aspx</see>
		MPEG_HEAAC = 5648,
		/// <summary>WAVE_FORMAT_DVM</summary>
		WAVE_FORMAT_DVM = 8192,
		/// <summary>WAVE_FORMAT_VORBIS1 "Og" Original stream compatible</summary>
		Vorbis1 = 26447,
		/// <summary>WAVE_FORMAT_VORBIS2 "Pg" Have independent header</summary>
		Vorbis2 = 26448,
		/// <summary>WAVE_FORMAT_VORBIS3 "Qg" Have no codebook header</summary>
		Vorbis3 = 26449,
		/// <summary>WAVE_FORMAT_VORBIS1P "og" Original stream compatible</summary>
		Vorbis1P = 26479,
		/// <summary>WAVE_FORMAT_VORBIS2P "pg" Have independent headere</summary>
		Vorbis2P = 26480,
		/// <summary>WAVE_FORMAT_VORBIS3P "qg" Have no codebook header</summary>
		Vorbis3P = 26481,
		/// <summary>WAVE_FORMAT_EXTENSIBLE</summary>
		Extensible = 65534,
		/// <summary></summary>
		WAVE_FORMAT_DEVELOPMENT = ushort.MaxValue
	}

	/// <summary>
	/// WaveFormatExtensible
	/// http://www.microsoft.com/whdc/device/audio/multichaud.mspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class WaveFormatExtensible : WaveFormat
	{
		private short wValidBitsPerSample;

		private int dwChannelMask;

		private Guid subFormat;

		/// <summary>
		/// SubFormat (may be one of AudioMediaSubtypes)
		/// </summary>
		public Guid SubFormat => subFormat;

		/// <summary>
		/// Parameterless constructor for marshalling
		/// </summary>
		private WaveFormatExtensible()
		{
		}

		/// <summary>
		/// Creates a new WaveFormatExtensible for PCM or IEEE
		/// </summary>
		public WaveFormatExtensible(int rate, int bits, int channels)
			: base(rate, bits, channels)
		{
			waveFormatTag = WaveFormatEncoding.Extensible;
			extraSize = 22;
			wValidBitsPerSample = (short)bits;
			for (int i = 0; i < channels; i++)
			{
				dwChannelMask |= 1 << i;
			}
			if (bits == 32)
			{
				subFormat = AudioMediaSubtypes.MEDIASUBTYPE_IEEE_FLOAT;
			}
			else
			{
				subFormat = AudioMediaSubtypes.MEDIASUBTYPE_PCM;
			}
		}

		/// <summary>
		/// WaveFormatExtensible for PCM or floating point can be awkward to work with
		/// This creates a regular WaveFormat structure representing the same audio format
		/// Returns the WaveFormat unchanged for non PCM or IEEE float
		/// </summary>
		/// <returns></returns>
		public WaveFormat ToStandardWaveFormat()
		{
			if (subFormat == AudioMediaSubtypes.MEDIASUBTYPE_IEEE_FLOAT && bitsPerSample == 32)
			{
				return WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channels);
			}
			if (subFormat == AudioMediaSubtypes.MEDIASUBTYPE_PCM)
			{
				return new WaveFormat(sampleRate, bitsPerSample, channels);
			}
			return this;
		}

		/// <summary>
		/// Serialize
		/// </summary>
		/// <param name="writer"></param>
		public override void Serialize(BinaryWriter writer)
		{
			base.Serialize(writer);
			writer.Write(wValidBitsPerSample);
			writer.Write(dwChannelMask);
			byte[] array = subFormat.ToByteArray();
			writer.Write(array, 0, array.Length);
		}

		/// <summary>
		/// String representation
		/// </summary>
		public override string ToString()
		{
			return "WAVE_FORMAT_EXTENSIBLE " + AudioMediaSubtypes.GetAudioSubtypeName(subFormat) + " " + $"{base.SampleRate}Hz {base.Channels} channels {base.BitsPerSample} bit";
		}
	}

	/// <summary>
	/// This class used for marshalling from unmanaged code
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	public class WaveFormatExtraData : WaveFormat
	{
		[MarshalAs(UnmanagedType.ByValArray, SizeConst = 100)]
		private byte[] extraData = new byte[100];

		/// <summary>
		/// Allows the extra data to be read
		/// </summary>
		public byte[] ExtraData => extraData;

		/// <summary>
		/// parameterless constructor for marshalling
		/// </summary>
		internal WaveFormatExtraData()
		{
		}

		/// <summary>
		/// Reads this structure from a BinaryReader
		/// </summary>
		public WaveFormatExtraData(BinaryReader reader)
			: base(reader)
		{
			ReadExtraData(reader);
		}

		internal void ReadExtraData(BinaryReader reader)
		{
			if (extraSize > 0)
			{
				reader.Read(extraData, 0, extraSize);
			}
		}

		/// <summary>
		/// Writes this structure to a BinaryWriter
		/// </summary>
		public override void Serialize(BinaryWriter writer)
		{
			base.Serialize(writer);
			if (extraSize > 0)
			{
				writer.Write(extraData, 0, extraSize);
			}
		}
	}

	/// <summary>
	/// Event Args for WaveInStream event
	/// </summary>
	public class WaveInEventArgs : EventArgs
	{
		private byte[] buffer;

		private int bytes;

		/// <summary>
		/// Buffer containing recorded data. Note that it might not be completely
		/// full. <seealso cref="P:NAudio.Wave.WaveInEventArgs.BytesRecorded" />
		/// </summary>
		public byte[] Buffer => buffer;

		/// <summary>
		/// The number of recorded bytes in Buffer. <seealso cref="P:NAudio.Wave.WaveInEventArgs.Buffer" />
		/// </summary>
		public int BytesRecorded => bytes;

		/// <summary>
		/// Creates new WaveInEventArgs
		/// </summary>
		public WaveInEventArgs(byte[] buffer, int bytes)
		{
			this.buffer = buffer;
			this.bytes = bytes;
		}
	}

	/// <summary>
	/// Buffered WaveProvider taking source data from WaveIn
	/// </summary>
	public class WaveInProvider : IWaveProvider
	{
		private readonly IWaveIn waveIn;

		private readonly BufferedWaveProvider bufferedWaveProvider;

		/// <summary>
		/// The WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => waveIn.WaveFormat;

		/// <summary>
		/// Creates a new WaveInProvider
		/// n.b. Should make sure the WaveFormat is set correctly on IWaveIn before calling
		/// </summary>
		/// <param name="waveIn">The source of wave data</param>
		public WaveInProvider(IWaveIn waveIn)
		{
			this.waveIn = waveIn;
			waveIn.DataAvailable += OnDataAvailable;
			bufferedWaveProvider = new BufferedWaveProvider(WaveFormat);
		}

		private void OnDataAvailable(object sender, WaveInEventArgs e)
		{
			bufferedWaveProvider.AddSamples(e.Buffer, 0, e.BytesRecorded);
		}

		/// <summary>
		/// Reads data from the WaveInProvider
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			return bufferedWaveProvider.Read(buffer, offset, count);
		}
	}

	/// <summary>
	/// WaveStream that can mix together multiple 32 bit input streams
	/// (Normally used with stereo input channels)
	/// All channels must have the same number of inputs
	/// </summary>
	public class WaveMixerStream32 : WaveStream
	{
		private readonly List<WaveStream> inputStreams;

		private readonly object inputsLock;

		private WaveFormat waveFormat;

		private long length;

		private long position;

		private readonly int bytesPerSample;

		/// <summary>
		/// The number of inputs to this mixer
		/// </summary>
		public int InputCount => inputStreams.Count;

		/// <summary>
		/// Automatically stop when all inputs have been read
		/// </summary>
		public bool AutoStop { get; set; }

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.BlockAlign" />
		/// </summary>
		public override int BlockAlign => waveFormat.BlockAlign;

		/// <summary>
		/// Length of this Wave Stream (in bytes)
		/// <see cref="P:System.IO.Stream.Length" />
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Position within this Wave Stream (in bytes)
		/// <see cref="P:System.IO.Stream.Position" />
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (inputsLock)
				{
					value = Math.Min(value, Length);
					foreach (WaveStream inputStream in inputStreams)
					{
						inputStream.Position = Math.Min(value, inputStream.Length);
					}
					position = value;
				}
			}
		}

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Creates a new 32 bit WaveMixerStream
		/// </summary>
		public WaveMixerStream32()
		{
			AutoStop = true;
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(44100, 2);
			bytesPerSample = 4;
			inputStreams = new List<WaveStream>();
			inputsLock = new object();
		}

		/// <summary>
		/// Creates a new 32 bit WaveMixerStream
		/// </summary>
		/// <param name="inputStreams">An Array of WaveStreams - must all have the same format.
		/// Use WaveChannel is designed for this purpose.</param>
		/// <param name="autoStop">Automatically stop when all inputs have been read</param>
		/// <exception cref="T:System.ArgumentException">Thrown if the input streams are not 32 bit floating point,
		/// or if they have different formats to each other</exception>
		public WaveMixerStream32(IEnumerable<WaveStream> inputStreams, bool autoStop)
			: this()
		{
			AutoStop = autoStop;
			foreach (WaveStream inputStream in inputStreams)
			{
				AddInputStream(inputStream);
			}
		}

		/// <summary>
		/// Add a new input to the mixer
		/// </summary>
		/// <param name="waveStream">The wave input to add</param>
		public void AddInputStream(WaveStream waveStream)
		{
			if (waveStream.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Must be IEEE floating point", "waveStream");
			}
			if (waveStream.WaveFormat.BitsPerSample != 32)
			{
				throw new ArgumentException("Only 32 bit audio currently supported", "waveStream");
			}
			if (inputStreams.Count == 0)
			{
				int sampleRate = waveStream.WaveFormat.SampleRate;
				int channels = waveStream.WaveFormat.Channels;
				waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channels);
			}
			else if (!waveStream.WaveFormat.Equals(waveFormat))
			{
				throw new ArgumentException("All incoming channels must have the same format", "waveStream");
			}
			lock (inputsLock)
			{
				inputStreams.Add(waveStream);
				length = Math.Max(length, waveStream.Length);
				waveStream.Position = Position;
			}
		}

		/// <summary>
		/// Remove a WaveStream from the mixer
		/// </summary>
		/// <param name="waveStream">waveStream to remove</param>
		public void RemoveInputStream(WaveStream waveStream)
		{
			lock (inputsLock)
			{
				if (!inputStreams.Remove(waveStream))
				{
					return;
				}
				long val = 0L;
				foreach (WaveStream inputStream in inputStreams)
				{
					val = Math.Max(val, inputStream.Length);
				}
				length = val;
			}
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="buffer">buffer to read into</param>
		/// <param name="offset">offset into buffer</param>
		/// <param name="count">number of bytes required</param>
		/// <returns>Number of bytes read.</returns>
		/// <exception cref="T:System.ArgumentException">Thrown if an invalid number of bytes requested</exception>
		public override int Read(byte[] buffer, int offset, int count)
		{
			if (AutoStop && position + count > length)
			{
				count = (int)(length - position);
			}
			if (count % bytesPerSample != 0)
			{
				throw new ArgumentException("Must read an whole number of samples", "count");
			}
			Array.Clear(buffer, offset, count);
			int val = 0;
			byte[] array = new byte[count];
			lock (inputsLock)
			{
				foreach (WaveStream inputStream in inputStreams)
				{
					if (inputStream.HasData(count))
					{
						int num = inputStream.Read(array, 0, count);
						val = Math.Max(val, num);
						if (num > 0)
						{
							Sum32BitAudio(buffer, offset, array, num);
						}
					}
					else
					{
						val = Math.Max(val, count);
						inputStream.Position += count;
					}
				}
			}
			position += count;
			return count;
		}

		/// <summary>
		/// Actually performs the mixing
		/// </summary>
		private unsafe static void Sum32BitAudio(byte[] destBuffer, int offset, byte[] sourceBuffer, int bytesRead)
		{
			fixed (byte* ptr = &destBuffer[offset])
			{
				fixed (byte* ptr3 = &sourceBuffer[0])
				{
					float* ptr2 = (float*)ptr;
					float* ptr4 = (float*)ptr3;
					int num = bytesRead / 4;
					for (int i = 0; i < num; i++)
					{
						ptr2[i] += ptr4[i];
					}
				}
			}
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing)
			{
				lock (inputsLock)
				{
					foreach (WaveStream inputStream in inputStreams)
					{
						inputStream.Dispose();
					}
				}
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// Simply shifts the input stream in time, optionally
	/// clipping its start and end.
	/// (n.b. may include looping in the future)
	/// </summary>
	public class WaveOffsetStream : WaveStream
	{
		private WaveStream sourceStream;

		private long audioStartPosition;

		private long sourceOffsetBytes;

		private long sourceLengthBytes;

		private long length;

		private readonly int bytesPerSample;

		private long position;

		private TimeSpan startTime;

		private TimeSpan sourceOffset;

		private TimeSpan sourceLength;

		private readonly object lockObject = new object();

		/// <summary>
		/// The length of time before which no audio will be played
		/// </summary>
		public TimeSpan StartTime
		{
			get
			{
				return startTime;
			}
			set
			{
				lock (lockObject)
				{
					startTime = value;
					audioStartPosition = (long)(startTime.TotalSeconds * (double)sourceStream.WaveFormat.SampleRate) * bytesPerSample;
					length = audioStartPosition + sourceLengthBytes;
					Position = Position;
				}
			}
		}

		/// <summary>
		/// An offset into the source stream from which to start playing
		/// </summary>
		public TimeSpan SourceOffset
		{
			get
			{
				return sourceOffset;
			}
			set
			{
				lock (lockObject)
				{
					sourceOffset = value;
					sourceOffsetBytes = (long)(sourceOffset.TotalSeconds * (double)sourceStream.WaveFormat.SampleRate) * bytesPerSample;
					Position = Position;
				}
			}
		}

		/// <summary>
		/// Length of time to read from the source stream
		/// </summary>
		public TimeSpan SourceLength
		{
			get
			{
				return sourceLength;
			}
			set
			{
				lock (lockObject)
				{
					sourceLength = value;
					sourceLengthBytes = (long)(sourceLength.TotalSeconds * (double)sourceStream.WaveFormat.SampleRate) * bytesPerSample;
					length = audioStartPosition + sourceLengthBytes;
					Position = Position;
				}
			}
		}

		/// <summary>
		/// Gets the block alignment for this WaveStream
		/// </summary>
		public override int BlockAlign => sourceStream.BlockAlign;

		/// <summary>
		/// Returns the stream length
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Gets or sets the current position in the stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				lock (lockObject)
				{
					value -= value % BlockAlign;
					if (value < audioStartPosition)
					{
						sourceStream.Position = sourceOffsetBytes;
					}
					else
					{
						sourceStream.Position = sourceOffsetBytes + (value - audioStartPosition);
					}
					position = value;
				}
			}
		}

		/// <summary>
		/// <see cref="P:NAudio.Wave.WaveStream.WaveFormat" />
		/// </summary>
		public override WaveFormat WaveFormat => sourceStream.WaveFormat;

		/// <summary>
		/// Creates a new WaveOffsetStream
		/// </summary>
		/// <param name="sourceStream">the source stream</param>
		/// <param name="startTime">the time at which we should start reading from the source stream</param>
		/// <param name="sourceOffset">amount to trim off the front of the source stream</param>
		/// <param name="sourceLength">length of time to play from source stream</param>
		public WaveOffsetStream(WaveStream sourceStream, TimeSpan startTime, TimeSpan sourceOffset, TimeSpan sourceLength)
		{
			if (sourceStream.WaveFormat.Encoding != WaveFormatEncoding.Pcm)
			{
				throw new ArgumentException("Only PCM supported");
			}
			this.sourceStream = sourceStream;
			position = 0L;
			bytesPerSample = sourceStream.WaveFormat.BitsPerSample / 8 * sourceStream.WaveFormat.Channels;
			StartTime = startTime;
			SourceOffset = sourceOffset;
			SourceLength = sourceLength;
		}

		/// <summary>
		/// Creates a WaveOffsetStream with default settings (no offset or pre-delay,
		/// and whole length of source stream)
		/// </summary>
		/// <param name="sourceStream">The source stream</param>
		public WaveOffsetStream(WaveStream sourceStream)
			: this(sourceStream, TimeSpan.Zero, TimeSpan.Zero, sourceStream.TotalTime)
		{
		}

		/// <summary>
		/// Reads bytes from this wave stream
		/// </summary>
		/// <param name="destBuffer">The destination buffer</param>
		/// <param name="offset">Offset into the destination buffer</param>
		/// <param name="numBytes">Number of bytes read</param>
		/// <returns>Number of bytes read.</returns>
		public override int Read(byte[] destBuffer, int offset, int numBytes)
		{
			lock (lockObject)
			{
				int num = 0;
				if (position < audioStartPosition)
				{
					num = (int)Math.Min(numBytes, audioStartPosition - position);
					for (int i = 0; i < num; i++)
					{
						destBuffer[i + offset] = 0;
					}
				}
				if (num < numBytes)
				{
					int count = (int)Math.Min(numBytes - num, sourceLengthBytes + sourceOffsetBytes - sourceStream.Position);
					int num2 = sourceStream.Read(destBuffer, num + offset, count);
					num += num2;
				}
				for (int j = num; j < numBytes; j++)
				{
					destBuffer[offset + j] = 0;
				}
				position += numBytes;
				return numBytes;
			}
		}

		/// <summary>
		/// Determines whether this channel has any data to play
		/// to allow optimisation to not read, but bump position forward
		/// </summary>
		public override bool HasData(int count)
		{
			if (position + count < audioStartPosition)
			{
				return false;
			}
			if (position >= length)
			{
				return false;
			}
			return sourceStream.HasData(count);
		}

		/// <summary>
		/// Disposes this WaveStream
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && sourceStream != null)
			{
				sourceStream.Dispose();
				sourceStream = null;
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// Base class for creating a 16 bit wave provider
	/// </summary>
	public abstract class WaveProvider16 : IWaveProvider
	{
		private WaveFormat waveFormat;

		/// <summary>
		/// The Wave Format
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Initializes a new instance of the WaveProvider16 class 
		/// defaulting to 44.1kHz mono
		/// </summary>
		public WaveProvider16()
			: this(44100, 1)
		{
		}

		/// <summary>
		/// Initializes a new instance of the WaveProvider16 class with the specified
		/// sample rate and number of channels
		/// </summary>
		public WaveProvider16(int sampleRate, int channels)
		{
			SetWaveFormat(sampleRate, channels);
		}

		/// <summary>
		/// Allows you to specify the sample rate and channels for this WaveProvider
		/// (should be initialised before you pass it to a wave player)
		/// </summary>
		public void SetWaveFormat(int sampleRate, int channels)
		{
			waveFormat = new WaveFormat(sampleRate, 16, channels);
		}

		/// <summary>
		/// Implements the Read method of IWaveProvider by delegating to the abstract
		/// Read method taking a short array
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			WaveBuffer waveBuffer = new WaveBuffer(buffer);
			int sampleCount = count / 2;
			return Read(waveBuffer.ShortBuffer, offset / 2, sampleCount) * 2;
		}

		/// <summary>
		/// Method to override in derived classes
		/// Supply the requested number of samples into the buffer
		/// </summary>
		public abstract int Read(short[] buffer, int offset, int sampleCount);
	}

	/// <summary>
	/// Base class for creating a 32 bit floating point wave provider
	/// Can also be used as a base class for an ISampleProvider that can 
	/// be plugged straight into anything requiring an IWaveProvider
	/// </summary>
	public abstract class WaveProvider32 : IWaveProvider, ISampleProvider
	{
		private WaveFormat waveFormat;

		/// <summary>
		/// The Wave Format
		/// </summary>
		public WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// Initializes a new instance of the WaveProvider32 class 
		/// defaulting to 44.1kHz mono
		/// </summary>
		public WaveProvider32()
			: this(44100, 1)
		{
		}

		/// <summary>
		/// Initializes a new instance of the WaveProvider32 class with the specified
		/// sample rate and number of channels
		/// </summary>
		public WaveProvider32(int sampleRate, int channels)
		{
			SetWaveFormat(sampleRate, channels);
		}

		/// <summary>
		/// Allows you to specify the sample rate and channels for this WaveProvider
		/// (should be initialised before you pass it to a wave player)
		/// </summary>
		public void SetWaveFormat(int sampleRate, int channels)
		{
			waveFormat = WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channels);
		}

		/// <summary>
		/// Implements the Read method of IWaveProvider by delegating to the abstract
		/// Read method taking a float array
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			WaveBuffer waveBuffer = new WaveBuffer(buffer);
			int sampleCount = count / 4;
			return Read(waveBuffer.FloatBuffer, offset / 4, sampleCount) * 4;
		}

		/// <summary>
		/// Method to override in derived classes
		/// Supply the requested number of samples into the buffer
		/// </summary>
		public abstract int Read(float[] buffer, int offset, int sampleCount);
	}

	/// <summary>
	/// Utility class to intercept audio from an IWaveProvider and
	/// save it to disk
	/// </summary>
	public class WaveRecorder : IWaveProvider, IDisposable
	{
		private WaveFileWriter writer;

		private IWaveProvider source;

		/// <summary>
		/// The WaveFormat
		/// </summary>
		public WaveFormat WaveFormat => source.WaveFormat;

		/// <summary>
		/// Constructs a new WaveRecorder
		/// </summary>
		/// <param name="destination">The location to write the WAV file to</param>
		/// <param name="source">The Source Wave Provider</param>
		public WaveRecorder(IWaveProvider source, string destination)
		{
			this.source = source;
			writer = new WaveFileWriter(destination, source.WaveFormat);
		}

		/// <summary>
		/// Read simply returns what the source returns, but writes to disk along the way
		/// </summary>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = source.Read(buffer, offset, count);
			writer.Write(buffer, offset, num);
			return num;
		}

		/// <summary>
		/// Closes the WAV file
		/// </summary>
		public void Dispose()
		{
			if (writer != null)
			{
				writer.Dispose();
				writer = null;
			}
		}
	}

	/// <summary>
	/// Base class for all WaveStream classes. Derives from stream.
	/// </summary>
	public abstract class WaveStream : Stream, IWaveProvider
	{
		/// <summary>
		/// Retrieves the WaveFormat for this stream
		/// </summary>
		public abstract WaveFormat WaveFormat { get; }

		/// <summary>
		/// We can read from this stream
		/// </summary>
		public override bool CanRead => true;

		/// <summary>
		/// We can seek within this stream
		/// </summary>
		public override bool CanSeek => true;

		/// <summary>
		/// We can't write to this stream
		/// </summary>
		public override bool CanWrite => false;

		/// <summary>
		/// The block alignment for this wavestream. Do not modify the Position
		/// to anything that is not a whole multiple of this value
		/// </summary>
		public virtual int BlockAlign => WaveFormat.BlockAlign;

		/// <summary>
		/// The current position in the stream in Time format
		/// </summary>
		public virtual TimeSpan CurrentTime
		{
			get
			{
				return TimeSpan.FromSeconds((double)Position / (double)WaveFormat.AverageBytesPerSecond);
			}
			set
			{
				Position = (long)(value.TotalSeconds * (double)WaveFormat.AverageBytesPerSecond);
			}
		}

		/// <summary>
		/// Total length in real-time of the stream (may be an estimate for compressed files)
		/// </summary>
		public virtual TimeSpan TotalTime => TimeSpan.FromSeconds((double)Length / (double)WaveFormat.AverageBytesPerSecond);

		/// <summary>
		/// Flush does not need to do anything
		/// See <see cref="M:System.IO.Stream.Flush" />
		/// </summary>
		public override void Flush()
		{
		}

		/// <summary>
		/// An alternative way of repositioning.
		/// See <see cref="M:System.IO.Stream.Seek(System.Int64,System.IO.SeekOrigin)" />
		/// </summary>
		public override long Seek(long offset, SeekOrigin origin)
		{
			switch (origin)
			{
			case SeekOrigin.Begin:
				Position = offset;
				break;
			case SeekOrigin.Current:
				Position += offset;
				break;
			default:
				Position = Length + offset;
				break;
			}
			return Position;
		}

		/// <summary>
		/// Sets the length of the WaveStream. Not Supported.
		/// </summary>
		/// <param name="length"></param>
		public override void SetLength(long length)
		{
			throw new NotSupportedException("Can't set length of a WaveFormatString");
		}

		/// <summary>
		/// Writes to the WaveStream. Not Supported.
		/// </summary>
		public override void Write(byte[] buffer, int offset, int count)
		{
			throw new NotSupportedException("Can't write to a WaveFormatString");
		}

		/// <summary>
		/// Moves forward or backwards the specified number of seconds in the stream
		/// </summary>
		/// <param name="seconds">Number of seconds to move, can be negative</param>
		public void Skip(int seconds)
		{
			long num = Position + WaveFormat.AverageBytesPerSecond * seconds;
			if (num > Length)
			{
				Position = Length;
			}
			else if (num < 0)
			{
				Position = 0L;
			}
			else
			{
				Position = num;
			}
		}

		/// <summary>
		/// Whether the WaveStream has non-zero sample data at the current position for the 
		/// specified count
		/// </summary>
		/// <param name="count">Number of bytes to read</param>
		public virtual bool HasData(int count)
		{
			return Position < Length;
		}
	}

	/// <summary>
	/// Represents a Xing VBR header
	/// </summary>
	public class XingHeader
	{
		[Flags]
		private enum XingHeaderOptions
		{
			Frames = 1,
			Bytes = 2,
			Toc = 4,
			VbrScale = 8
		}

		private static int[] sr_table = new int[4] { 44100, 48000, 32000, 99999 };

		private int vbrScale = -1;

		private int startOffset;

		private int endOffset;

		private int tocOffset = -1;

		private int framesOffset = -1;

		private int bytesOffset = -1;

		private Mp3Frame frame;

		/// <summary>
		/// Number of frames
		/// </summary>
		public int Frames
		{
			get
			{
				if (framesOffset == -1)
				{
					return -1;
				}
				return ReadBigEndian(frame.RawData, framesOffset);
			}
			set
			{
				if (framesOffset == -1)
				{
					throw new InvalidOperationException("Frames flag is not set");
				}
				WriteBigEndian(frame.RawData, framesOffset, value);
			}
		}

		/// <summary>
		/// Number of bytes
		/// </summary>
		public int Bytes
		{
			get
			{
				if (bytesOffset == -1)
				{
					return -1;
				}
				return ReadBigEndian(frame.RawData, bytesOffset);
			}
			set
			{
				if (framesOffset == -1)
				{
					throw new InvalidOperationException("Bytes flag is not set");
				}
				WriteBigEndian(frame.RawData, bytesOffset, value);
			}
		}

		/// <summary>
		/// VBR Scale property
		/// </summary>
		public int VbrScale => vbrScale;

		/// <summary>
		/// The MP3 frame
		/// </summary>
		public Mp3Frame Mp3Frame => frame;

		private static int ReadBigEndian(byte[] buffer, int offset)
		{
			return (((((buffer[offset] << 8) | buffer[offset + 1]) << 8) | buffer[offset + 2]) << 8) | buffer[offset + 3];
		}

		private void WriteBigEndian(byte[] buffer, int offset, int value)
		{
			byte[] bytes = BitConverter.GetBytes(value);
			for (int i = 0; i < 4; i++)
			{
				buffer[offset + 3 - i] = bytes[i];
			}
		}

		/// <summary>
		/// Load Xing Header
		/// </summary>
		/// <param name="frame">Frame</param>
		/// <returns>Xing Header</returns>
		public static XingHeader LoadXingHeader(Mp3Frame frame)
		{
			XingHeader xingHeader = new XingHeader();
			xingHeader.frame = frame;
			int num = 0;
			if (frame.MpegVersion == MpegVersion.Version1)
			{
				num = ((frame.ChannelMode == ChannelMode.Mono) ? 21 : 36);
			}
			else
			{
				if (frame.MpegVersion != MpegVersion.Version2)
				{
					return null;
				}
				num = ((frame.ChannelMode == ChannelMode.Mono) ? 13 : 21);
			}
			if (frame.RawData[num] == 88 && frame.RawData[num + 1] == 105 && frame.RawData[num + 2] == 110 && frame.RawData[num + 3] == 103)
			{
				xingHeader.startOffset = num;
				num += 4;
			}
			else
			{
				if (frame.RawData[num] != 73 || frame.RawData[num + 1] != 110 || frame.RawData[num + 2] != 102 || frame.RawData[num + 3] != 111)
				{
					return null;
				}
				xingHeader.startOffset = num;
				num += 4;
			}
			int num2 = ReadBigEndian(frame.RawData, num);
			num += 4;
			if (((uint)num2 & (true ? 1u : 0u)) != 0)
			{
				xingHeader.framesOffset = num;
				num += 4;
			}
			if (((uint)num2 & 2u) != 0)
			{
				xingHeader.bytesOffset = num;
				num += 4;
			}
			if (((uint)num2 & 4u) != 0)
			{
				xingHeader.tocOffset = num;
				num += 100;
			}
			if (((uint)num2 & 8u) != 0)
			{
				xingHeader.vbrScale = ReadBigEndian(frame.RawData, num);
				num += 4;
			}
			xingHeader.endOffset = num;
			return xingHeader;
		}

		/// <summary>
		/// Sees if a frame contains a Xing header
		/// </summary>
		private XingHeader()
		{
		}
	}

	/// <summary>
	/// AudioFileReader simplifies opening an audio file in NAudio
	/// Simply pass in the filename, and it will attempt to open the
	/// file and set up a conversion path that turns into PCM IEEE float.
	/// ACM codecs will be used for conversion.
	/// It provides a volume property and implements both WaveStream and
	/// ISampleProvider, making it possibly the only stage in your audio
	/// pipeline necessary for simple playback scenarios
	/// </summary>
	public class AudioFileReader : WaveStream, ISampleProvider
	{
		private WaveStream readerStream;

		private readonly SampleChannel sampleChannel;

		private readonly int destBytesPerSample;

		private readonly int sourceBytesPerSample;

		private readonly long length;

		private readonly object lockObject;

		/// <summary>
		/// File Name
		/// </summary>
		public string FileName { get; }

		/// <summary>
		/// WaveFormat of this stream
		/// </summary>
		public override WaveFormat WaveFormat => sampleChannel.WaveFormat;

		/// <summary>
		/// Length of this stream (in bytes)
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Position of this stream (in bytes)
		/// </summary>
		public override long Position
		{
			get
			{
				return SourceToDest(readerStream.Position);
			}
			set
			{
				lock (lockObject)
				{
					readerStream.Position = DestToSource(value);
				}
			}
		}

		/// <summary>
		/// Gets or Sets the Volume of this AudioFileReader. 1.0f is full volume
		/// </summary>
		public float Volume
		{
			get
			{
				return sampleChannel.Volume;
			}
			set
			{
				sampleChannel.Volume = value;
			}
		}

		/// <summary>
		/// Initializes a new instance of AudioFileReader
		/// </summary>
		/// <param name="fileName">The file to open</param>
		public AudioFileReader(string fileName)
		{
			lockObject = new object();
			FileName = fileName;
			CreateReaderStream(fileName);
			sourceBytesPerSample = readerStream.WaveFormat.BitsPerSample / 8 * readerStream.WaveFormat.Channels;
			sampleChannel = new SampleChannel(readerStream, forceStereo: false);
			destBytesPerSample = 4 * sampleChannel.WaveFormat.Channels;
			length = SourceToDest(readerStream.Length);
		}

		/// <summary>
		/// Creates the reader stream, supporting all filetypes in the core NAudio library,
		/// and ensuring we are in PCM format
		/// </summary>
		/// <param name="fileName">File Name</param>
		private void CreateReaderStream(string fileName)
		{
			if (fileName.EndsWith(".wav", StringComparison.OrdinalIgnoreCase))
			{
				readerStream = new WaveFileReader(fileName);
				if (readerStream.WaveFormat.Encoding != WaveFormatEncoding.Pcm && readerStream.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
				{
					readerStream = WaveFormatConversionStream.CreatePcmStream(readerStream);
					readerStream = new BlockAlignReductionStream(readerStream);
				}
			}
			else if (fileName.EndsWith(".mp3", StringComparison.OrdinalIgnoreCase))
			{
				if (Environment.OSVersion.Version.Major < 6)
				{
					readerStream = new Mp3FileReader(fileName);
				}
				else
				{
					readerStream = new MediaFoundationReader(fileName);
				}
			}
			else if (fileName.EndsWith(".aiff", StringComparison.OrdinalIgnoreCase) || fileName.EndsWith(".aif", StringComparison.OrdinalIgnoreCase))
			{
				readerStream = new AiffFileReader(fileName);
			}
			else
			{
				readerStream = new MediaFoundationReader(fileName);
			}
		}

		/// <summary>
		/// Reads from this wave stream
		/// </summary>
		/// <param name="buffer">Audio buffer</param>
		/// <param name="offset">Offset into buffer</param>
		/// <param name="count">Number of bytes required</param>
		/// <returns>Number of bytes read</returns>
		public override int Read(byte[] buffer, int offset, int count)
		{
			WaveBuffer waveBuffer = new WaveBuffer(buffer);
			int count2 = count / 4;
			return Read(waveBuffer.FloatBuffer, offset / 4, count2) * 4;
		}

		/// <summary>
		/// Reads audio from this sample provider
		/// </summary>
		/// <param name="buffer">Sample buffer</param>
		/// <param name="offset">Offset into sample buffer</param>
		/// <param name="count">Number of samples required</param>
		/// <returns>Number of samples read</returns>
		public int Read(float[] buffer, int offset, int count)
		{
			lock (lockObject)
			{
				return sampleChannel.Read(buffer, offset, count);
			}
		}

		/// <summary>
		/// Helper to convert source to dest bytes
		/// </summary>
		private long SourceToDest(long sourceBytes)
		{
			return destBytesPerSample * (sourceBytes / sourceBytesPerSample);
		}

		/// <summary>
		/// Helper to convert dest to source bytes
		/// </summary>
		private long DestToSource(long destBytes)
		{
			return sourceBytesPerSample * (destBytes / destBytesPerSample);
		}

		/// <summary>
		/// Disposes this AudioFileReader
		/// </summary>
		/// <param name="disposing">True if called from Dispose</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && readerStream != null)
			{
				readerStream.Dispose();
				readerStream = null;
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// Class for reading from MP3 files
	/// </summary>
	public class Mp3FileReader : Mp3FileReaderBase
	{
		/// <summary>Supports opening a MP3 file</summary>
		public Mp3FileReader(string mp3FileName)
			: base(File.OpenRead(mp3FileName), CreateAcmFrameDecompressor, ownInputStream: true)
		{
		}

		/// <summary>
		/// Opens MP3 from a stream rather than a file
		/// Will not dispose of this stream itself
		/// </summary>
		/// <param name="inputStream">The incoming stream containing MP3 data</param>
		public Mp3FileReader(Stream inputStream)
			: base(inputStream, CreateAcmFrameDecompressor, ownInputStream: false)
		{
		}

		/// <summary>
		/// Creates an ACM MP3 Frame decompressor. This is the default with NAudio
		/// </summary>
		/// <param name="mp3Format">A WaveFormat object based </param>
		/// <returns></returns>
		public static IMp3FrameDecompressor CreateAcmFrameDecompressor(WaveFormat mp3Format)
		{
			return new AcmMp3FrameDecompressor(mp3Format);
		}
	}
}

namespace NAudio.Extras
{
	using NAudio.Dsp;
	using NAudio.Wave;
	using NAudio.Wave.SampleProviders;
	
	/// <summary>
	/// Demo for fire and forget playback
	/// </summary>
	public class AudioPlaybackEngine : IDisposable
	{
		private readonly IWavePlayer outputDevice;

		private readonly MixingSampleProvider mixer;

		public AudioPlaybackEngine(int sampleRate = 44100, int channelCount = 2)
		{
			outputDevice = new WaveOutEvent();
			mixer = new MixingSampleProvider(WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channelCount));
			mixer.ReadFully = true;
			outputDevice.Init(mixer);
			outputDevice.Play();
		}

		public void PlaySound(string fileName)
		{
			AudioFileReader reader = new AudioFileReader(fileName);
			AddMixerInput(new AutoDisposeFileReader(reader));
		}

		private ISampleProvider ConvertToRightChannelCount(ISampleProvider input)
		{
			if (input.WaveFormat.Channels == mixer.WaveFormat.Channels)
			{
				return input;
			}
			if (input.WaveFormat.Channels == 1 && mixer.WaveFormat.Channels == 2)
			{
				return new MonoToStereoSampleProvider(input);
			}
			throw new NotImplementedException("Not yet implemented this channel count conversion");
		}

		public void PlaySound(CachedSound sound)
		{
			AddMixerInput(new CachedSoundSampleProvider(sound));
		}

		private void AddMixerInput(ISampleProvider input)
		{
			mixer.AddMixerInput(ConvertToRightChannelCount(input));
		}

		public void Dispose()
		{
			outputDevice.Dispose();
		}
	}

	/// <summary>
	/// Used by AudioPlaybackEngine
	/// </summary>
	public class AutoDisposeFileReader : ISampleProvider
	{
		private readonly ISampleProvider reader;

		private bool isDisposed;

		public WaveFormat WaveFormat { get; }

		public AutoDisposeFileReader(ISampleProvider reader)
		{
			this.reader = reader;
			WaveFormat = reader.WaveFormat;
		}

		public int Read(float[] buffer, int offset, int count)
		{
			if (isDisposed)
			{
				return 0;
			}
			int num = reader.Read(buffer, offset, count);
			if (num == 0)
			{
				if (reader is IDisposable disposable)
				{
					disposable.Dispose();
				}
				isDisposed = true;
			}
			return num;
		}
	}

	/// <summary>
	/// Used by AudioPlaybackEngine
	/// </summary>
	public class CachedSound
	{
		public float[] AudioData { get; }

		public WaveFormat WaveFormat { get; }

		public CachedSound(string audioFileName)
		{
			using AudioFileReader audioFileReader = new AudioFileReader(audioFileName);
			WaveFormat = audioFileReader.WaveFormat;
			List<float> list = new List<float>((int)(audioFileReader.Length / 4));
			float[] array = new float[audioFileReader.WaveFormat.SampleRate * audioFileReader.WaveFormat.Channels];
			int count;
			while ((count = audioFileReader.Read(array, 0, array.Length)) > 0)
			{
				list.AddRange(array.Take(count));
			}
			AudioData = list.ToArray();
		}
	}

	internal class CachedSoundSampleProvider : ISampleProvider
	{
		private readonly CachedSound cachedSound;

		private long position;

		public WaveFormat WaveFormat => cachedSound.WaveFormat;

		public CachedSoundSampleProvider(CachedSound cachedSound)
		{
			this.cachedSound = cachedSound;
		}

		public int Read(float[] buffer, int offset, int count)
		{
			long num = Math.Min(cachedSound.AudioData.Length - position, count);
			Array.Copy(cachedSound.AudioData, position, buffer, offset, num);
			position += num;
			return (int)num;
		}
	}

	/// <summary>
	/// Basic example of a multi-band eq
	/// uses the same settings for both channels in stereo audio
	/// Call Update after you've updated the bands
	/// Potentially to be added to NAudio in a future version
	/// </summary>
	public class Equalizer : ISampleProvider
	{
		private readonly ISampleProvider sourceProvider;

		private readonly EqualizerBand[] bands;

		private readonly BiQuadFilter[,] filters;

		private readonly int channels;

		private readonly int bandCount;

		private bool updated;

		public WaveFormat WaveFormat => sourceProvider.WaveFormat;

		public Equalizer(ISampleProvider sourceProvider, EqualizerBand[] bands)
		{
			this.sourceProvider = sourceProvider;
			this.bands = bands;
			channels = sourceProvider.WaveFormat.Channels;
			bandCount = bands.Length;
			filters = new BiQuadFilter[channels, bands.Length];
			CreateFilters();
		}

		private void CreateFilters()
		{
			for (int i = 0; i < bandCount; i++)
			{
				EqualizerBand equalizerBand = bands[i];
				for (int j = 0; j < channels; j++)
				{
					if (filters[j, i] == null)
					{
						filters[j, i] = BiQuadFilter.PeakingEQ(sourceProvider.WaveFormat.SampleRate, equalizerBand.Frequency, equalizerBand.Bandwidth, equalizerBand.Gain);
					}
					else
					{
						filters[j, i].SetPeakingEq(sourceProvider.WaveFormat.SampleRate, equalizerBand.Frequency, equalizerBand.Bandwidth, equalizerBand.Gain);
					}
				}
			}
		}

		public void Update()
		{
			updated = true;
			CreateFilters();
		}

		public int Read(float[] buffer, int offset, int count)
		{
			int num = sourceProvider.Read(buffer, offset, count);
			if (updated)
			{
				CreateFilters();
				updated = false;
			}
			for (int i = 0; i < num; i++)
			{
				int num2 = i % channels;
				for (int j = 0; j < bandCount; j++)
				{
					buffer[offset + i] = filters[num2, j].Transform(buffer[offset + i]);
				}
			}
			return num;
		}
	}

	public class EqualizerBand
	{
		public float Frequency { get; set; }

		public float Gain { get; set; }

		public float Bandwidth { get; set; }
	}

	public class FftEventArgs : EventArgs
	{
		public Complex[] Result { get; private set; }

		[DebuggerStepThrough]
		public FftEventArgs(Complex[] result)
		{
			Result = result;
		}
	}

	/// <summary>
	/// Loopable WaveStream
	/// </summary>
	public class LoopStream : WaveStream
	{
		private readonly WaveStream sourceStream;

		/// <summary>
		/// The WaveFormat of this stream
		/// </summary>
		public override WaveFormat WaveFormat => sourceStream.WaveFormat;

		/// <summary>
		/// Length in bytes of this stream (effectively infinite)
		/// </summary>
		public override long Length => 288230376151711743L;

		/// <summary>
		/// Position within this stream in bytes
		/// </summary>
		public override long Position
		{
			get
			{
				return sourceStream.Position;
			}
			set
			{
				sourceStream.Position = value;
			}
		}

		/// <summary>
		/// Creates a new Loop stream
		/// </summary>
		public LoopStream(WaveStream source)
		{
			sourceStream = source;
		}

		/// <summary>
		/// Always has data available
		/// </summary>
		public override bool HasData(int count)
		{
			return true;
		}

		/// <summary>
		/// Read data from this stream
		/// </summary>
		public override int Read(byte[] buffer, int offset, int count)
		{
			int i;
			int num2;
			for (i = 0; i < count; i += num2)
			{
				int num = count - i;
				num2 = sourceStream.Read(buffer, offset + i, num);
				if (num2 < num)
				{
					sourceStream.Position = 0L;
				}
				if (sourceStream.Position >= sourceStream.Length)
				{
					sourceStream.Position = 0L;
				}
			}
			return i;
		}

		/// <summary>
		/// Dispose this WaveStream (disposes the source)
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			sourceStream.Dispose();
			base.Dispose(disposing);
		}
	}

	public class MaxSampleEventArgs : EventArgs
	{
		public float MaxSample { get; private set; }

		public float MinSample { get; private set; }

		[DebuggerStepThrough]
		public MaxSampleEventArgs(float minValue, float maxValue)
		{
			MaxSample = maxValue;
			MinSample = minValue;
		}
	}

	/// <summary>
	/// Demo sample provider that performs FFTs
	/// </summary>
	public class SampleAggregator : ISampleProvider
	{
		private float maxValue;

		private float minValue;

		private int count;

		private readonly Complex[] fftBuffer;

		private readonly FftEventArgs fftArgs;

		private int fftPos;

		private readonly int fftLength;

		private readonly int m;

		private readonly ISampleProvider source;

		private readonly int channels;

		public int NotificationCount { get; set; }

		public bool PerformFFT { get; set; }

		public WaveFormat WaveFormat => source.WaveFormat;

		public event EventHandler<MaxSampleEventArgs> MaximumCalculated;

		public event EventHandler<FftEventArgs> FftCalculated;

		public SampleAggregator(ISampleProvider source, int fftLength = 1024)
		{
			channels = source.WaveFormat.Channels;
			if (!IsPowerOfTwo(fftLength))
			{
				throw new ArgumentException("FFT Length must be a power of two");
			}
			m = (int)Math.Log(fftLength, 2.0);
			this.fftLength = fftLength;
			fftBuffer = new Complex[fftLength];
			fftArgs = new FftEventArgs(fftBuffer);
			this.source = source;
		}

		private static bool IsPowerOfTwo(int x)
		{
			return (x & (x - 1)) == 0;
		}

		public void Reset()
		{
			count = 0;
			maxValue = (minValue = 0f);
		}

		private void Add(float value)
		{
			if (PerformFFT && this.FftCalculated != null)
			{
				fftBuffer[fftPos].X = (float)((double)value * FastFourierTransform.HammingWindow(fftPos, fftLength));
				fftBuffer[fftPos].Y = 0f;
				fftPos++;
				if (fftPos >= fftBuffer.Length)
				{
					fftPos = 0;
					FastFourierTransform.FFT(forward: true, m, fftBuffer);
					this.FftCalculated(this, fftArgs);
				}
			}
			maxValue = Math.Max(maxValue, value);
			minValue = Math.Min(minValue, value);
			count++;
			if (count >= NotificationCount && NotificationCount > 0)
			{
				this.MaximumCalculated?.Invoke(this, new MaxSampleEventArgs(minValue, maxValue));
				Reset();
			}
		}

		public int Read(float[] buffer, int offset, int count)
		{
			int num = source.Read(buffer, offset, count);
			for (int i = 0; i < num; i += channels)
			{
				Add(buffer[i + offset]);
			}
			return num;
		}
	}
}


namespace NAudio.Midi
{
	using NAudio.Utils;
	using System.Collections;
	
	/// <summary>
	/// Represents a MIDI Channel AfterTouch Event.
	/// </summary>
	public class ChannelAfterTouchEvent : MidiEvent
	{
		private byte afterTouchPressure;

		/// <summary>
		/// The aftertouch pressure value
		/// </summary>
		public int AfterTouchPressure
		{
			get
			{
				return afterTouchPressure;
			}
			set
			{
				if (value < 0 || value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "After touch pressure must be in the range 0-127");
				}
				afterTouchPressure = (byte)value;
			}
		}

		/// <summary>
		/// Creates a new ChannelAfterTouchEvent from raw MIDI data
		/// </summary>
		/// <param name="br">A binary reader</param>
		public ChannelAfterTouchEvent(BinaryReader br)
		{
			afterTouchPressure = br.ReadByte();
			if ((afterTouchPressure & 0x80u) != 0)
			{
				throw new FormatException("Invalid afterTouchPressure");
			}
		}

		/// <summary>
		/// Creates a new Channel After-Touch Event
		/// </summary>
		/// <param name="absoluteTime">Absolute time</param>
		/// <param name="channel">Channel</param>
		/// <param name="afterTouchPressure">After-touch pressure</param>
		public ChannelAfterTouchEvent(long absoluteTime, int channel, int afterTouchPressure)
			: base(absoluteTime, channel, MidiCommandCode.ChannelAfterTouch)
		{
			AfterTouchPressure = afterTouchPressure;
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(afterTouchPressure);
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.GetAsShortMessage" />
		/// </summary>
		public override int GetAsShortMessage()
		{
			return base.GetAsShortMessage() + (afterTouchPressure << 8);
		}

		/// <summary>
		/// Describes this channel after-touch event
		/// </summary>
		public override string ToString()
		{
			return $"{base.ToString()} {afterTouchPressure}";
		}
	}

	/// <summary>
	/// Represents a MIDI control change event
	/// </summary>
	public class ControlChangeEvent : MidiEvent
	{
		private MidiController controller;

		private byte controllerValue;

		/// <summary>
		/// The controller number
		/// </summary>
		public MidiController Controller
		{
			get
			{
				return controller;
			}
			set
			{
				if ((int)value < 0 || (int)value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "Controller number must be in the range 0-127");
				}
				controller = value;
			}
		}

		/// <summary>
		/// The controller value
		/// </summary>
		public int ControllerValue
		{
			get
			{
				return controllerValue;
			}
			set
			{
				if (value < 0 || value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "Controller Value must be in the range 0-127");
				}
				controllerValue = (byte)value;
			}
		}

		/// <summary>
		/// Reads a control change event from a MIDI stream
		/// </summary>
		/// <param name="br">Binary reader on the MIDI stream</param>
		public ControlChangeEvent(BinaryReader br)
		{
			byte b = br.ReadByte();
			controllerValue = br.ReadByte();
			if ((b & 0x80u) != 0)
			{
				throw new InvalidDataException("Invalid controller");
			}
			controller = (MidiController)b;
			if ((controllerValue & 0x80u) != 0)
			{
				throw new InvalidDataException($"Invalid controllerValue {controllerValue} for controller {controller}, Pos 0x{br.BaseStream.Position:X}");
			}
		}

		/// <summary>
		/// Creates a control change event
		/// </summary>
		/// <param name="absoluteTime">Time</param>
		/// <param name="channel">MIDI Channel Number</param>
		/// <param name="controller">The MIDI Controller</param>
		/// <param name="controllerValue">Controller value</param>
		public ControlChangeEvent(long absoluteTime, int channel, MidiController controller, int controllerValue)
			: base(absoluteTime, channel, MidiCommandCode.ControlChange)
		{
			Controller = controller;
			ControllerValue = controllerValue;
		}

		/// <summary>
		/// Describes this control change event
		/// </summary>
		/// <returns>A string describing this event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} Controller {controller} Value {controllerValue}";
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.GetAsShortMessage" />
		/// </summary>
		public override int GetAsShortMessage()
		{
			byte b = (byte)controller;
			return base.GetAsShortMessage() + (b << 8) + (controllerValue << 16);
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)controller);
			writer.Write(controllerValue);
		}
	}

	/// <summary>
	/// Represents a MIDI key signature event event
	/// </summary>
	public class KeySignatureEvent : MetaEvent
	{
		private readonly byte sharpsFlats;

		private readonly byte majorMinor;

		/// <summary>
		/// Number of sharps or flats
		/// </summary>
		public int SharpsFlats => (sbyte)sharpsFlats;

		/// <summary>
		/// Major or Minor key
		/// </summary>
		public int MajorMinor => majorMinor;

		/// <summary>
		/// Reads a new track sequence number event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">the data length</param>
		public KeySignatureEvent(BinaryReader br, int length)
		{
			if (length != 2)
			{
				throw new FormatException("Invalid key signature length");
			}
			sharpsFlats = br.ReadByte();
			majorMinor = br.ReadByte();
		}

		/// <summary>
		/// Creates a new Key signature event with the specified data
		/// </summary>
		public KeySignatureEvent(int sharpsFlats, int majorMinor, long absoluteTime)
			: base(MetaEventType.KeySignature, 2, absoluteTime)
		{
			this.sharpsFlats = (byte)sharpsFlats;
			this.majorMinor = (byte)majorMinor;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (KeySignatureEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this event
		/// </summary>
		/// <returns>String describing the event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {SharpsFlats} {majorMinor}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(sharpsFlats);
			writer.Write(majorMinor);
		}
	}

	/// <summary>
	/// Represents a MIDI meta event
	/// </summary>
	public class MetaEvent : MidiEvent
	{
		private MetaEventType metaEvent;

		internal int metaDataLength;

		/// <summary>
		/// Gets the type of this meta event
		/// </summary>
		public MetaEventType MetaEventType => metaEvent;

		/// <summary>
		/// Empty constructor
		/// </summary>
		protected MetaEvent()
		{
		}

		/// <summary>
		/// Custom constructor for use by derived types, who will manage the data themselves
		/// </summary>
		/// <param name="metaEventType">Meta event type</param>
		/// <param name="metaDataLength">Meta data length</param>
		/// <param name="absoluteTime">Absolute time</param>
		public MetaEvent(MetaEventType metaEventType, int metaDataLength, long absoluteTime)
			: base(absoluteTime, 1, MidiCommandCode.MetaEvent)
		{
			metaEvent = metaEventType;
			this.metaDataLength = metaDataLength;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return new MetaEvent(metaEvent, metaDataLength, base.AbsoluteTime);
		}

		/// <summary>
		/// Reads a meta-event from a stream
		/// </summary>
		/// <param name="br">A binary reader based on the stream of MIDI data</param>
		/// <returns>A new MetaEvent object</returns>
		public static MetaEvent ReadMetaEvent(BinaryReader br)
		{
			MetaEventType metaEventType = (MetaEventType)br.ReadByte();
			int num = MidiEvent.ReadVarInt(br);
			MetaEvent metaEvent = new MetaEvent();
			if (metaEventType <= MetaEventType.SetTempo)
			{
				if (metaEventType <= MetaEventType.DeviceName)
				{
					if (metaEventType != 0)
					{
						if (metaEventType - 1 > MetaEventType.ProgramName)
						{
							goto IL_00a6;
						}
						metaEvent = new TextEvent(br, num);
					}
					else
					{
						metaEvent = new TrackSequenceNumberEvent(br, num);
					}
				}
				else if (metaEventType != MetaEventType.EndTrack)
				{
					if (metaEventType != MetaEventType.SetTempo)
					{
						goto IL_00a6;
					}
					metaEvent = new TempoEvent(br, num);
				}
				else if (num != 0)
				{
					throw new FormatException("End track length");
				}
			}
			else if (metaEventType <= MetaEventType.TimeSignature)
			{
				if (metaEventType != MetaEventType.SmpteOffset)
				{
					if (metaEventType != MetaEventType.TimeSignature)
					{
						goto IL_00a6;
					}
					metaEvent = new TimeSignatureEvent(br, num);
				}
				else
				{
					metaEvent = new SmpteOffsetEvent(br, num);
				}
			}
			else if (metaEventType != MetaEventType.KeySignature)
			{
				if (metaEventType != MetaEventType.SequencerSpecific)
				{
					goto IL_00a6;
				}
				metaEvent = new SequencerSpecificEvent(br, num);
			}
			else
			{
				metaEvent = new KeySignatureEvent(br, num);
			}
			metaEvent.metaEvent = metaEventType;
			metaEvent.metaDataLength = num;
			return metaEvent;
			IL_00a6:
			byte[] array = br.ReadBytes(num);
			if (array.Length != num)
			{
				throw new FormatException("Failed to read metaevent's data fully");
			}
			return new RawMetaEvent(metaEventType, 0L, array);
		}

		/// <summary>
		/// Describes this meta event
		/// </summary>
		public override string ToString()
		{
			return $"{base.AbsoluteTime} {metaEvent}";
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)" />
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)metaEvent);
			MidiEvent.WriteVarInt(writer, metaDataLength);
		}
	}

	/// <summary>
	/// MIDI MetaEvent Type
	/// </summary>
	public enum MetaEventType : byte
	{
		/// <summary>Track sequence number</summary>
		TrackSequenceNumber = 0,
		/// <summary>Text event</summary>
		TextEvent = 1,
		/// <summary>Copyright</summary>
		Copyright = 2,
		/// <summary>Sequence track name</summary>
		SequenceTrackName = 3,
		/// <summary>Track instrument name</summary>
		TrackInstrumentName = 4,
		/// <summary>Lyric</summary>
		Lyric = 5,
		/// <summary>Marker</summary>
		Marker = 6,
		/// <summary>Cue point</summary>
		CuePoint = 7,
		/// <summary>Program (patch) name</summary>
		ProgramName = 8,
		/// <summary>Device (port) name</summary>
		DeviceName = 9,
		/// <summary>MIDI Channel (not official?)</summary>
		MidiChannel = 32,
		/// <summary>MIDI Port (not official?)</summary>
		MidiPort = 33,
		/// <summary>End track</summary>
		EndTrack = 47,
		/// <summary>Set tempo</summary>
		SetTempo = 81,
		/// <summary>SMPTE offset</summary>
		SmpteOffset = 84,
		/// <summary>Time signature</summary>
		TimeSignature = 88,
		/// <summary>Key signature</summary>
		KeySignature = 89,
		/// <summary>Sequencer specific</summary>
		SequencerSpecific = 127
	}

	/// <summary>
	/// MIDI command codes
	/// </summary>
	public enum MidiCommandCode : byte
	{
		/// <summary>Note Off</summary>
		NoteOff = 128,
		/// <summary>Note On</summary>
		NoteOn = 144,
		/// <summary>Key After-touch</summary>
		KeyAfterTouch = 160,
		/// <summary>Control change</summary>
		ControlChange = 176,
		/// <summary>Patch change</summary>
		PatchChange = 192,
		/// <summary>Channel after-touch</summary>
		ChannelAfterTouch = 208,
		/// <summary>Pitch wheel change</summary>
		PitchWheelChange = 224,
		/// <summary>Sysex message</summary>
		Sysex = 240,
		/// <summary>Eox (comes at end of a sysex message)</summary>
		Eox = 247,
		/// <summary>Timing clock (used when synchronization is required)</summary>
		TimingClock = 248,
		/// <summary>Start sequence</summary>
		StartSequence = 250,
		/// <summary>Continue sequence</summary>
		ContinueSequence = 251,
		/// <summary>Stop sequence</summary>
		StopSequence = 252,
		/// <summary>Auto-Sensing</summary>
		AutoSensing = 254,
		/// <summary>Meta-event</summary>
		MetaEvent = byte.MaxValue
	}

	/// <summary>
	/// MidiController enumeration
	/// http://www.midi.org/techspecs/midimessages.php#3
	/// </summary>
	public enum MidiController : byte
	{
		/// <summary>Bank Select (MSB)</summary>
		BankSelect = 0,
		/// <summary>Modulation (MSB)</summary>
		Modulation = 1,
		/// <summary>Breath Controller</summary>
		BreathController = 2,
		/// <summary>Foot controller (MSB)</summary>
		FootController = 4,
		/// <summary>Main volume</summary>
		MainVolume = 7,
		/// <summary>Pan</summary>
		Pan = 10,
		/// <summary>Expression</summary>
		Expression = 11,
		/// <summary>Bank Select LSB</summary>
		BankSelectLsb = 32,
		/// <summary>Sustain</summary>
		Sustain = 64,
		/// <summary>Portamento On/Off</summary>
		Portamento = 65,
		/// <summary>Sostenuto On/Off</summary>
		Sostenuto = 66,
		/// <summary>Soft Pedal On/Off</summary>
		SoftPedal = 67,
		/// <summary>Legato Footswitch</summary>
		LegatoFootswitch = 68,
		/// <summary>Reset all controllers</summary>
		ResetAllControllers = 121,
		/// <summary>All notes off</summary>
		AllNotesOff = 123
	}

	/// <summary>
	/// Represents an individual MIDI event
	/// </summary>
	public class MidiEvent : ICloneable
	{
		/// <summary>The MIDI command code</summary>
		private MidiCommandCode commandCode;

		private int channel;

		private int deltaTime;

		private long absoluteTime;

		/// <summary>
		/// The MIDI Channel Number for this event (1-16)
		/// </summary>
		public virtual int Channel
		{
			get
			{
				return channel;
			}
			set
			{
				if (value < 1 || value > 16)
				{
					throw new ArgumentOutOfRangeException("value", value, $"Channel must be 1-16 (Got {value})");
				}
				channel = value;
			}
		}

		/// <summary>
		/// The Delta time for this event
		/// </summary>
		public int DeltaTime => deltaTime;

		/// <summary>
		/// The absolute time for this event
		/// </summary>
		public long AbsoluteTime
		{
			get
			{
				return absoluteTime;
			}
			set
			{
				absoluteTime = value;
			}
		}

		/// <summary>
		/// The command code for this event
		/// </summary>
		public MidiCommandCode CommandCode => commandCode;

		/// <summary>
		/// Creates a MidiEvent from a raw message received using
		/// the MME MIDI In APIs
		/// </summary>
		/// <param name="rawMessage">The short MIDI message</param>
		/// <returns>A new MIDI Event</returns>
		public static MidiEvent FromRawMessage(int rawMessage)
		{
			long num = 0L;
			int num2 = rawMessage & 0xFF;
			int num3 = (rawMessage >> 8) & 0xFF;
			int num4 = (rawMessage >> 16) & 0xFF;
			int num5 = 1;
			MidiCommandCode midiCommandCode;
			if ((num2 & 0xF0) == 240)
			{
				midiCommandCode = (MidiCommandCode)num2;
			}
			else
			{
				midiCommandCode = (MidiCommandCode)((uint)num2 & 0xF0u);
				num5 = (num2 & 0xF) + 1;
			}
			switch (midiCommandCode)
			{
			case MidiCommandCode.NoteOff:
			case MidiCommandCode.NoteOn:
			case MidiCommandCode.KeyAfterTouch:
				if (num4 > 0 && midiCommandCode == MidiCommandCode.NoteOn)
				{
					return new NoteOnEvent(num, num5, num3, num4, 0);
				}
				return new NoteEvent(num, num5, midiCommandCode, num3, num4);
			case MidiCommandCode.ControlChange:
				return new ControlChangeEvent(num, num5, (MidiController)num3, num4);
			case MidiCommandCode.PatchChange:
				return new PatchChangeEvent(num, num5, num3);
			case MidiCommandCode.ChannelAfterTouch:
				return new ChannelAfterTouchEvent(num, num5, num3);
			case MidiCommandCode.PitchWheelChange:
				return new PitchWheelChangeEvent(num, num5, num3 + (num4 << 7));
			case MidiCommandCode.TimingClock:
			case MidiCommandCode.StartSequence:
			case MidiCommandCode.ContinueSequence:
			case MidiCommandCode.StopSequence:
			case MidiCommandCode.AutoSensing:
				return new MidiEvent(num, num5, midiCommandCode);
			default:
				throw new FormatException($"Unsupported MIDI Command Code for Raw Message {midiCommandCode}");
			}
		}

		/// <summary>
		/// Constructs a MidiEvent from a BinaryStream
		/// </summary>
		/// <param name="br">The binary stream of MIDI data</param>
		/// <param name="previous">The previous MIDI event (pass null for first event)</param>
		/// <returns>A new MidiEvent</returns>
		public static MidiEvent ReadNextEvent(BinaryReader br, MidiEvent previous)
		{
			int num = ReadVarInt(br);
			int num2 = 1;
			byte b = br.ReadByte();
			MidiCommandCode midiCommandCode;
			if ((b & 0x80) == 0)
			{
				midiCommandCode = previous.CommandCode;
				num2 = previous.Channel;
				br.BaseStream.Position--;
			}
			else if ((b & 0xF0) == 240)
			{
				midiCommandCode = (MidiCommandCode)b;
			}
			else
			{
				midiCommandCode = (MidiCommandCode)(b & 0xF0u);
				num2 = (b & 0xF) + 1;
			}
			MidiEvent midiEvent;
			switch (midiCommandCode)
			{
			case MidiCommandCode.NoteOn:
				midiEvent = new NoteOnEvent(br);
				break;
			case MidiCommandCode.NoteOff:
			case MidiCommandCode.KeyAfterTouch:
				midiEvent = new NoteEvent(br);
				break;
			case MidiCommandCode.ControlChange:
				midiEvent = new ControlChangeEvent(br);
				break;
			case MidiCommandCode.PatchChange:
				midiEvent = new PatchChangeEvent(br);
				break;
			case MidiCommandCode.ChannelAfterTouch:
				midiEvent = new ChannelAfterTouchEvent(br);
				break;
			case MidiCommandCode.PitchWheelChange:
				midiEvent = new PitchWheelChangeEvent(br);
				break;
			case MidiCommandCode.TimingClock:
			case MidiCommandCode.StartSequence:
			case MidiCommandCode.ContinueSequence:
			case MidiCommandCode.StopSequence:
				midiEvent = new MidiEvent();
				break;
			case MidiCommandCode.Sysex:
				midiEvent = SysexEvent.ReadSysexEvent(br);
				break;
			case MidiCommandCode.MetaEvent:
				midiEvent = MetaEvent.ReadMetaEvent(br);
				break;
			default:
				throw new FormatException($"Unsupported MIDI Command Code {(byte)midiCommandCode:X2}");
			}
			midiEvent.channel = num2;
			midiEvent.deltaTime = num;
			midiEvent.commandCode = midiCommandCode;
			return midiEvent;
		}

		/// <summary>
		/// Converts this MIDI event to a short message (32 bit integer) that
		/// can be sent by the Windows MIDI out short message APIs
		/// Cannot be implemented for all MIDI messages
		/// </summary>
		/// <returns>A short message</returns>
		public virtual int GetAsShortMessage()
		{
			return channel - 1 + (int)commandCode;
		}

		/// <summary>
		/// Default constructor
		/// </summary>
		protected MidiEvent()
		{
		}

		/// <summary>
		/// Creates a MIDI event with specified parameters
		/// </summary>
		/// <param name="absoluteTime">Absolute time of this event</param>
		/// <param name="channel">MIDI channel number</param>
		/// <param name="commandCode">MIDI command code</param>
		public MidiEvent(long absoluteTime, int channel, MidiCommandCode commandCode)
		{
			this.absoluteTime = absoluteTime;
			Channel = channel;
			this.commandCode = commandCode;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public virtual MidiEvent Clone()
		{
			return (MidiEvent)MemberwiseClone();
		}

		object ICloneable.Clone()
		{
			return Clone();
		}

		/// <summary>
		/// Whether this is a note off event
		/// </summary>
		public static bool IsNoteOff(MidiEvent midiEvent)
		{
			if (midiEvent != null)
			{
				if (midiEvent.CommandCode == MidiCommandCode.NoteOn)
				{
					return ((NoteEvent)midiEvent).Velocity == 0;
				}
				return midiEvent.CommandCode == MidiCommandCode.NoteOff;
			}
			return false;
		}

		/// <summary>
		/// Whether this is a note on event
		/// </summary>
		public static bool IsNoteOn(MidiEvent midiEvent)
		{
			if (midiEvent != null && midiEvent.CommandCode == MidiCommandCode.NoteOn)
			{
				return ((NoteEvent)midiEvent).Velocity > 0;
			}
			return false;
		}

		/// <summary>
		/// Determines if this is an end track event
		/// </summary>
		public static bool IsEndTrack(MidiEvent midiEvent)
		{
			if (midiEvent != null && midiEvent is MetaEvent metaEvent)
			{
				return metaEvent.MetaEventType == MetaEventType.EndTrack;
			}
			return false;
		}

		/// <summary>
		/// Displays a summary of the MIDI event
		/// </summary>
		/// <returns>A string containing a brief description of this MIDI event</returns>
		public override string ToString()
		{
			if ((int)commandCode >= 240)
			{
				return $"{absoluteTime} {commandCode}";
			}
			return $"{absoluteTime} {commandCode} Ch: {channel}";
		}

		/// <summary>
		/// Utility function that can read a variable length integer from a binary stream
		/// </summary>
		/// <param name="br">The binary stream</param>
		/// <returns>The integer read</returns>
		public static int ReadVarInt(BinaryReader br)
		{
			int num = 0;
			for (int i = 0; i < 4; i++)
			{
				byte b = br.ReadByte();
				num <<= 7;
				num += b & 0x7F;
				if ((b & 0x80) == 0)
				{
					return num;
				}
			}
			throw new FormatException("Invalid Var Int");
		}

		/// <summary>
		/// Writes a variable length integer to a binary stream
		/// </summary>
		/// <param name="writer">Binary stream</param>
		/// <param name="value">The value to write</param>
		public static void WriteVarInt(BinaryWriter writer, int value)
		{
			if (value < 0)
			{
				throw new ArgumentOutOfRangeException("value", value, "Cannot write a negative Var Int");
			}
			if (value > 268435455)
			{
				throw new ArgumentOutOfRangeException("value", value, "Maximum allowed Var Int is 0x0FFFFFFF");
			}
			int num = 0;
			byte[] array = new byte[4];
			do
			{
				array[num++] = (byte)((uint)value & 0x7Fu);
				value >>= 7;
			}
			while (value > 0);
			while (num > 0)
			{
				num--;
				if (num > 0)
				{
					writer.Write((byte)(array[num] | 0x80u));
				}
				else
				{
					writer.Write(array[num]);
				}
			}
		}

		/// <summary>
		/// Exports this MIDI event's data
		/// Overriden in derived classes, but they should call this version
		/// </summary>
		/// <param name="absoluteTime">Absolute time used to calculate delta. 
		/// Is updated ready for the next delta calculation</param>
		/// <param name="writer">Stream to write to</param>
		public virtual void Export(ref long absoluteTime, BinaryWriter writer)
		{
			if (this.absoluteTime < absoluteTime)
			{
				throw new FormatException("Can't export unsorted MIDI events");
			}
			WriteVarInt(writer, (int)(this.absoluteTime - absoluteTime));
			absoluteTime = this.absoluteTime;
			int num = (int)commandCode;
			if (commandCode != MidiCommandCode.MetaEvent)
			{
				num += channel - 1;
			}
			writer.Write((byte)num);
		}
	}

	/// <summary>
	/// A helper class to manage collection of MIDI events
	/// It has the ability to organise them in tracks
	/// </summary>
	public class MidiEventCollection : IEnumerable<IList<MidiEvent>>, IEnumerable
	{
		private int midiFileType;

		private readonly List<IList<MidiEvent>> trackEvents;

		/// <summary>
		/// The number of tracks
		/// </summary>
		public int Tracks => trackEvents.Count;

		/// <summary>
		/// The absolute time that should be considered as time zero
		/// Not directly used here, but useful for timeshifting applications
		/// </summary>
		public long StartAbsoluteTime { get; set; }

		/// <summary>
		/// The number of ticks per quarter note
		/// </summary>
		public int DeltaTicksPerQuarterNote { get; }

		/// <summary>
		/// Gets events on a specific track
		/// </summary>
		/// <param name="trackNumber">Track number</param>
		/// <returns>The list of events</returns>
		public IList<MidiEvent> this[int trackNumber] => trackEvents[trackNumber];

		/// <summary>
		/// The MIDI file type
		/// </summary>
		public int MidiFileType
		{
			get
			{
				return midiFileType;
			}
			set
			{
				if (midiFileType != value)
				{
					midiFileType = value;
					if (value == 0)
					{
						FlattenToOneTrack();
					}
					else
					{
						ExplodeToManyTracks();
					}
				}
			}
		}

		/// <summary>
		/// Creates a new Midi Event collection
		/// </summary>
		/// <param name="midiFileType">Initial file type</param>
		/// <param name="deltaTicksPerQuarterNote">Delta Ticks Per Quarter Note</param>
		public MidiEventCollection(int midiFileType, int deltaTicksPerQuarterNote)
		{
			this.midiFileType = midiFileType;
			DeltaTicksPerQuarterNote = deltaTicksPerQuarterNote;
			StartAbsoluteTime = 0L;
			trackEvents = new List<IList<MidiEvent>>();
		}

		/// <summary>
		/// Gets events on a specified track
		/// </summary>
		/// <param name="trackNumber">Track number</param>
		/// <returns>The list of events</returns>
		public IList<MidiEvent> GetTrackEvents(int trackNumber)
		{
			return trackEvents[trackNumber];
		}

		/// <summary>
		/// Adds a new track
		/// </summary>
		/// <returns>The new track event list</returns>
		public IList<MidiEvent> AddTrack()
		{
			return AddTrack(null);
		}

		/// <summary>
		/// Adds a new track
		/// </summary>
		/// <param name="initialEvents">Initial events to add to the new track</param>
		/// <returns>The new track event list</returns>
		public IList<MidiEvent> AddTrack(IList<MidiEvent> initialEvents)
		{
			List<MidiEvent> list = new List<MidiEvent>();
			if (initialEvents != null)
			{
				list.AddRange(initialEvents);
			}
			trackEvents.Add(list);
			return list;
		}

		/// <summary>
		/// Removes a track
		/// </summary>
		/// <param name="track">Track number to remove</param>
		public void RemoveTrack(int track)
		{
			trackEvents.RemoveAt(track);
		}

		/// <summary>
		/// Clears all events
		/// </summary>
		public void Clear()
		{
			trackEvents.Clear();
		}

		/// <summary>
		/// Adds an event to the appropriate track depending on file type
		/// </summary>
		/// <param name="midiEvent">The event to be added</param>
		/// <param name="originalTrack">The original (or desired) track number</param>
		/// <remarks>When adding events in type 0 mode, the originalTrack parameter
		/// is ignored. If in type 1 mode, it will use the original track number to
		/// store the new events. If the original track was 0 and this is a channel based
		/// event, it will create new tracks if necessary and put it on the track corresponding
		/// to its channel number</remarks>
		public void AddEvent(MidiEvent midiEvent, int originalTrack)
		{
			if (midiFileType == 0)
			{
				EnsureTracks(1);
				trackEvents[0].Add(midiEvent);
			}
			else if (originalTrack == 0)
			{
				switch (midiEvent.CommandCode)
				{
				case MidiCommandCode.NoteOff:
				case MidiCommandCode.NoteOn:
				case MidiCommandCode.KeyAfterTouch:
				case MidiCommandCode.ControlChange:
				case MidiCommandCode.PatchChange:
				case MidiCommandCode.ChannelAfterTouch:
				case MidiCommandCode.PitchWheelChange:
					EnsureTracks(midiEvent.Channel + 1);
					trackEvents[midiEvent.Channel].Add(midiEvent);
					break;
				default:
					EnsureTracks(1);
					trackEvents[0].Add(midiEvent);
					break;
				}
			}
			else
			{
				EnsureTracks(originalTrack + 1);
				trackEvents[originalTrack].Add(midiEvent);
			}
		}

		private void EnsureTracks(int count)
		{
			for (int i = trackEvents.Count; i < count; i++)
			{
				trackEvents.Add(new List<MidiEvent>());
			}
		}

		private void ExplodeToManyTracks()
		{
			IList<MidiEvent> list = trackEvents[0];
			Clear();
			foreach (MidiEvent item in list)
			{
				AddEvent(item, 0);
			}
			PrepareForExport();
		}

		private void FlattenToOneTrack()
		{
			bool flag = false;
			for (int i = 1; i < trackEvents.Count; i++)
			{
				foreach (MidiEvent item in trackEvents[i])
				{
					if (!MidiEvent.IsEndTrack(item))
					{
						trackEvents[0].Add(item);
						flag = true;
					}
				}
			}
			for (int num = trackEvents.Count - 1; num > 0; num--)
			{
				RemoveTrack(num);
			}
			if (flag)
			{
				PrepareForExport();
			}
		}

		/// <summary>
		/// Sorts, removes empty tracks and adds end track markers
		/// </summary>
		public void PrepareForExport()
		{
			MidiEventComparer comparer = new MidiEventComparer();
			foreach (IList<MidiEvent> trackEvent in trackEvents)
			{
				MergeSort.Sort(trackEvent, comparer);
				int num = 0;
				while (num < trackEvent.Count - 1)
				{
					if (MidiEvent.IsEndTrack(trackEvent[num]))
					{
						trackEvent.RemoveAt(num);
					}
					else
					{
						num++;
					}
				}
			}
			int num2 = 0;
			while (num2 < trackEvents.Count)
			{
				IList<MidiEvent> list = trackEvents[num2];
				if (list.Count == 0)
				{
					RemoveTrack(num2);
					continue;
				}
				if (list.Count == 1 && MidiEvent.IsEndTrack(list[0]))
				{
					RemoveTrack(num2);
					continue;
				}
				if (!MidiEvent.IsEndTrack(list[list.Count - 1]))
				{
					list.Add(new MetaEvent(MetaEventType.EndTrack, 0, list[list.Count - 1].AbsoluteTime));
				}
				num2++;
			}
		}

		/// <summary>
		/// Gets an enumerator for the lists of track events
		/// </summary>
		public IEnumerator<IList<MidiEvent>> GetEnumerator()
		{
			return trackEvents.GetEnumerator();
		}

		/// <summary>
		/// Gets an enumerator for the lists of track events
		/// </summary>
		IEnumerator IEnumerable.GetEnumerator()
		{
			return trackEvents.GetEnumerator();
		}
	}

	/// <summary>
	/// Utility class for comparing MidiEvent objects
	/// </summary>
	public class MidiEventComparer : IComparer<MidiEvent>
	{
		/// <summary>
		/// Compares two MidiEvents
		/// Sorts by time, with EndTrack always sorted to the end
		/// </summary>
		public int Compare(MidiEvent x, MidiEvent y)
		{
			long num = x.AbsoluteTime;
			long num2 = y.AbsoluteTime;
			if (num == num2)
			{
				MetaEvent metaEvent = x as MetaEvent;
				MetaEvent metaEvent2 = y as MetaEvent;
				if (metaEvent != null)
				{
					num = ((metaEvent.MetaEventType != MetaEventType.EndTrack) ? long.MinValue : long.MaxValue);
				}
				if (metaEvent2 != null)
				{
					num2 = ((metaEvent2.MetaEventType != MetaEventType.EndTrack) ? long.MinValue : long.MaxValue);
				}
			}
			return num.CompareTo(num2);
		}
	}

	/// <summary>
	/// Class able to read a MIDI file
	/// </summary>
	public class MidiFile
	{
		private readonly MidiEventCollection events;

		private readonly ushort fileFormat;

		private readonly ushort deltaTicksPerQuarterNote;

		private readonly bool strictChecking;

		/// <summary>
		/// MIDI File format
		/// </summary>
		public int FileFormat => fileFormat;

		/// <summary>
		/// The collection of events in this MIDI file
		/// </summary>
		public MidiEventCollection Events => events;

		/// <summary>
		/// Number of tracks in this MIDI file
		/// </summary>
		public int Tracks => events.Tracks;

		/// <summary>
		/// Delta Ticks Per Quarter Note
		/// </summary>
		public int DeltaTicksPerQuarterNote => deltaTicksPerQuarterNote;

		/// <summary>
		/// Opens a MIDI file for reading
		/// </summary>
		/// <param name="filename">Name of MIDI file</param>
		public MidiFile(string filename)
			: this(filename, strictChecking: true)
		{
		}

		/// <summary>
		/// Opens a MIDI file for reading
		/// </summary>
		/// <param name="filename">Name of MIDI file</param>
		/// <param name="strictChecking">If true will error on non-paired note events</param>
		public MidiFile(string filename, bool strictChecking)
			: this(File.OpenRead(filename), strictChecking, ownInputStream: true)
		{
		}

		/// <summary>
		/// Opens a MIDI file stream for reading
		/// </summary>
		/// <param name="inputStream">The input stream containing a MIDI file</param>
		/// <param name="strictChecking">If true will error on non-paired note events</param>
		public MidiFile(Stream inputStream, bool strictChecking)
			: this(inputStream, strictChecking, ownInputStream: false)
		{
		}

		private MidiFile(Stream inputStream, bool strictChecking, bool ownInputStream)
		{
			this.strictChecking = strictChecking;
			BinaryReader binaryReader = new BinaryReader(inputStream);
			try
			{
				if (Encoding.UTF8.GetString(binaryReader.ReadBytes(4)) != "MThd")
				{
					throw new FormatException("Not a MIDI file - header chunk missing");
				}
				uint num = SwapUInt32(binaryReader.ReadUInt32());
				if (num != 6)
				{
					throw new FormatException("Unexpected header chunk length");
				}
				fileFormat = SwapUInt16(binaryReader.ReadUInt16());
				int num2 = SwapUInt16(binaryReader.ReadUInt16());
				deltaTicksPerQuarterNote = SwapUInt16(binaryReader.ReadUInt16());
				events = new MidiEventCollection((fileFormat != 0) ? 1 : 0, deltaTicksPerQuarterNote);
				for (int i = 0; i < num2; i++)
				{
					events.AddTrack();
				}
				long num3 = 0L;
				for (int j = 0; j < num2; j++)
				{
					if (fileFormat == 1)
					{
						num3 = 0L;
					}
					if (Encoding.UTF8.GetString(binaryReader.ReadBytes(4)) != "MTrk")
					{
						throw new FormatException("Invalid chunk header");
					}
					num = SwapUInt32(binaryReader.ReadUInt32());
					long position = binaryReader.BaseStream.Position;
					MidiEvent midiEvent = null;
					List<NoteOnEvent> list = new List<NoteOnEvent>();
					while (binaryReader.BaseStream.Position < position + num)
					{
						try
						{
							midiEvent = MidiEvent.ReadNextEvent(binaryReader, midiEvent);
						}
						catch (InvalidDataException)
						{
							if (strictChecking)
							{
								throw;
							}
							continue;
						}
						catch (FormatException)
						{
							if (strictChecking)
							{
								throw;
							}
							continue;
						}
						num3 = (midiEvent.AbsoluteTime = num3 + midiEvent.DeltaTime);
						events[j].Add(midiEvent);
						if (midiEvent.CommandCode == MidiCommandCode.NoteOn)
						{
							NoteEvent noteEvent = (NoteEvent)midiEvent;
							if (noteEvent.Velocity > 0)
							{
								list.Add((NoteOnEvent)noteEvent);
							}
							else
							{
								FindNoteOn(noteEvent, list);
							}
						}
						else if (midiEvent.CommandCode == MidiCommandCode.NoteOff)
						{
							FindNoteOn((NoteEvent)midiEvent, list);
						}
						else if (midiEvent.CommandCode == MidiCommandCode.MetaEvent && ((MetaEvent)midiEvent).MetaEventType == MetaEventType.EndTrack && strictChecking && binaryReader.BaseStream.Position < position + num)
						{
							throw new FormatException($"End Track event was not the last MIDI event on track {j}");
						}
					}
					if (list.Count > 0 && strictChecking)
					{
						throw new FormatException($"Note ons without note offs {list.Count} (file format {fileFormat})");
					}
					if (binaryReader.BaseStream.Position != position + num)
					{
						throw new FormatException($"Read too far {num}+{position}!={binaryReader.BaseStream.Position}");
					}
				}
			}
			finally
			{
				if (ownInputStream)
				{
					binaryReader.Dispose();
				}
			}
		}

		private void FindNoteOn(NoteEvent offEvent, List<NoteOnEvent> outstandingNoteOns)
		{
			bool flag = false;
			foreach (NoteOnEvent outstandingNoteOn in outstandingNoteOns)
			{
				if (outstandingNoteOn.Channel == offEvent.Channel && outstandingNoteOn.NoteNumber == offEvent.NoteNumber)
				{
					outstandingNoteOn.OffEvent = offEvent;
					outstandingNoteOns.Remove(outstandingNoteOn);
					flag = true;
					break;
				}
			}
			if (!flag && strictChecking)
			{
				throw new FormatException($"Got an off without an on {offEvent}");
			}
		}

		private static uint SwapUInt32(uint i)
		{
			return ((i & 0xFF000000u) >> 24) | ((i & 0xFF0000) >> 8) | ((i & 0xFF00) << 8) | ((i & 0xFF) << 24);
		}

		private static ushort SwapUInt16(ushort i)
		{
			return (ushort)(((i & 0xFF00) >> 8) | ((i & 0xFF) << 8));
		}

		/// <summary>
		/// Describes the MIDI file
		/// </summary>
		/// <returns>A string describing the MIDI file and its events</returns>
		public override string ToString()
		{
			StringBuilder stringBuilder = new StringBuilder();
			stringBuilder.AppendFormat("Format {0}, Tracks {1}, Delta Ticks Per Quarter Note {2}\r\n", fileFormat, Tracks, deltaTicksPerQuarterNote);
			for (int i = 0; i < Tracks; i++)
			{
				foreach (MidiEvent item in events[i])
				{
					stringBuilder.AppendFormat("{0}\r\n", item);
				}
			}
			return stringBuilder.ToString();
		}

		/// <summary>
		/// Exports a MIDI file
		/// </summary>
		/// <param name="filename">Filename to export to</param>
		/// <param name="events">Events to export</param>
		public static void Export(string filename, MidiEventCollection events)
		{
			if (events.MidiFileType == 0 && events.Tracks > 1)
			{
				throw new ArgumentException("Can't export more than one track to a type 0 file");
			}
			using BinaryWriter binaryWriter = new BinaryWriter(File.Create(filename));
			binaryWriter.Write(Encoding.UTF8.GetBytes("MThd"));
			binaryWriter.Write(SwapUInt32(6u));
			binaryWriter.Write(SwapUInt16((ushort)events.MidiFileType));
			binaryWriter.Write(SwapUInt16((ushort)events.Tracks));
			binaryWriter.Write(SwapUInt16((ushort)events.DeltaTicksPerQuarterNote));
			for (int i = 0; i < events.Tracks; i++)
			{
				IList<MidiEvent> list = events[i];
				binaryWriter.Write(Encoding.UTF8.GetBytes("MTrk"));
				long position = binaryWriter.BaseStream.Position;
				binaryWriter.Write(SwapUInt32(0u));
				long absoluteTime = events.StartAbsoluteTime;
				MergeSort.Sort(list, new MidiEventComparer());
				_ = list.Count;
				_ = 0;
				foreach (MidiEvent item in list)
				{
					item.Export(ref absoluteTime, binaryWriter);
				}
				uint num = (uint)((int)(binaryWriter.BaseStream.Position - position) - 4);
				binaryWriter.BaseStream.Position = position;
				binaryWriter.Write(SwapUInt32(num));
				binaryWriter.BaseStream.Position += num;
			}
		}
	}

	/// <summary>
	/// Represents a MIDI in device
	/// </summary>
	public class MidiIn : IDisposable
	{
		private IntPtr hMidiIn = IntPtr.Zero;

		private bool disposeIsRunning;

		private bool disposed;

		private MidiInterop.MidiInCallback callback;

		private IntPtr[] SysexBufferHeaders = new IntPtr[0];

		/// <summary>
		/// Gets the number of MIDI input devices available in the system
		/// </summary>
		public static int NumberOfDevices => MidiInterop.midiInGetNumDevs();

		/// <summary>
		/// Called when a MIDI message is received
		/// </summary>
		public event EventHandler<MidiInMessageEventArgs> MessageReceived;

		/// <summary>
		/// An invalid MIDI message
		/// </summary>
		public event EventHandler<MidiInMessageEventArgs> ErrorReceived;

		/// <summary>
		/// Called when a Sysex MIDI message is received
		/// </summary>
		public event EventHandler<MidiInSysexMessageEventArgs> SysexMessageReceived;

		/// <summary>
		/// Opens a specified MIDI in device
		/// </summary>
		/// <param name="deviceNo">The device number</param>
		public MidiIn(int deviceNo)
		{
			callback = Callback;
			MmException.Try(MidiInterop.midiInOpen(out hMidiIn, (IntPtr)deviceNo, callback, IntPtr.Zero, 196608), "midiInOpen");
		}

		/// <summary>
		/// Closes this MIDI in device
		/// </summary>
		public void Close()
		{
			Dispose();
		}

		/// <summary>
		/// Closes this MIDI in device
		/// </summary>
		public void Dispose()
		{
			GC.KeepAlive(callback);
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Start the MIDI in device
		/// </summary>
		public void Start()
		{
			MmException.Try(MidiInterop.midiInStart(hMidiIn), "midiInStart");
		}

		/// <summary>
		/// Stop the MIDI in device
		/// </summary>
		public void Stop()
		{
			MmException.Try(MidiInterop.midiInStop(hMidiIn), "midiInStop");
		}

		/// <summary>
		/// Reset the MIDI in device
		/// </summary>
		public void Reset()
		{
			MmException.Try(MidiInterop.midiInReset(hMidiIn), "midiInReset");
		}

		/// <summary>
		/// Create a number of buffers and make them available to receive incoming Sysex messages
		/// </summary>
		/// <param name="bufferSize">The size of each buffer, ideally large enough to hold a complete message from the device</param>
		/// <param name="numberOfBuffers">The number of buffers needed to handle incoming Midi while busy</param>
		public void CreateSysexBuffers(int bufferSize, int numberOfBuffers)
		{
			SysexBufferHeaders = new IntPtr[numberOfBuffers];
			int cb = Marshal.SizeOf(typeof(MidiInterop.MIDIHDR));
			for (int i = 0; i < numberOfBuffers; i++)
			{
				MidiInterop.MIDIHDR structure = default(MidiInterop.MIDIHDR);
				structure.dwBufferLength = bufferSize;
				structure.dwBytesRecorded = 0;
				structure.lpData = Marshal.AllocHGlobal(bufferSize);
				structure.dwFlags = 0;
				IntPtr intPtr = Marshal.AllocHGlobal(cb);
				Marshal.StructureToPtr(structure, intPtr, fDeleteOld: false);
				MmException.Try(MidiInterop.midiInPrepareHeader(hMidiIn, intPtr, Marshal.SizeOf(typeof(MidiInterop.MIDIHDR))), "midiInPrepareHeader");
				MmException.Try(MidiInterop.midiInAddBuffer(hMidiIn, intPtr, Marshal.SizeOf(typeof(MidiInterop.MIDIHDR))), "midiInAddBuffer");
				SysexBufferHeaders[i] = intPtr;
			}
		}

		private void Callback(IntPtr midiInHandle, MidiInterop.MidiInMessage message, IntPtr userData, IntPtr messageParameter1, IntPtr messageParameter2)
		{
			switch (message)
			{
			case MidiInterop.MidiInMessage.Data:
				if (this.MessageReceived != null)
				{
					this.MessageReceived(this, new MidiInMessageEventArgs(messageParameter1.ToInt32(), messageParameter2.ToInt32()));
				}
				break;
			case MidiInterop.MidiInMessage.Error:
				if (this.ErrorReceived != null)
				{
					this.ErrorReceived(this, new MidiInMessageEventArgs(messageParameter1.ToInt32(), messageParameter2.ToInt32()));
				}
				break;
			case MidiInterop.MidiInMessage.LongData:
				if (this.SysexMessageReceived != null)
				{
					MidiInterop.MIDIHDR mIDIHDR = (MidiInterop.MIDIHDR)Marshal.PtrToStructure(messageParameter1, typeof(MidiInterop.MIDIHDR));
					byte[] array = new byte[mIDIHDR.dwBytesRecorded];
					Marshal.Copy(mIDIHDR.lpData, array, 0, mIDIHDR.dwBytesRecorded);
					if (array.Length != 0)
					{
						this.SysexMessageReceived(this, new MidiInSysexMessageEventArgs(array, messageParameter2.ToInt32()));
					}
					if (!disposeIsRunning)
					{
						MidiInterop.midiInAddBuffer(hMidiIn, messageParameter1, Marshal.SizeOf(typeof(MidiInterop.MIDIHDR)));
					}
				}
				break;
			case MidiInterop.MidiInMessage.Open:
			case MidiInterop.MidiInMessage.Close:
			case MidiInterop.MidiInMessage.LongError:
			case (MidiInterop.MidiInMessage)967:
			case (MidiInterop.MidiInMessage)968:
			case (MidiInterop.MidiInMessage)969:
			case (MidiInterop.MidiInMessage)970:
			case (MidiInterop.MidiInMessage)971:
			case MidiInterop.MidiInMessage.MoreData:
				break;
			}
		}

		/// <summary>
		/// Gets the MIDI in device info
		/// </summary>
		public static MidiInCapabilities DeviceInfo(int midiInDeviceNumber)
		{
			MidiInCapabilities capabilities = default(MidiInCapabilities);
			int size = Marshal.SizeOf(capabilities);
			MmException.Try(MidiInterop.midiInGetDevCaps((IntPtr)midiInDeviceNumber, out capabilities, size), "midiInGetDevCaps");
			return capabilities;
		}

		/// <summary>
		/// Closes the MIDI in device
		/// </summary>
		/// <param name="disposing">True if called from Dispose</param>
		protected virtual void Dispose(bool disposing)
		{
			if (!disposed)
			{
				disposeIsRunning = true;
				if (SysexBufferHeaders.Length != 0)
				{
					MmException.Try(MidiInterop.midiInReset(hMidiIn), "midiInReset");
					IntPtr[] sysexBufferHeaders = SysexBufferHeaders;
					foreach (IntPtr intPtr in sysexBufferHeaders)
					{
						MidiInterop.MIDIHDR obj = (MidiInterop.MIDIHDR)Marshal.PtrToStructure(intPtr, typeof(MidiInterop.MIDIHDR));
						MmException.Try(MidiInterop.midiInUnprepareHeader(hMidiIn, intPtr, Marshal.SizeOf(typeof(MidiInterop.MIDIHDR))), "midiInPrepareHeader");
						Marshal.FreeHGlobal(obj.lpData);
						Marshal.FreeHGlobal(intPtr);
					}
					SysexBufferHeaders = new IntPtr[0];
				}
				MidiInterop.midiInClose(hMidiIn);
			}
			disposed = true;
			disposeIsRunning = false;
		}

		/// <summary>
		/// Cleanup
		/// </summary>
		~MidiIn()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// MIDI In Device Capabilities
	/// </summary>
	[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto)]
	public struct MidiInCapabilities
	{
		/// <summary>
		/// wMid
		/// </summary>
		private ushort manufacturerId;

		/// <summary>
		/// wPid
		/// </summary>
		private ushort productId;

		/// <summary>
		/// vDriverVersion
		/// </summary>
		private uint driverVersion;

		/// <summary>
		/// Product Name
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		private string productName;

		/// <summary>
		/// Support - Reserved
		/// </summary>
		private int support;

		private const int MaxProductNameLength = 32;

		/// <summary>
		/// Gets the manufacturer of this device
		/// </summary>
		public Manufacturers Manufacturer => (Manufacturers)manufacturerId;

		/// <summary>
		/// Gets the product identifier (manufacturer specific)
		/// </summary>
		public int ProductId => productId;

		/// <summary>
		/// Gets the product name
		/// </summary>
		public string ProductName => productName;
	}

	/// <summary>
	/// MIDI In Message Information
	/// </summary>
	public class MidiInMessageEventArgs : EventArgs
	{
		/// <summary>
		/// The Raw message received from the MIDI In API
		/// </summary>
		public int RawMessage { get; private set; }

		/// <summary>
		/// The raw message interpreted as a MidiEvent
		/// </summary>
		public MidiEvent MidiEvent { get; private set; }

		/// <summary>
		/// The timestamp in milliseconds for this message
		/// </summary>
		public int Timestamp { get; private set; }

		/// <summary>
		/// Create a new MIDI In Message EventArgs
		/// </summary>
		/// <param name="message"></param>
		/// <param name="timestamp"></param>
		public MidiInMessageEventArgs(int message, int timestamp)
		{
			RawMessage = message;
			Timestamp = timestamp;
			try
			{
				MidiEvent = MidiEvent.FromRawMessage(message);
			}
			catch (Exception)
			{
			}
		}
	}

	/// <summary>
	/// MIDI In Sysex Message Information
	/// </summary>
	public class MidiInSysexMessageEventArgs : EventArgs
	{
		/// <summary>
		/// The Raw Sysex bytes received in a long MIDI message
		/// </summary>
		public byte[] SysexBytes { get; private set; }

		/// <summary>
		/// The timestamp in milliseconds (since MidiInStart) for this message
		/// </summary>
		public int Timestamp { get; private set; }

		/// <summary>
		/// Create a new Sysex MIDI In Message EventArgs
		/// </summary>
		/// <param name="sysexBytes">The Sysex byte array received</param>
		/// <param name="timestamp">Milliseconds since MidiInStart</param>
		public MidiInSysexMessageEventArgs(byte[] sysexBytes, int timestamp)
		{
			SysexBytes = sysexBytes;
			Timestamp = timestamp;
		}
	}

	internal class MidiInterop
	{
		public enum MidiInMessage
		{
			/// <summary>
			/// MIM_OPEN
			/// </summary>
			Open = 961,
			/// <summary>
			/// MIM_CLOSE
			/// </summary>
			Close = 962,
			/// <summary>
			/// MIM_DATA
			/// </summary>
			Data = 963,
			/// <summary>
			/// MIM_LONGDATA
			/// </summary>
			LongData = 964,
			/// <summary>
			/// MIM_ERROR
			/// </summary>
			Error = 965,
			/// <summary>
			/// MIM_LONGERROR
			/// </summary>
			LongError = 966,
			/// <summary>
			/// MIM_MOREDATA
			/// </summary>
			MoreData = 972
		}

		public enum MidiOutMessage
		{
			/// <summary>
			/// MOM_OPEN
			/// </summary>
			Open = 967,
			/// <summary>
			/// MOM_CLOSE
			/// </summary>
			Close,
			/// <summary>
			/// MOM_DONE
			/// </summary>
			Done
		}

		public delegate void MidiInCallback(IntPtr midiInHandle, MidiInMessage message, IntPtr userData, IntPtr messageParameter1, IntPtr messageParameter2);

		public delegate void MidiOutCallback(IntPtr midiInHandle, MidiOutMessage message, IntPtr userData, IntPtr messageParameter1, IntPtr messageParameter2);

		public struct MMTIME
		{
			public int wType;

			public int u;
		}

		public struct MIDIEVENT
		{
			public int dwDeltaTime;

			public int dwStreamID;

			public int dwEvent;

			[MarshalAs(UnmanagedType.ByValArray, SizeConst = 1)]
			public int dwParms;
		}

		public struct MIDIHDR
		{
			public IntPtr lpData;

			public int dwBufferLength;

			public int dwBytesRecorded;

			public IntPtr dwUser;

			public int dwFlags;

			public IntPtr lpNext;

			public IntPtr reserved;

			public int dwOffset;

			[MarshalAs(UnmanagedType.ByValArray, SizeConst = 8)]
			public IntPtr[] dwReserved;
		}

		public struct MIDIPROPTEMPO
		{
			public int cbStruct;

			public int dwTempo;
		}

		public const int CALLBACK_FUNCTION = 196608;

		public const int CALLBACK_NULL = 0;

		[DllImport("winmm.dll")]
		public static extern MmResult midiConnect(IntPtr hMidiIn, IntPtr hMidiOut, IntPtr pReserved);

		[DllImport("winmm.dll")]
		public static extern MmResult midiDisconnect(IntPtr hMidiIn, IntPtr hMidiOut, IntPtr pReserved);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInAddBuffer(IntPtr hMidiIn, IntPtr lpMidiInHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInClose(IntPtr hMidiIn);

		[DllImport("winmm.dll", CharSet = CharSet.Auto)]
		public static extern MmResult midiInGetDevCaps(IntPtr deviceId, out MidiInCapabilities capabilities, int size);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInGetErrorText(int err, string lpText, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInGetID(IntPtr hMidiIn, out int lpuDeviceId);

		[DllImport("winmm.dll")]
		public static extern int midiInGetNumDevs();

		[DllImport("winmm.dll")]
		public static extern MmResult midiInMessage(IntPtr hMidiIn, int msg, IntPtr dw1, IntPtr dw2);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInOpen(out IntPtr hMidiIn, IntPtr uDeviceID, MidiInCallback callback, IntPtr dwInstance, int dwFlags);

		[DllImport("winmm.dll", EntryPoint = "midiInOpen")]
		public static extern MmResult midiInOpenWindow(out IntPtr hMidiIn, IntPtr uDeviceID, IntPtr callbackWindowHandle, IntPtr dwInstance, int dwFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInPrepareHeader(IntPtr hMidiIn, IntPtr lpMidiInHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInReset(IntPtr hMidiIn);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInStart(IntPtr hMidiIn);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInStop(IntPtr hMidiIn);

		[DllImport("winmm.dll")]
		public static extern MmResult midiInUnprepareHeader(IntPtr hMidiIn, IntPtr lpMidiInHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutCacheDrumPatches(IntPtr hMidiOut, int uPatch, IntPtr lpKeyArray, int uFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutCachePatches(IntPtr hMidiOut, int uBank, IntPtr lpPatchArray, int uFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutClose(IntPtr hMidiOut);

		[DllImport("winmm.dll", CharSet = CharSet.Auto)]
		public static extern MmResult midiOutGetDevCaps(IntPtr deviceNumber, out MidiOutCapabilities caps, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutGetErrorText(IntPtr err, string lpText, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutGetID(IntPtr hMidiOut, out int lpuDeviceID);

		[DllImport("winmm.dll")]
		public static extern int midiOutGetNumDevs();

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutGetVolume(IntPtr uDeviceID, ref int lpdwVolume);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutLongMsg(IntPtr hMidiOut, ref MIDIHDR lpMidiOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutMessage(IntPtr hMidiOut, int msg, IntPtr dw1, IntPtr dw2);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutOpen(out IntPtr lphMidiOut, IntPtr uDeviceID, MidiOutCallback dwCallback, IntPtr dwInstance, int dwFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutPrepareHeader(IntPtr hMidiOut, ref MIDIHDR lpMidiOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutReset(IntPtr hMidiOut);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutSetVolume(IntPtr hMidiOut, int dwVolume);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutShortMsg(IntPtr hMidiOut, int dwMsg);

		[DllImport("winmm.dll")]
		public static extern MmResult midiOutUnprepareHeader(IntPtr hMidiOut, ref MIDIHDR lpMidiOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamClose(IntPtr hMidiStream);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamOpen(out IntPtr hMidiStream, IntPtr puDeviceID, int cMidi, IntPtr dwCallback, IntPtr dwInstance, int fdwOpen);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamOut(IntPtr hMidiStream, ref MIDIHDR pmh, int cbmh);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamPause(IntPtr hMidiStream);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamPosition(IntPtr hMidiStream, ref MMTIME lpmmt, int cbmmt);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamProperty(IntPtr hMidiStream, IntPtr lppropdata, int dwProperty);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamRestart(IntPtr hMidiStream);

		[DllImport("winmm.dll")]
		public static extern MmResult midiStreamStop(IntPtr hMidiStream);
	}

	/// <summary>
	/// Represents a MIDI message
	/// </summary>
	public class MidiMessage
	{
		private int rawData;

		/// <summary>
		/// Returns the raw MIDI message data
		/// </summary>
		public int RawData => rawData;

		/// <summary>
		/// Creates a new MIDI message
		/// </summary>
		/// <param name="status">Status</param>
		/// <param name="data1">Data parameter 1</param>
		/// <param name="data2">Data parameter 2</param>
		public MidiMessage(int status, int data1, int data2)
		{
			rawData = status + (data1 << 8) + (data2 << 16);
		}

		/// <summary>
		/// Creates a new MIDI message from a raw message
		/// </summary>
		/// <param name="rawData">A packed MIDI message from an MMIO function</param>
		public MidiMessage(int rawData)
		{
			this.rawData = rawData;
		}

		/// <summary>
		/// Creates a Note On message
		/// </summary>
		/// <param name="note">Note number (0 to 127)</param>
		/// <param name="volume">Volume (0 to 127)</param>
		/// <param name="channel">MIDI channel (1 to 16)</param>
		/// <returns>A new MidiMessage object</returns>
		public static MidiMessage StartNote(int note, int volume, int channel)
		{
			ValidateNoteParameters(note, volume, channel);
			return new MidiMessage(144 + channel - 1, note, volume);
		}

		private static void ValidateNoteParameters(int note, int volume, int channel)
		{
			ValidateChannel(channel);
			if (note < 0 || note > 127)
			{
				throw new ArgumentOutOfRangeException("note", "Note number must be in the range 0-127");
			}
			if (volume < 0 || volume > 127)
			{
				throw new ArgumentOutOfRangeException("volume", "Velocity must be in the range 0-127");
			}
		}

		private static void ValidateChannel(int channel)
		{
			if (channel < 1 || channel > 16)
			{
				throw new ArgumentOutOfRangeException("channel", channel, $"Channel must be 1-16 (Got {channel})");
			}
		}

		/// <summary>
		/// Creates a Note Off message
		/// </summary>
		/// <param name="note">Note number</param>
		/// <param name="volume">Volume </param>
		/// <param name="channel">MIDI channel (1-16)</param>
		/// <returns>A new MidiMessage object</returns>
		public static MidiMessage StopNote(int note, int volume, int channel)
		{
			ValidateNoteParameters(note, volume, channel);
			return new MidiMessage(128 + channel - 1, note, volume);
		}

		/// <summary>
		/// Creates a patch change message
		/// </summary>
		/// <param name="patch">The patch number</param>
		/// <param name="channel">The MIDI channel number (1-16)</param>
		/// <returns>A new MidiMessageObject</returns>
		public static MidiMessage ChangePatch(int patch, int channel)
		{
			ValidateChannel(channel);
			return new MidiMessage(192 + channel - 1, patch, 0);
		}

		/// <summary>
		/// Creates a Control Change message
		/// </summary>
		/// <param name="controller">The controller number to change</param>
		/// <param name="value">The value to set the controller to</param>
		/// <param name="channel">The MIDI channel number (1-16)</param>
		/// <returns>A new MidiMessageObject</returns>
		public static MidiMessage ChangeControl(int controller, int value, int channel)
		{
			ValidateChannel(channel);
			return new MidiMessage(176 + channel - 1, controller, value);
		}
	}

	/// <summary>
	/// Represents a MIDI out device
	/// </summary>
	public class MidiOut : IDisposable
	{
		private IntPtr hMidiOut = IntPtr.Zero;

		private bool disposed;

		private MidiInterop.MidiOutCallback callback;

		/// <summary>
		/// Gets the number of MIDI devices available in the system
		/// </summary>
		public static int NumberOfDevices => MidiInterop.midiOutGetNumDevs();

		/// <summary>
		/// Gets or sets the volume for this MIDI out device
		/// </summary>
		public int Volume
		{
			get
			{
				int lpdwVolume = 0;
				MmException.Try(MidiInterop.midiOutGetVolume(hMidiOut, ref lpdwVolume), "midiOutGetVolume");
				return lpdwVolume;
			}
			set
			{
				MmException.Try(MidiInterop.midiOutSetVolume(hMidiOut, value), "midiOutSetVolume");
			}
		}

		/// <summary>
		/// Gets the MIDI Out device info
		/// </summary>
		public static MidiOutCapabilities DeviceInfo(int midiOutDeviceNumber)
		{
			MidiOutCapabilities caps = default(MidiOutCapabilities);
			int uSize = Marshal.SizeOf(caps);
			MmException.Try(MidiInterop.midiOutGetDevCaps((IntPtr)midiOutDeviceNumber, out caps, uSize), "midiOutGetDevCaps");
			return caps;
		}

		/// <summary>
		/// Opens a specified MIDI out device
		/// </summary>
		/// <param name="deviceNo">The device number</param>
		public MidiOut(int deviceNo)
		{
			callback = Callback;
			MmException.Try(MidiInterop.midiOutOpen(out hMidiOut, (IntPtr)deviceNo, callback, IntPtr.Zero, 196608), "midiOutOpen");
		}

		/// <summary>
		/// Closes this MIDI out device
		/// </summary>
		public void Close()
		{
			Dispose();
		}

		/// <summary>
		/// Closes this MIDI out device
		/// </summary>
		public void Dispose()
		{
			GC.KeepAlive(callback);
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Resets the MIDI out device
		/// </summary>
		public void Reset()
		{
			MmException.Try(MidiInterop.midiOutReset(hMidiOut), "midiOutReset");
		}

		/// <summary>
		/// Sends a MIDI out message
		/// </summary>
		/// <param name="message">Message</param>
		/// <param name="param1">Parameter 1</param>
		/// <param name="param2">Parameter 2</param>
		public void SendDriverMessage(int message, int param1, int param2)
		{
			MmException.Try(MidiInterop.midiOutMessage(hMidiOut, message, (IntPtr)param1, (IntPtr)param2), "midiOutMessage");
		}

		/// <summary>
		/// Sends a MIDI message to the MIDI out device
		/// </summary>
		/// <param name="message">The message to send</param>
		public void Send(int message)
		{
			MmException.Try(MidiInterop.midiOutShortMsg(hMidiOut, message), "midiOutShortMsg");
		}

		/// <summary>
		/// Closes the MIDI out device
		/// </summary>
		/// <param name="disposing">True if called from Dispose</param>
		protected virtual void Dispose(bool disposing)
		{
			if (!disposed)
			{
				MidiInterop.midiOutClose(hMidiOut);
			}
			disposed = true;
		}

		private void Callback(IntPtr midiInHandle, MidiInterop.MidiOutMessage message, IntPtr userData, IntPtr messageParameter1, IntPtr messageParameter2)
		{
		}

		/// <summary>
		/// Send a long message, for example sysex.
		/// </summary>
		/// <param name="byteBuffer">The bytes to send.</param>
		public void SendBuffer(byte[] byteBuffer)
		{
			MidiInterop.MIDIHDR lpMidiOutHdr = default(MidiInterop.MIDIHDR);
			lpMidiOutHdr.lpData = Marshal.AllocHGlobal(byteBuffer.Length);
			Marshal.Copy(byteBuffer, 0, lpMidiOutHdr.lpData, byteBuffer.Length);
			lpMidiOutHdr.dwBufferLength = byteBuffer.Length;
			lpMidiOutHdr.dwBytesRecorded = byteBuffer.Length;
			int uSize = Marshal.SizeOf(lpMidiOutHdr);
			MidiInterop.midiOutPrepareHeader(hMidiOut, ref lpMidiOutHdr, uSize);
			if (MidiInterop.midiOutLongMsg(hMidiOut, ref lpMidiOutHdr, uSize) != 0)
			{
				MidiInterop.midiOutUnprepareHeader(hMidiOut, ref lpMidiOutHdr, uSize);
			}
			Marshal.FreeHGlobal(lpMidiOutHdr.lpData);
		}

		/// <summary>
		/// Cleanup
		/// </summary>
		~MidiOut()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// class representing the capabilities of a MIDI out device
	/// MIDIOUTCAPS: http://msdn.microsoft.com/en-us/library/dd798467%28VS.85%29.aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto)]
	public struct MidiOutCapabilities
	{
		[Flags]
		private enum MidiOutCapabilityFlags
		{
			/// <summary>
			/// MIDICAPS_VOLUME
			/// </summary>
			Volume = 1,
			/// <summary>
			/// separate left-right volume control
			/// MIDICAPS_LRVOLUME
			/// </summary>
			LeftRightVolume = 2,
			/// <summary>
			/// MIDICAPS_CACHE
			/// </summary>
			PatchCaching = 4,
			/// <summary>
			/// MIDICAPS_STREAM
			/// driver supports midiStreamOut directly
			/// </summary>
			Stream = 8
		}

		private short manufacturerId;

		private short productId;

		private int driverVersion;

		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		private string productName;

		private short wTechnology;

		private short wVoices;

		private short wNotes;

		private ushort wChannelMask;

		private MidiOutCapabilityFlags dwSupport;

		private const int MaxProductNameLength = 32;

		/// <summary>
		/// Gets the manufacturer of this device
		/// </summary>
		public Manufacturers Manufacturer => (Manufacturers)manufacturerId;

		/// <summary>
		/// Gets the product identifier (manufacturer specific)
		/// </summary>
		public short ProductId => productId;

		/// <summary>
		/// Gets the product name
		/// </summary>
		public string ProductName => productName;

		/// <summary>
		/// Returns the number of supported voices
		/// </summary>
		public int Voices => wVoices;

		/// <summary>
		/// Gets the polyphony of the device
		/// </summary>
		public int Notes => wNotes;

		/// <summary>
		/// Returns true if the device supports all channels
		/// </summary>
		public bool SupportsAllChannels => wChannelMask == ushort.MaxValue;

		/// <summary>
		/// Returns true if the device supports patch caching
		/// </summary>
		public bool SupportsPatchCaching => (dwSupport & MidiOutCapabilityFlags.PatchCaching) != 0;

		/// <summary>
		/// Returns true if the device supports separate left and right volume
		/// </summary>
		public bool SupportsSeparateLeftAndRightVolume => (dwSupport & MidiOutCapabilityFlags.LeftRightVolume) != 0;

		/// <summary>
		/// Returns true if the device supports MIDI stream out
		/// </summary>
		public bool SupportsMidiStreamOut => (dwSupport & MidiOutCapabilityFlags.Stream) != 0;

		/// <summary>
		/// Returns true if the device supports volume control
		/// </summary>
		public bool SupportsVolumeControl => (dwSupport & MidiOutCapabilityFlags.Volume) != 0;

		/// <summary>
		/// Returns the type of technology used by this MIDI out device
		/// </summary>
		public MidiOutTechnology Technology => (MidiOutTechnology)wTechnology;

		/// <summary>
		/// Queries whether a particular channel is supported
		/// </summary>
		/// <param name="channel">Channel number to test</param>
		/// <returns>True if the channel is supported</returns>
		public bool SupportsChannel(int channel)
		{
			return (wChannelMask & (1 << channel - 1)) > 0;
		}
	}

	/// <summary>
	/// Represents the different types of technology used by a MIDI out device
	/// </summary>
	/// <remarks>from mmsystem.h</remarks>
	public enum MidiOutTechnology
	{
		/// <summary>The device is a MIDI port</summary>
		MidiPort = 1,
		/// <summary>The device is a MIDI synth</summary>
		Synth,
		/// <summary>The device is a square wave synth</summary>
		SquareWaveSynth,
		/// <summary>The device is an FM synth</summary>
		FMSynth,
		/// <summary>The device is a MIDI mapper</summary>
		MidiMapper,
		/// <summary>The device is a WaveTable synth</summary>
		WaveTableSynth,
		/// <summary>The device is a software synth</summary>
		SoftwareSynth
	}

	/// <summary>
	/// Represents a note MIDI event
	/// </summary>
	public class NoteEvent : MidiEvent
	{
		private int noteNumber;

		private int velocity;

		private static readonly string[] NoteNames = new string[12]
		{
			"C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A",
			"A#", "B"
		};

		/// <summary>
		/// The MIDI note number
		/// </summary>
		public virtual int NoteNumber
		{
			get
			{
				return noteNumber;
			}
			set
			{
				if (value < 0 || value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "Note number must be in the range 0-127");
				}
				noteNumber = value;
			}
		}

		/// <summary>
		/// The note velocity
		/// </summary>
		public int Velocity
		{
			get
			{
				return velocity;
			}
			set
			{
				if (value < 0 || value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "Velocity must be in the range 0-127");
				}
				velocity = value;
			}
		}

		/// <summary>
		/// The note name
		/// </summary>
		public string NoteName
		{
			get
			{
				if (Channel == 16 || Channel == 10)
				{
					return noteNumber switch
					{
						35 => "Acoustic Bass Drum", 
						36 => "Bass Drum 1", 
						37 => "Side Stick", 
						38 => "Acoustic Snare", 
						39 => "Hand Clap", 
						40 => "Electric Snare", 
						41 => "Low Floor Tom", 
						42 => "Closed Hi-Hat", 
						43 => "High Floor Tom", 
						44 => "Pedal Hi-Hat", 
						45 => "Low Tom", 
						46 => "Open Hi-Hat", 
						47 => "Low-Mid Tom", 
						48 => "Hi-Mid Tom", 
						49 => "Crash Cymbal 1", 
						50 => "High Tom", 
						51 => "Ride Cymbal 1", 
						52 => "Chinese Cymbal", 
						53 => "Ride Bell", 
						54 => "Tambourine", 
						55 => "Splash Cymbal", 
						56 => "Cowbell", 
						57 => "Crash Cymbal 2", 
						58 => "Vibraslap", 
						59 => "Ride Cymbal 2", 
						60 => "Hi Bongo", 
						61 => "Low Bongo", 
						62 => "Mute Hi Conga", 
						63 => "Open Hi Conga", 
						64 => "Low Conga", 
						65 => "High Timbale", 
						66 => "Low Timbale", 
						67 => "High Agogo", 
						68 => "Low Agogo", 
						69 => "Cabasa", 
						70 => "Maracas", 
						71 => "Short Whistle", 
						72 => "Long Whistle", 
						73 => "Short Guiro", 
						74 => "Long Guiro", 
						75 => "Claves", 
						76 => "Hi Wood Block", 
						77 => "Low Wood Block", 
						78 => "Mute Cuica", 
						79 => "Open Cuica", 
						80 => "Mute Triangle", 
						81 => "Open Triangle", 
						_ => $"Drum {noteNumber}", 
					};
				}
				int num = noteNumber / 12;
				return $"{NoteNames[noteNumber % 12]}{num}";
			}
		}

		/// <summary>
		/// Reads a NoteEvent from a stream of MIDI data
		/// </summary>
		/// <param name="br">Binary Reader for the stream</param>
		public NoteEvent(BinaryReader br)
		{
			NoteNumber = br.ReadByte();
			velocity = br.ReadByte();
			if (velocity > 127)
			{
				velocity = 127;
			}
		}

		/// <summary>
		/// Creates a MIDI Note Event with specified parameters
		/// </summary>
		/// <param name="absoluteTime">Absolute time of this event</param>
		/// <param name="channel">MIDI channel number</param>
		/// <param name="commandCode">MIDI command code</param>
		/// <param name="noteNumber">MIDI Note Number</param>
		/// <param name="velocity">MIDI Note Velocity</param>
		public NoteEvent(long absoluteTime, int channel, MidiCommandCode commandCode, int noteNumber, int velocity)
			: base(absoluteTime, channel, commandCode)
		{
			NoteNumber = noteNumber;
			Velocity = velocity;
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.GetAsShortMessage" />
		/// </summary>
		public override int GetAsShortMessage()
		{
			return base.GetAsShortMessage() + (noteNumber << 8) + (velocity << 16);
		}

		/// <summary>
		/// Describes the Note Event
		/// </summary>
		/// <returns>Note event as a string</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {NoteName} Vel:{Velocity}";
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)" />
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)noteNumber);
			writer.Write((byte)velocity);
		}
	}

	/// <summary>
	/// Represents a MIDI note on event
	/// </summary>
	public class NoteOnEvent : NoteEvent
	{
		private NoteEvent offEvent;

		/// <summary>
		/// The associated Note off event
		/// </summary>
		public NoteEvent OffEvent
		{
			get
			{
				return offEvent;
			}
			set
			{
				if (!MidiEvent.IsNoteOff(value))
				{
					throw new ArgumentException("OffEvent must be a valid MIDI note off event");
				}
				if (value.NoteNumber != NoteNumber)
				{
					throw new ArgumentException("Note Off Event must be for the same note number");
				}
				if (value.Channel != Channel)
				{
					throw new ArgumentException("Note Off Event must be for the same channel");
				}
				offEvent = value;
			}
		}

		/// <summary>
		/// Get or set the Note Number, updating the off event at the same time
		/// </summary>
		public override int NoteNumber
		{
			get
			{
				return base.NoteNumber;
			}
			set
			{
				base.NoteNumber = value;
				if (OffEvent != null)
				{
					OffEvent.NoteNumber = NoteNumber;
				}
			}
		}

		/// <summary>
		/// Get or set the channel, updating the off event at the same time
		/// </summary>
		public override int Channel
		{
			get
			{
				return base.Channel;
			}
			set
			{
				base.Channel = value;
				if (OffEvent != null)
				{
					OffEvent.Channel = Channel;
				}
			}
		}

		/// <summary>
		/// The duration of this note
		/// </summary>
		/// <remarks>
		/// There must be a note off event
		/// </remarks>
		public int NoteLength
		{
			get
			{
				return (int)(offEvent.AbsoluteTime - base.AbsoluteTime);
			}
			set
			{
				if (value < 0)
				{
					throw new ArgumentException("NoteLength must be 0 or greater");
				}
				offEvent.AbsoluteTime = base.AbsoluteTime + value;
			}
		}

		/// <summary>
		/// Reads a new Note On event from a stream of MIDI data
		/// </summary>
		/// <param name="br">Binary reader on the MIDI data stream</param>
		public NoteOnEvent(BinaryReader br)
			: base(br)
		{
		}

		/// <summary>
		/// Creates a NoteOn event with specified parameters
		/// </summary>
		/// <param name="absoluteTime">Absolute time of this event</param>
		/// <param name="channel">MIDI channel number</param>
		/// <param name="noteNumber">MIDI note number</param>
		/// <param name="velocity">MIDI note velocity</param>
		/// <param name="duration">MIDI note duration</param>
		public NoteOnEvent(long absoluteTime, int channel, int noteNumber, int velocity, int duration)
			: base(absoluteTime, channel, MidiCommandCode.NoteOn, noteNumber, velocity)
		{
			OffEvent = new NoteEvent(absoluteTime, channel, MidiCommandCode.NoteOff, noteNumber, 0);
			NoteLength = duration;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return new NoteOnEvent(base.AbsoluteTime, Channel, NoteNumber, base.Velocity, NoteLength);
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override string ToString()
		{
			if (base.Velocity == 0 && OffEvent == null)
			{
				return $"{base.ToString()} (Note Off)";
			}
			return string.Format("{0} Len: {1}", base.ToString(), (OffEvent == null) ? "?" : NoteLength.ToString());
		}
	}

	/// <summary>
	/// Represents a MIDI patch change event
	/// </summary>
	public class PatchChangeEvent : MidiEvent
	{
		private byte patch;

		private static readonly string[] patchNames = new string[128]
		{
			"Acoustic Grand", "Bright Acoustic", "Electric Grand", "Honky-Tonk", "Electric Piano 1", "Electric Piano 2", "Harpsichord", "Clav", "Celesta", "Glockenspiel",
			"Music Box", "Vibraphone", "Marimba", "Xylophone", "Tubular Bells", "Dulcimer", "Drawbar Organ", "Percussive Organ", "Rock Organ", "Church Organ",
			"Reed Organ", "Accoridan", "Harmonica", "Tango Accordian", "Acoustic Guitar(nylon)", "Acoustic Guitar(steel)", "Electric Guitar(jazz)", "Electric Guitar(clean)", "Electric Guitar(muted)", "Overdriven Guitar",
			"Distortion Guitar", "Guitar Harmonics", "Acoustic Bass", "Electric Bass(finger)", "Electric Bass(pick)", "Fretless Bass", "Slap Bass 1", "Slap Bass 2", "Synth Bass 1", "Synth Bass 2",
			"Violin", "Viola", "Cello", "Contrabass", "Tremolo Strings", "Pizzicato Strings", "Orchestral Strings", "Timpani", "String Ensemble 1", "String Ensemble 2",
			"SynthStrings 1", "SynthStrings 2", "Choir Aahs", "Voice Oohs", "Synth Voice", "Orchestra Hit", "Trumpet", "Trombone", "Tuba", "Muted Trumpet",
			"French Horn", "Brass Section", "SynthBrass 1", "SynthBrass 2", "Soprano Sax", "Alto Sax", "Tenor Sax", "Baritone Sax", "Oboe", "English Horn",
			"Bassoon", "Clarinet", "Piccolo", "Flute", "Recorder", "Pan Flute", "Blown Bottle", "Skakuhachi", "Whistle", "Ocarina",
			"Lead 1 (square)", "Lead 2 (sawtooth)", "Lead 3 (calliope)", "Lead 4 (chiff)", "Lead 5 (charang)", "Lead 6 (voice)", "Lead 7 (fifths)", "Lead 8 (bass+lead)", "Pad 1 (new age)", "Pad 2 (warm)",
			"Pad 3 (polysynth)", "Pad 4 (choir)", "Pad 5 (bowed)", "Pad 6 (metallic)", "Pad 7 (halo)", "Pad 8 (sweep)", "FX 1 (rain)", "FX 2 (soundtrack)", "FX 3 (crystal)", "FX 4 (atmosphere)",
			"FX 5 (brightness)", "FX 6 (goblins)", "FX 7 (echoes)", "FX 8 (sci-fi)", "Sitar", "Banjo", "Shamisen", "Koto", "Kalimba", "Bagpipe",
			"Fiddle", "Shanai", "Tinkle Bell", "Agogo", "Steel Drums", "Woodblock", "Taiko Drum", "Melodic Tom", "Synth Drum", "Reverse Cymbal",
			"Guitar Fret Noise", "Breath Noise", "Seashore", "Bird Tweet", "Telephone Ring", "Helicopter", "Applause", "Gunshot"
		};

		/// <summary>
		/// The Patch Number
		/// </summary>
		public int Patch
		{
			get
			{
				return patch;
			}
			set
			{
				if (value < 0 || value > 127)
				{
					throw new ArgumentOutOfRangeException("value", "Patch number must be in the range 0-127");
				}
				patch = (byte)value;
			}
		}

		/// <summary>
		/// Gets the default MIDI instrument names
		/// </summary>
		public static string GetPatchName(int patchNumber)
		{
			return patchNames[patchNumber];
		}

		/// <summary>
		/// Reads a new patch change event from a MIDI stream
		/// </summary>
		/// <param name="br">Binary reader for the MIDI stream</param>
		public PatchChangeEvent(BinaryReader br)
		{
			patch = br.ReadByte();
			if ((patch & 0x80u) != 0)
			{
				throw new FormatException("Invalid patch");
			}
		}

		/// <summary>
		/// Creates a new patch change event
		/// </summary>
		/// <param name="absoluteTime">Time of the event</param>
		/// <param name="channel">Channel number</param>
		/// <param name="patchNumber">Patch number</param>
		public PatchChangeEvent(long absoluteTime, int channel, int patchNumber)
			: base(absoluteTime, channel, MidiCommandCode.PatchChange)
		{
			Patch = patchNumber;
		}

		/// <summary>
		/// Describes this patch change event
		/// </summary>
		/// <returns>String describing the patch change event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {GetPatchName(patch)}";
		}

		/// <summary>
		/// Gets as a short message for sending with the midiOutShortMsg API
		/// </summary>
		/// <returns>short message</returns>
		public override int GetAsShortMessage()
		{
			return base.GetAsShortMessage() + (patch << 8);
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(patch);
		}
	}

	/// <summary>
	/// Represents a MIDI pitch wheel change event
	/// </summary>
	public class PitchWheelChangeEvent : MidiEvent
	{
		private int pitch;

		/// <summary>
		/// Pitch Wheel Value 0 is minimum, 0x2000 (8192) is default, 0x3FFF (16383) is maximum
		/// </summary>
		public int Pitch
		{
			get
			{
				return pitch;
			}
			set
			{
				if (value < 0 || value >= 16384)
				{
					throw new ArgumentOutOfRangeException("value", "Pitch value must be in the range 0 - 0x3FFF");
				}
				pitch = value;
			}
		}

		/// <summary>
		/// Reads a pitch wheel change event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream to read from</param>
		public PitchWheelChangeEvent(BinaryReader br)
		{
			byte b = br.ReadByte();
			byte b2 = br.ReadByte();
			if ((b & 0x80u) != 0)
			{
				throw new FormatException("Invalid pitchwheelchange byte 1");
			}
			if ((b2 & 0x80u) != 0)
			{
				throw new FormatException("Invalid pitchwheelchange byte 2");
			}
			pitch = b + (b2 << 7);
		}

		/// <summary>
		/// Creates a new pitch wheel change event
		/// </summary>
		/// <param name="absoluteTime">Absolute event time</param>
		/// <param name="channel">Channel</param>
		/// <param name="pitchWheel">Pitch wheel value</param>
		public PitchWheelChangeEvent(long absoluteTime, int channel, int pitchWheel)
			: base(absoluteTime, channel, MidiCommandCode.PitchWheelChange)
		{
			Pitch = pitchWheel;
		}

		/// <summary>
		/// Describes this pitch wheel change event
		/// </summary>
		/// <returns>String describing this pitch wheel change event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} Pitch {pitch} ({pitch - 8192})";
		}

		/// <summary>
		/// Gets a short message
		/// </summary>
		/// <returns>Integer to sent as short message</returns>
		public override int GetAsShortMessage()
		{
			return base.GetAsShortMessage() + ((pitch & 0x7F) << 8) + (((pitch >> 7) & 0x7F) << 16);
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)((uint)pitch & 0x7Fu));
			writer.Write((byte)((uint)(pitch >> 7) & 0x7Fu));
		}
	}

	/// <summary>
	/// Represents a MIDI meta event with raw data
	/// </summary>
	public class RawMetaEvent : MetaEvent
	{
		/// <summary>
		/// Raw data contained in the meta event
		/// </summary>
		public byte[] Data { get; set; }

		/// <summary>
		///  Creates a meta event with raw data
		/// </summary>
		public RawMetaEvent(MetaEventType metaEventType, long absoluteTime, byte[] data)
			: base(metaEventType, (data != null) ? data.Length : 0, absoluteTime)
		{
			Data = data;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return new RawMetaEvent(base.MetaEventType, base.AbsoluteTime, (byte[])Data?.Clone());
		}

		/// <summary>
		/// Describes this meta event
		/// </summary>
		public override string ToString()
		{
			StringBuilder stringBuilder = new StringBuilder().Append(base.ToString());
			byte[] data = Data;
			foreach (byte b in data)
			{
				stringBuilder.AppendFormat(" {0:X2}", b);
			}
			return stringBuilder.ToString();
		}

		/// <summary>
		/// <see cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)" />
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			if (Data != null)
			{
				writer.Write(Data, 0, Data.Length);
			}
		}
	}

	/// <summary>
	/// Represents a Sequencer Specific event
	/// </summary>
	public class SequencerSpecificEvent : MetaEvent
	{
		private byte[] data;

		/// <summary>
		/// The contents of this sequencer specific
		/// </summary>
		public byte[] Data
		{
			get
			{
				return data;
			}
			set
			{
				data = value;
				metaDataLength = data.Length;
			}
		}

		/// <summary>
		/// Reads a new sequencer specific event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">The data length</param>
		public SequencerSpecificEvent(BinaryReader br, int length)
		{
			data = br.ReadBytes(length);
		}

		/// <summary>
		/// Creates a new Sequencer Specific event
		/// </summary>
		/// <param name="data">The sequencer specific data</param>
		/// <param name="absoluteTime">Absolute time of this event</param>
		public SequencerSpecificEvent(byte[] data, long absoluteTime)
			: base(MetaEventType.SequencerSpecific, data.Length, absoluteTime)
		{
			this.data = data;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return new SequencerSpecificEvent((byte[])data.Clone(), base.AbsoluteTime);
		}

		/// <summary>
		/// Describes this MIDI text event
		/// </summary>
		/// <returns>A string describing this event</returns>
		public override string ToString()
		{
			StringBuilder stringBuilder = new StringBuilder();
			stringBuilder.Append(base.ToString());
			stringBuilder.Append(" ");
			byte[] array = data;
			foreach (byte b in array)
			{
				stringBuilder.AppendFormat("{0:X2} ", b);
			}
			stringBuilder.Length--;
			return stringBuilder.ToString();
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(data);
		}
	}

	/// <summary>
	/// SMPTE Offset Event
	/// </summary>
	public class SmpteOffsetEvent : MetaEvent
	{
		private readonly byte hours;

		private readonly byte minutes;

		private readonly byte seconds;

		private readonly byte frames;

		private readonly byte subFrames;

		/// <summary>
		/// Hours
		/// </summary>
		public int Hours => hours;

		/// <summary>
		/// Minutes
		/// </summary>
		public int Minutes => minutes;

		/// <summary>
		/// Seconds
		/// </summary>
		public int Seconds => seconds;

		/// <summary>
		/// Frames
		/// </summary>
		public int Frames => frames;

		/// <summary>
		/// SubFrames
		/// </summary>
		public int SubFrames => subFrames;

		/// <summary>
		/// Creates a new time signature event
		/// </summary>
		public SmpteOffsetEvent(byte hours, byte minutes, byte seconds, byte frames, byte subFrames)
		{
			this.hours = hours;
			this.minutes = minutes;
			this.seconds = seconds;
			this.frames = frames;
			this.subFrames = subFrames;
		}

		/// <summary>
		/// Reads a new time signature event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">The data length</param>
		public SmpteOffsetEvent(BinaryReader br, int length)
		{
			if (length != 5)
			{
				throw new FormatException($"Invalid SMPTE Offset length: Got {length}, expected 5");
			}
			hours = br.ReadByte();
			minutes = br.ReadByte();
			seconds = br.ReadByte();
			frames = br.ReadByte();
			subFrames = br.ReadByte();
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (SmpteOffsetEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this time signature event
		/// </summary>
		/// <returns>A string describing this event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {hours}:{minutes}:{seconds}:{frames}:{subFrames}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(hours);
			writer.Write(minutes);
			writer.Write(seconds);
			writer.Write(frames);
			writer.Write(subFrames);
		}
	}

	/// <summary>
	/// Represents a MIDI sysex message
	/// </summary>
	public class SysexEvent : MidiEvent
	{
		private byte[] data;

		/// <summary>
		/// Reads a sysex message from a MIDI stream
		/// </summary>
		/// <param name="br">Stream of MIDI data</param>
		/// <returns>a new sysex message</returns>
		public static SysexEvent ReadSysexEvent(BinaryReader br)
		{
			SysexEvent sysexEvent = new SysexEvent();
			List<byte> list = new List<byte>();
			bool flag = true;
			while (flag)
			{
				byte b = br.ReadByte();
				if (b == 247)
				{
					flag = false;
				}
				else
				{
					list.Add(b);
				}
			}
			sysexEvent.data = list.ToArray();
			return sysexEvent;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return new SysexEvent
			{
				data = (byte[])data?.Clone()
			};
		}

		/// <summary>
		/// Describes this sysex message
		/// </summary>
		/// <returns>A string describing the sysex message</returns>
		public override string ToString()
		{
			StringBuilder stringBuilder = new StringBuilder();
			byte[] array = data;
			foreach (byte b in array)
			{
				stringBuilder.AppendFormat("{0:X2} ", b);
			}
			return $"{base.AbsoluteTime} Sysex: {data.Length} bytes\r\n{stringBuilder.ToString()}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(data, 0, data.Length);
			writer.Write((byte)247);
		}
	}

	/// <summary>
	/// Represents a MIDI tempo event
	/// </summary>
	public class TempoEvent : MetaEvent
	{
		private int microsecondsPerQuarterNote;

		/// <summary>
		/// Microseconds per quarter note
		/// </summary>
		public int MicrosecondsPerQuarterNote
		{
			get
			{
				return microsecondsPerQuarterNote;
			}
			set
			{
				microsecondsPerQuarterNote = value;
			}
		}

		/// <summary>
		/// Tempo
		/// </summary>
		public double Tempo
		{
			get
			{
				return 60000000.0 / (double)microsecondsPerQuarterNote;
			}
			set
			{
				microsecondsPerQuarterNote = (int)(60000000.0 / value);
			}
		}

		/// <summary>
		/// Reads a new tempo event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">the data length</param>
		public TempoEvent(BinaryReader br, int length)
		{
			if (length != 3)
			{
				throw new FormatException("Invalid tempo length");
			}
			microsecondsPerQuarterNote = (br.ReadByte() << 16) + (br.ReadByte() << 8) + br.ReadByte();
		}

		/// <summary>
		/// Creates a new tempo event with specified settings
		/// </summary>
		/// <param name="microsecondsPerQuarterNote">Microseconds per quarter note</param>
		/// <param name="absoluteTime">Absolute time</param>
		public TempoEvent(int microsecondsPerQuarterNote, long absoluteTime)
			: base(MetaEventType.SetTempo, 3, absoluteTime)
		{
			this.microsecondsPerQuarterNote = microsecondsPerQuarterNote;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (TempoEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this tempo event
		/// </summary>
		/// <returns>String describing the tempo event</returns>
		public override string ToString()
		{
			return string.Format("{0} {2}bpm ({1})", base.ToString(), microsecondsPerQuarterNote, 60000000 / microsecondsPerQuarterNote);
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)((uint)(microsecondsPerQuarterNote >> 16) & 0xFFu));
			writer.Write((byte)((uint)(microsecondsPerQuarterNote >> 8) & 0xFFu));
			writer.Write((byte)((uint)microsecondsPerQuarterNote & 0xFFu));
		}
	}

	/// <summary>
	/// Represents a MIDI text event
	/// </summary>
	public class TextEvent : MetaEvent
	{
		private byte[] data;

		/// <summary>
		/// The contents of this text event
		/// </summary>
		public string Text
		{
			get
			{
				return ByteEncoding.Instance.GetString(data);
			}
			set
			{
				Encoding instance = ByteEncoding.Instance;
				data = instance.GetBytes(value);
				metaDataLength = data.Length;
			}
		}

		/// <summary>
		/// The raw contents of this text event
		/// </summary>
		public byte[] Data
		{
			get
			{
				return data;
			}
			set
			{
				data = value;
				metaDataLength = data.Length;
			}
		}

		/// <summary>
		/// Reads a new text event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">The data length</param>
		public TextEvent(BinaryReader br, int length)
		{
			data = br.ReadBytes(length);
		}

		/// <summary>
		/// Creates a new TextEvent
		/// </summary>
		/// <param name="text">The text in this type</param>
		/// <param name="metaEventType">MetaEvent type (must be one that is
		/// associated with text data)</param>
		/// <param name="absoluteTime">Absolute time of this event</param>
		public TextEvent(string text, MetaEventType metaEventType, long absoluteTime)
			: base(metaEventType, text.Length, absoluteTime)
		{
			Text = text;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (TextEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this MIDI text event
		/// </summary>
		/// <returns>A string describing this event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {Text}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(data);
		}
	}

	/// <summary>
	/// Represents a MIDI time signature event
	/// </summary>
	public class TimeSignatureEvent : MetaEvent
	{
		private byte numerator;

		private byte denominator;

		private byte ticksInMetronomeClick;

		private byte no32ndNotesInQuarterNote;

		/// <summary>
		/// Numerator (number of beats in a bar)
		/// </summary>
		public int Numerator => numerator;

		/// <summary>
		/// Denominator (Beat unit),
		/// 1 means 2, 2 means 4 (crochet), 3 means 8 (quaver), 4 means 16 and 5 means 32
		/// </summary>
		public int Denominator => denominator;

		/// <summary>
		/// Ticks in a metronome click
		/// </summary>
		public int TicksInMetronomeClick => ticksInMetronomeClick;

		/// <summary>
		/// Number of 32nd notes in a quarter note
		/// </summary>
		public int No32ndNotesInQuarterNote => no32ndNotesInQuarterNote;

		/// <summary>
		/// The time signature
		/// </summary>
		public string TimeSignature
		{
			get
			{
				string arg = $"Unknown ({denominator})";
				switch (denominator)
				{
				case 1:
					arg = "2";
					break;
				case 2:
					arg = "4";
					break;
				case 3:
					arg = "8";
					break;
				case 4:
					arg = "16";
					break;
				case 5:
					arg = "32";
					break;
				}
				return $"{numerator}/{arg}";
			}
		}

		/// <summary>
		/// Reads a new time signature event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">The data length</param>
		public TimeSignatureEvent(BinaryReader br, int length)
		{
			if (length != 4)
			{
				throw new FormatException($"Invalid time signature length: Got {length}, expected 4");
			}
			numerator = br.ReadByte();
			denominator = br.ReadByte();
			ticksInMetronomeClick = br.ReadByte();
			no32ndNotesInQuarterNote = br.ReadByte();
		}

		/// <summary>
		/// Creates a new TimeSignatureEvent
		/// </summary>
		/// <param name="absoluteTime">Time at which to create this event</param>
		/// <param name="numerator">Numerator</param>
		/// <param name="denominator">Denominator</param>
		/// <param name="ticksInMetronomeClick">Ticks in Metronome Click</param>
		/// <param name="no32ndNotesInQuarterNote">No of 32nd Notes in Quarter Click</param>
		public TimeSignatureEvent(long absoluteTime, int numerator, int denominator, int ticksInMetronomeClick, int no32ndNotesInQuarterNote)
			: base(MetaEventType.TimeSignature, 4, absoluteTime)
		{
			this.numerator = (byte)numerator;
			this.denominator = (byte)denominator;
			this.ticksInMetronomeClick = (byte)ticksInMetronomeClick;
			this.no32ndNotesInQuarterNote = (byte)no32ndNotesInQuarterNote;
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (TimeSignatureEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this time signature event
		/// </summary>
		/// <returns>A string describing this event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {TimeSignature} TicksInClick:{ticksInMetronomeClick} 32ndsInQuarterNote:{no32ndNotesInQuarterNote}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write(numerator);
			writer.Write(denominator);
			writer.Write(ticksInMetronomeClick);
			writer.Write(no32ndNotesInQuarterNote);
		}
	}

	/// <summary>
	/// Represents a MIDI track sequence number event event
	/// </summary>
	public class TrackSequenceNumberEvent : MetaEvent
	{
		private ushort sequenceNumber;

		/// <summary>
		/// Creates a new track sequence number event
		/// </summary>
		public TrackSequenceNumberEvent(ushort sequenceNumber)
		{
			this.sequenceNumber = sequenceNumber;
		}

		/// <summary>
		/// Reads a new track sequence number event from a MIDI stream
		/// </summary>
		/// <param name="br">The MIDI stream</param>
		/// <param name="length">the data length</param>
		public TrackSequenceNumberEvent(BinaryReader br, int length)
		{
			if (length != 2)
			{
				throw new FormatException("Invalid sequence number length");
			}
			sequenceNumber = (ushort)((br.ReadByte() << 8) + br.ReadByte());
		}

		/// <summary>
		/// Creates a deep clone of this MIDI event.
		/// </summary>
		public override MidiEvent Clone()
		{
			return (TrackSequenceNumberEvent)MemberwiseClone();
		}

		/// <summary>
		/// Describes this event
		/// </summary>
		/// <returns>String describing the event</returns>
		public override string ToString()
		{
			return $"{base.ToString()} {sequenceNumber}";
		}

		/// <summary>
		/// Calls base class export first, then exports the data 
		/// specific to this event
		/// <seealso cref="M:NAudio.Midi.MidiEvent.Export(System.Int64@,System.IO.BinaryWriter)">MidiEvent.Export</seealso>
		/// </summary>
		public override void Export(ref long absoluteTime, BinaryWriter writer)
		{
			base.Export(ref absoluteTime, writer);
			writer.Write((byte)((uint)(sequenceNumber >> 8) & 0xFFu));
			writer.Write((byte)(sequenceNumber & 0xFFu));
		}
	}
}


namespace NAudio.CoreAudioApi
{
	using System.Collections;
	using NAudio.CoreAudioApi.Interfaces;
	using NAudio.Wasapi.CoreAudioApi;
	using NAudio.Wave;
	
	/// <summary>
	/// Audio Capture Client
	/// </summary>
	public class AudioCaptureClient : IDisposable
	{
		private IAudioCaptureClient audioCaptureClientInterface;

		internal AudioCaptureClient(IAudioCaptureClient audioCaptureClientInterface)
		{
			this.audioCaptureClientInterface = audioCaptureClientInterface;
		}

		/// <summary>
		/// Gets a pointer to the buffer
		/// </summary>
		/// <returns>Pointer to the buffer</returns>
		public IntPtr GetBuffer(out int numFramesToRead, out AudioClientBufferFlags bufferFlags, out long devicePosition, out long qpcPosition)
		{
			Marshal.ThrowExceptionForHR(audioCaptureClientInterface.GetBuffer(out var dataBuffer, out numFramesToRead, out bufferFlags, out devicePosition, out qpcPosition));
			return dataBuffer;
		}

		/// <summary>
		/// Gets a pointer to the buffer
		/// </summary>
		/// <param name="numFramesToRead">Number of frames to read</param>
		/// <param name="bufferFlags">Buffer flags</param>
		/// <returns>Pointer to the buffer</returns>
		public IntPtr GetBuffer(out int numFramesToRead, out AudioClientBufferFlags bufferFlags)
		{
			Marshal.ThrowExceptionForHR(audioCaptureClientInterface.GetBuffer(out var dataBuffer, out numFramesToRead, out bufferFlags, out var _, out var _));
			return dataBuffer;
		}

		/// <summary>
		/// Gets the size of the next packet
		/// </summary>
		public int GetNextPacketSize()
		{
			Marshal.ThrowExceptionForHR(audioCaptureClientInterface.GetNextPacketSize(out var numFramesInNextPacket));
			return numFramesInNextPacket;
		}

		/// <summary>
		/// Release buffer
		/// </summary>
		/// <param name="numFramesWritten">Number of frames written</param>
		public void ReleaseBuffer(int numFramesWritten)
		{
			Marshal.ThrowExceptionForHR(audioCaptureClientInterface.ReleaseBuffer(numFramesWritten));
		}

		/// <summary>
		/// Release the COM object
		/// </summary>
		public void Dispose()
		{
			if (audioCaptureClientInterface != null)
			{
				Marshal.ReleaseComObject(audioCaptureClientInterface);
				audioCaptureClientInterface = null;
				GC.SuppressFinalize(this);
			}
		}
	}

	/// <summary>
	/// Windows CoreAudio AudioClient
	/// </summary>
	public class AudioClient : IDisposable
	{
		private IAudioClient audioClientInterface;

		private WaveFormat mixFormat;

		private AudioRenderClient audioRenderClient;

		private AudioCaptureClient audioCaptureClient;

		private AudioClockClient audioClockClient;

		private AudioStreamVolume audioStreamVolume;

		private AudioClientShareMode shareMode;

		/// <summary>
		/// Retrieves the stream format that the audio engine uses for its internal processing of shared-mode streams.
		/// Can be called before initialize
		/// </summary>
		public WaveFormat MixFormat
		{
			get
			{
				if (mixFormat == null)
				{
					Marshal.ThrowExceptionForHR(audioClientInterface.GetMixFormat(out var deviceFormatPointer));
					WaveFormat waveFormat = WaveFormat.MarshalFromPtr(deviceFormatPointer);
					Marshal.FreeCoTaskMem(deviceFormatPointer);
					mixFormat = waveFormat;
				}
				return mixFormat;
			}
		}

		/// <summary>
		/// Retrieves the size (maximum capacity) of the audio buffer associated with the endpoint. (must initialize first)
		/// </summary>
		public int BufferSize
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClientInterface.GetBufferSize(out var bufferSize));
				return (int)bufferSize;
			}
		}

		/// <summary>
		/// Retrieves the maximum latency for the current stream and can be called any time after the stream has been initialized.
		/// </summary>
		public long StreamLatency => audioClientInterface.GetStreamLatency();

		/// <summary>
		/// Retrieves the number of frames of padding in the endpoint buffer (must initialize first)
		/// </summary>
		public int CurrentPadding
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClientInterface.GetCurrentPadding(out var currentPadding));
				return currentPadding;
			}
		}

		/// <summary>
		/// Retrieves the length of the periodic interval separating successive processing passes by the audio engine on the data in the endpoint buffer.
		/// (can be called before initialize)
		/// </summary>
		public long DefaultDevicePeriod
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClientInterface.GetDevicePeriod(out var defaultDevicePeriod, out var _));
				return defaultDevicePeriod;
			}
		}

		/// <summary>
		/// Gets the minimum device period 
		/// (can be called before initialize)
		/// </summary>
		public long MinimumDevicePeriod
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClientInterface.GetDevicePeriod(out var _, out var minimumDevicePeriod));
				return minimumDevicePeriod;
			}
		}

		/// <summary>
		/// Returns the AudioStreamVolume service for this AudioClient.
		/// </summary>
		/// <remarks>
		/// This returns the AudioStreamVolume object ONLY for shared audio streams.
		/// </remarks>
		/// <exception cref="T:System.InvalidOperationException">
		/// This is thrown when an exclusive audio stream is being used.
		/// </exception>
		public AudioStreamVolume AudioStreamVolume
		{
			get
			{
				if (shareMode == AudioClientShareMode.Exclusive)
				{
					throw new InvalidOperationException("AudioStreamVolume is ONLY supported for shared audio streams.");
				}
				if (audioStreamVolume == null)
				{
					Guid interfaceId = new Guid("93014887-242D-4068-8A15-CF5E93B90FE3");
					Marshal.ThrowExceptionForHR(audioClientInterface.GetService(interfaceId, out var interfacePointer));
					audioStreamVolume = new AudioStreamVolume((IAudioStreamVolume)interfacePointer);
				}
				return audioStreamVolume;
			}
		}

		/// <summary>
		/// Gets the AudioClockClient service
		/// </summary>
		public AudioClockClient AudioClockClient
		{
			get
			{
				if (audioClockClient == null)
				{
					Guid interfaceId = new Guid("CD63314F-3FBA-4a1b-812C-EF96358728E7");
					Marshal.ThrowExceptionForHR(audioClientInterface.GetService(interfaceId, out var interfacePointer));
					audioClockClient = new AudioClockClient((IAudioClock)interfacePointer);
				}
				return audioClockClient;
			}
		}

		/// <summary>
		/// Gets the AudioRenderClient service
		/// </summary>
		public AudioRenderClient AudioRenderClient
		{
			get
			{
				if (audioRenderClient == null)
				{
					Guid interfaceId = new Guid("F294ACFC-3146-4483-A7BF-ADDCA7C260E2");
					Marshal.ThrowExceptionForHR(audioClientInterface.GetService(interfaceId, out var interfacePointer));
					audioRenderClient = new AudioRenderClient((IAudioRenderClient)interfacePointer);
				}
				return audioRenderClient;
			}
		}

		/// <summary>
		/// Gets the AudioCaptureClient service
		/// </summary>
		public AudioCaptureClient AudioCaptureClient
		{
			get
			{
				if (audioCaptureClient == null)
				{
					Guid interfaceId = new Guid("c8adbd64-e71e-48a0-a4de-185c395cd317");
					Marshal.ThrowExceptionForHR(audioClientInterface.GetService(interfaceId, out var interfacePointer));
					audioCaptureClient = new AudioCaptureClient((IAudioCaptureClient)interfacePointer);
				}
				return audioCaptureClient;
			}
		}

		/// <summary>
		/// Activate Async
		/// </summary>
		public static async Task<AudioClient> ActivateAsync(string deviceInterfacePath, AudioClientProperties? audioClientProperties)
		{
			ActivateAudioInterfaceCompletionHandler activateAudioInterfaceCompletionHandler = new ActivateAudioInterfaceCompletionHandler(delegate(IAudioClient2 ac2)
			{
				if (audioClientProperties.HasValue)
				{
					IntPtr intPtr = Marshal.AllocHGlobal(Marshal.SizeOf(audioClientProperties.Value));
					try
					{
						Marshal.StructureToPtr(audioClientProperties.Value, intPtr, fDeleteOld: false);
						ac2.SetClientProperties(intPtr);
					}
					finally
					{
						Marshal.FreeHGlobal(intPtr);
					}
				}
			});
			Guid riid = new Guid("726778CD-F60A-4eda-82DE-E47610CD78AA");
			NativeMethods.ActivateAudioInterfaceAsync(deviceInterfacePath, riid, IntPtr.Zero, activateAudioInterfaceCompletionHandler, out var _);
			return new AudioClient(await activateAudioInterfaceCompletionHandler);
		}

		public AudioClient(IAudioClient audioClientInterface)
		{
			this.audioClientInterface = audioClientInterface;
		}

		/// <summary>
		/// Initializes the Audio Client
		/// </summary>
		/// <param name="shareMode">Share Mode</param>
		/// <param name="streamFlags">Stream Flags</param>
		/// <param name="bufferDuration">Buffer Duration</param>
		/// <param name="periodicity">Periodicity</param>
		/// <param name="waveFormat">Wave Format</param>
		/// <param name="audioSessionGuid">Audio Session GUID (can be null)</param>
		public void Initialize(AudioClientShareMode shareMode, AudioClientStreamFlags streamFlags, long bufferDuration, long periodicity, WaveFormat waveFormat, Guid audioSessionGuid)
		{
			this.shareMode = shareMode;
			Marshal.ThrowExceptionForHR(audioClientInterface.Initialize(shareMode, streamFlags, bufferDuration, periodicity, waveFormat, ref audioSessionGuid));
			mixFormat = null;
		}

		/// <summary>
		/// Determines whether if the specified output format is supported
		/// </summary>
		/// <param name="shareMode">The share mode.</param>
		/// <param name="desiredFormat">The desired format.</param>
		/// <returns>True if the format is supported</returns>
		public bool IsFormatSupported(AudioClientShareMode shareMode, WaveFormat desiredFormat)
		{
			WaveFormatExtensible closestMatchFormat;
			return IsFormatSupported(shareMode, desiredFormat, out closestMatchFormat);
		}

		private IntPtr GetPointerToPointer()
		{
			return Marshal.AllocHGlobal(Marshal.SizeOf<IntPtr>());
		}

		/// <summary>
		/// Determines if the specified output format is supported in shared mode
		/// </summary>
		/// <param name="shareMode">Share Mode</param>
		/// <param name="desiredFormat">Desired Format</param>
		/// <param name="closestMatchFormat">Output The closest match format.</param>
		/// <returns>True if the format is supported</returns>
		public bool IsFormatSupported(AudioClientShareMode shareMode, WaveFormat desiredFormat, out WaveFormatExtensible closestMatchFormat)
		{
			IntPtr pointerToPointer = GetPointerToPointer();
			closestMatchFormat = null;
			int num = audioClientInterface.IsFormatSupported(shareMode, desiredFormat, pointerToPointer);
			IntPtr intPtr = Marshal.PtrToStructure<IntPtr>(pointerToPointer);
			if (intPtr != IntPtr.Zero)
			{
				closestMatchFormat = Marshal.PtrToStructure<WaveFormatExtensible>(intPtr);
				Marshal.FreeCoTaskMem(intPtr);
			}
			Marshal.FreeHGlobal(pointerToPointer);
			switch (num)
			{
			case 0:
				return true;
			case 1:
				return false;
			case -2004287480:
				return false;
			default:
				Marshal.ThrowExceptionForHR(num);
				throw new NotSupportedException("Unknown hresult " + num);
			}
		}

		/// <summary>
		/// Starts the audio stream
		/// </summary>
		public void Start()
		{
			audioClientInterface.Start();
		}

		/// <summary>
		/// Stops the audio stream.
		/// </summary>
		public void Stop()
		{
			audioClientInterface.Stop();
		}

		/// <summary>
		/// Set the Event Handle for buffer synchro.
		/// </summary>
		/// <param name="eventWaitHandle">The Wait Handle to setup</param>
		public void SetEventHandle(IntPtr eventWaitHandle)
		{
			audioClientInterface.SetEventHandle(eventWaitHandle);
		}

		/// <summary>
		/// Resets the audio stream
		/// Reset is a control method that the client calls to reset a stopped audio stream. 
		/// Resetting the stream flushes all pending data and resets the audio clock stream 
		/// position to 0. This method fails if it is called on a stream that is not stopped
		/// </summary>
		public void Reset()
		{
			audioClientInterface.Reset();
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (audioClientInterface != null)
			{
				if (audioClockClient != null)
				{
					audioClockClient.Dispose();
					audioClockClient = null;
				}
				if (audioRenderClient != null)
				{
					audioRenderClient.Dispose();
					audioRenderClient = null;
				}
				if (audioCaptureClient != null)
				{
					audioCaptureClient.Dispose();
					audioCaptureClient = null;
				}
				if (audioStreamVolume != null)
				{
					audioStreamVolume.Dispose();
					audioStreamVolume = null;
				}
				Marshal.ReleaseComObject(audioClientInterface);
				audioClientInterface = null;
				GC.SuppressFinalize(this);
			}
		}
	}

	/// <summary>
	/// AUDIOCLIENT_ACTIVATION_PARAMS
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclientactivationparams/ns-audioclientactivationparams-audioclient_activation_params
	/// </summary>
	internal struct AudioClientActivationParams
	{
		public AudioClientActivationType ActivationType;

		public AudioClientProcessLoopbackParams ProcessLoopbackParams;
	}

	/// <summary>
	/// AUDIOCLIENT_ACTIVATION_TYPE
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclientactivationparams/ne-audioclientactivationparams-audioclient_activation_type
	/// </summary>
	internal enum AudioClientActivationType
	{
		/// <summary>
		/// AUDIOCLIENT_ACTIVATION_TYPE_DEFAULT
		/// Default activation.
		/// </summary>
		Default,
		/// <summary>
		/// AUDIOCLIENT_ACTIVATION_TYPE_PROCESS_LOOPBACK
		/// Process loopback activation, allowing for the inclusion or exclusion of audio rendered by the specified process and its child processes.
		/// </summary>
		ProcessLoopback
	}

	/// <summary>
	/// Audio Client Buffer Flags
	/// </summary>
	[Flags]
	public enum AudioClientBufferFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// AUDCLNT_BUFFERFLAGS_DATA_DISCONTINUITY
		/// </summary>
		DataDiscontinuity = 1,
		/// <summary>
		/// AUDCLNT_BUFFERFLAGS_SILENT
		/// </summary>
		Silent = 2,
		/// <summary>
		/// AUDCLNT_BUFFERFLAGS_TIMESTAMP_ERROR
		/// </summary>
		TimestampError = 4
	}

	/// <summary>
	/// AUDIOCLIENT_PROCESS_LOOPBACK_PARAMS
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclientactivationparams/ns-audioclientactivationparams-audioclient_process_loopback_params
	/// </summary>
	internal struct AudioClientProcessLoopbackParams
	{
		/// <summary>
		/// AUDIOCLIENT_PROCESS_LOOPBACK_PARAMS
		/// The ID of the process for which the render streams, and the render streams of its child processes, will be included or excluded when activating the process loopback stream.
		/// </summary>
		public uint TargetProcessId;

		public ProcessLoopbackMode ProcessLoopbackMode;
	}

	/// <summary>
	/// The AudioClientProperties structure is used to set the parameters that describe the properties of the client's audio stream.
	/// </summary>
	/// <remarks>https://docs.microsoft.com/en-us/windows/win32/api/audioclient/ns-audioclient-audioclientproperties-r1</remarks>
	public struct AudioClientProperties
	{
		/// <summary>
		/// The size of the buffer for the audio stream.
		/// </summary>
		public uint cbSize;

		/// <summary>
		/// Boolean value to indicate whether or not the audio stream is hardware-offloaded
		/// </summary>
		public int bIsOffload;

		/// <summary>
		/// An enumeration that is used to specify the category of the audio stream.
		/// </summary>
		public AudioStreamCategory eCategory;

		/// <summary>
		/// A bit-field describing the characteristics of the stream. Supported in Windows 8.1 and later.
		/// </summary>
		public AudioClientStreamOptions Options;
	}

	/// <summary>
	/// AUDCLNT_SHAREMODE
	/// </summary>
	public enum AudioClientShareMode
	{
		/// <summary>
		/// AUDCLNT_SHAREMODE_SHARED,
		/// </summary>
		Shared,
		/// <summary>
		/// AUDCLNT_SHAREMODE_EXCLUSIVE
		/// </summary>
		Exclusive
	}

	/// <summary>
	/// AUDCLNT_STREAMFLAGS
	/// https://docs.microsoft.com/en-us/windows/win32/coreaudio/audclnt-streamflags-xxx-constants
	/// </summary>
	[Flags]
	public enum AudioClientStreamFlags : uint
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_CROSSPROCESS
		/// The audio stream will be a member of a cross-process audio session.
		/// </summary>
		CrossProcess = 0x10000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_LOOPBACK
		/// The audio stream will operate in loopback mode
		/// </summary>
		Loopback = 0x20000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_EVENTCALLBACK 
		/// Processing of the audio buffer by the client will be event driven
		/// </summary>
		EventCallback = 0x40000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_NOPERSIST   
		/// The volume and mute settings for an audio session will not persist across application restarts
		/// </summary>
		NoPersist = 0x80000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_RATEADJUST
		/// The sample rate of the stream is adjusted to a rate specified by an application.
		/// </summary>
		RateAdjust = 0x100000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_SRC_DEFAULT_QUALITY
		/// When used with AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM, a sample rate converter with better quality 
		/// than the default conversion but with a higher performance cost is used. This should be used if 
		/// the audio is ultimately intended to be heard by humans as opposed to other scenarios such as 
		/// pumping silence or populating a meter.
		/// </summary>
		SrcDefaultQuality = 0x8000000u,
		/// <summary>
		/// AUDCLNT_STREAMFLAGS_AUTOCONVERTPCM
		/// A channel matrixer and a sample rate converter are inserted as necessary to convert between the uncompressed format supplied to IAudioClient::Initialize and the audio engine mix format.
		/// </summary>
		AutoConvertPcm = 0x80000000u
	}

	/// <summary>
	/// Defines values that describe the characteristics of an audio stream.
	/// AUDCLNT_STREAMOPTIONS 
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclient/ne-audioclient-audclnt_streamoptions
	/// </summary>
	[Flags]
	public enum AudioClientStreamOptions
	{
		/// <summary>
		/// AUDCLNT_STREAMOPTIONS_NONE
		/// No stream options.
		/// </summary>
		None = 0,
		/// <summary>
		/// AUDCLNT_STREAMOPTIONS_RAW
		/// The audio stream is a 'raw' stream that bypasses all signal processing except for endpoint specific, always-on processing in the APO, driver, and hardware.
		/// </summary>
		Raw = 1,
		/// <summary>
		/// AUDCLNT_STREAMOPTIONS_MATCH_FORMAT
		/// The audio client is requesting that the audio engine match the format proposed by the client. The audio engine
		/// will match this format only if the format is supported by the audio driver and associated APOs.
		/// </summary>
		MatchFormat = 2,
		/// <summary>
		/// AUDCLNT_STREAMOPTIONS_AMBISONICS
		/// </summary>
		Ambisonics = 4
	}

	/// <summary>
	/// Audio Clock Client
	/// </summary>
	public class AudioClockClient : IDisposable
	{
		private IAudioClock audioClockClientInterface;

		/// <summary>
		/// Characteristics
		/// </summary>
		public int Characteristics
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClockClientInterface.GetCharacteristics(out var characteristics));
				return (int)characteristics;
			}
		}

		/// <summary>
		/// Frequency
		/// </summary>
		public ulong Frequency
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioClockClientInterface.GetFrequency(out var frequency));
				return frequency;
			}
		}

		/// <summary>
		/// Adjusted Position
		/// </summary>
		public ulong AdjustedPosition
		{
			get
			{
				int num = 0;
				ulong position;
				ulong qpcPosition;
				while (!GetPosition(out position, out qpcPosition) && ++num != 5)
				{
				}
				if (Stopwatch.IsHighResolution)
				{
					ulong num2 = ((ulong)((decimal)Stopwatch.GetTimestamp() * 10000000m / (decimal)Stopwatch.Frequency) - qpcPosition) * Frequency / 10000000uL;
					return position + num2;
				}
				return position;
			}
		}

		/// <summary>
		/// Can Adjust Position
		/// </summary>
		public bool CanAdjustPosition => Stopwatch.IsHighResolution;

		internal AudioClockClient(IAudioClock audioClockClientInterface)
		{
			this.audioClockClientInterface = audioClockClientInterface;
		}

		/// <summary>
		/// Get Position
		/// </summary>
		public bool GetPosition(out ulong position, out ulong qpcPosition)
		{
			int position2 = audioClockClientInterface.GetPosition(out position, out qpcPosition);
			if (position2 == -1)
			{
				return false;
			}
			Marshal.ThrowExceptionForHR(position2);
			return true;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (audioClockClientInterface != null)
			{
				Marshal.ReleaseComObject(audioClockClientInterface);
				audioClockClientInterface = null;
				GC.SuppressFinalize(this);
			}
		}
	}

	/// <summary>
	/// Audio Endpoint Volume
	/// </summary>
	public class AudioEndpointVolume : IDisposable
	{
		private readonly IAudioEndpointVolume audioEndPointVolume;

		private AudioEndpointVolumeCallback callBack;

		private Guid notificationGuid = Guid.Empty;

		/// <summary>
		/// GUID to pass to AudioEndpointVolumeCallback
		/// </summary>
		public Guid NotificationGuid
		{
			get
			{
				return notificationGuid;
			}
			set
			{
				notificationGuid = value;
			}
		}

		/// <summary>
		/// Volume Range
		/// </summary>
		public AudioEndpointVolumeVolumeRange VolumeRange { get; }

		/// <summary>
		/// Hardware Support
		/// </summary>
		public EEndpointHardwareSupport HardwareSupport { get; }

		/// <summary>
		/// Step Information
		/// </summary>
		public AudioEndpointVolumeStepInformation StepInformation { get; }

		/// <summary>
		/// Channels
		/// </summary>
		public AudioEndpointVolumeChannels Channels { get; }

		/// <summary>
		/// Master Volume Level
		/// </summary>
		public float MasterVolumeLevel
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.GetMasterVolumeLevel(out var pfLevelDB));
				return pfLevelDB;
			}
			set
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.SetMasterVolumeLevel(value, ref notificationGuid));
			}
		}

		/// <summary>
		/// Master Volume Level Scalar
		/// </summary>
		public float MasterVolumeLevelScalar
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.GetMasterVolumeLevelScalar(out var pfLevel));
				return pfLevel;
			}
			set
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.SetMasterVolumeLevelScalar(value, ref notificationGuid));
			}
		}

		/// <summary>
		/// Mute
		/// </summary>
		public bool Mute
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.GetMute(out var pbMute));
				return pbMute;
			}
			set
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.SetMute(value, ref notificationGuid));
			}
		}

		/// <summary>
		/// On Volume Notification
		/// </summary>
		public event AudioEndpointVolumeNotificationDelegate OnVolumeNotification;

		/// <summary>
		/// Volume Step Up
		/// </summary>
		public void VolumeStepUp()
		{
			Marshal.ThrowExceptionForHR(audioEndPointVolume.VolumeStepUp(ref notificationGuid));
		}

		/// <summary>
		/// Volume Step Down
		/// </summary>
		public void VolumeStepDown()
		{
			Marshal.ThrowExceptionForHR(audioEndPointVolume.VolumeStepDown(ref notificationGuid));
		}

		/// <summary>
		/// Creates a new Audio endpoint volume
		/// </summary>
		/// <param name="realEndpointVolume">IAudioEndpointVolume COM interface</param>
		internal AudioEndpointVolume(IAudioEndpointVolume realEndpointVolume)
		{
			audioEndPointVolume = realEndpointVolume;
			Channels = new AudioEndpointVolumeChannels(audioEndPointVolume);
			StepInformation = new AudioEndpointVolumeStepInformation(audioEndPointVolume);
			Marshal.ThrowExceptionForHR(audioEndPointVolume.QueryHardwareSupport(out var pdwHardwareSupportMask));
			HardwareSupport = (EEndpointHardwareSupport)pdwHardwareSupportMask;
			VolumeRange = new AudioEndpointVolumeVolumeRange(audioEndPointVolume);
			callBack = new AudioEndpointVolumeCallback(this);
			Marshal.ThrowExceptionForHR(audioEndPointVolume.RegisterControlChangeNotify(callBack));
		}

		internal void FireNotification(AudioVolumeNotificationData notificationData)
		{
			this.OnVolumeNotification?.Invoke(notificationData);
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (callBack != null)
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.UnregisterControlChangeNotify(callBack));
				callBack = null;
			}
			Marshal.ReleaseComObject(audioEndPointVolume);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~AudioEndpointVolume()
		{
			Dispose();
		}
	}

	internal class AudioEndpointVolumeCallback : IAudioEndpointVolumeCallback
	{
		private readonly AudioEndpointVolume parent;

		internal AudioEndpointVolumeCallback(AudioEndpointVolume parent)
		{
			this.parent = parent;
		}

		public void OnNotify(IntPtr notifyData)
		{
			AudioVolumeNotificationDataStruct audioVolumeNotificationDataStruct = Marshal.PtrToStructure<AudioVolumeNotificationDataStruct>(notifyData);
			IntPtr intPtr = Marshal.OffsetOf<AudioVolumeNotificationDataStruct>("ChannelVolume");
			IntPtr ptr = (IntPtr)((long)notifyData + (long)intPtr);
			float[] array = new float[audioVolumeNotificationDataStruct.nChannels];
			for (int i = 0; i < audioVolumeNotificationDataStruct.nChannels; i++)
			{
				array[i] = Marshal.PtrToStructure<float>(ptr);
			}
			AudioVolumeNotificationData notificationData = new AudioVolumeNotificationData(audioVolumeNotificationDataStruct.guidEventContext, audioVolumeNotificationDataStruct.bMuted, audioVolumeNotificationDataStruct.fMasterVolume, array, audioVolumeNotificationDataStruct.guidEventContext);
			parent.FireNotification(notificationData);
		}
	}

	/// <summary>
	/// Audio Endpoint Volume Channel
	/// </summary>
	public class AudioEndpointVolumeChannel
	{
		private readonly uint channel;

		private readonly IAudioEndpointVolume audioEndpointVolume;

		private Guid notificationGuid = Guid.Empty;

		/// <summary>
		/// GUID to pass to AudioEndpointVolumeCallback
		/// </summary>
		public Guid NotificationGuid
		{
			get
			{
				return notificationGuid;
			}
			set
			{
				notificationGuid = value;
			}
		}

		/// <summary>
		/// Volume Level
		/// </summary>
		public float VolumeLevel
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndpointVolume.GetChannelVolumeLevel(channel, out var pfLevelDB));
				return pfLevelDB;
			}
			set
			{
				Marshal.ThrowExceptionForHR(audioEndpointVolume.SetChannelVolumeLevel(channel, value, ref notificationGuid));
			}
		}

		/// <summary>
		/// Volume Level Scalar
		/// </summary>
		public float VolumeLevelScalar
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndpointVolume.GetChannelVolumeLevelScalar(channel, out var pfLevel));
				return pfLevel;
			}
			set
			{
				Marshal.ThrowExceptionForHR(audioEndpointVolume.SetChannelVolumeLevelScalar(channel, value, ref notificationGuid));
			}
		}

		internal AudioEndpointVolumeChannel(IAudioEndpointVolume parent, int channel)
		{
			this.channel = (uint)channel;
			audioEndpointVolume = parent;
		}
	}

	/// <summary>
	/// Audio Endpoint Volume Channels
	/// </summary>
	public class AudioEndpointVolumeChannels
	{
		private readonly IAudioEndpointVolume audioEndPointVolume;

		private readonly AudioEndpointVolumeChannel[] channels;

		/// <summary>
		/// Channel Count
		/// </summary>
		public int Count
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioEndPointVolume.GetChannelCount(out var pnChannelCount));
				return pnChannelCount;
			}
		}

		/// <summary>
		/// Indexer - get a specific channel
		/// </summary>
		public AudioEndpointVolumeChannel this[int index] => channels[index];

		internal AudioEndpointVolumeChannels(IAudioEndpointVolume parent)
		{
			audioEndPointVolume = parent;
			int count = Count;
			channels = new AudioEndpointVolumeChannel[count];
			for (int i = 0; i < count; i++)
			{
				channels[i] = new AudioEndpointVolumeChannel(audioEndPointVolume, i);
			}
		}
	}

	/// <summary>
	/// Audio Endpoint Volume Notifiaction Delegate
	/// </summary>
	/// <param name="data">Audio Volume Notification Data</param>
	public delegate void AudioEndpointVolumeNotificationDelegate(AudioVolumeNotificationData data);

	/// <summary>
	/// Audio Endpoint Volume Step Information
	/// </summary>
	public class AudioEndpointVolumeStepInformation
	{
		private readonly uint step;

		private readonly uint stepCount;

		/// <summary>
		/// Step
		/// </summary>
		public uint Step => step;

		/// <summary>
		/// StepCount
		/// </summary>
		public uint StepCount => stepCount;

		internal AudioEndpointVolumeStepInformation(IAudioEndpointVolume parent)
		{
			Marshal.ThrowExceptionForHR(parent.GetVolumeStepInfo(out step, out stepCount));
		}
	}

	/// <summary>
	/// Audio Endpoint Volume Volume Range
	/// </summary>
	public class AudioEndpointVolumeVolumeRange
	{
		private readonly float volumeMinDecibels;

		private readonly float volumeMaxDecibels;

		private readonly float volumeIncrementDecibels;

		/// <summary>
		/// Minimum Decibels
		/// </summary>
		public float MinDecibels => volumeMinDecibels;

		/// <summary>
		/// Maximum Decibels
		/// </summary>
		public float MaxDecibels => volumeMaxDecibels;

		/// <summary>
		/// Increment Decibels
		/// </summary>
		public float IncrementDecibels => volumeIncrementDecibels;

		internal AudioEndpointVolumeVolumeRange(IAudioEndpointVolume parent)
		{
			Marshal.ThrowExceptionForHR(parent.GetVolumeRange(out volumeMinDecibels, out volumeMaxDecibels, out volumeIncrementDecibels));
		}
	}

	/// <summary>
	/// Audio Meter Information
	/// </summary>
	public class AudioMeterInformation
	{
		private readonly IAudioMeterInformation audioMeterInformation;

		/// <summary>
		/// Peak Values
		/// </summary>
		public AudioMeterInformationChannels PeakValues { get; }

		/// <summary>
		/// Hardware Support
		/// </summary>
		public EEndpointHardwareSupport HardwareSupport { get; }

		/// <summary>
		/// Master Peak Value
		/// </summary>
		public float MasterPeakValue
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioMeterInformation.GetPeakValue(out var pfPeak));
				return pfPeak;
			}
		}

		internal AudioMeterInformation(IAudioMeterInformation realInterface)
		{
			audioMeterInformation = realInterface;
			Marshal.ThrowExceptionForHR(audioMeterInformation.QueryHardwareSupport(out var pdwHardwareSupportMask));
			HardwareSupport = (EEndpointHardwareSupport)pdwHardwareSupportMask;
			PeakValues = new AudioMeterInformationChannels(audioMeterInformation);
		}
	}

	/// <summary>
	/// Audio Meter Information Channels
	/// </summary>
	public class AudioMeterInformationChannels
	{
		private readonly IAudioMeterInformation audioMeterInformation;

		/// <summary>
		/// Metering Channel Count
		/// </summary>
		public int Count
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioMeterInformation.GetMeteringChannelCount(out var pnChannelCount));
				return pnChannelCount;
			}
		}

		/// <summary>
		/// Get Peak value
		/// </summary>
		/// <param name="index">Channel index</param>
		/// <returns>Peak value</returns>
		public float this[int index]
		{
			get
			{
				int count = Count;
				if (index >= count)
				{
					throw new ArgumentOutOfRangeException("index", $"Peak index cannot be greater than number of channels ({count})");
				}
				float[] array = new float[Count];
				GCHandle gCHandle = GCHandle.Alloc(array, GCHandleType.Pinned);
				Marshal.ThrowExceptionForHR(audioMeterInformation.GetChannelsPeakValues(array.Length, gCHandle.AddrOfPinnedObject()));
				gCHandle.Free();
				return array[index];
			}
		}

		internal AudioMeterInformationChannels(IAudioMeterInformation parent)
		{
			audioMeterInformation = parent;
		}
	}

	public class AudioMute
	{
		private IAudioMute audioMuteInterface;

		public bool IsMuted
		{
			get
			{
				audioMuteInterface.GetMute(out var mute);
				return mute;
			}
			set
			{
				Guid empty = Guid.Empty;
				IAudioMute audioMute = audioMuteInterface;
				Guid eventContext = empty;
				audioMute.SetMute(value, ref eventContext);
			}
		}

		internal AudioMute(IAudioMute audioMute)
		{
			audioMuteInterface = audioMute;
		}
	}

	/// <summary>
	/// Audio Render Client
	/// </summary>
	public class AudioRenderClient : IDisposable
	{
		private IAudioRenderClient audioRenderClientInterface;

		internal AudioRenderClient(IAudioRenderClient audioRenderClientInterface)
		{
			this.audioRenderClientInterface = audioRenderClientInterface;
		}

		/// <summary>
		/// Gets a pointer to the buffer
		/// </summary>
		/// <param name="numFramesRequested">Number of frames requested</param>
		/// <returns>Pointer to the buffer</returns>
		public IntPtr GetBuffer(int numFramesRequested)
		{
			Marshal.ThrowExceptionForHR(audioRenderClientInterface.GetBuffer(numFramesRequested, out var dataBufferPointer));
			return dataBufferPointer;
		}

		/// <summary>
		/// Release buffer
		/// </summary>
		/// <param name="numFramesWritten">Number of frames written</param>
		/// <param name="bufferFlags">Buffer flags</param>
		public void ReleaseBuffer(int numFramesWritten, AudioClientBufferFlags bufferFlags)
		{
			Marshal.ThrowExceptionForHR(audioRenderClientInterface.ReleaseBuffer(numFramesWritten, bufferFlags));
		}

		/// <summary>
		/// Release the COM object
		/// </summary>
		public void Dispose()
		{
			if (audioRenderClientInterface != null)
			{
				Marshal.ReleaseComObject(audioRenderClientInterface);
				audioRenderClientInterface = null;
				GC.SuppressFinalize(this);
			}
		}
	}

	/// <summary>
	/// AudioSessionControl object for information
	/// regarding an audio session
	/// </summary>
	public class AudioSessionControl : IDisposable
	{
		private readonly IAudioSessionControl audioSessionControlInterface;

		private readonly IAudioSessionControl2 audioSessionControlInterface2;

		private AudioSessionEventsCallback audioSessionEventCallback;

		/// <summary>
		/// Audio meter information of the audio session.
		/// </summary>
		public AudioMeterInformation AudioMeterInformation { get; }

		/// <summary>
		/// Simple audio volume of the audio session (for volume and mute status).
		/// </summary>
		public SimpleAudioVolume SimpleAudioVolume { get; }

		/// <summary>
		/// The current state of the audio session.
		/// </summary>
		public AudioSessionState State
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioSessionControlInterface.GetState(out var state));
				return state;
			}
		}

		/// <summary>
		/// The name of the audio session.
		/// </summary>
		public string DisplayName
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioSessionControlInterface.GetDisplayName(out var displayName));
				return displayName;
			}
			set
			{
				if (value != string.Empty)
				{
					Marshal.ThrowExceptionForHR(audioSessionControlInterface.SetDisplayName(value, Guid.Empty));
				}
			}
		}

		/// <summary>
		/// the path to the icon shown in the mixer.
		/// </summary>
		public string IconPath
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioSessionControlInterface.GetIconPath(out var iconPath));
				return iconPath;
			}
			set
			{
				if (value != string.Empty)
				{
					Marshal.ThrowExceptionForHR(audioSessionControlInterface.SetIconPath(value, Guid.Empty));
				}
			}
		}

		/// <summary>
		/// The session identifier of the audio session.
		/// </summary>
		public string GetSessionIdentifier
		{
			get
			{
				if (audioSessionControlInterface2 == null)
				{
					throw new InvalidOperationException("Not supported on this version of Windows");
				}
				Marshal.ThrowExceptionForHR(audioSessionControlInterface2.GetSessionIdentifier(out var retVal));
				return retVal;
			}
		}

		/// <summary>
		/// The session instance identifier of the audio session.
		/// </summary>
		public string GetSessionInstanceIdentifier
		{
			get
			{
				if (audioSessionControlInterface2 == null)
				{
					throw new InvalidOperationException("Not supported on this version of Windows");
				}
				Marshal.ThrowExceptionForHR(audioSessionControlInterface2.GetSessionInstanceIdentifier(out var retVal));
				return retVal;
			}
		}

		/// <summary>
		/// The process identifier of the audio session.
		/// </summary>
		public uint GetProcessID
		{
			get
			{
				if (audioSessionControlInterface2 == null)
				{
					throw new InvalidOperationException("Not supported on this version of Windows");
				}
				Marshal.ThrowExceptionForHR(audioSessionControlInterface2.GetProcessId(out var retVal));
				return retVal;
			}
		}

		/// <summary>
		/// Is the session a system sounds session.
		/// </summary>
		public bool IsSystemSoundsSession
		{
			get
			{
				if (audioSessionControlInterface2 == null)
				{
					throw new InvalidOperationException("Not supported on this version of Windows");
				}
				return audioSessionControlInterface2.IsSystemSoundsSession() == 0;
			}
		}

		/// <summary>
		/// Constructor.
		/// </summary>
		/// <param name="audioSessionControl"></param>
		public AudioSessionControl(IAudioSessionControl audioSessionControl)
		{
			audioSessionControlInterface = audioSessionControl;
			audioSessionControlInterface2 = audioSessionControl as IAudioSessionControl2;
			if (audioSessionControlInterface is IAudioMeterInformation realInterface)
			{
				AudioMeterInformation = new AudioMeterInformation(realInterface);
			}
			if (audioSessionControlInterface is ISimpleAudioVolume realSimpleVolume)
			{
				SimpleAudioVolume = new SimpleAudioVolume(realSimpleVolume);
			}
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (audioSessionEventCallback != null)
			{
				Marshal.ThrowExceptionForHR(audioSessionControlInterface.UnregisterAudioSessionNotification(audioSessionEventCallback));
				audioSessionEventCallback = null;
			}
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~AudioSessionControl()
		{
			Dispose();
		}

		/// <summary>
		/// the grouping param for an audio session grouping
		/// </summary>
		/// <returns></returns>
		public Guid GetGroupingParam()
		{
			Marshal.ThrowExceptionForHR(audioSessionControlInterface.GetGroupingParam(out var groupingId));
			return groupingId;
		}

		/// <summary>
		/// For chanigng the grouping param and supplying the context of said change
		/// </summary>
		/// <param name="groupingId"></param>
		/// <param name="context"></param>
		public void SetGroupingParam(Guid groupingId, Guid context)
		{
			Marshal.ThrowExceptionForHR(audioSessionControlInterface.SetGroupingParam(groupingId, context));
		}

		/// <summary>
		/// Registers an even client for callbacks
		/// </summary>
		/// <param name="eventClient"></param>
		public void RegisterEventClient(IAudioSessionEventsHandler eventClient)
		{
			audioSessionEventCallback = new AudioSessionEventsCallback(eventClient);
			Marshal.ThrowExceptionForHR(audioSessionControlInterface.RegisterAudioSessionNotification(audioSessionEventCallback));
		}

		/// <summary>
		/// Unregisters an event client from receiving callbacks
		/// </summary>
		/// <param name="eventClient"></param>
		public void UnRegisterEventClient(IAudioSessionEventsHandler eventClient)
		{
			if (audioSessionEventCallback != null)
			{
				Marshal.ThrowExceptionForHR(audioSessionControlInterface.UnregisterAudioSessionNotification(audioSessionEventCallback));
				audioSessionEventCallback = null;
			}
		}
	}

	/// <summary>
	/// AudioSessionEvents callback implementation
	/// </summary>
	public class AudioSessionEventsCallback : IAudioSessionEvents
	{
		private readonly IAudioSessionEventsHandler audioSessionEventsHandler;

		/// <summary>
		/// Constructor.
		/// </summary>
		/// <param name="handler"></param>
		public AudioSessionEventsCallback(IAudioSessionEventsHandler handler)
		{
			audioSessionEventsHandler = handler;
		}

		/// <summary>
		/// Notifies the client that the display name for the session has changed.
		/// </summary>
		/// <param name="displayName">The new display name for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnDisplayNameChanged([In][MarshalAs(UnmanagedType.LPWStr)] string displayName, [In] ref Guid eventContext)
		{
			audioSessionEventsHandler.OnDisplayNameChanged(displayName);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the display icon for the session has changed.
		/// </summary>
		/// <param name="iconPath">The path for the new display icon for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnIconPathChanged([In][MarshalAs(UnmanagedType.LPWStr)] string iconPath, [In] ref Guid eventContext)
		{
			audioSessionEventsHandler.OnIconPathChanged(iconPath);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the volume level or muting state of the session has changed.
		/// </summary>
		/// <param name="volume">The new volume level for the audio session.</param>
		/// <param name="isMuted">The new muting state.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnSimpleVolumeChanged([In][MarshalAs(UnmanagedType.R4)] float volume, [In][MarshalAs(UnmanagedType.Bool)] bool isMuted, [In] ref Guid eventContext)
		{
			audioSessionEventsHandler.OnVolumeChanged(volume, isMuted);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the volume level of an audio channel in the session submix has changed.
		/// </summary>
		/// <param name="channelCount">The channel count.</param>
		/// <param name="newVolumes">An array of volumnes cooresponding with each channel index.</param>
		/// <param name="channelIndex">The number of the channel whose volume level changed.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnChannelVolumeChanged([In][MarshalAs(UnmanagedType.U4)] uint channelCount, [In][MarshalAs(UnmanagedType.SysInt)] IntPtr newVolumes, [In][MarshalAs(UnmanagedType.U4)] uint channelIndex, [In] ref Guid eventContext)
		{
			audioSessionEventsHandler.OnChannelVolumeChanged(channelCount, newVolumes, channelIndex);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the grouping parameter for the session has changed.
		/// </summary>
		/// <param name="groupingId">The new grouping parameter for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnGroupingParamChanged([In] ref Guid groupingId, [In] ref Guid eventContext)
		{
			audioSessionEventsHandler.OnGroupingParamChanged(ref groupingId);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the stream-activity state of the session has changed.
		/// </summary>
		/// <param name="state">The new session state.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnStateChanged([In] AudioSessionState state)
		{
			audioSessionEventsHandler.OnStateChanged(state);
			return 0;
		}

		/// <summary>
		/// Notifies the client that the session has been disconnected.
		/// </summary>
		/// <param name="disconnectReason">The reason that the audio session was disconnected.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		public int OnSessionDisconnected([In] AudioSessionDisconnectReason disconnectReason)
		{
			audioSessionEventsHandler.OnSessionDisconnected(disconnectReason);
			return 0;
		}
	}

	/// <summary>
	/// AudioSessionManager
	///
	/// Designed to manage audio sessions and in particuar the
	/// SimpleAudioVolume interface to adjust a session volume
	/// </summary>
	public class AudioSessionManager
	{
		/// <summary>
		/// Session created delegate
		/// </summary>
		public delegate void SessionCreatedDelegate(object sender, IAudioSessionControl newSession);

		private readonly IAudioSessionManager audioSessionInterface;

		private readonly IAudioSessionManager2 audioSessionInterface2;

		private AudioSessionNotification audioSessionNotification;

		private SessionCollection sessions;

		private SimpleAudioVolume simpleAudioVolume;

		private AudioSessionControl audioSessionControl;

		/// <summary>
		/// SimpleAudioVolume object
		/// for adjusting the volume for the user session
		/// </summary>
		public SimpleAudioVolume SimpleAudioVolume
		{
			get
			{
				if (simpleAudioVolume == null)
				{
					audioSessionInterface.GetSimpleAudioVolume(Guid.Empty, 0u, out var audioVolume);
					simpleAudioVolume = new SimpleAudioVolume(audioVolume);
				}
				return simpleAudioVolume;
			}
		}

		/// <summary>
		/// AudioSessionControl object
		/// for registring for callbacks and other session information
		/// </summary>
		public AudioSessionControl AudioSessionControl
		{
			get
			{
				if (audioSessionControl == null)
				{
					audioSessionInterface.GetAudioSessionControl(Guid.Empty, 0u, out var sessionControl);
					audioSessionControl = new AudioSessionControl(sessionControl);
				}
				return audioSessionControl;
			}
		}

		/// <summary>
		/// Returns list of sessions of current device.
		/// </summary>
		public SessionCollection Sessions => sessions;

		/// <summary>
		/// Occurs when audio session has been added (for example run another program that use audio playback).
		/// </summary>
		public event SessionCreatedDelegate OnSessionCreated;

		internal AudioSessionManager(IAudioSessionManager audioSessionManager)
		{
			audioSessionInterface = audioSessionManager;
			audioSessionInterface2 = audioSessionManager as IAudioSessionManager2;
			RefreshSessions();
		}

		internal void FireSessionCreated(IAudioSessionControl newSession)
		{
			this.OnSessionCreated?.Invoke(this, newSession);
		}

		/// <summary>
		/// Refresh session of current device.
		/// </summary>
		public void RefreshSessions()
		{
			UnregisterNotifications();
			if (audioSessionInterface2 != null)
			{
				Marshal.ThrowExceptionForHR(audioSessionInterface2.GetSessionEnumerator(out var sessionEnum));
				sessions = new SessionCollection(sessionEnum);
				audioSessionNotification = new AudioSessionNotification(this);
				Marshal.ThrowExceptionForHR(audioSessionInterface2.RegisterSessionNotification(audioSessionNotification));
			}
		}

		/// <summary>
		/// Dispose.
		/// </summary>
		public void Dispose()
		{
			UnregisterNotifications();
			GC.SuppressFinalize(this);
		}

		private void UnregisterNotifications()
		{
			sessions = null;
			if (audioSessionNotification != null && audioSessionInterface2 != null)
			{
				Marshal.ThrowExceptionForHR(audioSessionInterface2.UnregisterSessionNotification(audioSessionNotification));
				audioSessionNotification = null;
			}
		}

		/// <summary>
		/// Finalizer.
		/// </summary>
		~AudioSessionManager()
		{
			Dispose();
		}
	}

	internal class AudioSessionNotification : IAudioSessionNotification
	{
		private AudioSessionManager parent;

		internal AudioSessionNotification(AudioSessionManager parent)
		{
			this.parent = parent;
		}

		[PreserveSig]
		public int OnSessionCreated(IAudioSessionControl newSession)
		{
			parent.FireSessionCreated(newSession);
			return 0;
		}
	}

	/// <summary>
	/// Specifies the category of an audio stream.
	/// https://docs.microsoft.com/en-us/windows/win32/api/audiosessiontypes/ne-audiosessiontypes-audio_stream_category
	/// AUDIO_STREAM_CATEGORY
	/// </summary>
	public enum AudioStreamCategory
	{
		/// <summary>
		/// Other audio stream.
		/// </summary>
		Other,
		/// <summary>
		/// Media that will only stream when the app is in the foreground.
		/// </summary>
		ForegroundOnlyMedia,
		/// <summary>
		/// Media that can be streamed when the app is in the background.
		/// </summary>
		BackgroundCapableMedia,
		/// <summary>
		/// Real-time communications, such as VOIP or chat.
		/// </summary>
		Communications,
		/// <summary>
		/// Alert sounds.
		/// </summary>
		Alerts,
		/// <summary>
		/// Sound effects.
		/// </summary>
		SoundEffects,
		/// <summary>
		/// Game sound effects.
		/// </summary>
		GameEffects,
		/// <summary>
		/// Background audio for games.
		/// </summary>
		GameMedia,
		/// <summary>
		/// Game chat audio. Similar to AudioCategory_Communications except that AudioCategory_GameChat will not attenuate other streams.
		/// </summary>
		GameChat,
		/// <summary>
		/// Speech
		/// </summary>
		Speech,
		/// <summary>
		/// Stream that includes audio with dialog.
		/// </summary>
		Movie,
		/// <summary>
		/// Stream that includes audio without dialog.
		/// </summary>
		Media,
		/// <summary>
		/// Media is audio captured with the intent of capturing voice sources located in the ‘far field’. (Far away from the microphone.)
		/// </summary>
		FarFieldSpeech,
		/// <summary>
		/// Media is captured audio that requires consistent speech processing for the captured audio stream across all Windows devices. Used by applications that process speech data using machine learning algorithms.
		/// </summary>
		UniformSpeech,
		/// <summary>
		/// Media is audio captured with the intent of enabling dictation or typing by voice.
		/// </summary>
		VoiceTyping
	}

	/// <summary>
	/// Manages the AudioStreamVolume for the <see cref="T:NAudio.CoreAudioApi.AudioClient" />.
	/// </summary>
	public class AudioStreamVolume : IDisposable
	{
		private IAudioStreamVolume audioStreamVolumeInterface;

		/// <summary>
		/// Returns the current number of channels in this audio stream.
		/// </summary>
		public int ChannelCount
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.GetChannelCount(out var dwCount));
				return (int)dwCount;
			}
		}

		internal AudioStreamVolume(IAudioStreamVolume audioStreamVolumeInterface)
		{
			this.audioStreamVolumeInterface = audioStreamVolumeInterface;
		}

		/// <summary>
		/// Verify that the channel index is valid.
		/// </summary>
		/// <param name="channelIndex"></param>
		/// <param name="parameter"></param>
		private void CheckChannelIndex(int channelIndex, string parameter)
		{
			int channelCount = ChannelCount;
			if (channelIndex >= channelCount)
			{
				throw new ArgumentOutOfRangeException(parameter, "You must supply a valid channel index < current count of channels: " + channelCount);
			}
		}

		/// <summary>
		/// Return the current stream volumes for all channels
		/// </summary>
		/// <returns>An array of volume levels between 0.0 and 1.0 for each channel in the audio stream.</returns>
		public float[] GetAllVolumes()
		{
			Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.GetChannelCount(out var dwCount));
			float[] array = new float[dwCount];
			Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.GetAllVolumes(dwCount, array));
			return array;
		}

		/// <summary>
		/// Return the current volume for the requested channel.
		/// </summary>
		/// <param name="channelIndex">The 0 based index into the channels.</param>
		/// <returns>The volume level for the channel between 0.0 and 1.0.</returns>
		public float GetChannelVolume(int channelIndex)
		{
			CheckChannelIndex(channelIndex, "channelIndex");
			Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.GetChannelVolume((uint)channelIndex, out var fLevel));
			return fLevel;
		}

		/// <summary>
		/// Set the volume level for each channel of the audio stream.
		/// </summary>
		/// <param name="levels">An array of volume levels (between 0.0 and 1.0) one for each channel.</param>
		/// <remarks>
		/// A volume level MUST be supplied for reach channel in the audio stream.
		/// </remarks>
		/// <exception cref="T:System.ArgumentOutOfRangeException">
		/// Thrown when <paramref name="levels" /> does not contain <see cref="P:NAudio.CoreAudioApi.AudioStreamVolume.ChannelCount" /> elements.
		/// </exception>
		public void SetAllVolumes(float[] levels)
		{
			int channelCount = ChannelCount;
			if (levels == null)
			{
				throw new ArgumentNullException("levels");
			}
			if (levels.Length != channelCount)
			{
				throw new ArgumentOutOfRangeException("levels", string.Format(CultureInfo.InvariantCulture, "SetAllVolumes MUST be supplied with a volume level for ALL channels. The AudioStream has {0} channels and you supplied {1} channels.", channelCount, levels.Length));
			}
			for (int i = 0; i < levels.Length; i++)
			{
				float num = levels[i];
				if (num < 0f)
				{
					throw new ArgumentOutOfRangeException("levels", "All volumes must be between 0.0 and 1.0. Invalid volume at index: " + i);
				}
				if (num > 1f)
				{
					throw new ArgumentOutOfRangeException("levels", "All volumes must be between 0.0 and 1.0. Invalid volume at index: " + i);
				}
			}
			Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.SetAllVoumes((uint)channelCount, levels));
		}

		/// <summary>
		/// Sets the volume level for one channel in the audio stream.
		/// </summary>
		/// <param name="index">The 0-based index into the channels to adjust the volume of.</param>
		/// <param name="level">The volume level between 0.0 and 1.0 for this channel of the audio stream.</param>
		public void SetChannelVolume(int index, float level)
		{
			CheckChannelIndex(index, "index");
			if (level < 0f)
			{
				throw new ArgumentOutOfRangeException("level", "Volume must be between 0.0 and 1.0");
			}
			if (level > 1f)
			{
				throw new ArgumentOutOfRangeException("level", "Volume must be between 0.0 and 1.0");
			}
			Marshal.ThrowExceptionForHR(audioStreamVolumeInterface.SetChannelVolume((uint)index, level));
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Release/cleanup objects during Dispose/finalization.
		/// </summary>
		/// <param name="disposing">True if disposing and false if being finalized.</param>
		protected virtual void Dispose(bool disposing)
		{
			if (disposing && audioStreamVolumeInterface != null)
			{
				Marshal.ReleaseComObject(audioStreamVolumeInterface);
				audioStreamVolumeInterface = null;
			}
		}
	}

	/// <summary>
	/// Audio Volume Notification Data
	/// </summary>
	public class AudioVolumeNotificationData
	{
		/// <summary>
		/// Event Context
		/// </summary>
		public Guid EventContext { get; }

		/// <summary>
		/// Muted
		/// </summary>
		public bool Muted { get; }

		/// <summary>
		/// Guid that raised the event
		/// </summary>
		public Guid Guid { get; }

		/// <summary>
		/// Master Volume
		/// </summary>
		public float MasterVolume { get; }

		/// <summary>
		/// Channels
		/// </summary>
		public int Channels { get; }

		/// <summary>
		/// Channel Volume
		/// </summary>
		public float[] ChannelVolume { get; }

		/// <summary>
		/// Audio Volume Notification Data
		/// </summary>
		/// <param name="eventContext"></param>
		/// <param name="muted"></param>
		/// <param name="masterVolume"></param>
		/// <param name="channelVolume"></param>
		/// <param name="guid"></param>
		public AudioVolumeNotificationData(Guid eventContext, bool muted, float masterVolume, float[] channelVolume, Guid guid)
		{
			EventContext = eventContext;
			Muted = muted;
			MasterVolume = masterVolume;
			Channels = channelVolume.Length;
			ChannelVolume = channelVolume;
			Guid = guid;
		}
	}

	/// <summary>
	/// Connector
	/// </summary>
	public class Connector
	{
		private readonly IConnector connectorInterface;

		/// <summary>
		/// Retreives the type of this connector
		/// </summary>
		public ConnectorType Type
		{
			get
			{
				connectorInterface.GetType(out var type);
				return type;
			}
		}

		/// <summary>
		/// Retreives the data flow of this connector
		/// </summary>
		public DataFlow DataFlow
		{
			get
			{
				connectorInterface.GetDataFlow(out var flow);
				return flow;
			}
		}

		/// <summary>
		/// Indicates whether this connector is connected to another connector
		/// </summary>
		public bool IsConnected
		{
			get
			{
				connectorInterface.IsConnected(out var connected);
				return connected;
			}
		}

		/// <summary>
		/// Retreives the connector this connector is connected to (if connected)
		/// </summary>
		public Connector ConnectedTo
		{
			get
			{
				connectorInterface.GetConnectedTo(out var conTo);
				return new Connector(conTo);
			}
		}

		/// <summary>
		/// Retreives the global ID of the connector this connector is connected to (if connected)
		/// </summary>
		public string ConnectedToConnectorId
		{
			get
			{
				connectorInterface.GetConnectorIdConnectedTo(out var id);
				return id;
			}
		}

		/// <summary>
		/// Retreives the device ID of the audio device this connector is connected to (if connected)
		/// </summary>
		public string ConnectedToDeviceId
		{
			get
			{
				connectorInterface.GetDeviceIdConnectedTo(out var id);
				return id;
			}
		}

		public Part Part => new Part(connectorInterface as IPart);

		internal Connector(IConnector connector)
		{
			connectorInterface = connector;
		}

		/// <summary>
		/// Connects this connector to a connector in another device-topology object
		/// </summary>
		public void ConnectTo(Connector other)
		{
			connectorInterface.ConnectTo(other.connectorInterface);
		}

		/// <summary>
		/// Disconnects this connector from it's connected connector (if connected)
		/// </summary>
		public void Disconnect()
		{
			connectorInterface.Disconnect();
		}
	}

	/// <summary>
	/// Connector Type
	/// </summary>
	public enum ConnectorType
	{
		/// <summary>
		/// The connector is part of a connection of unknown type.
		/// </summary>
		UnknownConnector,
		/// <summary>
		/// The connector is part of a physical connection to an auxiliary device that is installed inside the system chassis
		/// </summary>
		PhysicalInternal,
		/// <summary>
		/// The connector is part of a physical connection to an external device.
		/// </summary>
		PhysicalExternal,
		/// <summary>
		/// The connector is part of a software-configured I/O connection (typically a DMA channel) between system memory and an audio hardware device on an audio adapter.
		/// </summary>
		SoftwareIo,
		/// <summary>
		/// The connector is part of a permanent connection that is fixed and cannot be configured under software control.
		/// </summary>
		SoftwareFixed,
		/// <summary>
		/// The connector is part of a connection to a network.
		/// </summary>
		Network
	}

	/// <summary>
	/// The EDataFlow enumeration defines constants that indicate the direction 
	/// in which audio data flows between an audio endpoint device and an application
	/// </summary>
	public enum DataFlow
	{
		/// <summary>
		/// Audio rendering stream. 
		/// Audio data flows from the application to the audio endpoint device, which renders the stream.
		/// </summary>
		Render,
		/// <summary>
		/// Audio capture stream. Audio data flows from the audio endpoint device that captures the stream, 
		/// to the application
		/// </summary>
		Capture,
		/// <summary>
		/// Audio rendering or capture stream. Audio data can flow either from the application to the audio 
		/// endpoint device, or from the audio endpoint device to the application.
		/// </summary>
		All
	}

	/// <summary>
	/// Device State
	/// </summary>
	[Flags]
	public enum DeviceState
	{
		/// <summary>
		/// DEVICE_STATE_ACTIVE
		/// </summary>
		Active = 1,
		/// <summary>
		/// DEVICE_STATE_DISABLED
		/// </summary>
		Disabled = 2,
		/// <summary>
		/// DEVICE_STATE_NOTPRESENT 
		/// </summary>
		NotPresent = 4,
		/// <summary>
		/// DEVICE_STATE_UNPLUGGED
		/// </summary>
		Unplugged = 8,
		/// <summary>
		/// DEVICE_STATEMASK_ALL
		/// </summary>
		All = 0xF
	}

	/// <summary>
	/// Windows CoreAudio DeviceTopology
	/// </summary>
	public class DeviceTopology
	{
		private readonly IDeviceTopology deviceTopologyInterface;

		/// <summary>
		/// Retrieves the number of connections associated with this device-topology object
		/// </summary>
		public uint ConnectorCount
		{
			get
			{
				deviceTopologyInterface.GetConnectorCount(out var count);
				return count;
			}
		}

		/// <summary>
		/// Retrieves the device id of the device represented by this device-topology object
		/// </summary>
		public string DeviceId
		{
			get
			{
				deviceTopologyInterface.GetDeviceId(out var id);
				return id;
			}
		}

		internal DeviceTopology(IDeviceTopology deviceTopology)
		{
			deviceTopologyInterface = deviceTopology;
		}

		/// <summary>
		/// Retrieves the connector at the supplied index
		/// </summary>
		public Connector GetConnector(uint index)
		{
			deviceTopologyInterface.GetConnector(index, out var connector);
			return new Connector(connector);
		}
	}

	/// <summary>
	/// Endpoint Hardware Support
	/// </summary>
	[Flags]
	public enum EEndpointHardwareSupport
	{
		/// <summary>
		/// Volume
		/// </summary>
		Volume = 1,
		/// <summary>
		/// Mute
		/// </summary>
		Mute = 2,
		/// <summary>
		/// Meter
		/// </summary>
		Meter = 4
	}

	public class KsJackDescription
	{
		private readonly IKsJackDescription ksJackDescriptionInterface;

		public uint Count
		{
			get
			{
				ksJackDescriptionInterface.GetJackCount(out var jacks);
				return jacks;
			}
		}

		public string this[uint index]
		{
			get
			{
				ksJackDescriptionInterface.GetJackDescription(index, out var description);
				return description;
			}
		}

		internal KsJackDescription(IKsJackDescription ksJackDescription)
		{
			ksJackDescriptionInterface = ksJackDescription;
		}
	}

	/// <summary>
	/// MM Device
	/// </summary>
	public class MMDevice : IDisposable
	{
		private readonly IMMDevice deviceInterface;

		private PropertyStore propertyStore;

		private AudioMeterInformation audioMeterInformation;

		private AudioEndpointVolume audioEndpointVolume;

		private AudioSessionManager audioSessionManager;

		private DeviceTopology deviceTopology;

		private static Guid IID_IAudioMeterInformation = new Guid("C02216F6-8C67-4B5B-9D00-D008E73E0064");

		private static Guid IID_IAudioEndpointVolume = new Guid("5CDF2C82-841E-4546-9722-0CF74078229A");

		private static Guid IID_IAudioClient = new Guid("1CB9AD4C-DBFA-4c32-B178-C2F568A703B2");

		private static Guid IDD_IAudioSessionManager = new Guid("BFA971F1-4D5E-40BB-935E-967039BFBEE4");

		private static Guid IDD_IDeviceTopology = new Guid("2A07407E-6497-4A18-9787-32F79BD0D98F");

		/// <summary>
		/// Audio Client
		/// Makes a new one each call to allow caller to manage when to dispose
		/// n.b. should probably not be a property anymore
		/// </summary>
		public AudioClient AudioClient => GetAudioClient();

		/// <summary>
		/// Audio Meter Information
		/// </summary>
		public AudioMeterInformation AudioMeterInformation
		{
			get
			{
				if (audioMeterInformation == null)
				{
					GetAudioMeterInformation();
				}
				return audioMeterInformation;
			}
		}

		/// <summary>
		/// Audio Endpoint Volume
		/// </summary>
		public AudioEndpointVolume AudioEndpointVolume
		{
			get
			{
				if (audioEndpointVolume == null)
				{
					GetAudioEndpointVolume();
				}
				return audioEndpointVolume;
			}
		}

		/// <summary>
		/// AudioSessionManager instance
		/// </summary>
		public AudioSessionManager AudioSessionManager
		{
			get
			{
				if (audioSessionManager == null)
				{
					GetAudioSessionManager();
				}
				return audioSessionManager;
			}
		}

		/// <summary>
		/// DeviceTopology instance
		/// </summary>
		public DeviceTopology DeviceTopology
		{
			get
			{
				if (deviceTopology == null)
				{
					GetDeviceTopology();
				}
				return deviceTopology;
			}
		}

		/// <summary>
		/// Properties
		/// </summary>
		public PropertyStore Properties
		{
			get
			{
				if (propertyStore == null)
				{
					GetPropertyInformation();
				}
				return propertyStore;
			}
		}

		/// <summary>
		/// Friendly name for the endpoint
		/// </summary>
		public string FriendlyName
		{
			get
			{
				if (propertyStore == null)
				{
					GetPropertyInformation();
				}
				if (propertyStore.Contains(PropertyKeys.PKEY_Device_FriendlyName))
				{
					return (string)propertyStore[PropertyKeys.PKEY_Device_FriendlyName].Value;
				}
				return "Unknown";
			}
		}

		/// <summary>
		/// Friendly name of device
		/// </summary>
		public string DeviceFriendlyName
		{
			get
			{
				if (propertyStore == null)
				{
					GetPropertyInformation();
				}
				if (propertyStore.Contains(PropertyKeys.PKEY_DeviceInterface_FriendlyName))
				{
					return (string)propertyStore[PropertyKeys.PKEY_DeviceInterface_FriendlyName].Value;
				}
				return "Unknown";
			}
		}

		/// <summary>
		/// Icon path of device
		/// </summary>
		public string IconPath
		{
			get
			{
				if (propertyStore == null)
				{
					GetPropertyInformation();
				}
				if (propertyStore.Contains(PropertyKeys.PKEY_Device_IconPath))
				{
					return (string)propertyStore[PropertyKeys.PKEY_Device_IconPath].Value;
				}
				return "Unknown";
			}
		}

		/// <summary>
		/// Device Instance Id of Device
		/// </summary>
		public string InstanceId
		{
			get
			{
				if (propertyStore == null)
				{
					GetPropertyInformation();
				}
				if (propertyStore.Contains(PropertyKeys.PKEY_Device_InstanceId))
				{
					return (string)propertyStore[PropertyKeys.PKEY_Device_InstanceId].Value;
				}
				return "Unknown";
			}
		}

		/// <summary>
		/// Device ID
		/// </summary>
		public string ID
		{
			get
			{
				Marshal.ThrowExceptionForHR(deviceInterface.GetId(out var id));
				return id;
			}
		}

		/// <summary>
		/// Data Flow
		/// </summary>
		public DataFlow DataFlow
		{
			get
			{
				(deviceInterface as IMMEndpoint).GetDataFlow(out var dataFlow);
				return dataFlow;
			}
		}

		/// <summary>
		/// Device State
		/// </summary>
		public DeviceState State
		{
			get
			{
				Marshal.ThrowExceptionForHR(deviceInterface.GetState(out var state));
				return state;
			}
		}

		/// <summary>
		/// Initializes the device's property store.
		/// </summary>
		/// <param name="stgmAccess">The storage-access mode to open store for.</param>
		/// <remarks>Administrative client is required for Write and ReadWrite modes.</remarks>
		public void GetPropertyInformation(StorageAccessMode stgmAccess = StorageAccessMode.Read)
		{
			Marshal.ThrowExceptionForHR(deviceInterface.OpenPropertyStore(stgmAccess, out var properties));
			propertyStore = new PropertyStore(properties);
		}

		private AudioClient GetAudioClient()
		{
			Marshal.ThrowExceptionForHR(deviceInterface.Activate(ref IID_IAudioClient, ClsCtx.ALL, IntPtr.Zero, out var interfacePointer));
			return new AudioClient(interfacePointer as IAudioClient);
		}

		private void GetAudioMeterInformation()
		{
			Marshal.ThrowExceptionForHR(deviceInterface.Activate(ref IID_IAudioMeterInformation, ClsCtx.ALL, IntPtr.Zero, out var interfacePointer));
			audioMeterInformation = new AudioMeterInformation(interfacePointer as IAudioMeterInformation);
		}

		private void GetAudioEndpointVolume()
		{
			Marshal.ThrowExceptionForHR(deviceInterface.Activate(ref IID_IAudioEndpointVolume, ClsCtx.ALL, IntPtr.Zero, out var interfacePointer));
			audioEndpointVolume = new AudioEndpointVolume(interfacePointer as IAudioEndpointVolume);
		}

		private void GetAudioSessionManager()
		{
			Marshal.ThrowExceptionForHR(deviceInterface.Activate(ref IDD_IAudioSessionManager, ClsCtx.ALL, IntPtr.Zero, out var interfacePointer));
			audioSessionManager = new AudioSessionManager(interfacePointer as IAudioSessionManager);
		}

		private void GetDeviceTopology()
		{
			Marshal.ThrowExceptionForHR(deviceInterface.Activate(ref IDD_IDeviceTopology, ClsCtx.ALL, IntPtr.Zero, out var interfacePointer));
			deviceTopology = new DeviceTopology(interfacePointer as IDeviceTopology);
		}

		internal MMDevice(IMMDevice realDevice)
		{
			deviceInterface = realDevice;
		}

		/// <summary>
		/// To string
		/// </summary>
		public override string ToString()
		{
			return FriendlyName;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			audioEndpointVolume?.Dispose();
			audioSessionManager?.Dispose();
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~MMDevice()
		{
			Dispose();
		}
	}

	/// <summary>
	/// Multimedia Device Collection
	/// </summary>
	public class MMDeviceCollection : IEnumerable<MMDevice>, IEnumerable
	{
		private readonly IMMDeviceCollection mmDeviceCollection;

		/// <summary>
		/// Device count
		/// </summary>
		public int Count
		{
			get
			{
				Marshal.ThrowExceptionForHR(mmDeviceCollection.GetCount(out var numDevices));
				return numDevices;
			}
		}

		/// <summary>
		/// Get device by index
		/// </summary>
		/// <param name="index">Device index</param>
		/// <returns>Device at the specified index</returns>
		public MMDevice this[int index]
		{
			get
			{
				mmDeviceCollection.Item(index, out var device);
				return new MMDevice(device);
			}
		}

		internal MMDeviceCollection(IMMDeviceCollection parent)
		{
			mmDeviceCollection = parent;
		}

		/// <summary>
		/// Get Enumerator
		/// </summary>
		/// <returns>Device enumerator</returns>
		public IEnumerator<MMDevice> GetEnumerator()
		{
			for (int index = 0; index < Count; index++)
			{
				yield return this[index];
			}
		}

		IEnumerator IEnumerable.GetEnumerator()
		{
			return GetEnumerator();
		}
	}

	/// <summary>
	/// MM Device Enumerator
	/// </summary>
	public class MMDeviceEnumerator : IDisposable
	{
		private IMMDeviceEnumerator realEnumerator;

		/// <summary>
		/// Creates a new MM Device Enumerator
		/// </summary>
		public MMDeviceEnumerator()
		{
			if (Environment.OSVersion.Version.Major < 6)
			{
				throw new NotSupportedException("This functionality is only supported on Windows Vista or newer.");
			}
			realEnumerator = new MMDeviceEnumeratorComObject() as IMMDeviceEnumerator;
		}

		/// <summary>
		/// Enumerate Audio Endpoints
		/// </summary>
		/// <param name="dataFlow">Desired DataFlow</param>
		/// <param name="dwStateMask">State Mask</param>
		/// <returns>Device Collection</returns>
		public MMDeviceCollection EnumerateAudioEndPoints(DataFlow dataFlow, DeviceState dwStateMask)
		{
			Marshal.ThrowExceptionForHR(realEnumerator.EnumAudioEndpoints(dataFlow, dwStateMask, out var devices));
			return new MMDeviceCollection(devices);
		}

		/// <summary>
		/// Get Default Endpoint
		/// </summary>
		/// <param name="dataFlow">Data Flow</param>
		/// <param name="role">Role</param>
		/// <returns>Device</returns>
		public MMDevice GetDefaultAudioEndpoint(DataFlow dataFlow, Role role)
		{
			Marshal.ThrowExceptionForHR(realEnumerator.GetDefaultAudioEndpoint(dataFlow, role, out var endpoint));
			return new MMDevice(endpoint);
		}

		/// <summary>
		/// Check to see if a default audio end point exists without needing an exception.
		/// </summary>
		/// <param name="dataFlow">Data Flow</param>
		/// <param name="role">Role</param>
		/// <returns>True if one exists, and false if one does not exist.</returns>
		public bool HasDefaultAudioEndpoint(DataFlow dataFlow, Role role)
		{
			IMMDevice endpoint;
			int defaultAudioEndpoint = realEnumerator.GetDefaultAudioEndpoint(dataFlow, role, out endpoint);
			switch (defaultAudioEndpoint)
			{
			case 0:
				Marshal.ReleaseComObject(endpoint);
				return true;
			case -2147023728:
				return false;
			default:
				Marshal.ThrowExceptionForHR(defaultAudioEndpoint);
				return false;
			}
		}

		/// <summary>
		/// Get device by ID
		/// </summary>
		/// <param name="id">Device ID</param>
		/// <returns>Device</returns>
		public MMDevice GetDevice(string id)
		{
			Marshal.ThrowExceptionForHR(realEnumerator.GetDevice(id, out var deviceName));
			return new MMDevice(deviceName);
		}

		/// <summary>
		/// Registers a call back for Device Events
		/// </summary>
		/// <param name="client">Object implementing IMMNotificationClient type casted as IMMNotificationClient interface</param>
		/// <returns></returns>
		public int RegisterEndpointNotificationCallback([In][MarshalAs(UnmanagedType.Interface)] IMMNotificationClient client)
		{
			return realEnumerator.RegisterEndpointNotificationCallback(client);
		}

		/// <summary>
		/// Unregisters a call back for Device Events
		/// </summary>
		/// <param name="client">Object implementing IMMNotificationClient type casted as IMMNotificationClient interface </param>
		/// <returns></returns>
		public int UnregisterEndpointNotificationCallback([In][MarshalAs(UnmanagedType.Interface)] IMMNotificationClient client)
		{
			return realEnumerator.UnregisterEndpointNotificationCallback(client);
		}

		/// <inheritdoc />
		public void Dispose()
		{
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Called to dispose/finalize contained objects.
		/// </summary>
		/// <param name="disposing">True if disposing, false if called from a finalizer.</param>
		protected virtual void Dispose(bool disposing)
		{
			if (disposing && realEnumerator != null)
			{
				Marshal.ReleaseComObject(realEnumerator);
				realEnumerator = null;
			}
		}
	}

	/// <summary>
	/// Audio Part
	/// </summary>
	public class Part
	{
		private const int E_NOTFOUND = -2147023728;

		private readonly IPart partInterface;

		private DeviceTopology deviceTopology;

		private static Guid IID_IAudioVolumeLevel = new Guid("7FB7B48F-531D-44A2-BCB3-5AD5A134B3DC");

		private static Guid IID_IAudioMute = new Guid("DF45AEEA-B74A-4B6B-AFAD-2366B6AA012E");

		private static Guid IID_IAudioEndpointVolume = new Guid("5CDF2C82-841E-4546-9722-0CF74078229A");

		private static Guid IID_IKsJackDescription = new Guid("4509F757-2D46-4637-8E62-CE7DB944F57B");

		/// <summary>
		/// Name
		/// </summary>
		public string Name
		{
			get
			{
				partInterface.GetName(out var name);
				return name;
			}
		}

		/// <summary>
		/// Local ID
		/// </summary>
		public uint LocalId
		{
			get
			{
				partInterface.GetLocalId(out var id);
				return id;
			}
		}

		/// <summary>
		/// Global ID
		/// </summary>
		public string GlobalId
		{
			get
			{
				partInterface.GetGlobalId(out var id);
				return id;
			}
		}

		/// <summary>
		/// Part Type
		/// </summary>
		public PartTypeEnum PartType
		{
			get
			{
				partInterface.GetPartType(out var partType);
				return partType;
			}
		}

		/// <summary>
		/// Sub Type
		/// </summary>
		public Guid GetSubType
		{
			get
			{
				partInterface.GetSubType(out var subType);
				return subType;
			}
		}

		/// <summary>
		/// Control Interface Count
		/// </summary>
		public uint ControlInterfaceCount
		{
			get
			{
				partInterface.GetControlInterfaceCount(out var count);
				return count;
			}
		}

		/// <summary>
		/// Incoming parts list
		/// </summary>
		public PartsList PartsIncoming
		{
			get
			{
				IPartsList parts;
				int num = partInterface.EnumPartsIncoming(out parts);
				return num switch
				{
					-2147023728 => new PartsList(null), 
					0 => new PartsList(parts), 
					_ => throw new COMException("EnumPartsIncoming", num), 
				};
			}
		}

		/// <summary>
		/// Outgoing parts list
		/// </summary>
		public PartsList PartsOutgoing
		{
			get
			{
				IPartsList parts;
				int num = partInterface.EnumPartsOutgoing(out parts);
				return num switch
				{
					-2147023728 => new PartsList(null), 
					0 => new PartsList(parts), 
					_ => throw new COMException("EnumPartsOutgoing", num), 
				};
			}
		}

		/// <summary>
		/// Device topology
		/// </summary>
		public DeviceTopology DeviceTopology
		{
			get
			{
				if (deviceTopology == null)
				{
					GetDeviceTopology();
				}
				return deviceTopology;
			}
		}

		/// <summary>
		/// Audio Volume Level
		/// </summary>
		public AudioVolumeLevel AudioVolumeLevel
		{
			get
			{
				if (partInterface.Activate(ClsCtx.ALL, ref IID_IAudioVolumeLevel, out var interfacePointer) != 0)
				{
					return null;
				}
				return new AudioVolumeLevel(interfacePointer as IAudioVolumeLevel);
			}
		}

		/// <summary>
		/// Audio Mute
		/// </summary>
		public AudioMute AudioMute
		{
			get
			{
				if (partInterface.Activate(ClsCtx.ALL, ref IID_IAudioMute, out var interfacePointer) != 0)
				{
					return null;
				}
				return new AudioMute(interfacePointer as IAudioMute);
			}
		}

		/// <summary>
		/// Jack Description
		/// </summary>
		public KsJackDescription JackDescription
		{
			get
			{
				if (partInterface.Activate(ClsCtx.ALL, ref IID_IKsJackDescription, out var interfacePointer) != 0)
				{
					return null;
				}
				return new KsJackDescription(interfacePointer as IKsJackDescription);
			}
		}

		internal Part(IPart part)
		{
			partInterface = part;
		}

		/// <summary>
		/// Get Control Interface by index
		/// </summary>
		public IControlInterface GetControlInterface(uint index)
		{
			partInterface.GetControlInterface(index, out var controlInterface);
			return controlInterface;
		}

		private void GetDeviceTopology()
		{
			Marshal.ThrowExceptionForHR(partInterface.GetTopologyObject(out var topologyObject));
			deviceTopology = new DeviceTopology(topologyObject as IDeviceTopology);
		}
	}

	public class PartsList
	{
		private IPartsList partsListInterface;

		public uint Count
		{
			get
			{
				uint count = 0u;
				if (partsListInterface != null)
				{
					partsListInterface.GetCount(out count);
				}
				return count;
			}
		}

		public Part this[uint index]
		{
			get
			{
				if (partsListInterface == null)
				{
					throw new IndexOutOfRangeException();
				}
				partsListInterface.GetPart(index, out var part);
				return new Part(part);
			}
		}

		internal PartsList(IPartsList partsList)
		{
			partsListInterface = partsList;
		}
	}

	/// <summary>
	/// PROCESS_LOOPBACK_MODE
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclientactivationparams/ne-audioclientactivationparams-process_loopback_mode
	/// </summary>
	internal enum ProcessLoopbackMode
	{
		/// <summary>
		/// PROCESS_LOOPBACK_MODE_INCLUDE_TARGET_PROCESS_TREE
		/// Render streams from the specified process and its child processes are included in the activated process loopback stream.
		/// </summary>
		IncludeTargetProcessTree,
		/// <summary>
		/// PROCESS_LOOPBACK_MODE_EXCLUDE_TARGET_PROCESS_TREE
		/// Render streams from the specified process and its child processes are excluded from the activated process loopback stream.
		/// </summary>
		ExcludeTargetProcessTree
	}

	/// <summary>
	/// PROPERTYKEY is defined in wtypes.h
	/// </summary>
	public struct PropertyKey
	{
		/// <summary>
		/// Format ID
		/// </summary>
		public Guid formatId;

		/// <summary>
		/// Property ID
		/// </summary>
		public int propertyId;

		/// <summary>
		/// <param name="formatId"></param>
		/// <param name="propertyId"></param>
		/// </summary>
		public PropertyKey(Guid formatId, int propertyId)
		{
			this.formatId = formatId;
			this.propertyId = propertyId;
		}
	}

	/// <summary>
	/// Property Keys
	/// </summary>
	public static class PropertyKeys
	{
		/// <summary>
		/// PKEY_DeviceInterface_FriendlyName
		/// </summary>
		public static readonly PropertyKey PKEY_DeviceInterface_FriendlyName = new PropertyKey(new Guid(40784238, -18412, 16715, 131, 205, 133, 109, 111, 239, 72, 34), 2);

		/// <summary>
		/// PKEY_AudioEndpoint_FormFactor
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_FormFactor = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 0);

		/// <summary>
		/// PKEY_AudioEndpoint_ControlPanelPageProvider
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_ControlPanelPageProvider = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 1);

		/// <summary>
		/// PKEY_AudioEndpoint_Association
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_Association = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 2);

		/// <summary>
		/// PKEY_AudioEndpoint_PhysicalSpeakers
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_PhysicalSpeakers = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 3);

		/// <summary>
		/// PKEY_AudioEndpoint_GUID
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_GUID = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 4);

		/// <summary>
		/// PKEY_AudioEndpoint_Disable_SysFx 
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_Disable_SysFx = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 5);

		/// <summary>
		/// PKEY_AudioEndpoint_FullRangeSpeakers 
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_FullRangeSpeakers = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 6);

		/// <summary>
		/// PKEY_AudioEndpoint_Supports_EventDriven_Mode 
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_Supports_EventDriven_Mode = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 7);

		/// <summary>
		/// PKEY_AudioEndpoint_JackSubType
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEndpoint_JackSubType = new PropertyKey(new Guid(497408003, -11118, 20189, 140, 35, 224, 192, byte.MaxValue, 238, 127, 14), 8);

		/// <summary>
		/// PKEY_AudioEngine_DeviceFormat 
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEngine_DeviceFormat = new PropertyKey(new Guid(-241236403, 2092, 20007, 188, 115, 104, 130, 161, 187, 142, 76), 0);

		/// <summary>
		/// PKEY_AudioEngine_OEMFormat
		/// </summary>
		public static readonly PropertyKey PKEY_AudioEngine_OEMFormat = new PropertyKey(new Guid(-460911066, 15557, 19666, 186, 70, 202, 10, 154, 112, 237, 4), 3);

		/// <summary>
		/// PKEY _Devie_FriendlyName
		/// </summary>
		public static readonly PropertyKey PKEY_Device_FriendlyName = new PropertyKey(new Guid(-1537465010, -8420, 20221, 128, 32, 103, 209, 70, 168, 80, 224), 14);

		/// <summary>
		/// PKEY _Device_IconPath
		/// </summary>
		public static readonly PropertyKey PKEY_Device_IconPath = new PropertyKey(new Guid(630898684, 20647, 18382, 175, 8, 104, 201, 167, 215, 51, 102), 12);

		/// <summary>
		/// Device description property.
		/// </summary>
		public static readonly PropertyKey PKEY_Device_DeviceDesc = new PropertyKey(new Guid(-1537465010, -8420, 20221, 128, 32, 103, 209, 70, 168, 80, 224), 2);

		/// <summary>
		/// Id of controller device for endpoint device property.
		/// </summary>
		public static readonly PropertyKey PKEY_Device_ControllerDeviceId = new PropertyKey(new Guid(-1275528621, 4, 17294, 144, 3, 81, 164, 110, 19, 155, 252), 2);

		/// <summary>
		/// Device interface key property.
		/// </summary>
		public static readonly PropertyKey PKEY_Device_InterfaceKey = new PropertyKey(new Guid(590439624, 6956, 19581, 188, 104, 182, 113, 104, 122, 37, 103), 1);

		/// <summary>
		/// System-supplied device instance identification string, assigned by PnP manager, persistent across system restarts.
		/// </summary>
		public static readonly PropertyKey PKEY_Device_InstanceId = new PropertyKey(new Guid(2026065864, 4170, 19146, 158, 164, 82, 77, 82, 153, 110, 87), 256);
	}

	/// <summary>
	/// Property Store class, only supports reading properties at the moment.
	/// </summary>
	public class PropertyStore
	{
		private readonly IPropertyStore storeInterface;

		/// <summary>
		/// Property Count
		/// </summary>
		public int Count
		{
			get
			{
				Marshal.ThrowExceptionForHR(storeInterface.GetCount(out var propCount));
				return propCount;
			}
		}

		/// <summary>
		/// Gets property by index
		/// </summary>
		/// <param name="index">Property index</param>
		/// <returns>The property</returns>
		public PropertyStoreProperty this[int index]
		{
			get
			{
				PropertyKey key = Get(index);
				Marshal.ThrowExceptionForHR(storeInterface.GetValue(ref key, out var value));
				return new PropertyStoreProperty(key, value);
			}
		}

		/// <summary>
		/// Indexer by guid
		/// </summary>
		/// <param name="key">Property Key</param>
		/// <returns>Property or null if not found</returns>
		public PropertyStoreProperty this[PropertyKey key]
		{
			get
			{
				for (int i = 0; i < Count; i++)
				{
					PropertyKey key2 = Get(i);
					if (key2.formatId == key.formatId && key2.propertyId == key.propertyId)
					{
						Marshal.ThrowExceptionForHR(storeInterface.GetValue(ref key2, out var value));
						return new PropertyStoreProperty(key2, value);
					}
				}
				return null;
			}
		}

		/// <summary>
		/// Contains property guid
		/// </summary>
		/// <param name="key">Looks for a specific key</param>
		/// <returns>True if found</returns>
		public bool Contains(PropertyKey key)
		{
			for (int i = 0; i < Count; i++)
			{
				PropertyKey propertyKey = Get(i);
				if (propertyKey.formatId == key.formatId && propertyKey.propertyId == key.propertyId)
				{
					return true;
				}
			}
			return false;
		}

		/// <summary>
		/// Gets property key at sepecified index
		/// </summary>
		/// <param name="index">Index</param>
		/// <returns>Property key</returns>
		public PropertyKey Get(int index)
		{
			Marshal.ThrowExceptionForHR(storeInterface.GetAt(index, out var key));
			return key;
		}

		/// <summary>
		/// Gets property value at specified index
		/// </summary>
		/// <param name="index">Index</param>
		/// <returns>Property value</returns>
		public PropVariant GetValue(int index)
		{
			PropertyKey key = Get(index);
			Marshal.ThrowExceptionForHR(storeInterface.GetValue(ref key, out var value));
			return value;
		}

		/// <summary>
		/// Sets property value at specified key.
		/// </summary>
		/// <param name="key">Key of property to set.</param>
		/// <param name="value">Value to write.</param>
		public void SetValue(PropertyKey key, PropVariant value)
		{
			Marshal.ThrowExceptionForHR(storeInterface.SetValue(ref key, ref value));
		}

		/// <summary>
		/// Saves a property change.
		/// </summary>
		public void Commit()
		{
			Marshal.ThrowExceptionForHR(storeInterface.Commit());
		}

		/// <summary>
		/// Creates a new property store
		/// </summary>
		/// <param name="store">IPropertyStore COM interface</param>
		internal PropertyStore(IPropertyStore store)
		{
			storeInterface = store;
		}
	}

	/// <summary>
	/// Property Store Property
	/// </summary>
	public class PropertyStoreProperty
	{
		private PropVariant propertyValue;

		/// <summary>
		/// Property Key
		/// </summary>
		public PropertyKey Key { get; }

		/// <summary>
		/// Property Value
		/// </summary>
		public object Value => propertyValue.Value;

		internal PropertyStoreProperty(PropertyKey key, PropVariant value)
		{
			Key = key;
			propertyValue = value;
		}
	}

	/// <summary>
	/// The ERole enumeration defines constants that indicate the role 
	/// that the system has assigned to an audio endpoint device
	/// </summary>
	public enum Role
	{
		/// <summary>
		/// Games, system notification sounds, and voice commands.
		/// </summary>
		Console,
		/// <summary>
		/// Music, movies, narration, and live music recording
		/// </summary>
		Multimedia,
		/// <summary>
		/// Voice communications (talking to another person).
		/// </summary>
		Communications
	}

	/// <summary>
	/// Collection of sessions.
	/// </summary>
	public class SessionCollection
	{
		private readonly IAudioSessionEnumerator audioSessionEnumerator;

		/// <summary>
		/// Returns session at index.
		/// </summary>
		/// <param name="index"></param>
		/// <returns></returns>
		public AudioSessionControl this[int index]
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioSessionEnumerator.GetSession(index, out var session));
				return new AudioSessionControl(session);
			}
		}

		/// <summary>
		/// Number of current sessions.
		/// </summary>
		public int Count
		{
			get
			{
				Marshal.ThrowExceptionForHR(audioSessionEnumerator.GetCount(out var sessionCount));
				return sessionCount;
			}
		}

		internal SessionCollection(IAudioSessionEnumerator realEnumerator)
		{
			audioSessionEnumerator = realEnumerator;
		}
	}

	/// <summary>
	/// Windows CoreAudio SimpleAudioVolume
	/// </summary>
	public class SimpleAudioVolume : IDisposable
	{
		private readonly ISimpleAudioVolume simpleAudioVolume;

		/// <summary>
		/// Allows the user to adjust the volume from
		/// 0.0 to 1.0
		/// </summary>
		public float Volume
		{
			get
			{
				Marshal.ThrowExceptionForHR(simpleAudioVolume.GetMasterVolume(out var levelNorm));
				return levelNorm;
			}
			set
			{
				if ((double)value >= 0.0 && (double)value <= 1.0)
				{
					Marshal.ThrowExceptionForHR(simpleAudioVolume.SetMasterVolume(value, Guid.Empty));
				}
			}
		}

		/// <summary>
		/// Mute
		/// </summary>
		public bool Mute
		{
			get
			{
				Marshal.ThrowExceptionForHR(simpleAudioVolume.GetMute(out var isMuted));
				return isMuted;
			}
			set
			{
				Marshal.ThrowExceptionForHR(simpleAudioVolume.SetMute(value, Guid.Empty));
			}
		}

		/// <summary>
		/// Creates a new Audio endpoint volume
		/// </summary>
		/// <param name="realSimpleVolume">ISimpleAudioVolume COM interface</param>
		internal SimpleAudioVolume(ISimpleAudioVolume realSimpleVolume)
		{
			simpleAudioVolume = realSimpleVolume;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~SimpleAudioVolume()
		{
			Dispose();
		}
	}

	/// <summary>
	/// Audio Capture using Wasapi
	/// See http://msdn.microsoft.com/en-us/library/dd370800%28VS.85%29.aspx
	/// </summary>
	public class WasapiCapture : IWaveIn, IDisposable
	{
		private const long ReftimesPerSec = 10000000L;

		private const long ReftimesPerMillisec = 10000L;

		private volatile CaptureState captureState;

		private byte[] recordBuffer;

		private Thread captureThread;

		private AudioClient audioClient;

		private int bytesPerFrame;

		private WaveFormat waveFormat;

		private bool initialized;

		private readonly SynchronizationContext syncContext;

		private readonly bool isUsingEventSync;

		private EventWaitHandle frameEventWaitHandle;

		private readonly int audioBufferMillisecondsLength;

		/// <summary>
		/// Share Mode - set before calling StartRecording
		/// </summary>
		public AudioClientShareMode ShareMode { get; set; }

		/// <summary>
		/// Current Capturing State
		/// </summary>
		public CaptureState CaptureState => captureState;

		/// <summary>
		/// Capturing wave format
		/// </summary>
		public virtual WaveFormat WaveFormat
		{
			get
			{
				return waveFormat.AsStandardWaveFormat();
			}
			set
			{
				waveFormat = value;
			}
		}

		/// <summary>
		/// Indicates recorded data is available 
		/// </summary>
		public event EventHandler<WaveInEventArgs> DataAvailable;

		/// <summary>
		/// Indicates that all recorded data has now been received.
		/// </summary>
		public event EventHandler<StoppedEventArgs> RecordingStopped;

		/// <summary>
		/// Initialises a new instance of the WASAPI capture class
		/// </summary>
		public WasapiCapture()
			: this(GetDefaultCaptureDevice())
		{
		}

		/// <summary>
		/// Initialises a new instance of the WASAPI capture class
		/// </summary>
		/// <param name="captureDevice">Capture device to use</param>
		public WasapiCapture(MMDevice captureDevice)
			: this(captureDevice, useEventSync: false)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.CoreAudioApi.WasapiCapture" /> class.
		/// </summary>
		/// <param name="captureDevice">The capture device.</param>
		/// <param name="useEventSync">true if sync is done with event. false use sleep.</param>
		public WasapiCapture(MMDevice captureDevice, bool useEventSync)
			: this(captureDevice, useEventSync, 100)
		{
		}

		/// <summary>
		/// Initializes a new instance of the <see cref="T:NAudio.CoreAudioApi.WasapiCapture" /> class.
		/// </summary>
		/// <param name="captureDevice">The capture device.</param>
		/// <param name="useEventSync">true if sync is done with event. false use sleep.</param>
		/// <param name="audioBufferMillisecondsLength">Length of the audio buffer in milliseconds. A lower value means lower latency but increased CPU usage.</param>
		public WasapiCapture(MMDevice captureDevice, bool useEventSync, int audioBufferMillisecondsLength)
		{
			syncContext = SynchronizationContext.Current;
			audioClient = captureDevice.AudioClient;
			ShareMode = AudioClientShareMode.Shared;
			isUsingEventSync = useEventSync;
			this.audioBufferMillisecondsLength = audioBufferMillisecondsLength;
			waveFormat = audioClient.MixFormat;
		}

		/// <summary>
		/// Gets the default audio capture device
		/// </summary>
		/// <returns>The default audio capture device</returns>
		public static MMDevice GetDefaultCaptureDevice()
		{
			return new MMDeviceEnumerator().GetDefaultAudioEndpoint(DataFlow.Capture, Role.Console);
		}

		private void InitializeCaptureDevice()
		{
			if (initialized)
			{
				return;
			}
			long num = 10000L * (long)audioBufferMillisecondsLength;
			AudioClientStreamFlags audioClientStreamFlags = GetAudioClientStreamFlags();
			if (isUsingEventSync)
			{
				if (ShareMode == AudioClientShareMode.Shared)
				{
					audioClient.Initialize(ShareMode, AudioClientStreamFlags.EventCallback | audioClientStreamFlags, num, 0L, waveFormat, Guid.Empty);
				}
				else
				{
					audioClient.Initialize(ShareMode, AudioClientStreamFlags.EventCallback | audioClientStreamFlags, num, num, waveFormat, Guid.Empty);
				}
				frameEventWaitHandle = new EventWaitHandle(initialState: false, EventResetMode.AutoReset);
				audioClient.SetEventHandle(frameEventWaitHandle.SafeWaitHandle.DangerousGetHandle());
			}
			else
			{
				audioClient.Initialize(ShareMode, audioClientStreamFlags, num, 0L, waveFormat, Guid.Empty);
			}
			int bufferSize = audioClient.BufferSize;
			bytesPerFrame = waveFormat.Channels * waveFormat.BitsPerSample / 8;
			recordBuffer = new byte[bufferSize * bytesPerFrame];
			initialized = true;
		}

		/// <summary>
		/// To allow overrides to specify different flags (e.g. loopback)
		/// </summary>
		protected virtual AudioClientStreamFlags GetAudioClientStreamFlags()
		{
			return AudioClientStreamFlags.SrcDefaultQuality | AudioClientStreamFlags.AutoConvertPcm;
		}

		/// <summary>
		/// Start Capturing
		/// </summary>
		public void StartRecording()
		{
			if (captureState != 0)
			{
				throw new InvalidOperationException("Previous recording still in progress");
			}
			captureState = CaptureState.Starting;
			InitializeCaptureDevice();
			captureThread = new Thread((ThreadStart)delegate
			{
				CaptureThread(audioClient);
			})
			{
				IsBackground = true
			};
			captureThread.Start();
		}

		/// <summary>
		/// Stop Capturing (requests a stop, wait for RecordingStopped event to know it has finished)
		/// </summary>
		public void StopRecording()
		{
			if (captureState != 0)
			{
				captureState = CaptureState.Stopping;
			}
		}

		private void CaptureThread(AudioClient client)
		{
			Exception e = null;
			try
			{
				DoRecording(client);
			}
			catch (Exception ex)
			{
				e = ex;
			}
			finally
			{
				client.Stop();
			}
			captureThread = null;
			captureState = CaptureState.Stopped;
			RaiseRecordingStopped(e);
		}

		private void DoRecording(AudioClient client)
		{
			int bufferSize = client.BufferSize;
			long num = (long)(10000000.0 * (double)bufferSize / (double)waveFormat.SampleRate);
			int millisecondsTimeout = (int)(num / 10000 / 2);
			int millisecondsTimeout2 = (int)(3 * num / 10000);
			AudioCaptureClient audioCaptureClient = client.AudioCaptureClient;
			client.Start();
			if (captureState == CaptureState.Starting)
			{
				captureState = CaptureState.Capturing;
			}
			while (captureState == CaptureState.Capturing)
			{
				if (isUsingEventSync)
				{
					frameEventWaitHandle.WaitOne(millisecondsTimeout2, exitContext: false);
				}
				else
				{
					Thread.Sleep(millisecondsTimeout);
				}
				if (captureState == CaptureState.Capturing)
				{
					ReadNextPacket(audioCaptureClient);
					continue;
				}
				break;
			}
		}

		private void RaiseRecordingStopped(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.RecordingStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		private void ReadNextPacket(AudioCaptureClient capture)
		{
			int nextPacketSize = capture.GetNextPacketSize();
			int num = 0;
			while (nextPacketSize != 0)
			{
				int numFramesToRead;
				AudioClientBufferFlags bufferFlags;
				IntPtr buffer = capture.GetBuffer(out numFramesToRead, out bufferFlags);
				int num2 = numFramesToRead * bytesPerFrame;
				if (Math.Max(0, recordBuffer.Length - num) < num2 && num > 0)
				{
					this.DataAvailable?.Invoke(this, new WaveInEventArgs(recordBuffer, num));
					num = 0;
				}
				if ((bufferFlags & AudioClientBufferFlags.Silent) != AudioClientBufferFlags.Silent)
				{
					Marshal.Copy(buffer, recordBuffer, num, num2);
				}
				else
				{
					Array.Clear(recordBuffer, num, num2);
				}
				num += num2;
				capture.ReleaseBuffer(numFramesToRead);
				nextPacketSize = capture.GetNextPacketSize();
			}
			this.DataAvailable?.Invoke(this, new WaveInEventArgs(recordBuffer, num));
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			StopRecording();
			if (captureThread != null)
			{
				captureThread.Join();
				captureThread = null;
			}
			if (audioClient != null)
			{
				audioClient.Dispose();
				audioClient = null;
			}
		}
	}
}


namespace NAudio.CoreAudioApi.Interfaces
{
	using NAudio.Wave;
	using NAudio.Wasapi.CoreAudioApi.Interfaces;
	using System.Runtime.InteropServices.ComTypes;
	
	/// <summary>
	/// Audio Client WASAPI Error Codes (HResult)
	/// </summary>
	public static class AudioClientErrorCode
	{
		/// <summary>
		/// AUDCLNT_E_NOT_INITIALIZED
		/// </summary>
		public const int NotInitialized = -2004287487;

		/// <summary>
		/// AUDCLNT_E_ALREADY_INITIALIZED
		/// </summary>
		public const int AlreadyInitialized = -2004287486;

		/// <summary>
		/// AUDCLNT_E_WRONG_ENDPOINT_TYPE
		/// </summary>
		public const int WrongEndpointType = -2004287485;

		/// <summary>
		/// AUDCLNT_E_DEVICE_INVALIDATED
		/// </summary>
		public const int DeviceInvalidated = -2004287484;

		/// <summary>
		/// AUDCLNT_E_NOT_STOPPED
		/// </summary>
		public const int NotStopped = -2004287483;

		/// <summary>
		/// AUDCLNT_E_BUFFER_TOO_LARGE
		/// </summary>
		public const int BufferTooLarge = -2004287482;

		/// <summary>
		/// AUDCLNT_E_OUT_OF_ORDER
		/// </summary>
		public const int OutOfOrder = -2004287481;

		/// <summary>
		/// AUDCLNT_E_UNSUPPORTED_FORMAT
		/// </summary>
		public const int UnsupportedFormat = -2004287480;

		/// <summary>
		/// AUDCLNT_E_INVALID_SIZE
		/// </summary>
		public const int InvalidSize = -2004287479;

		/// <summary>
		/// AUDCLNT_E_DEVICE_IN_USE
		/// </summary>
		public const int DeviceInUse = -2004287478;

		/// <summary>
		/// AUDCLNT_E_BUFFER_OPERATION_PENDING
		/// </summary>
		public const int BufferOperationPending = -2004287477;

		/// <summary>
		/// AUDCLNT_E_THREAD_NOT_REGISTERED
		/// </summary>
		public const int ThreadNotRegistered = -2004287476;

		/// <summary>
		/// AUDCLNT_E_NO_SINGLE_PROCESS
		/// </summary>
		public const int NoSingleProcess = -2004287475;

		/// <summary>
		/// AUDCLNT_E_EXCLUSIVE_MODE_NOT_ALLOWED
		/// </summary>
		public const int ExclusiveModeNotAllowed = -2004287474;

		/// <summary>
		/// AUDCLNT_E_ENDPOINT_CREATE_FAILED
		/// </summary>
		public const int EndpointCreateFailed = -2004287473;

		/// <summary>
		/// AUDCLNT_E_SERVICE_NOT_RUNNING
		/// </summary>
		public const int ServiceNotRunning = -2004287472;

		/// <summary>
		/// AUDCLNT_E_EVENTHANDLE_NOT_EXPECTED
		/// </summary>
		public const int EventHandleNotExpected = -2004287471;

		/// <summary>
		/// AUDCLNT_E_EXCLUSIVE_MODE_ONLY
		/// </summary>
		public const int ExclusiveModeOnly = -2004287470;

		/// <summary>
		/// AUDCLNT_E_BUFDURATION_PERIOD_NOT_EQUAL
		/// </summary>
		public const int BufferDurationPeriodNotEqual = -2004287469;

		/// <summary>
		/// AUDCLNT_E_EVENTHANDLE_NOT_SET
		/// </summary>
		public const int EventHandleNotSet = -2004287468;

		/// <summary>
		/// AUDCLNT_E_INCORRECT_BUFFER_SIZE
		/// </summary>
		public const int IncorrectBufferSize = -2004287467;

		/// <summary>
		/// AUDCLNT_E_BUFFER_SIZE_ERROR
		/// </summary>
		public const int BufferSizeError = -2004287466;

		/// <summary>
		/// AUDCLNT_E_CPUUSAGE_EXCEEDED
		/// </summary>
		public const int CpuUsageExceeded = -2004287465;

		/// <summary>
		/// AUDCLNT_E_BUFFER_ERROR
		/// </summary>
		public const int BufferError = -2004287464;

		/// <summary>
		/// AUDCLNT_E_BUFFER_SIZE_NOT_ALIGNED
		/// </summary>
		public const int BufferSizeNotAligned = -2004287463;

		/// <summary>
		/// AUDCLNT_E_INVALID_DEVICE_PERIOD
		/// </summary>
		public const int InvalidDevicePeriod = -2004287456;

		/// <summary>
		/// AUDCLNT_E_INVALID_STREAM_FLAG
		/// </summary>
		public const int InvalidStreamFlag = -2004287455;

		/// <summary>
		/// AUDCLNT_E_ENDPOINT_OFFLOAD_NOT_CAPABLE
		/// </summary>
		public const int EndpointOffloadNotCapable = -2004287454;

		/// <summary>
		/// AUDCLNT_E_OUT_OF_OFFLOAD_RESOURCES
		/// </summary>
		public const int OutOfOffloadResources = -2004287453;

		/// <summary>
		/// AUDCLNT_E_OFFLOAD_MODE_ONLY
		/// </summary>
		public const int OffloadModeOnly = -2004287452;

		/// <summary>
		/// AUDCLNT_E_NONOFFLOAD_MODE_ONLY
		/// </summary>
		public const int NonOffloadModeOnly = -2004287451;

		/// <summary>
		/// AUDCLNT_E_RESOURCES_INVALIDATED
		/// </summary>
		public const int ResourcesInvalidated = -2004287450;

		/// <summary>
		/// AUDCLNT_E_RAW_MODE_UNSUPPORTED
		/// </summary>
		public const int RawModeUnsupported = -2004287449;

		/// <summary>
		/// AUDCLNT_E_ENGINE_PERIODICITY_LOCKED
		/// </summary>
		public const int EnginePeriodicityLocked = -2004287448;

		/// <summary>
		/// AUDCLNT_E_ENGINE_FORMAT_LOCKED
		/// </summary>
		public const int EngineFormatLocked = -2004287447;

		/// <summary>
		/// AUDCLNT_E_HEADTRACKING_ENABLED
		/// </summary>
		public const int HeadTrackingEnabled = -2004287440;

		/// <summary>
		/// AUDCLNT_E_HEADTRACKING_UNSUPPORTED
		/// </summary>
		public const int HeadTrackingUnsupported = -2004287424;
	}

	/// <summary>
	/// Defines constants that indicate a reason for an audio session being disconnected.
	/// </summary>
	/// <remarks>
	/// MSDN Reference: Unknown
	/// </remarks>
	public enum AudioSessionDisconnectReason
	{
		/// <summary>
		/// The user removed the audio endpoint device.
		/// </summary>
		DisconnectReasonDeviceRemoval,
		/// <summary>
		/// The Windows audio service has stopped.
		/// </summary>
		DisconnectReasonServerShutdown,
		/// <summary>
		/// The stream format changed for the device that the audio session is connected to.
		/// </summary>
		DisconnectReasonFormatChanged,
		/// <summary>
		/// The user logged off the WTS session that the audio session was running in.
		/// </summary>
		DisconnectReasonSessionLogoff,
		/// <summary>
		/// The WTS session that the audio session was running in was disconnected.
		/// </summary>
		DisconnectReasonSessionDisconnected,
		/// <summary>
		/// The (shared-mode) audio session was disconnected to make the audio endpoint device available for an exclusive-mode connection.
		/// </summary>
		DisconnectReasonExclusiveModeOverride
	}

	/// <summary>
	/// Defines constants that indicate the current state of an audio session.
	/// </summary>
	/// <remarks>
	/// MSDN Reference: http://msdn.microsoft.com/en-us/library/dd370792.aspx
	/// </remarks>
	public enum AudioSessionState
	{
		/// <summary>
		/// The audio session is inactive.
		/// </summary>
		AudioSessionStateInactive,
		/// <summary>
		/// The audio session is active.
		/// </summary>
		AudioSessionStateActive,
		/// <summary>
		/// The audio session has expired.
		/// </summary>
		AudioSessionStateExpired
	}

	internal struct AudioVolumeNotificationDataStruct
	{
		public Guid guidEventContext;

		public bool bMuted;

		public float fMasterVolume;

		public uint nChannels;

		public float ChannelVolume;
	}

	/// <summary>
	/// Representation of binary large object container.
	/// </summary>
	public struct Blob
	{
		/// <summary>
		/// Length of binary object.
		/// </summary>
		public int Length;

		/// <summary>
		/// Pointer to buffer storing data.
		/// </summary>
		public IntPtr Data;
	}

	/// <summary>
	/// is defined in WTypes.h
	/// </summary>
	[Flags]
	internal enum ClsCtx
	{
		INPROC_SERVER = 1,
		INPROC_HANDLER = 2,
		LOCAL_SERVER = 4,
		INPROC_SERVER16 = 8,
		REMOTE_SERVER = 0x10,
		INPROC_HANDLER16 = 0x20,
		NO_CODE_DOWNLOAD = 0x400,
		NO_CUSTOM_MARSHAL = 0x1000,
		ENABLE_CODE_DOWNLOAD = 0x2000,
		NO_FAILURE_LOG = 0x4000,
		DISABLE_AAA = 0x8000,
		ENABLE_AAA = 0x10000,
		FROM_DEFAULT_CONTEXT = 0x20000,
		ACTIVATE_32_BIT_SERVER = 0x40000,
		ACTIVATE_64_BIT_SERVER = 0x80000,
		ENABLE_CLOAKING = 0x100000,
		PS_DLL = int.MinValue,
		INPROC = 3,
		SERVER = 0x15,
		ALL = 0x17
	}

	[ComImport]
	[Guid("85401FD4-6DE4-4b9d-9869-2D6753A82F3C")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioAutoGainControl
	{
		[PreserveSig]
		int GetEnabled([MarshalAs(UnmanagedType.Bool)] out bool enabled);

		[PreserveSig]
		int SetEnabled([In][MarshalAs(UnmanagedType.Bool)] bool enabled);
	}

	[ComImport]
	[Guid("C8ADBD64-E71E-48a0-A4DE-185C395CD317")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioCaptureClient
	{
		int GetBuffer(out IntPtr dataBuffer, out int numFramesToRead, out AudioClientBufferFlags bufferFlags, out long devicePosition, out long qpcPosition);

		int ReleaseBuffer(int numFramesRead);

		int GetNextPacketSize(out int numFramesInNextPacket);
	}

	/// <summary>
	/// Windows CoreAudio IAudioClient interface
	/// Defined in AudioClient.h
	/// </summary>
	[ComImport]
	[Guid("1CB9AD4C-DBFA-4c32-B178-C2F568A703B2")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IAudioClient
	{
		[PreserveSig]
		int Initialize(AudioClientShareMode shareMode, AudioClientStreamFlags streamFlags, long hnsBufferDuration, long hnsPeriodicity, [In] WaveFormat pFormat, [In] ref Guid audioSessionGuid);

		/// <summary>
		/// The GetBufferSize method retrieves the size (maximum capacity) of the endpoint buffer.
		/// </summary>
		int GetBufferSize(out uint bufferSize);

		[return: MarshalAs(UnmanagedType.I8)]
		long GetStreamLatency();

		int GetCurrentPadding(out int currentPadding);

		[PreserveSig]
		int IsFormatSupported(AudioClientShareMode shareMode, [In] WaveFormat pFormat, IntPtr closestMatchFormat);

		int GetMixFormat(out IntPtr deviceFormatPointer);

		int GetDevicePeriod(out long defaultDevicePeriod, out long minimumDevicePeriod);

		int Start();

		int Stop();

		int Reset();

		int SetEventHandle(IntPtr eventHandle);

		/// <summary>
		/// The GetService method accesses additional services from the audio client object.
		/// </summary>
		/// <param name="interfaceId">The interface ID for the requested service.</param>
		/// <param name="interfacePointer">Pointer to a pointer variable into which the method writes the address of an instance of the requested interface. </param>
		[PreserveSig]
		int GetService([In][MarshalAs(UnmanagedType.LPStruct)] Guid interfaceId, [MarshalAs(UnmanagedType.IUnknown)] out object interfacePointer);
	}

	/// <summary>
	/// https://docs.microsoft.com/en-us/windows/win32/api/audioclient/nn-audioclient-iaudioclient2
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("726778CD-F60A-4eda-82DE-E47610CD78AA")]
	public interface IAudioClient2 : IAudioClient
	{
		/// <summary>
		/// The IsOffloadCapable method retrieves information about whether or not the endpoint on which a stream is created is capable of supporting an offloaded audio stream.
		/// </summary>
		/// <param name="category">An enumeration that specifies the category of an audio stream.</param>
		/// <param name="pbOffloadCapable">A pointer to a Boolean value. TRUE indicates that the endpoint is offload-capable. FALSE indicates that the endpoint is not offload-capable.</param>
		void IsOffloadCapable(AudioStreamCategory category, out bool pbOffloadCapable);

		/// <summary>
		/// Pointer to an AudioClientProperties structure.
		/// </summary>
		/// <param name="pProperties"></param>
		void SetClientProperties([In] IntPtr pProperties);

		/// <summary>
		/// The GetBufferSizeLimits method returns the buffer size limits of the hardware audio engine in 100-nanosecond units.
		/// </summary>
		/// <param name="pFormat">A pointer to the target format that is being queried for the buffer size limit.</param>
		/// <param name="bEventDriven">Boolean value to indicate whether or not the stream can be event-driven.</param>
		/// <param name="phnsMinBufferDuration">Returns a pointer to the minimum buffer size (in 100-nanosecond units) that is required for the underlying hardware audio engine to operate at the format specified in the pFormat parameter, without frequent audio glitching.</param>
		/// <param name="phnsMaxBufferDuration">Returns a pointer to the maximum buffer size (in 100-nanosecond units) that the underlying hardware audio engine can support for the format specified in the pFormat parameter.</param>
		void GetBufferSizeLimits(IntPtr pFormat, bool bEventDriven, out long phnsMinBufferDuration, out long phnsMaxBufferDuration);
	}

	/// <summary>
	/// Defined in AudioClient.h
	/// </summary>
	[ComImport]
	[Guid("CD63314F-3FBA-4a1b-812C-EF96358728E7")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioClock
	{
		[PreserveSig]
		int GetFrequency(out ulong frequency);

		[PreserveSig]
		int GetPosition(out ulong devicePosition, out ulong qpcPosition);

		[PreserveSig]
		int GetCharacteristics(out uint characteristics);
	}

	/// <summary>
	/// Defined in AudioClient.h
	/// </summary>
	[ComImport]
	[Guid("6f49ff73-6727-49AC-A008-D98CF5E70048")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioClock2 : IAudioClock
	{
		[PreserveSig]
		int GetDevicePosition(out ulong devicePosition, out ulong qpcPosition);
	}

	[ComImport]
	[Guid("5CDF2C82-841E-4546-9722-0CF74078229A")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioEndpointVolume
	{
		int RegisterControlChangeNotify(IAudioEndpointVolumeCallback pNotify);

		int UnregisterControlChangeNotify(IAudioEndpointVolumeCallback pNotify);

		int GetChannelCount(out int pnChannelCount);

		int SetMasterVolumeLevel(float fLevelDB, ref Guid pguidEventContext);

		int SetMasterVolumeLevelScalar(float fLevel, ref Guid pguidEventContext);

		int GetMasterVolumeLevel(out float pfLevelDB);

		int GetMasterVolumeLevelScalar(out float pfLevel);

		int SetChannelVolumeLevel(uint nChannel, float fLevelDB, ref Guid pguidEventContext);

		int SetChannelVolumeLevelScalar(uint nChannel, float fLevel, ref Guid pguidEventContext);

		int GetChannelVolumeLevel(uint nChannel, out float pfLevelDB);

		int GetChannelVolumeLevelScalar(uint nChannel, out float pfLevel);

		int SetMute([MarshalAs(UnmanagedType.Bool)] bool bMute, ref Guid pguidEventContext);

		int GetMute(out bool pbMute);

		int GetVolumeStepInfo(out uint pnStep, out uint pnStepCount);

		int VolumeStepUp(ref Guid pguidEventContext);

		int VolumeStepDown(ref Guid pguidEventContext);

		int QueryHardwareSupport(out uint pdwHardwareSupportMask);

		int GetVolumeRange(out float pflVolumeMindB, out float pflVolumeMaxdB, out float pflVolumeIncrementdB);
	}

	[ComImport]
	[Guid("657804FA-D6AD-4496-8A60-352752AF4F89")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioEndpointVolumeCallback
	{
		void OnNotify(IntPtr notifyData);
	}

	[ComImport]
	[Guid("C02216F6-8C67-4B5B-9D00-D008E73E0064")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioMeterInformation
	{
		int GetPeakValue(out float pfPeak);

		int GetMeteringChannelCount(out int pnChannelCount);

		int GetChannelsPeakValues(int u32ChannelCount, [In] IntPtr afPeakValues);

		int QueryHardwareSupport(out int pdwHardwareSupportMask);
	}

	[ComImport]
	[Guid("DF45AEEA-B74A-4B6B-AFAD-2366B6AA012E")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioMute
	{
		[PreserveSig]
		int GetMute([MarshalAs(UnmanagedType.Bool)] out bool mute);

		[PreserveSig]
		int SetMute([In][MarshalAs(UnmanagedType.Bool)] bool mute, [In] ref Guid eventContext);
	}

	[ComImport]
	[Guid("F294ACFC-3146-4483-A7BF-ADDCA7C260E2")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioRenderClient
	{
		int GetBuffer(int numFramesRequested, out IntPtr dataBufferPointer);

		int ReleaseBuffer(int numFramesWritten, AudioClientBufferFlags bufferFlags);
	}

	/// <summary>
	/// Windows CoreAudio IAudioSessionControl interface
	/// Defined in AudioPolicy.h
	/// </summary>
	[ComImport]
	[Guid("F4B1A599-7266-4319-A8CA-E70ACB11E8CD")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IAudioSessionControl
	{
		/// <summary>
		/// Retrieves the current state of the audio session.
		/// </summary>
		/// <param name="state">Receives the current session state.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetState(out AudioSessionState state);

		/// <summary>
		/// Retrieves the display name for the audio session.
		/// </summary>
		/// <param name="displayName">Receives a string that contains the display name.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetDisplayName([MarshalAs(UnmanagedType.LPWStr)] out string displayName);

		/// <summary>
		/// Assigns a display name to the current audio session.
		/// </summary>
		/// <param name="displayName">A string that contains the new display name for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetDisplayName([In][MarshalAs(UnmanagedType.LPWStr)] string displayName, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the path for the display icon for the audio session.
		/// </summary>
		/// <param name="iconPath">Receives a string that specifies the fully qualified path of the file that contains the icon.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetIconPath([MarshalAs(UnmanagedType.LPWStr)] out string iconPath);

		/// <summary>
		/// Assigns a display icon to the current session.
		/// </summary>
		/// <param name="iconPath">A string that specifies the fully qualified path of the file that contains the new icon.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetIconPath([In][MarshalAs(UnmanagedType.LPWStr)] string iconPath, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the grouping parameter of the audio session.
		/// </summary>
		/// <param name="groupingId">Receives the grouping parameter ID.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetGroupingParam(out Guid groupingId);

		/// <summary>
		/// Assigns a session to a grouping of sessions.
		/// </summary>
		/// <param name="groupingId">The new grouping parameter ID.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetGroupingParam([In][MarshalAs(UnmanagedType.LPStruct)] Guid groupingId, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Registers the client to receive notifications of session events, including changes in the session state.
		/// </summary>
		/// <param name="client">A client-implemented <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionEvents" /> interface.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int RegisterAudioSessionNotification([In] IAudioSessionEvents client);

		/// <summary>
		/// Deletes a previous registration by the client to receive notifications.
		/// </summary>
		/// <param name="client">A client-implemented <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionEvents" /> interface.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int UnregisterAudioSessionNotification([In] IAudioSessionEvents client);
	}

	/// <summary>
	/// Windows CoreAudio IAudioSessionControl interface
	/// Defined in AudioPolicy.h
	/// </summary>
	[ComImport]
	[Guid("bfb7ff88-7239-4fc9-8fa2-07c950be9c6d")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IAudioSessionControl2 : IAudioSessionControl
	{
		/// <summary>
		/// Retrieves the current state of the audio session.
		/// </summary>
		/// <param name="state">Receives the current session state.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetState(out AudioSessionState state);

		/// <summary>
		/// Retrieves the display name for the audio session.
		/// </summary>
		/// <param name="displayName">Receives a string that contains the display name.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetDisplayName([MarshalAs(UnmanagedType.LPWStr)] out string displayName);

		/// <summary>
		/// Assigns a display name to the current audio session.
		/// </summary>
		/// <param name="displayName">A string that contains the new display name for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int SetDisplayName([In][MarshalAs(UnmanagedType.LPWStr)] string displayName, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the path for the display icon for the audio session.
		/// </summary>
		/// <param name="iconPath">Receives a string that specifies the fully qualified path of the file that contains the icon.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetIconPath([MarshalAs(UnmanagedType.LPWStr)] out string iconPath);

		/// <summary>
		/// Assigns a display icon to the current session.
		/// </summary>
		/// <param name="iconPath">A string that specifies the fully qualified path of the file that contains the new icon.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int SetIconPath([In][MarshalAs(UnmanagedType.LPWStr)] string iconPath, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the grouping parameter of the audio session.
		/// </summary>
		/// <param name="groupingId">Receives the grouping parameter ID.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetGroupingParam(out Guid groupingId);

		/// <summary>
		/// Assigns a session to a grouping of sessions.
		/// </summary>
		/// <param name="groupingId">The new grouping parameter ID.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int SetGroupingParam([In][MarshalAs(UnmanagedType.LPStruct)] Guid groupingId, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Registers the client to receive notifications of session events, including changes in the session state.
		/// </summary>
		/// <param name="client">A client-implemented <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionEvents" /> interface.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int RegisterAudioSessionNotification([In] IAudioSessionEvents client);

		/// <summary>
		/// Deletes a previous registration by the client to receive notifications.
		/// </summary>
		/// <param name="client">A client-implemented <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionEvents" /> interface.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int UnregisterAudioSessionNotification([In] IAudioSessionEvents client);

		/// <summary>
		/// Retrieves the identifier for the audio session.
		/// </summary>
		/// <param name="retVal">Receives the session identifier.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetSessionIdentifier([MarshalAs(UnmanagedType.LPWStr)] out string retVal);

		/// <summary>
		/// Retrieves the identifier of the audio session instance.
		/// </summary>
		/// <param name="retVal">Receives the identifier of a particular instance.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetSessionInstanceIdentifier([MarshalAs(UnmanagedType.LPWStr)] out string retVal);

		/// <summary>
		/// Retrieves the process identifier of the audio session.
		/// </summary>
		/// <param name="retVal">Receives the process identifier of the audio session.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetProcessId(out uint retVal);

		/// <summary>
		/// Indicates whether the session is a system sounds session.
		/// </summary>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int IsSystemSoundsSession();

		/// <summary>
		/// Enables or disables the default stream attenuation experience (auto-ducking) provided by the system.
		/// </summary>
		/// <param name="optOut">A variable that enables or disables system auto-ducking.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetDuckingPreference(bool optOut);
	}

	[ComImport]
	[Guid("E2F5BB11-0570-40CA-ACDD-3AA01277DEE8")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioSessionEnumerator
	{
		int GetCount(out int sessionCount);

		int GetSession(int sessionCount, out IAudioSessionControl session);
	}

	/// <summary>
	/// Windows CoreAudio IAudioSessionControl interface
	/// Defined in AudioPolicy.h
	/// </summary>
	[ComImport]
	[Guid("24918ACC-64B3-37C1-8CA9-74A66E9957A8")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IAudioSessionEvents
	{
		/// <summary>
		/// Notifies the client that the display name for the session has changed.
		/// </summary>
		/// <param name="displayName">The new display name for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnDisplayNameChanged([In][MarshalAs(UnmanagedType.LPWStr)] string displayName, [In] ref Guid eventContext);

		/// <summary>
		/// Notifies the client that the display icon for the session has changed.
		/// </summary>
		/// <param name="iconPath">The path for the new display icon for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnIconPathChanged([In][MarshalAs(UnmanagedType.LPWStr)] string iconPath, [In] ref Guid eventContext);

		/// <summary>
		/// Notifies the client that the volume level or muting state of the session has changed.
		/// </summary>
		/// <param name="volume">The new volume level for the audio session.</param>
		/// <param name="isMuted">The new muting state.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnSimpleVolumeChanged([In][MarshalAs(UnmanagedType.R4)] float volume, [In][MarshalAs(UnmanagedType.Bool)] bool isMuted, [In] ref Guid eventContext);

		/// <summary>
		/// Notifies the client that the volume level of an audio channel in the session submix has changed.
		/// </summary>
		/// <param name="channelCount">The channel count.</param>
		/// <param name="newVolumes">An array of volumnes cooresponding with each channel index.</param>
		/// <param name="channelIndex">The number of the channel whose volume level changed.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnChannelVolumeChanged([In][MarshalAs(UnmanagedType.U4)] uint channelCount, [In][MarshalAs(UnmanagedType.SysInt)] IntPtr newVolumes, [In][MarshalAs(UnmanagedType.U4)] uint channelIndex, [In] ref Guid eventContext);

		/// <summary>
		/// Notifies the client that the grouping parameter for the session has changed.
		/// </summary>
		/// <param name="groupingId">The new grouping parameter for the session.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnGroupingParamChanged([In] ref Guid groupingId, [In] ref Guid eventContext);

		/// <summary>
		/// Notifies the client that the stream-activity state of the session has changed.
		/// </summary>
		/// <param name="state">The new session state.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnStateChanged([In] AudioSessionState state);

		/// <summary>
		/// Notifies the client that the session has been disconnected.
		/// </summary>
		/// <param name="disconnectReason">The reason that the audio session was disconnected.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnSessionDisconnected([In] AudioSessionDisconnectReason disconnectReason);
	}

	/// <summary>
	/// interface to receive session related events
	/// </summary>
	public interface IAudioSessionEventsHandler
	{
		/// <summary>
		/// notification of volume changes including muting of audio session
		/// </summary>
		/// <param name="volume">the current volume</param>
		/// <param name="isMuted">the current mute state, true muted, false otherwise</param>
		void OnVolumeChanged(float volume, bool isMuted);

		/// <summary>
		/// notification of display name changed
		/// </summary>
		/// <param name="displayName">the current display name</param>
		void OnDisplayNameChanged(string displayName);

		/// <summary>
		/// notification of icon path changed
		/// </summary>
		/// <param name="iconPath">the current icon path</param>
		void OnIconPathChanged(string iconPath);

		/// <summary>
		/// notification of the client that the volume level of an audio channel in the session submix has changed
		/// </summary>
		/// <param name="channelCount">The channel count.</param>
		/// <param name="newVolumes">An array of volumnes cooresponding with each channel index.</param>
		/// <param name="channelIndex">The number of the channel whose volume level changed.</param>
		void OnChannelVolumeChanged(uint channelCount, IntPtr newVolumes, uint channelIndex);

		/// <summary>
		/// notification of the client that the grouping parameter for the session has changed
		/// </summary>
		/// <param name="groupingId">&gt;The new grouping parameter for the session.</param>
		void OnGroupingParamChanged(ref Guid groupingId);

		/// <summary>
		/// notification of the client that the stream-activity state of the session has changed
		/// </summary>
		/// <param name="state">The new session state.</param>
		void OnStateChanged(AudioSessionState state);

		/// <summary>
		/// notification of the client that the session has been disconnected
		/// </summary>
		/// <param name="disconnectReason">The reason that the audio session was disconnected.</param>
		void OnSessionDisconnected(AudioSessionDisconnectReason disconnectReason);
	}

	/// <summary>
	/// Windows CoreAudio IAudioSessionManager interface
	/// Defined in AudioPolicy.h
	/// </summary>
	[ComImport]
	[Guid("BFA971F1-4D5E-40BB-935E-967039BFBEE4")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioSessionManager
	{
		/// <summary>
		/// Retrieves an audio session control.
		/// </summary>
		/// <param name="sessionId">A new or existing session ID.</param>
		/// <param name="streamFlags">Audio session flags.</param>
		/// <param name="sessionControl">Receives an <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionControl" /> interface for the audio session.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetAudioSessionControl([Optional][In][MarshalAs(UnmanagedType.LPStruct)] Guid sessionId, [In][MarshalAs(UnmanagedType.U4)] uint streamFlags, [MarshalAs(UnmanagedType.Interface)] out IAudioSessionControl sessionControl);

		/// <summary>
		/// Retrieves a simple audio volume control.
		/// </summary>
		/// <param name="sessionId">A new or existing session ID.</param>
		/// <param name="streamFlags">Audio session flags.</param>
		/// <param name="audioVolume">Receives an <see cref="T:NAudio.CoreAudioApi.Interfaces.ISimpleAudioVolume" /> interface for the audio session.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetSimpleAudioVolume([Optional][In][MarshalAs(UnmanagedType.LPStruct)] Guid sessionId, [In][MarshalAs(UnmanagedType.U4)] uint streamFlags, [MarshalAs(UnmanagedType.Interface)] out ISimpleAudioVolume audioVolume);
	}

	[ComImport]
	[Guid("77AA99A0-1BD6-484F-8BC7-2C654C9A9B6F")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioSessionManager2 : IAudioSessionManager
	{
		/// <summary>
		/// Retrieves an audio session control.
		/// </summary>
		/// <param name="sessionId">A new or existing session ID.</param>
		/// <param name="streamFlags">Audio session flags.</param>
		/// <param name="sessionControl">Receives an <see cref="T:NAudio.CoreAudioApi.Interfaces.IAudioSessionControl" /> interface for the audio session.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetAudioSessionControl([Optional][In][MarshalAs(UnmanagedType.LPStruct)] Guid sessionId, [In][MarshalAs(UnmanagedType.U4)] uint streamFlags, [MarshalAs(UnmanagedType.Interface)] out IAudioSessionControl sessionControl);

		/// <summary>
		/// Retrieves a simple audio volume control.
		/// </summary>
		/// <param name="sessionId">A new or existing session ID.</param>
		/// <param name="streamFlags">Audio session flags.</param>
		/// <param name="audioVolume">Receives an <see cref="T:NAudio.CoreAudioApi.Interfaces.ISimpleAudioVolume" /> interface for the audio session.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		new int GetSimpleAudioVolume([Optional][In][MarshalAs(UnmanagedType.LPStruct)] Guid sessionId, [In][MarshalAs(UnmanagedType.U4)] uint streamFlags, [MarshalAs(UnmanagedType.Interface)] out ISimpleAudioVolume audioVolume);

		[PreserveSig]
		int GetSessionEnumerator(out IAudioSessionEnumerator sessionEnum);

		[PreserveSig]
		int RegisterSessionNotification(IAudioSessionNotification sessionNotification);

		[PreserveSig]
		int UnregisterSessionNotification(IAudioSessionNotification sessionNotification);

		[PreserveSig]
		int RegisterDuckNotification(string sessionId, IAudioSessionNotification audioVolumeDuckNotification);

		[PreserveSig]
		int UnregisterDuckNotification(IntPtr audioVolumeDuckNotification);
	}

	/// <summary>
	/// Windows CoreAudio IAudioSessionNotification interface
	/// Defined in AudioPolicy.h
	/// </summary>
	[ComImport]
	[Guid("641DD20B-4D41-49CC-ABA3-174B9477BB08")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IAudioSessionNotification
	{
		/// <summary>
		///
		/// </summary>
		/// <param name="newSession">session being added</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int OnSessionCreated(IAudioSessionControl newSession);
	}

	[ComImport]
	[Guid("93014887-242D-4068-8A15-CF5E93B90FE3")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioStreamVolume
	{
		[PreserveSig]
		int GetChannelCount(out uint dwCount);

		[PreserveSig]
		int SetChannelVolume([In] uint dwIndex, [In] float fLevel);

		[PreserveSig]
		int GetChannelVolume([In] uint dwIndex, out float fLevel);

		[PreserveSig]
		int SetAllVoumes([In] uint dwCount, [In][MarshalAs(UnmanagedType.LPArray, ArraySubType = UnmanagedType.R4, SizeParamIndex = 0)] float[] fVolumes);

		[PreserveSig]
		int GetAllVolumes([In] uint dwCount, [MarshalAs(UnmanagedType.LPArray)] float[] pfVolumes);
	}

	[ComImport]
	[Guid("7FB7B48F-531D-44A2-BCB3-5AD5A134B3DC")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IAudioVolumeLevel : IPerChannelDbLevel { }

	/// <summary>
	/// Windows CoreAudio IConnector interface
	/// Defined in devicetopology.h
	/// </summary>
	[ComImport]
	[Guid("9C2C4058-23F5-41DE-877A-DF3AF236A09E")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IConnector
	{
		int GetType(out ConnectorType type);

		int GetDataFlow(out DataFlow flow);

		int ConnectTo([In] IConnector connectTo);

		int Disconnect();

		int IsConnected(out bool connected);

		int GetConnectedTo(out IConnector conTo);

		int GetConnectorIdConnectedTo([MarshalAs(UnmanagedType.LPWStr)] out string id);

		int GetDeviceIdConnectedTo([MarshalAs(UnmanagedType.LPWStr)] out string id);
	}

	[ComImport]
	[Guid("45d37c3f-5140-444a-ae24-400789f3cbf3")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IControlInterface { }

	/// <summary>
	/// Windows CoreAudio IDeviceTopology interface
	/// Defined in devicetopology.h
	/// </summary>
	[ComImport]
	[Guid("2A07407E-6497-4A18-9787-32F79BD0D98F")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDeviceTopology
	{
		int GetConnectorCount(out uint count);

		int GetConnector(uint index, out IConnector connector);

		int GetSubunitCount(out uint count);

		int GetSubunit(uint index, out ISubunit subunit);

		int GetPartById(uint id, out IPart part);

		int GetDeviceId([MarshalAs(UnmanagedType.LPWStr)] out string id);

		int GetSignalPath(IPart from, IPart to, bool rejectMixedPaths, out IPartsList parts);
	}

	[ComImport]
	[Guid("4509F757-2D46-4637-8E62-CE7DB944F57B")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IKsJackDescription
	{
		int GetJackCount(out uint jacks);

		int GetJackDescription([In] uint jack, [MarshalAs(UnmanagedType.LPWStr)] out string description);
	}

	[ComImport]
	[Guid("D666063F-1587-4E43-81F1-B948E807363F")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMMDevice
	{
		int Activate(ref Guid id, ClsCtx clsCtx, IntPtr activationParams, [MarshalAs(UnmanagedType.IUnknown)] out object interfacePointer);

		int OpenPropertyStore(StorageAccessMode stgmAccess, out IPropertyStore properties);

		int GetId([MarshalAs(UnmanagedType.LPWStr)] out string id);

		int GetState(out DeviceState state);
	}

	[ComImport]
	[Guid("0BD7A1BE-7A1A-44DB-8397-CC5392387B5E")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMMDeviceCollection
	{
		int GetCount(out int numDevices);

		int Item(int deviceNumber, out IMMDevice device);
	}

	[ComImport]
	[Guid("A95664D2-9614-4F35-A746-DE8DB63617E6")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMMDeviceEnumerator
	{
		int EnumAudioEndpoints(DataFlow dataFlow, DeviceState stateMask, out IMMDeviceCollection devices);

		[PreserveSig]
		int GetDefaultAudioEndpoint(DataFlow dataFlow, Role role, out IMMDevice endpoint);

		int GetDevice(string id, out IMMDevice deviceName);

		int RegisterEndpointNotificationCallback(IMMNotificationClient client);

		int UnregisterEndpointNotificationCallback(IMMNotificationClient client);
	}

	/// <summary>
	/// defined in MMDeviceAPI.h
	/// </summary>
	[ComImport]
	[Guid("1BE09788-6894-4089-8586-9A2A6C265AC5")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMMEndpoint
	{
		int GetDataFlow(out DataFlow dataFlow);
	}

	/// <summary>
	/// IMMNotificationClient
	/// </summary>
	[ComImport]
	[Guid("7991EEC9-7E89-4D85-8390-6C703CEC60C0")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IMMNotificationClient
	{
		/// <summary>
		/// Device State Changed
		/// </summary>
		void OnDeviceStateChanged([MarshalAs(UnmanagedType.LPWStr)] string deviceId, [MarshalAs(UnmanagedType.I4)] DeviceState newState);

		/// <summary>
		/// Device Added
		/// </summary>
		void OnDeviceAdded([MarshalAs(UnmanagedType.LPWStr)] string pwstrDeviceId);

		/// <summary>
		/// Device Removed
		/// </summary>
		void OnDeviceRemoved([MarshalAs(UnmanagedType.LPWStr)] string deviceId);

		/// <summary>
		/// Default Device Changed
		/// </summary>
		void OnDefaultDeviceChanged(DataFlow flow, Role role, [MarshalAs(UnmanagedType.LPWStr)] string defaultDeviceId);

		/// <summary>
		/// Property Value Changed
		/// </summary>
		/// <param name="pwstrDeviceId"></param>
		/// <param name="key"></param>
		void OnPropertyValueChanged([MarshalAs(UnmanagedType.LPWStr)] string pwstrDeviceId, PropertyKey key);
	}

	/// <summary>
	/// Windows CoreAudio IPart interface
	/// Defined in devicetopology.h
	/// </summary>
	[ComImport]
	[Guid("AE2DE0E4-5BCA-4F2D-AA46-5D13F8FDB3A9")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IPart
	{
		int GetName([MarshalAs(UnmanagedType.LPWStr)] out string name);

		int GetLocalId(out uint id);

		int GetGlobalId([MarshalAs(UnmanagedType.LPWStr)] out string id);

		int GetPartType(out PartTypeEnum partType);

		int GetSubType(out Guid subType);

		int GetControlInterfaceCount(out uint count);

		int GetControlInterface([In] uint index, [MarshalAs(UnmanagedType.IUnknown)] out IControlInterface controlInterface);

		[PreserveSig]
		int EnumPartsIncoming(out IPartsList parts);

		[PreserveSig]
		int EnumPartsOutgoing(out IPartsList parts);

		int GetTopologyObject(out object topologyObject);

		[PreserveSig]
		int Activate([In] ClsCtx dwClsContext, [In] ref Guid refiid, [MarshalAs(UnmanagedType.IUnknown)] out object interfacePointer);

		int RegisterControlChangeCallback([In] ref Guid refiid, [In] IControlChangeNotify notify);

		int UnregisterControlChangeCallback([In] IControlChangeNotify notify);
	}

	/// <summary>
	/// Windows CoreAudio IPartsList interface
	/// Defined in devicetopology.h
	/// </summary>
	[ComImport]
	[Guid("6DAA848C-5EB0-45CC-AEA5-998A2CDA1FFB")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IPartsList
	{
		int GetCount(out uint count);

		int GetPart(uint index, out IPart part);
	}

	[ComImport]
	[Guid("7FB7B48F-531D-44A2-BCB3-5AD5A134B3DC")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IPerChannelDbLevel
	{
		int GetChannelCount(out uint channels);

		int GetLevelRange(uint channel, out float minLevelDb, out float maxLevelDb, out float stepping);

		int GetLevel(uint channel, out float levelDb);

		int SetLevel(uint channel, float levelDb, ref Guid eventGuidContext);

		int SetLevelUniform(float levelDb, ref Guid eventGuidContext);

		int SetLevelAllChannel(float[] levelsDb, uint channels, ref Guid eventGuidContext);
	}

	/// <summary>
	/// is defined in propsys.h
	/// </summary>
	[ComImport]
	[Guid("886d8eeb-8cf2-4446-8d02-cdba1dbdcf99")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IPropertyStore
	{
		int GetCount(out int propCount);

		int GetAt(int property, out PropertyKey key);

		int GetValue(ref PropertyKey key, out PropVariant value);

		int SetValue(ref PropertyKey key, ref PropVariant value);

		int Commit();
	}

	/// <summary>
	/// Windows CoreAudio ISimpleAudioVolume interface
	/// Defined in AudioClient.h
	/// </summary>
	[ComImport]
	[Guid("87CE5498-68D6-44E5-9215-6DA47EF883D8")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface ISimpleAudioVolume
	{
		/// <summary>
		/// Sets the master volume level for the audio session.
		/// </summary>
		/// <param name="levelNorm">The new volume level expressed as a normalized value between 0.0 and 1.0.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetMasterVolume([In][MarshalAs(UnmanagedType.R4)] float levelNorm, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the client volume level for the audio session.
		/// </summary>
		/// <param name="levelNorm">Receives the volume level expressed as a normalized value between 0.0 and 1.0. </param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetMasterVolume([MarshalAs(UnmanagedType.R4)] out float levelNorm);

		/// <summary>
		/// Sets the muting state for the audio session.
		/// </summary>
		/// <param name="isMuted">The new muting state.</param>
		/// <param name="eventContext">A user context value that is passed to the notification callback.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int SetMute([In][MarshalAs(UnmanagedType.Bool)] bool isMuted, [In][MarshalAs(UnmanagedType.LPStruct)] Guid eventContext);

		/// <summary>
		/// Retrieves the current muting state for the audio session.
		/// </summary>
		/// <param name="isMuted">Receives the muting state.</param>
		/// <returns>An HRESULT code indicating whether the operation succeeded of failed.</returns>
		[PreserveSig]
		int GetMute([MarshalAs(UnmanagedType.Bool)] out bool isMuted);
	}

	[ComImport]
	[Guid("82149A85-DBA6-4487-86BB-EA8F7FEFCC71")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface ISubunit { }

	/// <summary>
	/// implements IMMDeviceEnumerator
	/// </summary>
	[ComImport]
	[Guid("BCDE0395-E52F-467C-8E3D-C4579291692E")]
	internal class MMDeviceEnumeratorComObject { }

	public enum PartTypeEnum
	{
		Connector,
		Subunit,
		HardwarePeriphery,
		SoftwareDriver,
		Splitter,
		Category,
		Other
	}

	/// <summary>
	/// from Propidl.h.
	/// http://msdn.microsoft.com/en-us/library/aa380072(VS.85).aspx
	/// contains a union so we have to do an explicit layout
	/// </summary>
	[StructLayout(LayoutKind.Explicit)]
	public struct PropVariant
	{
		/// <summary>
		/// Value type tag.
		/// </summary>
		[FieldOffset(0)]
		public short vt;

		/// <summary>
		/// Reserved1.
		/// </summary>
		[FieldOffset(2)]
		public short wReserved1;

		/// <summary>
		/// Reserved2.
		/// </summary>
		[FieldOffset(4)]
		public short wReserved2;

		/// <summary>
		/// Reserved3.
		/// </summary>
		[FieldOffset(6)]
		public short wReserved3;

		/// <summary>
		/// cVal.
		/// </summary>
		[FieldOffset(8)]
		public sbyte cVal;

		/// <summary>
		/// bVal.
		/// </summary>
		[FieldOffset(8)]
		public byte bVal;

		/// <summary>
		/// iVal.
		/// </summary>
		[FieldOffset(8)]
		public short iVal;

		/// <summary>
		/// uiVal.
		/// </summary>
		[FieldOffset(8)]
		public ushort uiVal;

		/// <summary>
		/// lVal.
		/// </summary>
		[FieldOffset(8)]
		public int lVal;

		/// <summary>
		/// ulVal.
		/// </summary>
		[FieldOffset(8)]
		public uint ulVal;

		/// <summary>
		/// intVal.
		/// </summary>
		[FieldOffset(8)]
		public int intVal;

		/// <summary>
		/// uintVal.
		/// </summary>
		[FieldOffset(8)]
		public uint uintVal;

		/// <summary>
		/// hVal.
		/// </summary>
		[FieldOffset(8)]
		public long hVal;

		/// <summary>
		/// uhVal.
		/// </summary>
		[FieldOffset(8)]
		public long uhVal;

		/// <summary>
		/// fltVal.
		/// </summary>
		[FieldOffset(8)]
		public float fltVal;

		/// <summary>
		/// dblVal.
		/// </summary>
		[FieldOffset(8)]
		public double dblVal;

		/// <summary>
		/// boolVal.
		/// </summary>
		[FieldOffset(8)]
		public short boolVal;

		/// <summary>
		/// scode.
		/// </summary>
		[FieldOffset(8)]
		public int scode;

		/// <summary>
		/// Date time.
		/// </summary>
		[FieldOffset(8)]
		public FILETIME filetime;

		/// <summary>
		/// Binary large object.
		/// </summary>
		[FieldOffset(8)]
		public Blob blobVal;

		/// <summary>
		/// Pointer value.
		/// </summary>
		[FieldOffset(8)]
		public IntPtr pointerValue;

		/// <summary>
		/// Gets the type of data in this PropVariant
		/// </summary>
		public VarEnum DataType => (VarEnum)vt;

		/// <summary>
		/// Property value
		/// </summary>
		public object Value
		{
			get
			{
				VarEnum dataType = DataType;
				switch (dataType)
				{
				case VarEnum.VT_I1:
					return bVal;
				case VarEnum.VT_I2:
					return iVal;
				case VarEnum.VT_I4:
					return lVal;
				case VarEnum.VT_I8:
					return hVal;
				case VarEnum.VT_INT:
					return iVal;
				case VarEnum.VT_UI4:
					return ulVal;
				case VarEnum.VT_UI8:
					return uhVal;
				case VarEnum.VT_LPWSTR:
					return Marshal.PtrToStringUni(pointerValue);
				case VarEnum.VT_BLOB:
				case (VarEnum)4113:
					return GetBlob();
				case VarEnum.VT_CLSID:
					return Marshal.PtrToStructure<Guid>(pointerValue);
				case VarEnum.VT_BOOL:
					return boolVal switch
					{
						-1 => true, 
						0 => false, 
						_ => throw new NotSupportedException("PropVariant VT_BOOL must be either -1 or 0"), 
					};
				case VarEnum.VT_FILETIME:
					return DateTime.FromFileTime(((long)filetime.dwHighDateTime << 32) + filetime.dwLowDateTime);
				default:
					throw new NotImplementedException("PropVariant " + dataType);
				}
			}
		}

		/// <summary>
		/// Creates a new PropVariant containing a long value
		/// </summary>
		public static PropVariant FromLong(long value)
		{
			PropVariant result = default(PropVariant);
			result.vt = 20;
			result.hVal = value;
			return result;
		}

		/// <summary>
		/// Helper method to gets blob data
		/// </summary>
		private byte[] GetBlob()
		{
			byte[] array = new byte[blobVal.Length];
			Marshal.Copy(blobVal.Data, array, 0, array.Length);
			return array;
		}

		/// <summary>
		/// Interprets a blob as an array of structs
		/// </summary>
		public T[] GetBlobAsArrayOf<T>()
		{
			int length = blobVal.Length;
			int num = Marshal.SizeOf((T)Activator.CreateInstance(typeof(T)));
			if (length % num != 0)
			{
				throw new InvalidDataException($"Blob size {length} not a multiple of struct size {num}");
			}
			int num2 = length / num;
			T[] array = new T[num2];
			for (int i = 0; i < num2; i++)
			{
				array[i] = (T)Activator.CreateInstance(typeof(T));
				Marshal.PtrToStructure(new IntPtr((long)blobVal.Data + i * num), array[i]);
			}
			return array;
		}

		/// <summary>
		/// Clears with a known pointer
		/// </summary>
		public static void Clear(IntPtr ptr)
		{
			PropVariantNative.PropVariantClear(ptr);
		}
	}

	internal class PropVariantNative
	{
		[DllImport("ole32.dll")]
		internal static extern int PropVariantClear(ref PropVariant pvar);

		[DllImport("ole32.dll")]
		internal static extern int PropVariantClear(IntPtr pvar);
	}

	/// <summary>
	/// MMDevice STGM enumeration
	/// </summary>
	public enum StorageAccessMode
	{
		/// <summary>
		/// Read-only access mode.
		/// </summary>
		Read,
		/// <summary>
		/// Write-only access mode.
		/// </summary>
		Write,
		/// <summary>
		/// Read-write access mode.
		/// </summary>
		ReadWrite
	}
}

namespace NAudio.Dmo
{
	using NAudio.Wave;
	using NAudio.CoreAudioApi.Interfaces;
	using NAudio.Utils;
	
	/// <summary>
	/// Contains the name and CLSID of a DirectX Media Object
	/// </summary>
	public class DmoDescriptor
	{
		/// <summary>
		/// Name
		/// </summary>
		public string Name { get; private set; }

		/// <summary>
		/// CLSID
		/// </summary>
		public Guid Clsid { get; private set; }

		/// <summary>
		/// Initializes a new instance of DmoDescriptor
		/// </summary>
		public DmoDescriptor(string name, Guid clsid)
		{
			Name = name;
			Clsid = clsid;
		}
	}

	/// <summary>
	/// DirectX Media Object Enumerator
	/// </summary>
	public class DmoEnumerator
	{
		/// <summary>
		/// Get audio effect names
		/// </summary>
		/// <returns>Audio effect names</returns>
		public static IEnumerable<DmoDescriptor> GetAudioEffectNames()
		{
			return GetDmos(DmoGuids.DMOCATEGORY_AUDIO_EFFECT);
		}

		/// <summary>
		/// Get audio encoder names
		/// </summary>
		/// <returns>Audio encoder names</returns>
		public static IEnumerable<DmoDescriptor> GetAudioEncoderNames()
		{
			return GetDmos(DmoGuids.DMOCATEGORY_AUDIO_ENCODER);
		}

		/// <summary>
		/// Get audio decoder names
		/// </summary>
		/// <returns>Audio decoder names</returns>
		public static IEnumerable<DmoDescriptor> GetAudioDecoderNames()
		{
			return GetDmos(DmoGuids.DMOCATEGORY_AUDIO_DECODER);
		}

		private static IEnumerable<DmoDescriptor> GetDmos(Guid category)
		{
			Marshal.ThrowExceptionForHR(DmoInterop.DMOEnum(ref category, DmoEnumFlags.None, 0, null, 0, null, out var enumDmo));
			int itemsFetched;
			do
			{
				enumDmo.Next(1, out var clsid, out var name, out itemsFetched);
				if (itemsFetched == 1)
				{
					string name2 = Marshal.PtrToStringUni(name);
					Marshal.FreeCoTaskMem(name);
					yield return new DmoDescriptor(name2, clsid);
				}
			}
			while (itemsFetched > 0);
		}
	}

	[Flags]
	internal enum DmoEnumFlags
	{
		None = 0,
		DMO_ENUMF_INCLUDE_KEYED = 1
	}

	/// <summary>
	/// DMO Guids for use with DMOEnum
	/// dmoreg.h
	/// </summary>
	internal static class DmoGuids
	{
		public static readonly Guid DMOCATEGORY_AUDIO_DECODER = new Guid("57f2db8b-e6bb-4513-9d43-dcd2a6593125");

		public static readonly Guid DMOCATEGORY_AUDIO_ENCODER = new Guid("33D9A761-90C8-11d0-BD43-00A0C911CE86");

		public static readonly Guid DMOCATEGORY_VIDEO_DECODER = new Guid("4a69b442-28be-4991-969c-b500adf5d8a8");

		public static readonly Guid DMOCATEGORY_VIDEO_ENCODER = new Guid("33D9A760-90C8-11d0-BD43-00A0C911CE86");

		public static readonly Guid DMOCATEGORY_AUDIO_EFFECT = new Guid("f3602b3f-0592-48df-a4cd-674721e7ebeb");

		public static readonly Guid DMOCATEGORY_VIDEO_EFFECT = new Guid("d990ee14-776c-4723-be46-3da2f56f10b9");

		public static readonly Guid DMOCATEGORY_AUDIO_CAPTURE_EFFECT = new Guid("f665aaba-3e09-4920-aa5f-219811148f09");
	}

	/// <summary>
	/// MediaErr.h
	/// </summary>
	internal enum DmoHResults
	{
		DMO_E_INVALIDSTREAMINDEX = -2147220991,
		DMO_E_INVALIDTYPE,
		DMO_E_TYPE_NOT_SET,
		DMO_E_NOTACCEPTING,
		DMO_E_TYPE_NOT_ACCEPTED,
		DMO_E_NO_MORE_ITEMS
	}

	/// <summary>
	/// DMO Inplace Process Flags
	/// </summary>
	[Flags]
	public enum DmoInPlaceProcessFlags
	{
		/// <summary>
		/// DMO_INPLACE_NORMAL 
		/// </summary>
		Normal = 0,
		/// <summary>
		/// DMO_INPLACE_ZERO
		/// </summary>
		Zero = 1
	}

	/// <summary>
	/// Return value when Process is executed with IMediaObjectInPlace
	/// </summary>
	public enum DmoInPlaceProcessReturn
	{
		/// <summary>
		/// Success. There is no remaining data to process.
		/// </summary>
		Normal,
		/// <summary>
		/// Success. There is still data to process.
		/// </summary>
		HasEffectTail
	}

	/// <summary>
	/// DMO Input Data Buffer Flags
	/// </summary>
	[Flags]
	public enum DmoInputDataBufferFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// DMO_INPUT_DATA_BUFFERF_SYNCPOINT
		/// </summary>
		SyncPoint = 1,
		/// <summary>
		/// DMO_INPUT_DATA_BUFFERF_TIME
		/// </summary>
		Time = 2,
		/// <summary>
		/// DMO_INPUT_DATA_BUFFERF_TIMELENGTH
		/// </summary>
		TimeLength = 4
	}

	[Flags]
	internal enum DmoInputStatusFlags
	{
		None = 0,
		DMO_INPUT_STATUSF_ACCEPT_DATA = 1
	}

	internal static class DmoInterop
	{
		[DllImport("msdmo.dll")]
		public static extern int DMOEnum([In] ref Guid guidCategory, DmoEnumFlags flags, int inTypes, [In] DmoPartialMediaType[] inTypesArray, int outTypes, [In] DmoPartialMediaType[] outTypesArray, out IEnumDmo enumDmo);

		[DllImport("msdmo.dll")]
		public static extern int MoFreeMediaType([In] ref DmoMediaType mediaType);

		[DllImport("msdmo.dll")]
		public static extern int MoInitMediaType([In][Out] ref DmoMediaType mediaType, int formatBlockBytes);

		[DllImport("msdmo.dll")]
		public static extern int DMOGetName([In] ref Guid clsidDMO, [Out] StringBuilder name);
	}

	/// <summary>
	/// http://msdn.microsoft.com/en-us/library/aa929922.aspx
	/// DMO_MEDIA_TYPE 
	/// </summary>
	public struct DmoMediaType
	{
		private Guid majortype;

		private Guid subtype;

		private bool bFixedSizeSamples;

		private bool bTemporalCompression;

		private int lSampleSize;

		private Guid formattype;

		private IntPtr pUnk;

		private int cbFormat;

		private IntPtr pbFormat;

		/// <summary>
		/// Major type
		/// </summary>
		public Guid MajorType => majortype;

		/// <summary>
		/// Major type name
		/// </summary>
		public string MajorTypeName => MediaTypes.GetMediaTypeName(majortype);

		/// <summary>
		/// Subtype
		/// </summary>
		public Guid SubType => subtype;

		/// <summary>
		/// Subtype name
		/// </summary>
		public string SubTypeName
		{
			get
			{
				if (majortype == MediaTypes.MEDIATYPE_Audio)
				{
					return AudioMediaSubtypes.GetAudioSubtypeName(subtype);
				}
				return subtype.ToString();
			}
		}

		/// <summary>
		/// Fixed size samples
		/// </summary>
		public bool FixedSizeSamples => bFixedSizeSamples;

		/// <summary>
		/// Sample size
		/// </summary>
		public int SampleSize => lSampleSize;

		/// <summary>
		/// Format type
		/// </summary>
		public Guid FormatType => formattype;

		/// <summary>
		/// Format type name
		/// </summary>
		public string FormatTypeName
		{
			get
			{
				if (formattype == DmoMediaTypeGuids.FORMAT_None)
				{
					return "None";
				}
				if (formattype == Guid.Empty)
				{
					return "Null";
				}
				if (formattype == DmoMediaTypeGuids.FORMAT_WaveFormatEx)
				{
					return "WaveFormatEx";
				}
				return FormatType.ToString();
			}
		}

		/// <summary>
		/// Gets the structure as a Wave format (if it is one)
		/// </summary>        
		public WaveFormat GetWaveFormat()
		{
			if (formattype == DmoMediaTypeGuids.FORMAT_WaveFormatEx)
			{
				return WaveFormat.MarshalFromPtr(pbFormat);
			}
			throw new InvalidOperationException("Not a WaveFormat type");
		}

		/// <summary>
		/// Sets this object up to point to a wave format
		/// </summary>
		/// <param name="waveFormat">Wave format structure</param>
		public void SetWaveFormat(WaveFormat waveFormat)
		{
			majortype = MediaTypes.MEDIATYPE_Audio;
			if (waveFormat is WaveFormatExtensible waveFormatExtensible)
			{
				subtype = waveFormatExtensible.SubFormat;
			}
			else
			{
				switch (waveFormat.Encoding)
				{
				case WaveFormatEncoding.Pcm:
					subtype = AudioMediaSubtypes.MEDIASUBTYPE_PCM;
					break;
				case WaveFormatEncoding.IeeeFloat:
					subtype = AudioMediaSubtypes.MEDIASUBTYPE_IEEE_FLOAT;
					break;
				case WaveFormatEncoding.MpegLayer3:
					subtype = AudioMediaSubtypes.WMMEDIASUBTYPE_MP3;
					break;
				default:
					throw new ArgumentException($"Not a supported encoding {waveFormat.Encoding}");
				}
			}
			bFixedSizeSamples = SubType == AudioMediaSubtypes.MEDIASUBTYPE_PCM || SubType == AudioMediaSubtypes.MEDIASUBTYPE_IEEE_FLOAT;
			formattype = DmoMediaTypeGuids.FORMAT_WaveFormatEx;
			if (cbFormat < Marshal.SizeOf(waveFormat))
			{
				throw new InvalidOperationException("Not enough memory assigned for a WaveFormat structure");
			}
			Marshal.StructureToPtr(waveFormat, pbFormat, fDeleteOld: false);
		}
	}

	internal static class DmoMediaTypeGuids
	{
		public static readonly Guid FORMAT_None = new Guid("0F6417D6-C318-11D0-A43F-00A0C9223196");

		public static readonly Guid FORMAT_VideoInfo = new Guid("05589f80-c356-11ce-bf01-00aa0055595a");

		public static readonly Guid FORMAT_VideoInfo2 = new Guid("F72A76A0-EB0A-11d0-ACE4-0000C0CC16BA");

		public static readonly Guid FORMAT_WaveFormatEx = new Guid("05589f81-c356-11ce-bf01-00aa0055595a");

		public static readonly Guid FORMAT_MPEGVideo = new Guid("05589f82-c356-11ce-bf01-00aa0055595a");

		public static readonly Guid FORMAT_MPEGStreams = new Guid("05589f83-c356-11ce-bf01-00aa0055595a");

		public static readonly Guid FORMAT_DvInfo = new Guid("05589f84-c356-11ce-bf01-00aa0055595a");

		public static readonly Guid FORMAT_525WSS = new Guid("C7ECF04D-4582-4869-9ABB-BFB523B62EDF");
	}

	/// <summary>
	/// DMO Output Data Buffer
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 8)]
	public struct DmoOutputDataBuffer : IDisposable
	{
		[MarshalAs(UnmanagedType.Interface)]
		private IMediaBuffer pBuffer;

		private DmoOutputDataBufferFlags dwStatus;

		private long rtTimestamp;

		private long referenceTimeDuration;

		/// <summary>
		/// Media Buffer
		/// </summary>
		public IMediaBuffer MediaBuffer
		{
			get
			{
				return pBuffer;
			}
			internal set
			{
				pBuffer = value;
			}
		}

		/// <summary>
		/// Length of data in buffer
		/// </summary>
		public int Length => ((MediaBuffer)pBuffer).Length;

		/// <summary>
		/// Status Flags
		/// </summary>
		public DmoOutputDataBufferFlags StatusFlags
		{
			get
			{
				return dwStatus;
			}
			internal set
			{
				dwStatus = value;
			}
		}

		/// <summary>
		/// Timestamp
		/// </summary>
		public long Timestamp
		{
			get
			{
				return rtTimestamp;
			}
			internal set
			{
				rtTimestamp = value;
			}
		}

		/// <summary>
		/// Duration
		/// </summary>
		public long Duration
		{
			get
			{
				return referenceTimeDuration;
			}
			internal set
			{
				referenceTimeDuration = value;
			}
		}

		/// <summary>
		/// Is more data available
		/// If true, ProcessOuput should be called again
		/// </summary>
		public bool MoreDataAvailable => (StatusFlags & DmoOutputDataBufferFlags.Incomplete) == DmoOutputDataBufferFlags.Incomplete;

		/// <summary>
		/// Creates a new DMO Output Data Buffer structure
		/// </summary>
		/// <param name="maxBufferSize">Maximum buffer size</param>
		public DmoOutputDataBuffer(int maxBufferSize)
		{
			pBuffer = new MediaBuffer(maxBufferSize);
			dwStatus = DmoOutputDataBufferFlags.None;
			rtTimestamp = 0L;
			referenceTimeDuration = 0L;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (pBuffer != null)
			{
				((MediaBuffer)pBuffer).Dispose();
				pBuffer = null;
				GC.SuppressFinalize(this);
			}
		}

		/// <summary>
		/// Retrives the data in this buffer
		/// </summary>
		/// <param name="data">Buffer to receive data</param>
		/// <param name="offset">Offset into buffer</param>
		public void RetrieveData(byte[] data, int offset)
		{
			((MediaBuffer)pBuffer).RetrieveData(data, offset);
		}
	}

	/// <summary>
	/// DMO Output Data Buffer Flags
	/// </summary>
	[Flags]
	public enum DmoOutputDataBufferFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// DMO_OUTPUT_DATA_BUFFERF_SYNCPOINT
		/// </summary>
		SyncPoint = 1,
		/// <summary>
		/// DMO_OUTPUT_DATA_BUFFERF_TIME
		/// </summary>
		Time = 2,
		/// <summary>
		/// DMO_OUTPUT_DATA_BUFFERF_TIMELENGTH
		/// </summary>
		TimeLength = 4,
		/// <summary>
		/// DMO_OUTPUT_DATA_BUFFERF_INCOMPLETE
		/// </summary>
		Incomplete = 0x1000000
	}

	/// <summary>
	/// DMO_PARTIAL_MEDIATYPE
	/// </summary>
	internal struct DmoPartialMediaType
	{
		private Guid type;

		private Guid subtype;

		public Guid Type
		{
			get
			{
				return type;
			}
			internal set
			{
				type = value;
			}
		}

		public Guid Subtype
		{
			get
			{
				return subtype;
			}
			internal set
			{
				subtype = value;
			}
		}
	}

	/// <summary>
	/// DMO Process Output Flags
	/// </summary>
	[Flags]
	public enum DmoProcessOutputFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// DMO_PROCESS_OUTPUT_DISCARD_WHEN_NO_BUFFER
		/// </summary>
		DiscardWhenNoBuffer = 1
	}

	/// <summary>
	/// DMO Resampler
	/// </summary>
	public class DmoResampler : IDisposable
	{
		private MediaObject mediaObject;

		private IPropertyStore propertyStoreInterface;

		private IWMResamplerProps resamplerPropsInterface;

		private ResamplerMediaComObject mediaComObject;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Creates a new Resampler based on the DMO Resampler
		/// </summary>
		public DmoResampler()
		{
			mediaComObject = new ResamplerMediaComObject();
			mediaObject = new MediaObject((IMediaObject)mediaComObject);
			propertyStoreInterface = (IPropertyStore)mediaComObject;
			resamplerPropsInterface = (IWMResamplerProps)mediaComObject;
		}

		/// <summary>
		/// Dispose code - experimental at the moment
		/// Was added trying to track down why Resampler crashes NUnit
		/// This code not currently being called by ResamplerDmoStream
		/// </summary>
		public void Dispose()
		{
			if (propertyStoreInterface != null)
			{
				Marshal.ReleaseComObject(propertyStoreInterface);
				propertyStoreInterface = null;
			}
			if (resamplerPropsInterface != null)
			{
				Marshal.ReleaseComObject(resamplerPropsInterface);
				resamplerPropsInterface = null;
			}
			if (mediaObject != null)
			{
				mediaObject.Dispose();
				mediaObject = null;
			}
			if (mediaComObject != null)
			{
				Marshal.ReleaseComObject(mediaComObject);
				mediaComObject = null;
			}
		}
	}

	[Flags]
	internal enum DmoSetTypeFlags
	{
		None = 0,
		DMO_SET_TYPEF_TEST_ONLY = 1,
		DMO_SET_TYPEF_CLEAR = 2
	}

	[ComImport]
	[Guid("2c3cd98a-2bfa-4a53-9c27-5249ba64ba0f")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IEnumDmo
	{
		int Next(int itemsToFetch, out Guid clsid, out IntPtr name, out int itemsFetched);

		int Skip(int itemsToSkip);

		int Reset();

		int Clone(out IEnumDmo enumPointer);
	}

	/// <summary>
	/// IMediaBuffer Interface
	/// </summary>
	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("59eff8b9-938c-4a26-82f2-95cb84cdc837")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IMediaBuffer
	{
		/// <summary>
		/// Set Length
		/// </summary>
		/// <param name="length">Length</param>
		/// <returns>HRESULT</returns>
		[PreserveSig]
		int SetLength(int length);

		/// <summary>
		/// Get Max Length
		/// </summary>
		/// <param name="maxLength">Max Length</param>
		/// <returns>HRESULT</returns>
		[PreserveSig]
		int GetMaxLength(out int maxLength);

		/// <summary>
		/// Get Buffer and Length
		/// </summary>
		/// <param name="bufferPointerPointer">Pointer to variable into which to write the Buffer Pointer </param>
		/// <param name="validDataLengthPointer">Pointer to variable into which to write the Valid Data Length</param>
		/// <returns>HRESULT</returns>
		[PreserveSig]
		int GetBufferAndLength(IntPtr bufferPointerPointer, IntPtr validDataLengthPointer);
	}

	/// <summary>
	/// defined in mediaobj.h
	/// </summary>
	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("d8ad0f58-5494-4102-97c5-ec798e59bcf4")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMediaObject
	{
		[PreserveSig]
		int GetStreamCount(out int inputStreams, out int outputStreams);

		[PreserveSig]
		int GetInputStreamInfo(int inputStreamIndex, out InputStreamInfoFlags flags);

		[PreserveSig]
		int GetOutputStreamInfo(int outputStreamIndex, out OutputStreamInfoFlags flags);

		[PreserveSig]
		int GetInputType(int inputStreamIndex, int typeIndex, out DmoMediaType mediaType);

		[PreserveSig]
		int GetOutputType(int outputStreamIndex, int typeIndex, out DmoMediaType mediaType);

		[PreserveSig]
		int SetInputType(int inputStreamIndex, [In] ref DmoMediaType mediaType, DmoSetTypeFlags flags);

		[PreserveSig]
		int SetOutputType(int outputStreamIndex, [In] ref DmoMediaType mediaType, DmoSetTypeFlags flags);

		[PreserveSig]
		int GetInputCurrentType(int inputStreamIndex, out DmoMediaType mediaType);

		[PreserveSig]
		int GetOutputCurrentType(int outputStreamIndex, out DmoMediaType mediaType);

		[PreserveSig]
		int GetInputSizeInfo(int inputStreamIndex, out int size, out int maxLookahead, out int alignment);

		[PreserveSig]
		int GetOutputSizeInfo(int outputStreamIndex, out int size, out int alignment);

		[PreserveSig]
		int GetInputMaxLatency(int inputStreamIndex, out long referenceTimeMaxLatency);

		[PreserveSig]
		int SetInputMaxLatency(int inputStreamIndex, long referenceTimeMaxLatency);

		[PreserveSig]
		int Flush();

		[PreserveSig]
		int Discontinuity(int inputStreamIndex);

		[PreserveSig]
		int AllocateStreamingResources();

		[PreserveSig]
		int FreeStreamingResources();

		[PreserveSig]
		int GetInputStatus(int inputStreamIndex, out DmoInputStatusFlags flags);

		[PreserveSig]
		int ProcessInput(int inputStreamIndex, [In] IMediaBuffer mediaBuffer, DmoInputDataBufferFlags flags, long referenceTimeTimestamp, long referenceTimeDuration);

		[PreserveSig]
		int ProcessOutput(DmoProcessOutputFlags flags, int outputBufferCount, [In][Out][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 1)] DmoOutputDataBuffer[] outputBuffers, out int statusReserved);

		[PreserveSig]
		int Lock(bool acquireLock);
	}

	/// <summary>
	/// defined in mediaobj.h
	/// </summary>
	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("651B9AD0-0FC7-4AA9-9538-D89931010741")]
	internal interface IMediaObjectInPlace
	{
		[PreserveSig]
		int Process([In] int size, [In] IntPtr data, [In] long refTimeStart, [In] DmoInPlaceProcessFlags dwFlags);

		[PreserveSig]
		int Clone([MarshalAs(UnmanagedType.Interface)] out IMediaObjectInPlace mediaObjectInPlace);

		[PreserveSig]
		int GetLatency(out long latencyTime);
	}

	/// <summary>
	/// defined in Medparam.h
	/// </summary>
	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("6d6cbb60-a223-44aa-842f-a2f06750be6d")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IMediaParamInfo
	{
		[PreserveSig]
		int GetParamCount(out int paramCount);

		[PreserveSig]
		int GetParamInfo(int paramIndex, ref MediaParamInfo paramInfo);

		[PreserveSig]
		int GetParamText(int paramIndex, out IntPtr paramText);

		[PreserveSig]
		int GetNumTimeFormats(out int numTimeFormats);

		[PreserveSig]
		int GetSupportedTimeFormat(int formatIndex, out Guid guidTimeFormat);

		[PreserveSig]
		int GetCurrentTimeFormat(out Guid guidTimeFormat, out int mediaTimeData);
	}

	[Flags]
	internal enum InputStreamInfoFlags
	{
		None = 0,
		DMO_INPUT_STREAMF_WHOLE_SAMPLES = 1,
		DMO_INPUT_STREAMF_SINGLE_SAMPLE_PER_BUFFER = 2,
		DMO_INPUT_STREAMF_FIXED_SAMPLE_SIZE = 4,
		DMO_INPUT_STREAMF_HOLDS_BUFFERS = 8
	}

	/// <summary>
	/// Windows Media Resampler Props
	/// wmcodecdsp.h
	/// </summary>
	[ComImport]
	[Guid("E7E9984F-F09F-4da4-903F-6E2E0EFE56B5")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IWMResamplerProps
	{
		/// <summary>
		/// Range is 1 to 60
		/// </summary>
		int SetHalfFilterLength(int outputQuality);

		/// <summary>
		///  Specifies the channel matrix.
		/// </summary>
		int SetUserChannelMtx([In] float[] channelConversionMatrix);
	}

	/// <summary>
	/// Attempting to implement the COM IMediaBuffer interface as a .NET object
	/// Not sure what will happen when I pass this to an unmanaged object
	/// </summary>
	public class MediaBuffer : IMediaBuffer, IDisposable
	{
		private IntPtr buffer;

		private int length;

		private readonly int maxLength;

		/// <summary>
		/// Length of data in the media buffer
		/// </summary>
		public int Length
		{
			get
			{
				return length;
			}
			set
			{
				if (length > maxLength)
				{
					throw new ArgumentException("Cannot be greater than maximum buffer size");
				}
				length = value;
			}
		}

		/// <summary>
		/// Creates a new Media Buffer
		/// </summary>
		/// <param name="maxLength">Maximum length in bytes</param>
		public MediaBuffer(int maxLength)
		{
			buffer = Marshal.AllocCoTaskMem(maxLength);
			this.maxLength = maxLength;
		}

		/// <summary>
		/// Dispose and free memory for buffer
		/// </summary>
		public void Dispose()
		{
			if (buffer != IntPtr.Zero)
			{
				Marshal.FreeCoTaskMem(buffer);
				buffer = IntPtr.Zero;
				GC.SuppressFinalize(this);
			}
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~MediaBuffer()
		{
			Dispose();
		}

		/// <summary>
		/// Set length of valid data in the buffer
		/// </summary>
		/// <param name="length">length</param>
		/// <returns>HRESULT</returns>
		int IMediaBuffer.SetLength(int length)
		{
			if (length > maxLength)
			{
				return -2147483645;
			}
			this.length = length;
			return 0;
		}

		/// <summary>
		/// Gets the maximum length of the buffer
		/// </summary>
		/// <param name="maxLength">Max length (output parameter)</param>
		/// <returns>HRESULT</returns>
		int IMediaBuffer.GetMaxLength(out int maxLength)
		{
			maxLength = this.maxLength;
			return 0;
		}

		/// <summary>
		/// Gets buffer and / or length
		/// </summary>
		/// <param name="bufferPointerPointer">Pointer to variable into which buffer pointer should be written</param>
		/// <param name="validDataLengthPointer">Pointer to variable into which valid data length should be written</param>
		/// <returns>HRESULT</returns>
		int IMediaBuffer.GetBufferAndLength(IntPtr bufferPointerPointer, IntPtr validDataLengthPointer)
		{
			if (bufferPointerPointer != IntPtr.Zero)
			{
				Marshal.WriteIntPtr(bufferPointerPointer, buffer);
			}
			if (validDataLengthPointer != IntPtr.Zero)
			{
				Marshal.WriteInt32(validDataLengthPointer, length);
			}
			return 0;
		}

		/// <summary>
		/// Loads data into this buffer
		/// </summary>
		/// <param name="data">Data to load</param>
		/// <param name="bytes">Number of bytes to load</param>
		public void LoadData(byte[] data, int bytes)
		{
			Length = bytes;
			Marshal.Copy(data, 0, buffer, bytes);
		}

		/// <summary>
		/// Retrieves the data in the output buffer
		/// </summary>
		/// <param name="data">buffer to retrieve into</param>
		/// <param name="offset">offset within that buffer</param>
		public void RetrieveData(byte[] data, int offset)
		{
			Marshal.Copy(buffer, data, offset, Length);
		}
	}

	/// <summary>
	/// Media Object
	/// </summary>
	public class MediaObject : IDisposable
	{
		private IMediaObject mediaObject;

		private readonly int inputStreams;

		private readonly int outputStreams;

		/// <summary>
		/// Number of input streams
		/// </summary>
		public int InputStreamCount => inputStreams;

		/// <summary>
		/// Number of output streams
		/// </summary>
		public int OutputStreamCount => outputStreams;

		/// <summary>
		/// Creates a new Media Object
		/// </summary>
		/// <param name="mediaObject">Media Object COM interface</param>
		internal MediaObject(IMediaObject mediaObject)
		{
			this.mediaObject = mediaObject;
			mediaObject.GetStreamCount(out inputStreams, out outputStreams);
		}

		/// <summary>
		/// Gets the input media type for the specified input stream
		/// </summary>
		/// <param name="inputStream">Input stream index</param>
		/// <param name="inputTypeIndex">Input type index</param>
		/// <returns>DMO Media Type or null if there are no more input types</returns>
		public DmoMediaType? GetInputType(int inputStream, int inputTypeIndex)
		{
			try
			{
				if (mediaObject.GetInputType(inputStream, inputTypeIndex, out var mediaType) == 0)
				{
					DmoInterop.MoFreeMediaType(ref mediaType);
					return mediaType;
				}
			}
			catch (COMException exception)
			{
				if (exception.GetHResult() != -2147220986)
				{
					throw;
				}
			}
			return null;
		}

		/// <summary>
		/// Gets the DMO Media Output type
		/// </summary>
		/// <param name="outputStream">The output stream</param>
		/// <param name="outputTypeIndex">Output type index</param>
		/// <returns>DMO Media Type or null if no more available</returns>
		public DmoMediaType? GetOutputType(int outputStream, int outputTypeIndex)
		{
			try
			{
				if (mediaObject.GetOutputType(outputStream, outputTypeIndex, out var mediaType) == 0)
				{
					DmoInterop.MoFreeMediaType(ref mediaType);
					return mediaType;
				}
			}
			catch (COMException exception)
			{
				if (exception.GetHResult() != -2147220986)
				{
					throw;
				}
			}
			return null;
		}

		/// <summary>
		/// retrieves the media type that was set for an output stream, if any
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <returns>DMO Media Type or null if no more available</returns>
		public DmoMediaType GetOutputCurrentType(int outputStreamIndex)
		{
			DmoMediaType mediaType;
			int outputCurrentType = mediaObject.GetOutputCurrentType(outputStreamIndex, out mediaType);
			switch (outputCurrentType)
			{
			case 0:
				DmoInterop.MoFreeMediaType(ref mediaType);
				return mediaType;
			case -2147220989:
				throw new InvalidOperationException("Media type was not set.");
			default:
				throw Marshal.GetExceptionForHR(outputCurrentType);
			}
		}

		/// <summary>
		/// Enumerates the supported input types
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <returns>Enumeration of input types</returns>
		public IEnumerable<DmoMediaType> GetInputTypes(int inputStreamIndex)
		{
			int typeIndex = 0;
			while (true)
			{
				DmoMediaType? inputType;
				DmoMediaType? dmoMediaType = (inputType = GetInputType(inputStreamIndex, typeIndex));
				if (dmoMediaType.HasValue)
				{
					yield return inputType.Value;
					typeIndex++;
					continue;
				}
				break;
			}
		}

		/// <summary>
		/// Enumerates the output types
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <returns>Enumeration of supported output types</returns>
		public IEnumerable<DmoMediaType> GetOutputTypes(int outputStreamIndex)
		{
			int typeIndex = 0;
			while (true)
			{
				DmoMediaType? outputType;
				DmoMediaType? dmoMediaType = (outputType = GetOutputType(outputStreamIndex, typeIndex));
				if (dmoMediaType.HasValue)
				{
					yield return outputType.Value;
					typeIndex++;
					continue;
				}
				break;
			}
		}

		/// <summary>
		/// Querys whether a specified input type is supported
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <param name="mediaType">Media type to check</param>
		/// <returns>true if supports</returns>
		public bool SupportsInputType(int inputStreamIndex, DmoMediaType mediaType)
		{
			return SetInputType(inputStreamIndex, mediaType, DmoSetTypeFlags.DMO_SET_TYPEF_TEST_ONLY);
		}

		/// <summary>
		/// Sets the input type helper method
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <param name="mediaType">Media type</param>
		/// <param name="flags">Flags (can be used to test rather than set)</param>
		private bool SetInputType(int inputStreamIndex, DmoMediaType mediaType, DmoSetTypeFlags flags)
		{
			switch (mediaObject.SetInputType(inputStreamIndex, ref mediaType, flags))
			{
			case -2147220991:
				throw new ArgumentException("Invalid stream index");
			default:
				_ = -2147220987;
				return false;
			case 0:
				return true;
			}
		}

		/// <summary>
		/// Sets the input type
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <param name="mediaType">Media Type</param>
		public void SetInputType(int inputStreamIndex, DmoMediaType mediaType)
		{
			if (!SetInputType(inputStreamIndex, mediaType, DmoSetTypeFlags.None))
			{
				throw new ArgumentException("Media Type not supported");
			}
		}

		/// <summary>
		/// Sets the input type to the specified Wave format
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <param name="waveFormat">Wave format</param>
		public void SetInputWaveFormat(int inputStreamIndex, WaveFormat waveFormat)
		{
			DmoMediaType mediaType = CreateDmoMediaTypeForWaveFormat(waveFormat);
			bool num = SetInputType(inputStreamIndex, mediaType, DmoSetTypeFlags.None);
			DmoInterop.MoFreeMediaType(ref mediaType);
			if (!num)
			{
				throw new ArgumentException("Media Type not supported");
			}
		}

		/// <summary>
		/// Requests whether the specified Wave format is supported as an input
		/// </summary>
		/// <param name="inputStreamIndex">Input stream index</param>
		/// <param name="waveFormat">Wave format</param>
		/// <returns>true if supported</returns>
		public bool SupportsInputWaveFormat(int inputStreamIndex, WaveFormat waveFormat)
		{
			DmoMediaType mediaType = CreateDmoMediaTypeForWaveFormat(waveFormat);
			bool result = SetInputType(inputStreamIndex, mediaType, DmoSetTypeFlags.DMO_SET_TYPEF_TEST_ONLY);
			DmoInterop.MoFreeMediaType(ref mediaType);
			return result;
		}

		/// <summary>
		/// Helper function to make a DMO Media Type to represent a particular WaveFormat
		/// </summary>
		private DmoMediaType CreateDmoMediaTypeForWaveFormat(WaveFormat waveFormat)
		{
			DmoMediaType mediaType = default(DmoMediaType);
			int formatBlockBytes = Marshal.SizeOf(waveFormat);
			DmoInterop.MoInitMediaType(ref mediaType, formatBlockBytes);
			mediaType.SetWaveFormat(waveFormat);
			return mediaType;
		}

		/// <summary>
		/// Checks if a specified output type is supported
		/// n.b. you may need to set the input type first
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <param name="mediaType">Media type</param>
		/// <returns>True if supported</returns>
		public bool SupportsOutputType(int outputStreamIndex, DmoMediaType mediaType)
		{
			return SetOutputType(outputStreamIndex, mediaType, DmoSetTypeFlags.DMO_SET_TYPEF_TEST_ONLY);
		}

		/// <summary>
		/// Tests if the specified Wave Format is supported for output
		/// n.b. may need to set the input type first
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <param name="waveFormat">Wave format</param>
		/// <returns>True if supported</returns>
		public bool SupportsOutputWaveFormat(int outputStreamIndex, WaveFormat waveFormat)
		{
			DmoMediaType mediaType = CreateDmoMediaTypeForWaveFormat(waveFormat);
			bool result = SetOutputType(outputStreamIndex, mediaType, DmoSetTypeFlags.DMO_SET_TYPEF_TEST_ONLY);
			DmoInterop.MoFreeMediaType(ref mediaType);
			return result;
		}

		/// <summary>
		/// Helper method to call SetOutputType
		/// </summary>
		private bool SetOutputType(int outputStreamIndex, DmoMediaType mediaType, DmoSetTypeFlags flags)
		{
			int num = mediaObject.SetOutputType(outputStreamIndex, ref mediaType, flags);
			return num switch
			{
				-2147220987 => false, 
				0 => true, 
				_ => throw Marshal.GetExceptionForHR(num), 
			};
		}

		/// <summary>
		/// Sets the output type
		/// n.b. may need to set the input type first
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <param name="mediaType">Media type to set</param>
		public void SetOutputType(int outputStreamIndex, DmoMediaType mediaType)
		{
			if (!SetOutputType(outputStreamIndex, mediaType, DmoSetTypeFlags.None))
			{
				throw new ArgumentException("Media Type not supported");
			}
		}

		/// <summary>
		/// Set output type to the specified wave format
		/// n.b. may need to set input type first
		/// </summary>
		/// <param name="outputStreamIndex">Output stream index</param>
		/// <param name="waveFormat">Wave format</param>
		public void SetOutputWaveFormat(int outputStreamIndex, WaveFormat waveFormat)
		{
			DmoMediaType mediaType = CreateDmoMediaTypeForWaveFormat(waveFormat);
			bool num = SetOutputType(outputStreamIndex, mediaType, DmoSetTypeFlags.None);
			DmoInterop.MoFreeMediaType(ref mediaType);
			if (!num)
			{
				throw new ArgumentException("Media Type not supported");
			}
		}

		/// <summary>
		/// Get Input Size Info
		/// </summary>
		/// <param name="inputStreamIndex">Input Stream Index</param>
		/// <returns>Input Size Info</returns>
		public MediaObjectSizeInfo GetInputSizeInfo(int inputStreamIndex)
		{
			Marshal.ThrowExceptionForHR(mediaObject.GetInputSizeInfo(inputStreamIndex, out var size, out var maxLookahead, out var alignment));
			return new MediaObjectSizeInfo(size, maxLookahead, alignment);
		}

		/// <summary>
		/// Get Output Size Info
		/// </summary>
		/// <param name="outputStreamIndex">Output Stream Index</param>
		/// <returns>Output Size Info</returns>
		public MediaObjectSizeInfo GetOutputSizeInfo(int outputStreamIndex)
		{
			Marshal.ThrowExceptionForHR(mediaObject.GetOutputSizeInfo(outputStreamIndex, out var size, out var alignment));
			return new MediaObjectSizeInfo(size, 0, alignment);
		}

		/// <summary>
		/// Process Input
		/// </summary>
		/// <param name="inputStreamIndex">Input Stream index</param>
		/// <param name="mediaBuffer">Media Buffer</param>
		/// <param name="flags">Flags</param>
		/// <param name="timestamp">Timestamp</param>
		/// <param name="duration">Duration</param>
		public void ProcessInput(int inputStreamIndex, IMediaBuffer mediaBuffer, DmoInputDataBufferFlags flags, long timestamp, long duration)
		{
			Marshal.ThrowExceptionForHR(mediaObject.ProcessInput(inputStreamIndex, mediaBuffer, flags, timestamp, duration));
		}

		/// <summary>
		/// Process Output
		/// </summary>
		/// <param name="flags">Flags</param>
		/// <param name="outputBufferCount">Output buffer count</param>
		/// <param name="outputBuffers">Output buffers</param>
		public void ProcessOutput(DmoProcessOutputFlags flags, int outputBufferCount, DmoOutputDataBuffer[] outputBuffers)
		{
			Marshal.ThrowExceptionForHR(mediaObject.ProcessOutput(flags, outputBufferCount, outputBuffers, out var _));
		}

		/// <summary>
		/// Gives the DMO a chance to allocate any resources needed for streaming
		/// </summary>
		public void AllocateStreamingResources()
		{
			Marshal.ThrowExceptionForHR(mediaObject.AllocateStreamingResources());
		}

		/// <summary>
		/// Tells the DMO to free any resources needed for streaming
		/// </summary>
		public void FreeStreamingResources()
		{
			Marshal.ThrowExceptionForHR(mediaObject.FreeStreamingResources());
		}

		/// <summary>
		/// Gets maximum input latency
		/// </summary>
		/// <param name="inputStreamIndex">input stream index</param>
		/// <returns>Maximum input latency as a ref-time</returns>
		public long GetInputMaxLatency(int inputStreamIndex)
		{
			Marshal.ThrowExceptionForHR(mediaObject.GetInputMaxLatency(inputStreamIndex, out var referenceTimeMaxLatency));
			return referenceTimeMaxLatency;
		}

		/// <summary>
		/// Flushes all buffered data
		/// </summary>
		public void Flush()
		{
			Marshal.ThrowExceptionForHR(mediaObject.Flush());
		}

		/// <summary>
		/// Report a discontinuity on the specified input stream
		/// </summary>
		/// <param name="inputStreamIndex">Input Stream index</param>
		public void Discontinuity(int inputStreamIndex)
		{
			Marshal.ThrowExceptionForHR(mediaObject.Discontinuity(inputStreamIndex));
		}

		/// <summary>
		/// Is this input stream accepting data?
		/// </summary>
		/// <param name="inputStreamIndex">Input Stream index</param>
		/// <returns>true if accepting data</returns>
		public bool IsAcceptingData(int inputStreamIndex)
		{
			Marshal.ThrowExceptionForHR(mediaObject.GetInputStatus(inputStreamIndex, out var flags));
			return (flags & DmoInputStatusFlags.DMO_INPUT_STATUSF_ACCEPT_DATA) == DmoInputStatusFlags.DMO_INPUT_STATUSF_ACCEPT_DATA;
		}

		/// <summary>
		/// Experimental code, not currently being called
		/// Not sure if it is necessary anyway
		/// </summary>
		public void Dispose()
		{
			if (mediaObject != null)
			{
				Marshal.ReleaseComObject(mediaObject);
				mediaObject = null;
			}
		}
	}

	/// <summary>
	/// Media Object InPlace
	/// </summary>
	public class MediaObjectInPlace : IDisposable
	{
		private IMediaObjectInPlace mediaObjectInPlace;

		/// <summary>
		/// Creates a new Media Object InPlace
		/// </summary>
		/// <param name="mediaObjectInPlace">Media Object InPlace COM Interface</param>
		internal MediaObjectInPlace(IMediaObjectInPlace mediaObjectInPlace)
		{
			this.mediaObjectInPlace = mediaObjectInPlace;
		}

		/// <summary>
		/// Processes a block of data.
		/// The application supplies a pointer to a block of input data. The DMO processes the data in place.
		/// </summary>
		/// <param name="size">Size of the data, in bytes.</param>
		/// <param name="offset">offset into buffer</param>
		/// <param name="data">In/Out Data Buffer</param>
		/// <param name="timeStart">Start time of the data.</param>
		/// <param name="inPlaceFlag">DmoInplaceProcessFlags</param>
		/// <returns>Return value when Process is executed with IMediaObjectInPlace</returns>
		public DmoInPlaceProcessReturn Process(int size, int offset, byte[] data, long timeStart, DmoInPlaceProcessFlags inPlaceFlag)
		{
			IntPtr intPtr = Marshal.AllocHGlobal(size);
			Marshal.Copy(data, offset, intPtr, size);
			int num = mediaObjectInPlace.Process(size, intPtr, timeStart, inPlaceFlag);
			Marshal.ThrowExceptionForHR(num);
			Marshal.Copy(intPtr, data, offset, size);
			Marshal.FreeHGlobal(intPtr);
			return (DmoInPlaceProcessReturn)num;
		}

		/// <summary>
		/// Creates a copy of the DMO in its current state.
		/// </summary>
		/// <returns>Copyed MediaObjectInPlace</returns>
		public MediaObjectInPlace Clone()
		{
			Marshal.ThrowExceptionForHR(this.mediaObjectInPlace.Clone(out var mediaObjectInPlace));
			return new MediaObjectInPlace(mediaObjectInPlace);
		}

		/// <summary>
		/// Retrieves the latency introduced by this DMO.
		/// </summary>
		/// <returns>The latency, in 100-nanosecond units</returns>
		public long GetLatency()
		{
			Marshal.ThrowExceptionForHR(mediaObjectInPlace.GetLatency(out var latencyTime));
			return latencyTime;
		}

		/// <summary>
		/// Get Media Object
		/// </summary>
		/// <returns>Media Object</returns>
		public MediaObject GetMediaObject()
		{
			return new MediaObject((IMediaObject)mediaObjectInPlace);
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			if (mediaObjectInPlace != null)
			{
				Marshal.ReleaseComObject(mediaObjectInPlace);
				mediaObjectInPlace = null;
			}
		}
	}

	/// <summary>
	/// Media Object Size Info
	/// </summary>
	public class MediaObjectSizeInfo
	{
		/// <summary>
		/// Minimum Buffer Size, in bytes
		/// </summary>
		public int Size { get; private set; }

		/// <summary>
		/// Max Lookahead
		/// </summary>
		public int MaxLookahead { get; }

		/// <summary>
		/// Alignment
		/// </summary>
		public int Alignment { get; }

		/// <summary>
		/// Media Object Size Info
		/// </summary>
		public MediaObjectSizeInfo(int size, int maxLookahead, int alignment)
		{
			Size = size;
			MaxLookahead = maxLookahead;
			Alignment = alignment;
		}

		/// <summary>
		/// ToString
		/// </summary>        
		public override string ToString()
		{
			return $"Size: {Size}, Alignment {Alignment}, MaxLookahead {MaxLookahead}";
		}
	}

	/// <summary>
	/// MP_CURVE_TYPE
	/// </summary>
	[Flags]
	internal enum MediaParamCurveType
	{
		MP_CURVE_JUMP = 1,
		MP_CURVE_LINEAR = 2,
		MP_CURVE_SQUARE = 4,
		MP_CURVE_INVSQUARE = 8,
		MP_CURVE_SINE = 0x10
	}

	/// <summary>
	/// MP_PARAMINFO
	/// </summary>
	internal struct MediaParamInfo
	{
		public MediaParamType mpType;

		public MediaParamCurveType mopCaps;

		public float mpdMinValue;

		public float mpdMaxValue;

		public float mpdNeutralValue;

		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		public string szUnitText;

		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		public string szLabel;
	}

	/// <summary>
	/// MP_TYPE
	/// </summary>
	internal enum MediaParamType
	{
		/// <summary>
		/// MPT_INT
		/// </summary>
		Int,
		/// <summary>
		/// MPT_FLOAT
		/// </summary>
		Float,
		/// <summary>
		/// MPT_BOOL
		/// </summary>
		Bool,
		/// <summary>
		/// MPT_ENUM
		/// </summary>
		Enum,
		/// <summary>
		/// MPT_MAX
		/// </summary>
		Max
	}

	/// <summary>
	/// uuids.h, ksuuids.h
	/// </summary>
	internal static class MediaTypes
	{
		public static readonly Guid MEDIATYPE_AnalogAudio = new Guid("0482DEE1-7817-11cf-8a03-00aa006ecb65");

		public static readonly Guid MEDIATYPE_AnalogVideo = new Guid("0482DDE1-7817-11cf-8A03-00AA006ECB65");

		public static readonly Guid MEDIATYPE_Audio = new Guid("73647561-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_AUXLine21Data = new Guid("670AEA80-3A82-11d0-B79B-00AA003767A7");

		public static readonly Guid MEDIATYPE_File = new Guid("656c6966-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_Interleaved = new Guid("73766169-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_Midi = new Guid("7364696D-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_ScriptCommand = new Guid("73636d64-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_Stream = new Guid("e436eb83-524f-11ce-9f53-0020af0ba770");

		public static readonly Guid MEDIATYPE_Text = new Guid("73747874-0000-0010-8000-00AA00389B71");

		public static readonly Guid MEDIATYPE_Timecode = new Guid("0482DEE3-7817-11cf-8a03-00aa006ecb65");

		public static readonly Guid MEDIATYPE_Video = new Guid("73646976-0000-0010-8000-00AA00389B71");

		public static readonly Guid[] MajorTypes = new Guid[12]
		{
			MEDIATYPE_AnalogAudio, MEDIATYPE_AnalogVideo, MEDIATYPE_Audio, MEDIATYPE_AUXLine21Data, MEDIATYPE_File, MEDIATYPE_Interleaved, MEDIATYPE_Midi, MEDIATYPE_ScriptCommand, MEDIATYPE_Stream, MEDIATYPE_Text,
			MEDIATYPE_Timecode, MEDIATYPE_Video
		};

		public static readonly string[] MajorTypeNames = new string[12]
		{
			"Analog Audio", "Analog Video", "Audio", "AUXLine21Data", "File", "Interleaved", "Midi", "ScriptCommand", "Stream", "Text",
			"Timecode", "Video"
		};

		public static string GetMediaTypeName(Guid majorType)
		{
			for (int i = 0; i < MajorTypes.Length; i++)
			{
				if (majorType == MajorTypes[i])
				{
					return MajorTypeNames[i];
				}
			}
			throw new ArgumentException("Major Type not found");
		}
	}

	[Flags]
	internal enum OutputStreamInfoFlags
	{
		DMO_OUTPUT_STREAMF_WHOLE_SAMPLES = 1,
		DMO_OUTPUT_STREAMF_SINGLE_SAMPLE_PER_BUFFER = 2,
		DMO_OUTPUT_STREAMF_FIXED_SAMPLE_SIZE = 4,
		DMO_OUTPUT_STREAMF_DISCARDABLE = 8,
		DMO_OUTPUT_STREAMF_OPTIONAL = 0x10
	}

	/// <summary>
	/// From wmcodecsdp.h
	/// Implements:
	/// - IMediaObject 
	/// - IMFTransform (Media foundation - we will leave this for now as there is loads of MF stuff)
	/// - IPropertyStore 
	/// - IWMResamplerProps 
	/// Can resample PCM or IEEE
	/// </summary>
	[ComImport]
	[Guid("f447b69e-1884-4a7e-8055-346f74d6edb3")]
	internal class ResamplerMediaComObject { }

	/// <summary>
	/// Windows Media MP3 Decoder (as a DMO)
	/// WORK IN PROGRESS - DO NOT USE!
	/// </summary>
	public class WindowsMediaMp3Decoder : IDisposable
	{
		private MediaObject mediaObject;

		private IPropertyStore propertyStoreInterface;

		private WindowsMediaMp3DecoderComObject mediaComObject;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Creates a new Resampler based on the DMO Resampler
		/// </summary>
		public WindowsMediaMp3Decoder()
		{
			mediaComObject = new WindowsMediaMp3DecoderComObject();
			mediaObject = new MediaObject((IMediaObject)mediaComObject);
			propertyStoreInterface = (IPropertyStore)mediaComObject;
		}

		/// <summary>
		/// Dispose code - experimental at the moment
		/// Was added trying to track down why Resampler crashes NUnit
		/// This code not currently being called by ResamplerDmoStream
		/// </summary>
		public void Dispose()
		{
			if (propertyStoreInterface != null)
			{
				Marshal.ReleaseComObject(propertyStoreInterface);
				propertyStoreInterface = null;
			}
			if (mediaObject != null)
			{
				mediaObject.Dispose();
				mediaObject = null;
			}
			if (mediaComObject != null)
			{
				Marshal.ReleaseComObject(mediaComObject);
				mediaComObject = null;
			}
		}
	}

	/// <summary>
	/// implements IMediaObject  (DirectX Media Object)
	/// implements IMFTransform (Media Foundation Transform)
	/// On Windows XP, it is always an MM (if present at all)
	/// </summary>
	[ComImport]
	[Guid("bbeea841-0a63-4f52-a7ab-a9b3a84ed38a")]
	internal class WindowsMediaMp3DecoderComObject { }
}

namespace NAudio.Dmo.Effect
{
	/// <summary>
	/// Chorus Phase
	/// </summary>
	public enum ChorusPhase
	{
		/// <summary>
		/// DSFXCHORUS_PHASE_NEG_180
		/// </summary>
		Neg180,
		/// <summary>
		/// DSFXCHORUS_PHASE_NEG_90
		/// </summary>
		Neg90,
		/// <summary>
		/// DSFXCHORUS_PHASE_ZERO
		/// </summary>
		Zero,
		/// <summary>
		/// DSFXCHORUS_PHASE_90
		/// </summary>
		Pos90,
		/// <summary>
		/// DSFXCHORUS_PHASE_180
		/// </summary>
		Pos180
	}

	/// <summary>
	/// Chorus Wave Form
	/// </summary>
	public enum ChorusWaveForm
	{
		/// <summary>
		/// DSFXCHORUS_WAVE_TRIANGLE
		/// </summary>
		Triangle,
		/// <summary>
		/// DSFXCHORUS_WAVE_SIN
		/// </summary>
		Sin
	}

	/// <summary>
	/// DMO Chorus Effect
	/// </summary>
	public class DmoChorus : IDmoEffector<DmoChorus.Params>, IDisposable
	{
		/// <summary>
		/// DMO Chorus Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXCHORUS_WETDRYMIX_MIN
			/// </summary>
			public const float WetDryMixMin = 0f;

			/// <summary>
			/// DSFXCHORUS_WETDRYMIX_MAX
			/// </summary>
			public const float WetDryMixMax = 100f;

			/// <summary>
			/// DSFXCHORUS_WETDRYMIX_DEFAULT
			/// </summary>
			public const float WetDrtMixDefault = 50f;

			/// <summary>
			/// DSFXCHORUS_DEPTH_MIN
			/// </summary>
			public const float DepthMin = 0f;

			/// <summary>
			/// DSFXCHORUS_DEPTH_MAX
			/// </summary>
			public const float DepthMax = 100f;

			/// <summary>
			/// DSFXCHORUS_DEPTH_DEFAULT
			/// </summary>
			public const float DepthDefault = 10f;

			/// <summary>
			/// DSFXCHORUS_FEEDBACK_MIN
			/// </summary>
			public const float FeedBackMin = -99f;

			/// <summary>
			/// DSFXCHORUS_FEEDBACK_MAX
			/// </summary>
			public const float FeedBackMax = 99f;

			/// <summary>
			/// DSFXCHORUS_FEEDBACK_DEFAULT
			/// </summary>
			public const float FeedBaclDefault = 25f;

			/// <summary>
			/// DSFXCHORUS_FREQUENCY_MIN
			/// </summary>
			public const float FrequencyMin = 0f;

			/// <summary>
			/// DSFXCHORUS_FREQUENCY_MAX
			/// </summary>
			public const float FrequencyMax = 10f;

			/// <summary>
			/// DSFXCHORUS_FREQUENCY_DEFAULT
			/// </summary>
			public const float FrequencyDefault = 1.1f;

			/// <summary>
			/// DSFXCHORUS_WAVE_DEFAULT
			/// </summary>
			public const ChorusWaveForm WaveFormDefault = ChorusWaveForm.Sin;

			/// <summary>
			/// DSFXCHORUS_DELAY_MIN
			/// </summary>
			public const float DelayMin = 0f;

			/// <summary>
			/// DSFXCHORUS_DELAY_MAX
			/// </summary>
			public const float DelayMax = 20f;

			/// <summary>
			/// DSFXCHORUS_DELAY_DEFAULT
			/// </summary>
			public const float DelayDefault = 16f;

			/// <summary>
			/// DSFXCHORUS_PHASE_DEFAULT
			/// </summary>
			public const ChorusPhase PhaseDefault = ChorusPhase.Pos90;

			private readonly IDirectSoundFXChorus fxChorus;

			/// <summary>
			/// Ratio of wet (processed) signal to dry (unprocessed) signal.
			/// </summary>
			public float WetDryMix
			{
				get
				{
					return GetAllParameters().WetDryMix;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					allParameters.WetDryMix = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage by which the delay time is modulated by the low-frequency oscillator,
			/// in hundredths of a percentage point.
			/// </summary>
			public float Depth
			{
				get
				{
					return GetAllParameters().Depth;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					allParameters.Depth = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage of output signal to feed back into the effect's input.
			/// </summary>
			public float FeedBack
			{
				get
				{
					return GetAllParameters().FeedBack;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					allParameters.FeedBack = Math.Max(Math.Min(99f, value), -99f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Frequency of the LFO.
			/// </summary>
			public float Frequency
			{
				get
				{
					return GetAllParameters().Frequency;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					allParameters.Frequency = Math.Max(Math.Min(10f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Waveform shape of the LFO.
			/// </summary>
			public ChorusWaveForm WaveForm
			{
				get
				{
					return GetAllParameters().WaveForm;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(ChorusWaveForm), value))
					{
						allParameters.WaveForm = value;
					}
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Number of milliseconds the input is delayed before it is played back.
			/// </summary>
			public float Delay
			{
				get
				{
					return GetAllParameters().Delay;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					allParameters.Delay = Math.Max(Math.Min(20f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Phase differential between left and right LFOs.
			/// </summary>
			public ChorusPhase Phase
			{
				get
				{
					return GetAllParameters().Phase;
				}
				set
				{
					DsFxChorus allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(ChorusPhase), value))
					{
						allParameters.Phase = value;
					}
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXChorus dsFxObject)
			{
				fxChorus = dsFxObject;
			}

			private void SetAllParameters(DsFxChorus param)
			{
				Marshal.ThrowExceptionForHR(fxChorus.SetAllParameters(ref param));
			}

			private DsFxChorus GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxChorus.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Chorus
		/// </summary>
		public DmoChorus()
		{
			Guid guidChorus = new Guid("EFE6629C-81F7-4281-BD91-C9D604A95AF6");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidChorus));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXChorus)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Compressor Effect
	/// </summary>
	public class DmoCompressor : IDmoEffector<DmoCompressor.Params>, IDisposable
	{
		/// <summary>
		/// DMO Compressor Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXCOMPRESSOR_GAIN_MIN
			/// </summary>
			public const float GainMin = -60f;

			/// <summary>
			/// DSFXCOMPRESSOR_GAIN_MAX
			/// </summary>
			public const float GainMax = 60f;

			/// <summary>
			/// DSFXCOMPRESSOR_GAIN_DEFAULT
			/// </summary>
			public const float GainDefault = 0f;

			/// <summary>
			/// DSFXCOMPRESSOR_ATTACK_MIN
			/// </summary>
			public const float AttackMin = 0.01f;

			/// <summary>
			/// DSFXCOMPRESSOR_ATTACK_MAX
			/// </summary>
			public const float AttackMax = 500f;

			/// <summary>
			/// DSFXCOMPRESSOR_ATTACK_DEFAULT
			/// </summary>
			public const float AttackDefault = 10f;

			/// <summary>
			/// DSFXCOMPRESSOR_RELEASE_MIN
			/// </summary>
			public const float ReleaseMin = 50f;

			/// <summary>
			/// DSFXCOMPRESSOR_RELEASE_MAX
			/// </summary>
			public const float ReleaseMax = 3000f;

			/// <summary>
			/// DSFXCOMPRESSOR_RELEASE_DEFAULT
			/// </summary>
			public const float ReleaseDefault = 200f;

			/// <summary>
			/// DSFXCOMPRESSOR_THRESHOLD_MIN
			/// </summary>
			public const float ThresholdMin = -60f;

			/// <summary>
			/// DSFXCOMPRESSOR_THRESHOLD_MAX
			/// </summary>
			public const float ThresholdMax = 0f;

			/// <summary>
			/// DSFXCOMPRESSOR_THRESHOLD_DEFAULT
			/// </summary>
			public const float TjresholdDefault = -20f;

			/// <summary>
			/// DSFXCOMPRESSOR_RATIO_MIN
			/// </summary>
			public const float RatioMin = 1f;

			/// <summary>
			/// DSFXCOMPRESSOR_RATIO_MAX
			/// </summary>
			public const float RatioMax = 100f;

			/// <summary>
			/// DSFXCOMPRESSOR_RATIO_DEFAULT
			/// </summary>
			public const float RatioDefault = 3f;

			/// <summary>
			/// DSFXCOMPRESSOR_PREDELAY_MIN
			/// </summary>
			public const float PreDelayMin = 0f;

			/// <summary>
			/// DSFXCOMPRESSOR_PREDELAY_MAX
			/// </summary>
			public const float PreDelayMax = 4f;

			/// <summary>
			/// DSFXCOMPRESSOR_PREDELAY_DEFAULT
			/// </summary>
			public const float PreDelayDefault = 4f;

			private readonly IDirectSoundFXCompressor fxCompressor;

			/// <summary>
			/// Output gain of signal after compression.
			/// </summary>
			public float Gain
			{
				get
				{
					return GetAllParameters().Gain;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.Gain = Math.Max(Math.Min(60f, value), -60f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Time before compression reaches its full value.
			/// </summary>
			public float Attack
			{
				get
				{
					return GetAllParameters().Attack;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.Attack = Math.Max(Math.Min(500f, value), 0.01f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Speed at which compression is stopped after input drops below Threshold.
			/// </summary>
			public float Release
			{
				get
				{
					return GetAllParameters().Release;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.Release = Math.Max(Math.Min(3000f, value), 50f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Point at which compression begins, in decibels.
			/// </summary>
			public float Threshold
			{
				get
				{
					return GetAllParameters().Threshold;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.Threshold = Math.Max(Math.Min(0f, value), -60f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Compression ratio
			/// </summary>
			public float Ratio
			{
				get
				{
					return GetAllParameters().Ratio;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.Ratio = Math.Max(Math.Min(100f, value), 1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Time after Threshold is reached before attack phase is started, in milliseconds.
			/// </summary>
			public float PreDelay
			{
				get
				{
					return GetAllParameters().PreDelay;
				}
				set
				{
					DsFxCompressor allParameters = GetAllParameters();
					allParameters.PreDelay = Math.Max(Math.Min(4f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXCompressor dsFxObject)
			{
				fxCompressor = dsFxObject;
			}

			private void SetAllParameters(DsFxCompressor param)
			{
				Marshal.ThrowExceptionForHR(fxCompressor.SetAllParameters(ref param));
			}

			private DsFxCompressor GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxCompressor.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Compressor
		/// </summary>
		public DmoCompressor()
		{
			Guid guidChorus = new Guid("EF011F79-4000-406D-87AF-BFFB3FC39D57");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidChorus));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXCompressor)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Distortion Effect
	/// </summary>
	public class DmoDistortion : IDmoEffector<DmoDistortion.Params>, IDisposable
	{
		/// <summary>
		/// DMO Distortion Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXDISTORTION_GAIN_MIN
			/// </summary>
			public const float GainMin = -60f;

			/// <summary>
			/// DSFXDISTORTION_GAIN_MAX
			/// </summary>
			public const float GainMax = 0f;

			/// <summary>
			/// DSFXDISTORTION_GAIN_DEFAULT
			/// </summary>
			public const float GainDefault = -18f;

			/// <summary>
			/// DSFXDISTORTION_EDGE_MIN
			/// </summary>
			public const float EdgeMin = 0f;

			/// <summary>
			/// DSFXDISTORTION_EDGE_MAX
			/// </summary>
			public const float EdgeMax = 100f;

			/// <summary>
			/// DSFXDISTORTION_EDGE_DEFAULT
			/// </summary>
			public const float EdgeDefault = 15f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQCENTERFREQUENCY_MIN
			/// </summary>
			public const float PostEqCenterFrequencyMin = 100f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQCENTERFREQUENCY_MAX
			/// </summary>
			public const float PostEqCenterFrequencyMax = 8000f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQCENTERFREQUENCY_DEFAULT
			/// </summary>
			public const float PostEqCenterFrequencyDefault = 2400f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQBANDWIDTH_MIN
			/// </summary>
			public const float PostEqBandWidthMin = 100f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQBANDWIDTH_MAX
			/// </summary>
			public const float PostEqBandWidthMax = 8000f;

			/// <summary>
			/// DSFXDISTORTION_POSTEQBANDWIDTH_DEFAULT
			/// </summary>
			public const float PostEqBandWidthDefault = 2400f;

			/// <summary>
			/// DSFXDISTORTION_PRELOWPASSCUTOFF_MIN
			/// </summary>
			public const float PreLowPassCutoffMin = 100f;

			/// <summary>
			/// DSFXDISTORTION_PRELOWPASSCUTOFF_MAX
			/// </summary>
			public const float PreLowPassCutoffMax = 8000f;

			/// <summary>
			/// DSFXDISTORTION_PRELOWPASSCUTOFF_DEFAULT
			/// </summary>
			public const float PreLowPassCutoffDefault = 8000f;

			private readonly IDirectSoundFXDistortion fxDistortion;

			/// <summary>
			/// Amount of signal change after distortion.
			/// </summary>
			public float Gain
			{
				get
				{
					return GetAllParameters().Gain;
				}
				set
				{
					DsFxDistortion allParameters = GetAllParameters();
					allParameters.Gain = Math.Max(Math.Min(0f, value), -60f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage of distortion intensity.
			/// </summary>
			public float Edge
			{
				get
				{
					return GetAllParameters().Edge;
				}
				set
				{
					DsFxDistortion allParameters = GetAllParameters();
					allParameters.Edge = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Center frequency of harmonic content addition.
			/// </summary>
			public float PostEqCenterFrequency
			{
				get
				{
					return GetAllParameters().PostEqCenterFrequency;
				}
				set
				{
					DsFxDistortion allParameters = GetAllParameters();
					allParameters.PostEqCenterFrequency = Math.Max(Math.Min(8000f, value), 100f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Width of frequency band that determines range of harmonic content addition.
			/// </summary>
			public float PostEqBandWidth
			{
				get
				{
					return GetAllParameters().PostEqBandWidth;
				}
				set
				{
					DsFxDistortion allParameters = GetAllParameters();
					allParameters.PostEqBandWidth = Math.Max(Math.Min(8000f, value), 100f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Filter cutoff for high-frequency harmonics attenuation.
			/// </summary>
			public float PreLowPassCutoff
			{
				get
				{
					return GetAllParameters().PreLowPassCutoff;
				}
				set
				{
					DsFxDistortion allParameters = GetAllParameters();
					allParameters.PreLowPassCutoff = Math.Max(Math.Min(8000f, value), 100f);
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXDistortion dsFxObject)
			{
				fxDistortion = dsFxObject;
			}

			private void SetAllParameters(DsFxDistortion param)
			{
				Marshal.ThrowExceptionForHR(fxDistortion.SetAllParameters(ref param));
			}

			private DsFxDistortion GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxDistortion.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Distortion
		/// </summary>
		public DmoDistortion()
		{
			Guid guidDistortion = new Guid("EF114C90-CD1D-484E-96E5-09CFAF912A21");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidDistortion));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXDistortion)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// Dmo Echo Effect
	/// </summary>
	public class DmoEcho : IDmoEffector<DmoEcho.Params>, IDisposable
	{
		/// <summary>
		/// DMO Echo Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXECHO_WETDRYMIX_MIN
			/// </summary>
			public const float WetDryMixMin = 0f;

			/// <summary>
			/// DSFXECHO_WETDRYMIX_MAX
			/// </summary>
			public const float WetDryMixMax = 100f;

			/// <summary>
			/// DSFXECHO_WETDRYMIX_DEFAULT
			/// </summary>
			public const float WetDeyMixDefault = 50f;

			/// <summary>
			/// DSFXECHO_FEEDBACK_MIN
			/// </summary>
			public const float FeedBackMin = 0f;

			/// <summary>
			/// DSFXECHO_FEEDBACK_MAX
			/// </summary>
			public const float FeedBackMax = 100f;

			/// <summary>
			/// DSFXECHO_FEEDBACK_DEFAULT
			/// </summary>
			public const float FeedBackDefault = 50f;

			/// <summary>
			/// DSFXECHO_LEFTDELAY_MIN
			/// </summary>
			public const float LeftDelayMin = 1f;

			/// <summary>
			/// DSFXECHO_LEFTDELAY_MAX
			/// </summary>
			public const float LeftDelayMax = 2000f;

			/// <summary>
			/// DSFXECHO_LEFTDELAY_DEFAULT
			/// </summary>
			public const float LeftDelayDefault = 500f;

			/// <summary>
			/// DSFXECHO_RIGHTDELAY_MIN
			/// </summary>
			public const float RightDelayMin = 1f;

			/// <summary>
			/// DSFXECHO_RIGHTDELAY_MAX
			/// </summary>
			public const float RightDelayMax = 2000f;

			/// <summary>
			/// DSFXECHO_RIGHTDELAY_DEFAULT
			/// </summary>
			public const float RightDelayDefault = 500f;

			/// <summary>
			/// DSFXECHO_PANDELAY_DEFAULT
			/// </summary>
			public const EchoPanDelay PanDelayDefault = EchoPanDelay.Off;

			private readonly IDirectSoundFXEcho fxEcho;

			/// <summary>
			/// Ratio of wet (processed) signal to dry (unprocessed) signal.
			/// </summary>
			public float WetDryMix
			{
				get
				{
					return GetAllParameters().WetDryMix;
				}
				set
				{
					DsFxEcho allParameters = GetAllParameters();
					allParameters.WetDryMix = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage of output fed back into input.
			/// </summary>
			public float FeedBack
			{
				get
				{
					return GetAllParameters().FeedBack;
				}
				set
				{
					DsFxEcho allParameters = GetAllParameters();
					allParameters.FeedBack = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Delay for left channel, in milliseconds.
			/// </summary>
			public float LeftDelay
			{
				get
				{
					return GetAllParameters().LeftDelay;
				}
				set
				{
					DsFxEcho allParameters = GetAllParameters();
					allParameters.LeftDelay = Math.Max(Math.Min(2000f, value), 1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Delay for right channel, in milliseconds.
			/// </summary>
			public float RightDelay
			{
				get
				{
					return GetAllParameters().RightDelay;
				}
				set
				{
					DsFxEcho allParameters = GetAllParameters();
					allParameters.RightDelay = Math.Max(Math.Min(2000f, value), 1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Value that specifies whether to swap left and right delays with each successive echo.
			/// </summary>
			public EchoPanDelay PanDelay
			{
				get
				{
					return GetAllParameters().PanDelay;
				}
				set
				{
					DsFxEcho allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(EchoPanDelay), value))
					{
						allParameters.PanDelay = value;
					}
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXEcho dsFxObject)
			{
				fxEcho = dsFxObject;
			}

			private void SetAllParameters(DsFxEcho param)
			{
				Marshal.ThrowExceptionForHR(fxEcho.SetAllParameters(ref param));
			}

			private DsFxEcho GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxEcho.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Echo
		/// </summary>
		public DmoEcho()
		{
			Guid guidEcho = new Guid("EF3E932C-D40B-4F51-8CCF-3F98F1B29D5D");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidEcho));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXEcho)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Flanger Effect
	/// </summary>
	public class DmoFlanger : IDmoEffector<DmoFlanger.Params>, IDisposable
	{
		/// <summary>
		/// DMO Flanger Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXFLANGER_WETDRYMIX_MIN
			/// </summary>
			public const float WetDryMixMin = 0f;

			/// <summary>
			/// DSFXFLANGER_WETDRYMIX_MAX
			/// </summary>
			public const float WetDryMixMax = 100f;

			/// <summary>
			/// DSFXFLANGER_WETDRYMIX_DEFAULT
			/// </summary>
			public const float WetDrtMixDefault = 50f;

			/// <summary>
			/// DSFXFLANGER_DEPTH_MIN
			/// </summary>
			public const float DepthMin = 0f;

			/// <summary>
			/// DSFXFLANGER_DEPTH_MAX
			/// </summary>
			public const float DepthMax = 100f;

			/// <summary>
			/// DSFXFLANGER_DEPTH_DEFAULT
			/// </summary>
			public const float DepthDefault = 100f;

			/// <summary>
			/// DSFXFLANGER_FEEDBACK_MIN
			/// </summary>
			public const float FeedBackMin = -99f;

			/// <summary>
			/// DSFXFLANGER_FEEDBACK_MAX
			/// </summary>
			public const float FeedBackMax = 99f;

			/// <summary>
			/// DSFXFLANGER_FEEDBACK_DEFAULT
			/// </summary>
			public const float FeedBaclDefault = -50f;

			/// <summary>
			/// DSFXFLANGER_FREQUENCY_MIN
			/// </summary>
			public const float FrequencyMin = 0f;

			/// <summary>
			/// DSFXFLANGER_FREQUENCY_MAX
			/// </summary>
			public const float FrequencyMax = 10f;

			/// <summary>
			/// DSFXFLANGER_FREQUENCY_DEFAULT
			/// </summary>
			public const float FrequencyDefault = 0.25f;

			/// <summary>
			/// DSFXFLANGER_WAVE_DEFAULT
			/// </summary>
			public const FlangerWaveForm WaveFormDefault = FlangerWaveForm.Sin;

			/// <summary>
			/// DSFXFLANGER_DELAY_MIN
			/// </summary>
			public const float DelayMin = 0f;

			/// <summary>
			/// DSFXFLANGER_DELAY_MAX
			/// </summary>
			public const float DelayMax = 4f;

			/// <summary>
			/// DSFXFLANGER_DELAY_DEFAULT
			/// </summary>
			public const float DelayDefault = 2f;

			/// <summary>
			/// DSFXFLANGER_PHASE_DEFAULT
			/// </summary>
			public const FlangerPhase PhaseDefault = FlangerPhase.Zero;

			private readonly IDirectSoundFXFlanger fxFlanger;

			/// <summary>
			/// Ratio of wet (processed) signal to dry (unprocessed) signal.
			/// </summary>
			public float WetDryMix
			{
				get
				{
					return GetAllParameters().WetDryMix;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					allParameters.WetDryMix = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage by which the delay time is modulated by the low-frequency oscillator,
			/// in hundredths of a percentage point.
			/// </summary>
			public float Depth
			{
				get
				{
					return GetAllParameters().Depth;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					allParameters.Depth = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Percentage of output signal to feed back into the effect's input.
			/// </summary>
			public float FeedBack
			{
				get
				{
					return GetAllParameters().FeedBack;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					allParameters.FeedBack = Math.Max(Math.Min(99f, value), -99f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Frequency of the LFO.
			/// </summary>
			public float Frequency
			{
				get
				{
					return GetAllParameters().Frequency;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					allParameters.Frequency = Math.Max(Math.Min(10f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Waveform shape of the LFO.
			/// </summary>
			public FlangerWaveForm WaveForm
			{
				get
				{
					return GetAllParameters().WaveForm;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(FlangerWaveForm), value))
					{
						allParameters.WaveForm = value;
					}
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Number of milliseconds the input is delayed before it is played back.
			/// </summary>
			public float Delay
			{
				get
				{
					return GetAllParameters().Delay;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					allParameters.Delay = Math.Max(Math.Min(4f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Phase differential between left and right LFOs.
			/// </summary>
			public FlangerPhase Phase
			{
				get
				{
					return GetAllParameters().Phase;
				}
				set
				{
					DsFxFlanger allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(FlangerPhase), value))
					{
						allParameters.Phase = value;
					}
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXFlanger dsFxObject)
			{
				fxFlanger = dsFxObject;
			}

			private void SetAllParameters(DsFxFlanger param)
			{
				Marshal.ThrowExceptionForHR(fxFlanger.SetAllParameters(ref param));
			}

			private DsFxFlanger GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxFlanger.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Flanger
		/// </summary>
		public DmoFlanger()
		{
			Guid guidFlanger = new Guid("EFCA3D92-DFD8-4672-A603-7420894BAD98");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidFlanger));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXFlanger)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Gargle Effect
	/// </summary>
	public class DmoGargle : IDmoEffector<DmoGargle.Params>, IDisposable
	{
		/// <summary>
		/// DMO Gargle Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXGARGLE_RATEHZ_MIN
			/// </summary>
			public const uint RateHzMin = 1u;

			/// <summary>
			/// DSFXGARGLE_RATEHZ_MAX
			/// </summary>
			public const uint RateHzMax = 1000u;

			/// <summary>
			/// DSFXGARGLE_RATEHZ_DEFAULT
			/// </summary>
			public const uint RateHzDefault = 20u;

			/// <summary>
			/// DSFXGARGLE_WAVE_DEFAULT
			/// </summary>
			public const GargleWaveShape WaveShapeDefault = GargleWaveShape.Triangle;

			private readonly IDirectSoundFXGargle fxGargle;

			/// <summary>
			/// Rate of modulation in hz
			/// </summary>
			public uint RateHz
			{
				get
				{
					return GetAllParameters().RateHz;
				}
				set
				{
					DsFxGargle allParameters = GetAllParameters();
					allParameters.RateHz = Math.Max(Math.Min(1000u, value), 1u);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Gargle Wave Shape
			/// </summary>
			public GargleWaveShape WaveShape
			{
				get
				{
					return GetAllParameters().WaveShape;
				}
				set
				{
					DsFxGargle allParameters = GetAllParameters();
					if (Enum.IsDefined(typeof(GargleWaveShape), value))
					{
						allParameters.WaveShape = value;
					}
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXGargle dsFxObject)
			{
				fxGargle = dsFxObject;
			}

			private void SetAllParameters(DsFxGargle param)
			{
				Marshal.ThrowExceptionForHR(fxGargle.SetAllParameters(ref param));
			}

			private DsFxGargle GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxGargle.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO Gargle
		/// </summary>
		public DmoGargle()
		{
			Guid guidGargle = new Guid("DAFD8210-5711-4B91-9FE3-F75B7AE279BF");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidGargle));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXGargle)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO I3DL2Reverb Effect
	/// </summary>
	public class DmoI3DL2Reverb : IDmoEffector<DmoI3DL2Reverb.Params>, IDisposable
	{
		/// <summary>
		/// DMO I3DL2Reverb Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFX_I3DL2REVERB_ROOM_MIN
			/// </summary>
			public const int RoomMin = -10000;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOM_MAX
			/// </summary>
			public const int RoomMax = 0;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOM_DEFAULT
			/// </summary>
			public const int RoomDefault = -1000;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMHF_MIN
			/// </summary>
			public const int RoomHfMin = -10000;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMHF_MAX
			/// </summary>
			public const int RoomHfMax = 0;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMHF_DEFAULT
			/// </summary>
			public const int RoomHfDefault = -100;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMROLLOFFFACTOR_MIN
			/// </summary>
			public const float RoomRollOffFactorMin = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMROLLOFFFACTOR_MAX
			/// </summary>
			public const float RoomRollOffFactorMax = 10f;

			/// <summary>
			/// DSFX_I3DL2REVERB_ROOMROLLOFFFACTOR_DEFAULT
			/// </summary>
			public const float RoomRollOffFactorDefault = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYTIME_MIN
			/// </summary>
			public const float DecayTimeMin = 0.1f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYTIME_MAX
			/// </summary>
			public const float DecayTimeMax = 20f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYTIME_DEFAULT
			/// </summary>
			public const float DecayTimeDefault = 1.49f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYHFRATIO_MIN
			/// </summary>
			public const float DecayHfRatioMin = 0.1f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYHFRATIO_MAX
			/// </summary>
			public const float DecayHfRatioMax = 2f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DECAYHFRATIO_DEFAULT
			/// </summary>
			public const float DecayHfRatioDefault = 0.83f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONS_MIN
			/// </summary>
			public const int ReflectionsMin = -10000;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONS_MAX
			/// </summary>
			public const int ReflectionsMax = 1000;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONS_DEFAULT
			/// </summary>
			public const int ReflectionsDefault = -2602;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONSDELAY_MIN
			/// </summary>
			public const float ReflectionsDelayMin = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONSDELAY_MAX
			/// </summary>
			public const float ReflectionsDelayMax = 0.3f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REFLECTIONSDELAY_DEFAULT
			/// </summary>
			public const float ReflectionsDelayDefault = 0.007f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERB_MIN
			/// </summary>
			public const int ReverbMin = -10000;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERB_MAX
			/// </summary>
			public const int ReverbMax = 2000;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERB_DEFAULT
			/// </summary>
			public const int ReverbDefault = 200;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERBDELAY_MIN
			/// </summary>
			public const float ReverbDelayMin = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERBDELAY_MAX
			/// </summary>
			public const float ReverbDelayMax = 0.1f;

			/// <summary>
			/// DSFX_I3DL2REVERB_REVERBDELAY_DEFAULT
			/// </summary>
			public const float ReverbDelayDefault = 0.011f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DIFFUSION_MIN
			/// </summary>
			public const float DiffusionMin = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DIFFUSION_MAX
			/// </summary>
			public const float DiffusionMax = 100f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DIFFUSION_DEFAULT
			/// </summary>
			public const float DiffusionDefault = 100f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DENSITY_MIN
			/// </summary>
			public const float DensityMin = 0f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DENSITY_MAX
			/// </summary>
			public const float DensityMax = 100f;

			/// <summary>
			/// DSFX_I3DL2REVERB_DENSITY_DEFAULT
			/// </summary>
			public const float DensityDefault = 100f;

			/// <summary>
			/// DSFX_I3DL2REVERB_HFREFERENCE_MIN
			/// </summary>
			public const float HfReferenceMin = 20f;

			/// <summary>
			/// DSFX_I3DL2REVERB_HFREFERENCE_MAX
			/// </summary>
			public const float HfReferenceMax = 20000f;

			/// <summary>
			/// DSFX_I3DL2REVERB_HFREFERENCE_DEFAULT
			/// </summary>
			public const float HfReferenceDefault = 5000f;

			/// <summary>
			/// DSFX_I3DL2REVERB_QUALITY_MIN
			/// </summary>
			public const int QualityMin = 0;

			/// <summary>
			/// DSFX_I3DL2REVERB_QUALITY_MAX
			/// </summary>
			public const int QualityMax = 3;

			/// <summary>
			/// DSFX_I3DL2REVERB_QUALITY_DEFAULT
			/// </summary>
			public const int QualityDefault = 2;

			private readonly IDirectSoundFXI3DL2Reverb fxI3Dl2Reverb;

			/// <summary>
			/// Attenuation of the room effect, in millibels (mB)
			/// </summary>
			public int Room
			{
				get
				{
					return GetAllParameters().Room;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.Room = Math.Max(Math.Min(0, value), -10000);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Attenuation of the room high-frequency effect, in mB.
			/// </summary>
			public int RoomHf
			{
				get
				{
					return GetAllParameters().RoomHf;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.RoomHf = Math.Max(Math.Min(0, value), -10000);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Rolloff factor for the reflected signals.
			/// </summary>
			public float RoomRollOffFactor
			{
				get
				{
					return GetAllParameters().RoomRollOffFactor;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.RoomRollOffFactor = Math.Max(Math.Min(10f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Decay time, in seconds.
			/// </summary>
			public float DecayTime
			{
				get
				{
					return GetAllParameters().DecayTime;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.DecayTime = Math.Max(Math.Min(20f, value), 0.1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Ratio of the decay time at high frequencies to the decay time at low frequencies.
			/// </summary>
			public float DecayHfRatio
			{
				get
				{
					return GetAllParameters().DecayHfRatio;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.DecayHfRatio = Math.Max(Math.Min(2f, value), 0.1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Attenuation of early reflections relative to lRoom, in mB.
			/// </summary>
			public int Reflections
			{
				get
				{
					return GetAllParameters().Reflections;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.Reflections = Math.Max(Math.Min(1000, value), -10000);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Delay time of the first reflection relative to the direct path, in seconds.
			/// </summary>
			public float ReflectionsDelay
			{
				get
				{
					return GetAllParameters().ReflectionsDelay;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.ReflectionsDelay = Math.Max(Math.Min(0.3f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Attenuation of late reverberation relative to lRoom, in mB.
			/// </summary>
			public int Reverb
			{
				get
				{
					return GetAllParameters().Reverb;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.Reverb = Math.Max(Math.Min(2000, value), -10000);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Time limit between the early reflections and the late reverberation relative to the time of the first reflection.
			/// </summary>
			public float ReverbDelay
			{
				get
				{
					return GetAllParameters().ReverbDelay;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.ReverbDelay = Math.Max(Math.Min(0.1f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Echo density in the late reverberation decay, in percent.
			/// </summary>
			public float Diffusion
			{
				get
				{
					return GetAllParameters().Diffusion;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.Diffusion = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Modal density in the late reverberation decay, in percent.
			/// </summary>
			public float Density
			{
				get
				{
					return GetAllParameters().Density;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.Density = Math.Max(Math.Min(100f, value), 0f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Reference high frequency, in hertz.
			/// </summary>
			public float HfReference
			{
				get
				{
					return GetAllParameters().HfReference;
				}
				set
				{
					DsFxI3Dl2Reverb allParameters = GetAllParameters();
					allParameters.HfReference = Math.Max(Math.Min(20000f, value), 20f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// the quality of the environmental reverberation effect. Higher values produce better quality at the expense of processing time.
			/// </summary>
			public int Quality
			{
				get
				{
					Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.GetQuality(out var quality));
					return quality;
				}
				set
				{
					Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.SetQuality(value));
				}
			}

			internal Params(IDirectSoundFXI3DL2Reverb dsFxObject)
			{
				fxI3Dl2Reverb = dsFxObject;
			}

			/// <summary>
			/// Sets standard reverberation parameters of a buffer.
			/// </summary>
			/// <param name="preset">I3DL2EnvironmentPreset</param>
			public void SetPreset(I3DL2EnvironmentPreset preset)
			{
				Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.SetPreset((uint)preset));
			}

			/// <summary>
			/// retrieves an identifier for standard reverberation parameters of a buffer.
			/// </summary>
			/// <returns>I3DL2EnvironmentPreset</returns>
			public I3DL2EnvironmentPreset GetPreset()
			{
				Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.GetPreset(out var preset));
				return (I3DL2EnvironmentPreset)preset;
			}

			private void SetAllParameters(DsFxI3Dl2Reverb param)
			{
				Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.SetAllParameters(ref param));
			}

			private DsFxI3Dl2Reverb GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxI3Dl2Reverb.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO I3DL2Reverb
		/// </summary>
		public DmoI3DL2Reverb()
		{
			Guid guidi3Dl2Reverb = new Guid("EF985E71-D5C7-42D4-BA4D-2D073E2E96F4");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidi3Dl2Reverb));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXI3DL2Reverb)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Parametric Equalizer Effect
	/// </summary>
	public class DmoParamEq : IDmoEffector<DmoParamEq.Params>, IDisposable
	{
		/// <summary>
		/// DMO ParamEq Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFXPARAMEQ_CENTER_MIN
			/// </summary>
			public const float CenterMin = 80f;

			/// <summary>
			/// DSFXPARAMEQ_CENTER_MAX
			/// </summary>
			public const float CenterMax = 16000f;

			/// <summary>
			/// DSFXPARAMEQ_CENTER_DEFAULT
			/// </summary>
			public const float CenterDefault = 8000f;

			/// <summary>
			/// DSFXPARAMEQ_BANDWIDTH_MIN
			/// </summary>
			public const float BandWidthMin = 1f;

			/// <summary>
			/// DSFXPARAMEQ_BANDWIDTH_MAX
			/// </summary>
			public const float BandWidthMax = 36f;

			/// <summary>
			/// DSFXPARAMEQ_BANDWIDTH_DEFAULT
			/// </summary>
			public const float BandWidthDefault = 12f;

			/// <summary>
			/// DSFXPARAMEQ_GAIN_MIN
			/// </summary>
			public const float GainMin = -15f;

			/// <summary>
			/// DSFXPARAMEQ_GAIN_MAX
			/// </summary>
			public const float GainMax = 15f;

			/// <summary>
			/// DSFXPARAMEQ_GAIN_DEFAULT
			/// </summary>
			public const float GainDefault = 0f;

			private readonly IDirectSoundFxParamEq fxParamEq;

			/// <summary>
			/// Center frequency, in hertz
			/// </summary>
			public float Center
			{
				get
				{
					return GetAllParameters().Center;
				}
				set
				{
					DsFxParamEq allParameters = GetAllParameters();
					allParameters.Center = Math.Max(Math.Min(16000f, value), 80f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Bandwidth, in semitones.
			/// </summary>
			public float BandWidth
			{
				get
				{
					return GetAllParameters().BandWidth;
				}
				set
				{
					DsFxParamEq allParameters = GetAllParameters();
					allParameters.BandWidth = Math.Max(Math.Min(36f, value), 1f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Gain
			/// </summary>
			public float Gain
			{
				get
				{
					return GetAllParameters().Gain;
				}
				set
				{
					DsFxParamEq allParameters = GetAllParameters();
					allParameters.Gain = Math.Max(Math.Min(15f, value), -15f);
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFxParamEq dsFxObject)
			{
				fxParamEq = dsFxObject;
			}

			private void SetAllParameters(DsFxParamEq param)
			{
				Marshal.ThrowExceptionForHR(fxParamEq.SetAllParameters(ref param));
			}

			private DsFxParamEq GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxParamEq.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO ParamEq
		/// </summary>
		public DmoParamEq()
		{
			Guid guidParamEq = new Guid("120CED89-3BF4-4173-A132-3CB406CF3231");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidParamEq));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFxParamEq)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	/// <summary>
	/// DMO Reverb Effect
	/// </summary>
	public class DmoWavesReverb : IDmoEffector<DmoWavesReverb.Params>, IDisposable
	{
		/// <summary>
		/// DMO Reverb Params
		/// </summary>
		public struct Params
		{
			/// <summary>
			/// DSFX_WAVESREVERB_INGAIN_MIN
			/// </summary>
			public const float InGainMin = -96f;

			/// <summary>
			/// DSFX_WAVESREVERB_INGAIN_MAX
			/// </summary>
			public const float InGainMax = 0f;

			/// <summary>
			/// DSFX_WAVESREVERB_INGAIN_DEFAULT
			/// </summary>
			public const float InGainDefault = 0f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBMIX_MIN
			/// </summary>
			public const float ReverbMixMin = -96f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBMIX_MAX
			/// </summary>
			public const float ReverbMixMax = 0f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBMIX_DEFAULT
			/// </summary>
			public const float ReverbMixDefault = 0f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBTIME_MIN
			/// </summary>
			public const float ReverbTimeMin = 0.001f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBTIME_MAX
			/// </summary>
			public const float ReverbTimeMax = 3000f;

			/// <summary>
			/// DSFX_WAVESREVERB_REVERBTIME_DEFAULT
			/// </summary>
			public const float ReverbTimeDefault = 1000f;

			/// <summary>
			/// DSFX_WAVESREVERB_HIGHFREQRTRATIO_MIN
			/// </summary>
			public const float HighFreqRtRatioMin = 0.001f;

			/// <summary>
			/// DSFX_WAVESREVERB_HIGHFREQRTRATIO_MAX
			/// </summary>
			public const float HighFreqRtRatioMax = 0.999f;

			/// <summary>
			/// DSFX_WAVESREVERB_HIGHFREQRTRATIO_DEFAULT
			/// </summary>
			public const float HighFreqRtRatioDefault = 0.001f;

			private readonly IDirectSoundFXWavesReverb fxWavesReverb;

			/// <summary>
			/// Input gain of signal, in decibels (dB).
			/// </summary>
			public float InGain
			{
				get
				{
					return GetAllParameters().InGain;
				}
				set
				{
					DsFxWavesReverb allParameters = GetAllParameters();
					allParameters.InGain = Math.Max(Math.Min(0f, value), -96f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Reverb mix, in dB.
			/// </summary>
			public float ReverbMix
			{
				get
				{
					return GetAllParameters().ReverbMix;
				}
				set
				{
					DsFxWavesReverb allParameters = GetAllParameters();
					allParameters.ReverbMix = Math.Max(Math.Min(0f, value), -96f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// Reverb time, in milliseconds.
			/// </summary>
			public float ReverbTime
			{
				get
				{
					return GetAllParameters().ReverbTime;
				}
				set
				{
					DsFxWavesReverb allParameters = GetAllParameters();
					allParameters.ReverbTime = Math.Max(Math.Min(3000f, value), 0.001f);
					SetAllParameters(allParameters);
				}
			}

			/// <summary>
			/// High-frequency reverb time ratio.
			/// </summary>
			public float HighFreqRtRatio
			{
				get
				{
					return GetAllParameters().HighFreqRtRatio;
				}
				set
				{
					DsFxWavesReverb allParameters = GetAllParameters();
					allParameters.HighFreqRtRatio = Math.Max(Math.Min(0.999f, value), 0.001f);
					SetAllParameters(allParameters);
				}
			}

			internal Params(IDirectSoundFXWavesReverb dsFxObject)
			{
				fxWavesReverb = dsFxObject;
			}

			private void SetAllParameters(DsFxWavesReverb param)
			{
				Marshal.ThrowExceptionForHR(fxWavesReverb.SetAllParameters(ref param));
			}

			private DsFxWavesReverb GetAllParameters()
			{
				Marshal.ThrowExceptionForHR(fxWavesReverb.GetAllParameters(out var param));
				return param;
			}
		}

		private readonly MediaObject mediaObject;

		private readonly MediaObjectInPlace mediaObjectInPlace;

		private readonly Params effectParams;

		/// <summary>
		/// Media Object
		/// </summary>
		public MediaObject MediaObject => mediaObject;

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		public MediaObjectInPlace MediaObjectInPlace => mediaObjectInPlace;

		/// <summary>
		/// Effect Parameter
		/// </summary>
		public Params EffectParams => effectParams;

		/// <summary>
		/// Create new DMO WavesReverb
		/// </summary>
		public DmoWavesReverb()
		{
			Guid guidWavesReverb = new Guid("87FC0268-9A55-4360-95AA-004A1D9DE26C");
			DmoDescriptor dmoDescriptor = DmoEnumerator.GetAudioEffectNames().First((DmoDescriptor descriptor) => object.Equals(descriptor.Clsid, guidWavesReverb));
			if (dmoDescriptor != null)
			{
				object obj = Activator.CreateInstance(Type.GetTypeFromCLSID(dmoDescriptor.Clsid));
				mediaObject = new MediaObject((IMediaObject)obj);
				mediaObjectInPlace = new MediaObjectInPlace((IMediaObjectInPlace)obj);
				effectParams = new Params((IDirectSoundFXWavesReverb)obj);
			}
		}

		/// <summary>
		/// Dispose code
		/// </summary>
		public void Dispose()
		{
			mediaObjectInPlace?.Dispose();
			mediaObject?.Dispose();
		}
	}

	internal struct DsFxChorus
	{
		public float WetDryMix;

		public float Depth;

		public float FeedBack;

		public float Frequency;

		public ChorusWaveForm WaveForm;

		public float Delay;

		public ChorusPhase Phase;
	}

	internal struct DsFxCompressor
	{
		public float Gain;

		public float Attack;

		public float Release;

		public float Threshold;

		public float Ratio;

		public float PreDelay;
	}

	internal struct DsFxDistortion
	{
		public float Gain;

		public float Edge;

		public float PostEqCenterFrequency;

		public float PostEqBandWidth;

		public float PreLowPassCutoff;
	}

	internal struct DsFxEcho
	{
		public float WetDryMix;

		public float FeedBack;

		public float LeftDelay;

		public float RightDelay;

		public EchoPanDelay PanDelay;
	}

	internal struct DsFxFlanger
	{
		public float WetDryMix;

		public float Depth;

		public float FeedBack;

		public float Frequency;

		public FlangerWaveForm WaveForm;

		public float Delay;

		public FlangerPhase Phase;
	}

	internal struct DsFxGargle
	{
		public uint RateHz;

		public GargleWaveShape WaveShape;
	}

	internal struct DsFxI3Dl2Reverb
	{
		public int Room;

		public int RoomHf;

		public float RoomRollOffFactor;

		public float DecayTime;

		public float DecayHfRatio;

		public int Reflections;

		public float ReflectionsDelay;

		public int Reverb;

		public float ReverbDelay;

		public float Diffusion;

		public float Density;

		public float HfReference;
	}

	internal struct DsFxParamEq
	{
		public float Center;

		public float BandWidth;

		public float Gain;
	}

	internal struct DsFxWavesReverb
	{
		public float InGain;

		public float ReverbMix;

		public float ReverbTime;

		public float HighFreqRtRatio;
	}

	/// <summary>
	/// DSFXECHO_PANDELAY
	/// </summary>
	public enum EchoPanDelay
	{
		/// <summary>
		/// DSFXECHO_PANDELAY_MIN
		/// </summary>
		Off,
		/// <summary>
		/// DSFXECHO_PANDELAY_MAX
		/// </summary>
		On
	}

	/// <summary>
	/// Flanger Phase
	/// </summary>
	public enum FlangerPhase
	{
		/// <summary>
		/// DSFXFLANGER_PHASE_NEG_180
		/// </summary>
		Neg180,
		/// <summary>
		/// DSFXFLANGER_PHASE_NEG_90
		/// </summary>
		Neg90,
		/// <summary>
		/// DSFXFLANGER_PHASE_ZERO
		/// </summary>
		Zero,
		/// <summary>
		/// DSFXFLANGER_PHASE_90
		/// </summary>
		Pos90,
		/// <summary>
		/// DSFXFLANGER_PHASE_180
		/// </summary>
		Pos180
	}

	/// <summary>
	/// Flanger Wave Form
	/// </summary>
	public enum FlangerWaveForm
	{
		/// <summary>
		/// DSFXFLANGER_WAVE_TRIANGLE
		/// </summary>
		Triangle,
		/// <summary>
		/// DSFXFLANGER_WAVE_SIN
		/// </summary>
		Sin
	}

	/// <summary>
	/// Gargle Wave Shape
	/// </summary>
	public enum GargleWaveShape : uint
	{
		/// <summary>
		/// DSFXGARGLE_WAVE_TRIANGLE
		/// </summary>
		Triangle,
		/// <summary>
		/// DSFXGARGLE_WAVE_SQUARE
		/// </summary>
		Square
	}

	/// <summary>
	/// I3DL2 Reverberation Presets
	/// </summary>
	public enum I3DL2EnvironmentPreset
	{
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_DEFAULT
		/// </summary>
		Default,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_GENERIC
		/// </summary>
		Generic,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_PADDEDCELL
		/// </summary>
		PaddedCell,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_ROOM
		/// </summary>
		Room,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_BATHROOM
		/// </summary>
		Bathroom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_LIVINGROOM
		/// </summary>
		LivingRoom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_STONEROOM
		/// </summary>
		StoneRoom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_AUDITORIUM
		/// </summary>
		Auditorium,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_CONCERTHALL
		/// </summary>
		ConcertHall,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_CAVE
		/// </summary>
		Cave,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_ARENA
		/// </summary>
		Arena,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_HANGAR
		/// </summary>
		Hangar,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_CARPETEDHALLWAY
		/// </summary>
		CarpetedHallway,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_HALLWAY
		/// </summary>
		Hallway,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_STONECORRIDOR
		/// </summary>
		StoneCorridor,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_ALLEY
		/// </summary>
		Alley,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_FOREST
		/// </summary>
		Forest,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_CITY
		/// </summary>
		City,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_MOUNTAINS
		/// </summary>
		Mountains,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_QUARRY
		/// </summary>
		Quarry,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_PLAIN
		/// </summary>
		Plain,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_PARKINGLOT
		/// </summary>
		ParkingLot,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_SEWERPIPE
		/// </summary>
		SewerPipe,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_UNDERWATER
		/// </summary>
		UnderWater,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_SMALLROOM
		/// </summary>
		SmallRoom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_MEDIUMROOM
		/// </summary>
		MediumRoom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_LARGEROOM
		/// </summary>
		LargeRoom,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_MEDIUMHALL
		/// </summary>
		MediumHall,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_LARGEHALL
		/// </summary>
		LargeHall,
		/// <summary>
		/// DSFX_I3DL2_ENVIRONMENT_PRESET_PLATE
		/// </summary>
		Plate
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("880842e3-145f-43e6-a934-a71806e50547")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXChorus
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxChorus param);

		[PreserveSig]
		int GetAllParameters(out DsFxChorus param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("4bbd1154-62f6-4e2c-a15c-d3b6c417f7a0")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXCompressor
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxCompressor param);

		[PreserveSig]
		int GetAllParameters(out DsFxCompressor param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("8ecf4326-455f-4d8b-bda9-8d5d3e9e3e0b")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXDistortion
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxDistortion param);

		[PreserveSig]
		int GetAllParameters(out DsFxDistortion param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("8bd28edf-50db-4e92-a2bd-445488d1ed42")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXEcho
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxEcho param);

		[PreserveSig]
		int GetAllParameters(out DsFxEcho param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("903e9878-2c92-4072-9b2c-ea68f5396783")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXFlanger
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxFlanger param);

		[PreserveSig]
		int GetAllParameters(out DsFxFlanger param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("d616f352-d622-11ce-aac5-0020af0b99a3")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXGargle
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxGargle param);

		[PreserveSig]
		int GetAllParameters(out DsFxGargle param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("4b166a6a-0d66-43f3-80e3-ee6280dee1a4")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXI3DL2Reverb
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxI3Dl2Reverb param);

		[PreserveSig]
		int GetAllParameters(out DsFxI3Dl2Reverb param);

		[PreserveSig]
		int SetPreset([In] uint preset);

		[PreserveSig]
		int GetPreset(out uint preset);

		[PreserveSig]
		int SetQuality([In] int quality);

		[PreserveSig]
		int GetQuality(out int quality);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("c03ca9fe-fe90-4204-8078-82334cd177da")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFxParamEq
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxParamEq param);

		[PreserveSig]
		int GetAllParameters(out DsFxParamEq param);
	}

	[ComImport]
	[SuppressUnmanagedCodeSecurity]
	[Guid("46858c3a-0dc6-45e3-b760-d4eef16cb325")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IDirectSoundFXWavesReverb
	{
		[PreserveSig]
		int SetAllParameters([In] ref DsFxWavesReverb param);

		[PreserveSig]
		int GetAllParameters(out DsFxWavesReverb param);
	}

	/// <summary>
	/// Interface of DMO Effectors
	/// </summary>
	/// <typeparam name="TParameters">Parameters of the effect to be used</typeparam>
	public interface IDmoEffector<out TParameters> : IDisposable
	{
		/// <summary>
		/// Media Object
		/// </summary>
		MediaObject MediaObject { get; }

		/// <summary>
		/// Media Object InPlace
		/// </summary>
		MediaObjectInPlace MediaObjectInPlace { get; }

		/// <summary>
		/// Effect Parameter
		/// </summary>
		TParameters EffectParams { get; }
	}
}

namespace NAudio.FileFormats.Mp3
{
	using NAudio.Dmo;
	using NAudio.Wave;

	/// <summary>
	/// MP3 Frame decompressor using the Windows Media MP3 Decoder DMO object
	/// </summary>
	public class DmoMp3FrameDecompressor : IMp3FrameDecompressor, IDisposable
	{
		private WindowsMediaMp3Decoder mp3Decoder;

		private WaveFormat pcmFormat;

		private MediaBuffer inputMediaBuffer;

		private DmoOutputDataBuffer outputBuffer;

		private bool reposition;

		/// <summary>
		/// Converted PCM WaveFormat
		/// </summary>
		public WaveFormat OutputFormat => pcmFormat;

		/// <summary>
		/// Initializes a new instance of the DMO MP3 Frame decompressor
		/// </summary>
		/// <param name="sourceFormat"></param>
		public DmoMp3FrameDecompressor(WaveFormat sourceFormat)
		{
			mp3Decoder = new WindowsMediaMp3Decoder();
			if (!mp3Decoder.MediaObject.SupportsInputWaveFormat(0, sourceFormat))
			{
				throw new ArgumentException("Unsupported input format");
			}
			mp3Decoder.MediaObject.SetInputWaveFormat(0, sourceFormat);
			pcmFormat = new WaveFormat(sourceFormat.SampleRate, sourceFormat.Channels);
			if (!mp3Decoder.MediaObject.SupportsOutputWaveFormat(0, pcmFormat))
			{
				throw new ArgumentException($"Unsupported output format {pcmFormat}");
			}
			mp3Decoder.MediaObject.SetOutputWaveFormat(0, pcmFormat);
			inputMediaBuffer = new MediaBuffer(sourceFormat.AverageBytesPerSecond);
			outputBuffer = new DmoOutputDataBuffer(pcmFormat.AverageBytesPerSecond);
		}

		/// <summary>
		/// Decompress a single frame of MP3
		/// </summary>
		public int DecompressFrame(Mp3Frame frame, byte[] dest, int destOffset)
		{
			inputMediaBuffer.LoadData(frame.RawData, frame.FrameLength);
			if (reposition)
			{
				mp3Decoder.MediaObject.Flush();
				reposition = false;
			}
			mp3Decoder.MediaObject.ProcessInput(0, inputMediaBuffer, DmoInputDataBufferFlags.None, 0L, 0L);
			outputBuffer.MediaBuffer.SetLength(0);
			outputBuffer.StatusFlags = DmoOutputDataBufferFlags.None;
			mp3Decoder.MediaObject.ProcessOutput(DmoProcessOutputFlags.None, 1, new DmoOutputDataBuffer[1] { outputBuffer });
			if (outputBuffer.Length == 0)
			{
				return 0;
			}
			outputBuffer.RetrieveData(dest, destOffset);
			return outputBuffer.Length;
		}

		/// <summary>
		/// Alerts us that a reposition has occured so the MP3 decoder needs to reset its state
		/// </summary>
		public void Reset()
		{
			reposition = true;
		}

		/// <summary>
		/// Dispose of this obejct and clean up resources
		/// </summary>
		public void Dispose()
		{
			if (inputMediaBuffer != null)
			{
				inputMediaBuffer.Dispose();
				inputMediaBuffer = null;
			}
			outputBuffer.Dispose();
			if (mp3Decoder != null)
			{
				mp3Decoder.Dispose();
				mp3Decoder = null;
			}
		}
	}
}

namespace NAudio.MediaFoundation
{
	using NAudio.Wave;
	using NAudio.Utils;
	using System.Runtime.InteropServices.ComTypes;
	
	
	/// <summary>
	/// Audio Subtype GUIDs
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/aa372553%28v=vs.85%29.aspx
	/// </summary>
	public static class AudioSubtypes
	{
		/// <summary>
		/// Advanced Audio Coding (AAC).
		/// </summary>
		[FieldDescription("AAC")]
		public static readonly Guid MFAudioFormat_AAC = new Guid("00001610-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Not used
		/// </summary>
		[FieldDescription("ADTS")]
		public static readonly Guid MFAudioFormat_ADTS = new Guid("00001600-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby AC-3 audio over Sony/Philips Digital Interface (S/PDIF).
		/// </summary>
		[FieldDescription("Dolby AC3 SPDIF")]
		public static readonly Guid MFAudioFormat_Dolby_AC3_SPDIF = new Guid("00000092-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Encrypted audio data used with secure audio path.
		/// </summary>
		[FieldDescription("DRM")]
		public static readonly Guid MFAudioFormat_DRM = new Guid("00000009-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Digital Theater Systems (DTS) audio.
		/// </summary>
		[FieldDescription("DTS")]
		public static readonly Guid MFAudioFormat_DTS = new Guid("00000008-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Uncompressed IEEE floating-point audio.
		/// </summary>
		[FieldDescription("IEEE floating-point")]
		public static readonly Guid MFAudioFormat_Float = new Guid("00000003-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// MPEG Audio Layer-3 (MP3).
		/// </summary>
		[FieldDescription("MP3")]
		public static readonly Guid MFAudioFormat_MP3 = new Guid("00000055-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// MPEG-1 audio payload.
		/// </summary>
		[FieldDescription("MPEG")]
		public static readonly Guid MFAudioFormat_MPEG = new Guid("00000050-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Windows Media Audio 9 Voice codec.
		/// </summary>
		[FieldDescription("WMA 9 Voice codec")]
		public static readonly Guid MFAudioFormat_MSP1 = new Guid("0000000a-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Uncompressed PCM audio.
		/// </summary>
		[FieldDescription("PCM")]
		public static readonly Guid MFAudioFormat_PCM = new Guid("00000001-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Windows Media Audio 9 Professional codec over S/PDIF.
		/// </summary>
		[FieldDescription("WMA SPDIF")]
		public static readonly Guid MFAudioFormat_WMASPDIF = new Guid("00000164-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Windows Media Audio 9 Lossless codec or Windows Media Audio 9.1 codec.
		/// </summary>
		[FieldDescription("WMAudio Lossless")]
		public static readonly Guid MFAudioFormat_WMAudio_Lossless = new Guid("00000163-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Windows Media Audio 8 codec, Windows Media Audio 9 codec, or Windows Media Audio 9.1 codec.
		/// </summary>
		[FieldDescription("Windows Media Audio")]
		public static readonly Guid MFAudioFormat_WMAudioV8 = new Guid("00000161-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Windows Media Audio 9 Professional codec or Windows Media Audio 9.1 Professional codec.
		/// </summary>
		[FieldDescription("Windows Media Audio Professional")]
		public static readonly Guid MFAudioFormat_WMAudioV9 = new Guid("00000162-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby Digital (AC-3).
		/// </summary>
		[FieldDescription("Dolby AC3")]
		public static readonly Guid MFAudioFormat_Dolby_AC3 = new Guid("e06d802c-db46-11cf-b4d1-00805f6cbbea");

		/// <summary>
		/// Free Lossless Audio Codec (Supported in Windows 10 and later.)
		/// </summary>
		public static readonly Guid MFAudioFormat_FLAC = new Guid("0000f1ac-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Apple Lossless Audio Codec (Supported in Windows 10 and later.)
		/// </summary>
		public static readonly Guid MFAudioFormat_ALAC = new Guid("63616c61-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// MPEG-4 and AAC Audio Types
		/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd317599(v=vs.85).aspx
		/// Reference : wmcodecdsp.h
		/// </summary>
		[FieldDescription("MPEG-4 and AAC Audio Types")]
		public static readonly Guid MEDIASUBTYPE_RAW_AAC1 = new Guid("000000ff-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby Audio Types
		/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd317599(v=vs.85).aspx
		/// Reference : wmcodecdsp.h
		/// </summary>
		[FieldDescription("Dolby Audio Types")]
		public static readonly Guid MEDIASUBTYPE_DVM = new Guid("00002000-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby Audio Types
		/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd317599(v=vs.85).aspx
		/// Reference : wmcodecdsp.h
		/// </summary>
		[FieldDescription("Dolby Audio Types")]
		public static readonly Guid MEDIASUBTYPE_DOLBY_DDPLUS = new Guid("a7fb87af-2d02-42fb-a4d4-05cd93843bdd");

		/// <summary>
		/// μ-law coding
		/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd390971(v=vs.85).aspx
		/// Reference : Ksmedia.h
		/// </summary>
		[FieldDescription("μ-law")]
		public static readonly Guid KSDATAFORMAT_SUBTYPE_MULAW = new Guid("00000007-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Adaptive delta pulse code modulation (ADPCM)
		/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd390971(v=vs.85).aspx
		/// Reference : Ksmedia.h
		/// </summary>
		[FieldDescription("ADPCM")]
		public static readonly Guid KSDATAFORMAT_SUBTYPE_ADPCM = new Guid("00000002-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Dolby Digital Plus formatted for HDMI output.
		/// http://msdn.microsoft.com/en-us/library/windows/hardware/ff538392(v=vs.85).aspx
		/// Reference : internet
		/// </summary>
		[FieldDescription("Dolby Digital Plus for HDMI")]
		public static readonly Guid KSDATAFORMAT_SUBTYPE_IEC61937_DOLBY_DIGITAL_PLUS = new Guid("0000000a-0cea-0010-8000-00aa00389b71");

		/// <summary>
		/// MSAudio1 - unknown meaning
		/// Reference : wmcodecdsp.h
		/// </summary>
		[FieldDescription("MSAudio1")]
		public static readonly Guid MEDIASUBTYPE_MSAUDIO1 = new Guid("00000160-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// IMA ADPCM ACM Wrapper
		/// </summary>
		[FieldDescription("IMA ADPCM")]
		public static readonly Guid ImaAdpcm = new Guid("00000011-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// WMSP2 - unknown meaning
		/// Reference: wmsdkidl.h
		/// </summary>
		[FieldDescription("WMSP2")]
		public static readonly Guid WMMEDIASUBTYPE_WMSP2 = new Guid("0000000b-0000-0010-8000-00aa00389b71");
	}

	/// <summary>
	/// IMFActivate, defined in mfobjects.h
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("7FEE9E9A-4A89-47a6-899C-B6A53A70FB67")]
	public interface IMFActivate : IMFAttributes
	{
		/// <summary>
		/// Retrieves the value associated with a key.
		/// </summary>
		new void GetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Retrieves the data type of the value associated with a key.
		/// </summary>
		new void GetItemType([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pType);

		/// <summary>
		/// Queries whether a stored attribute value equals a specified PROPVARIANT.
		/// </summary>
		new void CompareItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Compares the attributes on this object with the attributes on another object.
		/// </summary>
		new void Compare([MarshalAs(UnmanagedType.Interface)] IMFAttributes pTheirs, int matchType, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Retrieves a UINT32 value associated with a key.
		/// </summary>
		new void GetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int punValue);

		/// <summary>
		/// Retrieves a UINT64 value associated with a key.
		/// </summary>
		new void GetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out long punValue);

		/// <summary>
		/// Retrieves a double value associated with a key.
		/// </summary>
		new void GetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out double pfValue);

		/// <summary>
		/// Retrieves a GUID value associated with a key.
		/// </summary>
		new void GetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out Guid pguidValue);

		/// <summary>
		/// Retrieves the length of a string value associated with a key.
		/// </summary>
		new void GetStringLength([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key.
		/// </summary>
		new void GetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPWStr)] StringBuilder pwszValue, int cchBufSize, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key. This method allocates the memory for the string.
		/// </summary>
		new void GetAllocatedString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [MarshalAs(UnmanagedType.LPWStr)] out string ppwszValue, out int pcchLength);

		/// <summary>
		/// Retrieves the length of a byte array associated with a key.
		/// </summary>
		new void GetBlobSize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key.
		/// </summary>
		new void GetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPArray)] byte[] pBuf, int cbBufSize, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key. This method allocates the memory for the array.
		/// </summary>
		new void GetAllocatedBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out IntPtr ip, out int pcbSize);

		/// <summary>
		/// Retrieves an interface pointer associated with a key.
		/// </summary>
		new void GetUnknown([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.IUnknown)] out object ppv);

		/// <summary>
		/// Associates an attribute value with a key.
		/// </summary>
		new void SetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value);

		/// <summary>
		/// Removes a key/value pair from the object's attribute list.
		/// </summary>
		new void DeleteItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey);

		/// <summary>
		/// Removes all key/value pairs from the object's attribute list.
		/// </summary>
		new void DeleteAllItems();

		/// <summary>
		/// Associates a UINT32 value with a key.
		/// </summary>
		new void SetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, int unValue);

		/// <summary>
		/// Associates a UINT64 value with a key.
		/// </summary>
		new void SetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, long unValue);

		/// <summary>
		/// Associates a double value with a key.
		/// </summary>
		new void SetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, double fValue);

		/// <summary>
		/// Associates a GUID value with a key.
		/// </summary>
		new void SetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidValue);

		/// <summary>
		/// Associates a wide-character string with a key.
		/// </summary>
		new void SetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPWStr)] string wszValue);

		/// <summary>
		/// Associates a byte array with a key.
		/// </summary>
		new void SetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 2)] byte[] pBuf, int cbBufSize);

		/// <summary>
		/// Associates an IUnknown pointer with a key.
		/// </summary>
		new void SetUnknown([MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Locks the attribute store so that no other thread can access it.
		/// </summary>
		new void LockStore();

		/// <summary>
		/// Unlocks the attribute store.
		/// </summary>
		new void UnlockStore();

		/// <summary>
		/// Retrieves the number of attributes that are set on this object.
		/// </summary>
		new void GetCount(out int pcItems);

		/// <summary>
		/// Retrieves an attribute at the specified index.
		/// </summary>
		new void GetItemByIndex(int unIndex, out Guid pGuidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Copies all of the attributes from this object into another attribute store.
		/// </summary>
		new void CopyAllItems([In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pDest);

		/// <summary>
		/// Creates the object associated with this activation object. 
		/// </summary>
		void ActivateObject([In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.Interface)] out object ppv);

		/// <summary>
		/// Shuts down the created object.
		/// </summary>
		void ShutdownObject();

		/// <summary>
		/// Detaches the created object from the activation object.
		/// </summary>
		void DetachObject();
	}

	/// <summary>
	/// Provides a generic way to store key/value pairs on an object.
	/// http://msdn.microsoft.com/en-gb/library/windows/desktop/ms704598%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("2CD2D921-C447-44A7-A13C-4ADABFC247E3")]
	public interface IMFAttributes
	{
		/// <summary>
		/// Retrieves the value associated with a key.
		/// </summary>
		void GetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Retrieves the data type of the value associated with a key.
		/// </summary>
		void GetItemType([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pType);

		/// <summary>
		/// Queries whether a stored attribute value equals a specified PROPVARIANT.
		/// </summary>
		void CompareItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Compares the attributes on this object with the attributes on another object.
		/// </summary>
		void Compare([MarshalAs(UnmanagedType.Interface)] IMFAttributes pTheirs, int matchType, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Retrieves a UINT32 value associated with a key.
		/// </summary>
		void GetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int punValue);

		/// <summary>
		/// Retrieves a UINT64 value associated with a key.
		/// </summary>
		void GetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out long punValue);

		/// <summary>
		/// Retrieves a double value associated with a key.
		/// </summary>
		void GetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out double pfValue);

		/// <summary>
		/// Retrieves a GUID value associated with a key.
		/// </summary>
		void GetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out Guid pguidValue);

		/// <summary>
		/// Retrieves the length of a string value associated with a key.
		/// </summary>
		void GetStringLength([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key.
		/// </summary>
		void GetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPWStr)] StringBuilder pwszValue, int cchBufSize, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key. This method allocates the memory for the string.
		/// </summary>
		void GetAllocatedString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [MarshalAs(UnmanagedType.LPWStr)] out string ppwszValue, out int pcchLength);

		/// <summary>
		/// Retrieves the length of a byte array associated with a key.
		/// </summary>
		void GetBlobSize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key.
		/// </summary>
		void GetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPArray)] byte[] pBuf, int cbBufSize, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key. This method allocates the memory for the array.
		/// </summary>
		void GetAllocatedBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out IntPtr ip, out int pcbSize);

		/// <summary>
		/// Retrieves an interface pointer associated with a key.
		/// </summary>
		void GetUnknown([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.IUnknown)] out object ppv);

		/// <summary>
		/// Associates an attribute value with a key.
		/// </summary>
		void SetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr Value);

		/// <summary>
		/// Removes a key/value pair from the object's attribute list.
		/// </summary>
		void DeleteItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey);

		/// <summary>
		/// Removes all key/value pairs from the object's attribute list.
		/// </summary>
		void DeleteAllItems();

		/// <summary>
		/// Associates a UINT32 value with a key.
		/// </summary>
		void SetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, int unValue);

		/// <summary>
		/// Associates a UINT64 value with a key.
		/// </summary>
		void SetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, long unValue);

		/// <summary>
		/// Associates a double value with a key.
		/// </summary>
		void SetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, double fValue);

		/// <summary>
		/// Associates a GUID value with a key.
		/// </summary>
		void SetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidValue);

		/// <summary>
		/// Associates a wide-character string with a key.
		/// </summary>
		void SetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPWStr)] string wszValue);

		/// <summary>
		/// Associates a byte array with a key.
		/// </summary>
		void SetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 2)] byte[] pBuf, int cbBufSize);

		/// <summary>
		/// Associates an IUnknown pointer with a key.
		/// </summary>
		void SetUnknown([MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Locks the attribute store so that no other thread can access it.
		/// </summary>
		void LockStore();

		/// <summary>
		/// Unlocks the attribute store.
		/// </summary>
		void UnlockStore();

		/// <summary>
		/// Retrieves the number of attributes that are set on this object.
		/// </summary>
		void GetCount(out int pcItems);

		/// <summary>
		/// Retrieves an attribute at the specified index.
		/// </summary>
		void GetItemByIndex(int unIndex, out Guid pGuidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Copies all of the attributes from this object into another attribute store.
		/// </summary>
		void CopyAllItems([In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pDest);
	}

	/// <summary>
	/// IMFByteStream 
	/// http://msdn.microsoft.com/en-gb/library/windows/desktop/ms698720%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("ad4c1b00-4bf7-422f-9175-756693d9130d")]
	public interface IMFByteStream
	{
		/// <summary>
		/// Retrieves the characteristics of the byte stream. 
		/// virtual HRESULT STDMETHODCALLTYPE GetCapabilities(/*[out]*/ __RPC__out DWORD *pdwCapabilities) = 0;
		/// </summary>
		void GetCapabilities(ref int pdwCapabiities);

		/// <summary>
		/// Retrieves the length of the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE GetLength(/*[out]*/ __RPC__out QWORD *pqwLength) = 0;
		/// </summary>
		void GetLength(ref long pqwLength);

		/// <summary>
		/// Sets the length of the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE SetLength(/*[in]*/ QWORD qwLength) = 0;
		/// </summary>
		void SetLength(long qwLength);

		/// <summary>
		/// Retrieves the current read or write position in the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE GetCurrentPosition(/*[out]*/ __RPC__out QWORD *pqwPosition) = 0;
		/// </summary>
		void GetCurrentPosition(ref long pqwPosition);

		/// <summary>
		/// Sets the current read or write position. 
		/// virtual HRESULT STDMETHODCALLTYPE SetCurrentPosition(/*[in]*/ QWORD qwPosition) = 0;
		/// </summary>
		void SetCurrentPosition(long qwPosition);

		/// <summary>
		/// Queries whether the current position has reached the end of the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE IsEndOfStream(/*[out]*/ __RPC__out BOOL *pfEndOfStream) = 0;
		/// </summary>
		void IsEndOfStream([MarshalAs(UnmanagedType.Bool)] ref bool pfEndOfStream);

		/// <summary>
		/// Reads data from the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE Read(/*[size_is][out]*/ __RPC__out_ecount_full(cb) BYTE *pb, /*[in]*/ ULONG cb, /*[out]*/ __RPC__out ULONG *pcbRead) = 0;
		/// </summary>
		void Read(IntPtr pb, int cb, ref int pcbRead);

		/// <summary>
		/// Begins an asynchronous read operation from the stream. 
		/// virtual /*[local]*/ HRESULT STDMETHODCALLTYPE BeginRead(/*[out]*/ _Out_writes_bytes_(cb)  BYTE *pb, /*[in]*/ ULONG cb, /*[in]*/ IMFAsyncCallback *pCallback, /*[in]*/ IUnknown *punkState) = 0;
		/// </summary>
		void BeginRead(IntPtr pb, int cb, IntPtr pCallback, IntPtr punkState);

		/// <summary>
		/// Completes an asynchronous read operation. 
		/// virtual /*[local]*/ HRESULT STDMETHODCALLTYPE EndRead(/*[in]*/ IMFAsyncResult *pResult, /*[out]*/ _Out_  ULONG *pcbRead) = 0;
		/// </summary>
		void EndRead(IntPtr pResult, ref int pcbRead);

		/// <summary>
		/// Writes data to the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE Write(/*[size_is][in]*/ __RPC__in_ecount_full(cb) const BYTE *pb, /*[in]*/ ULONG cb, /*[out]*/ __RPC__out ULONG *pcbWritten) = 0;
		/// </summary>
		void Write(IntPtr pb, int cb, ref int pcbWritten);

		/// <summary>
		/// Begins an asynchronous write operation to the stream. 
		/// virtual /*[local]*/ HRESULT STDMETHODCALLTYPE BeginWrite(/*[in]*/ _In_reads_bytes_(cb)  const BYTE *pb, /*[in]*/ ULONG cb, /*[in]*/ IMFAsyncCallback *pCallback, /*[in]*/ IUnknown *punkState) = 0;
		/// </summary>
		void BeginWrite(IntPtr pb, int cb, IntPtr pCallback, IntPtr punkState);

		/// <summary>
		/// Completes an asynchronous write operation. 
		/// virtual /*[local]*/ HRESULT STDMETHODCALLTYPE EndWrite(/*[in]*/ IMFAsyncResult *pResult, /*[out]*/ _Out_  ULONG *pcbWritten) = 0;
		/// </summary>
		void EndWrite(IntPtr pResult, ref int pcbWritten);

		/// <summary>
		/// Moves the current position in the stream by a specified offset. 
		/// virtual HRESULT STDMETHODCALLTYPE Seek(/*[in]*/ MFBYTESTREAM_SEEK_ORIGIN SeekOrigin, /*[in]*/ LONGLONG llSeekOffset, /*[in]*/ DWORD dwSeekFlags, /*[out]*/ __RPC__out QWORD *pqwCurrentPosition) = 0;
		/// </summary>
		void Seek(int SeekOrigin, long llSeekOffset, int dwSeekFlags, ref long pqwCurrentPosition);

		/// <summary>
		/// Clears any internal buffers used by the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE Flush( void) = 0;
		/// </summary>
		void Flush();

		/// <summary>
		/// Closes the stream and releases any resources associated with the stream. 
		/// virtual HRESULT STDMETHODCALLTYPE Close( void) = 0;
		/// </summary>
		void Close();
	}

	/// <summary>
	/// Represents a generic collection of IUnknown pointers. 
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("5BC8A76B-869A-46A3-9B03-FA218A66AEBE")]
	public interface IMFCollection
	{
		/// <summary>
		/// Retrieves the number of objects in the collection.
		/// </summary>
		void GetElementCount(out int pcElements);

		/// <summary>
		/// Retrieves an object in the collection.
		/// </summary>
		void GetElement([In] int dwElementIndex, [MarshalAs(UnmanagedType.IUnknown)] out object ppUnkElement);

		/// <summary>
		/// Adds an object to the collection.
		/// </summary>
		void AddElement([In][MarshalAs(UnmanagedType.IUnknown)] object pUnkElement);

		/// <summary>
		/// Removes an object from the collection.
		/// </summary>
		void RemoveElement([In] int dwElementIndex, [MarshalAs(UnmanagedType.IUnknown)] out object ppUnkElement);

		/// <summary>
		/// Removes an object from the collection.
		/// </summary>
		void InsertElementAt([In] int dwIndex, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Removes all items from the collection.
		/// </summary>
		void RemoveAllElements();
	}

	/// <summary>
	/// IMFMediaBuffer
	/// http://msdn.microsoft.com/en-gb/library/windows/desktop/ms696261%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("045FA593-8799-42b8-BC8D-8968C6453507")]
	public interface IMFMediaBuffer
	{
		/// <summary>
		/// Gives the caller access to the memory in the buffer.
		/// </summary>
		void Lock(out IntPtr ppbBuffer, out int pcbMaxLength, out int pcbCurrentLength);

		/// <summary>
		/// Unlocks a buffer that was previously locked.
		/// </summary>
		void Unlock();

		/// <summary>
		/// Retrieves the length of the valid data in the buffer.
		/// </summary>
		void GetCurrentLength(out int pcbCurrentLength);

		/// <summary>
		/// Sets the length of the valid data in the buffer.
		/// </summary>
		void SetCurrentLength(int cbCurrentLength);

		/// <summary>
		/// Retrieves the allocated size of the buffer.
		/// </summary>
		void GetMaxLength(out int pcbMaxLength);
	}

	/// <summary>
	/// IMFMediaEvent - Represents an event generated by a Media Foundation object. Use this interface to get information about the event.
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/ms702249%28v=vs.85%29.aspx
	/// Mfobjects.h
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("DF598932-F10C-4E39-BBA2-C308F101DAA3")]
	public interface IMFMediaEvent : IMFAttributes
	{
		/// <summary>
		/// Retrieves the value associated with a key.
		/// </summary>
		new void GetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Retrieves the data type of the value associated with a key.
		/// </summary>
		new void GetItemType([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pType);

		/// <summary>
		/// Queries whether a stored attribute value equals a specified PROPVARIANT.
		/// </summary>
		new void CompareItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Compares the attributes on this object with the attributes on another object.
		/// </summary>
		new void Compare([MarshalAs(UnmanagedType.Interface)] IMFAttributes pTheirs, int matchType, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Retrieves a UINT32 value associated with a key.
		/// </summary>
		new void GetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int punValue);

		/// <summary>
		/// Retrieves a UINT64 value associated with a key.
		/// </summary>
		new void GetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out long punValue);

		/// <summary>
		/// Retrieves a double value associated with a key.
		/// </summary>
		new void GetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out double pfValue);

		/// <summary>
		/// Retrieves a GUID value associated with a key.
		/// </summary>
		new void GetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out Guid pguidValue);

		/// <summary>
		/// Retrieves the length of a string value associated with a key.
		/// </summary>
		new void GetStringLength([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key.
		/// </summary>
		new void GetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPWStr)] StringBuilder pwszValue, int cchBufSize, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key. This method allocates the memory for the string.
		/// </summary>
		new void GetAllocatedString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [MarshalAs(UnmanagedType.LPWStr)] out string ppwszValue, out int pcchLength);

		/// <summary>
		/// Retrieves the length of a byte array associated with a key.
		/// </summary>
		new void GetBlobSize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key.
		/// </summary>
		new void GetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPArray)] byte[] pBuf, int cbBufSize, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key. This method allocates the memory for the array.
		/// </summary>
		new void GetAllocatedBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out IntPtr ip, out int pcbSize);

		/// <summary>
		/// Retrieves an interface pointer associated with a key.
		/// </summary>
		new void GetUnknown([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.IUnknown)] out object ppv);

		/// <summary>
		/// Associates an attribute value with a key.
		/// </summary>
		new void SetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value);

		/// <summary>
		/// Removes a key/value pair from the object's attribute list.
		/// </summary>
		new void DeleteItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey);

		/// <summary>
		/// Removes all key/value pairs from the object's attribute list.
		/// </summary>
		new void DeleteAllItems();

		/// <summary>
		/// Associates a UINT32 value with a key.
		/// </summary>
		new void SetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, int unValue);

		/// <summary>
		/// Associates a UINT64 value with a key.
		/// </summary>
		new void SetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, long unValue);

		/// <summary>
		/// Associates a double value with a key.
		/// </summary>
		new void SetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, double fValue);

		/// <summary>
		/// Associates a GUID value with a key.
		/// </summary>
		new void SetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidValue);

		/// <summary>
		/// Associates a wide-character string with a key.
		/// </summary>
		new void SetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPWStr)] string wszValue);

		/// <summary>
		/// Associates a byte array with a key.
		/// </summary>
		new void SetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 2)] byte[] pBuf, int cbBufSize);

		/// <summary>
		/// Associates an IUnknown pointer with a key.
		/// </summary>
		new void SetUnknown([MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Locks the attribute store so that no other thread can access it.
		/// </summary>
		new void LockStore();

		/// <summary>
		/// Unlocks the attribute store.
		/// </summary>
		new void UnlockStore();

		/// <summary>
		/// Retrieves the number of attributes that are set on this object.
		/// </summary>
		new void GetCount(out int pcItems);

		/// <summary>
		/// Retrieves an attribute at the specified index.
		/// </summary>
		new void GetItemByIndex(int unIndex, out Guid pGuidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Copies all of the attributes from this object into another attribute store.
		/// </summary>
		new void CopyAllItems([In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pDest);

		/// <summary>
		/// Retrieves the event type. 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetType( 
		///     /* [out] */ __RPC__out MediaEventType *pmet) = 0;
		/// </remarks>
		void GetType(out MediaEventType pmet);

		/// <summary>
		/// Retrieves the extended type of the event.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetExtendedType( 
		///     /* [out] */ __RPC__out GUID *pguidExtendedType) = 0;
		/// </remarks>
		void GetExtendedType(out Guid pguidExtendedType);

		/// <summary>
		/// Retrieves an HRESULT that specifies the event status.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetStatus( 
		///     /* [out] */ __RPC__out HRESULT *phrStatus) = 0;
		/// </remarks>
		void GetStatus([MarshalAs(UnmanagedType.Error)] out int phrStatus);

		/// <summary>
		/// Retrieves the value associated with the event, if any. 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetValue( 
		///     /* [out] */ __RPC__out PROPVARIANT *pvValue) = 0;
		/// </remarks>
		void GetValue([Out] IntPtr pvValue);
	}

	/// <summary>
	/// Represents a description of a media format. 
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/ms704850%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("44AE0FA8-EA31-4109-8D2E-4CAE4997C555")]
	public interface IMFMediaType : IMFAttributes
	{
		/// <summary>
		/// Retrieves the value associated with a key.
		/// </summary>
		new void GetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Retrieves the data type of the value associated with a key.
		/// </summary>
		new void GetItemType([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pType);

		/// <summary>
		/// Queries whether a stored attribute value equals a specified PROPVARIANT.
		/// </summary>
		new void CompareItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Compares the attributes on this object with the attributes on another object.
		/// </summary>
		new void Compare([MarshalAs(UnmanagedType.Interface)] IMFAttributes pTheirs, int matchType, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Retrieves a UINT32 value associated with a key.
		/// </summary>
		new void GetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int punValue);

		/// <summary>
		/// Retrieves a UINT64 value associated with a key.
		/// </summary>
		new void GetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out long punValue);

		/// <summary>
		/// Retrieves a double value associated with a key.
		/// </summary>
		new void GetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out double pfValue);

		/// <summary>
		/// Retrieves a GUID value associated with a key.
		/// </summary>
		new void GetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out Guid pguidValue);

		/// <summary>
		/// Retrieves the length of a string value associated with a key.
		/// </summary>
		new void GetStringLength([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key.
		/// </summary>
		new void GetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPWStr)] StringBuilder pwszValue, int cchBufSize, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key. This method allocates the memory for the string.
		/// </summary>
		new void GetAllocatedString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [MarshalAs(UnmanagedType.LPWStr)] out string ppwszValue, out int pcchLength);

		/// <summary>
		/// Retrieves the length of a byte array associated with a key.
		/// </summary>
		new void GetBlobSize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key.
		/// </summary>
		new void GetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPArray)] byte[] pBuf, int cbBufSize, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key. This method allocates the memory for the array.
		/// </summary>
		new void GetAllocatedBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out IntPtr ip, out int pcbSize);

		/// <summary>
		/// Retrieves an interface pointer associated with a key.
		/// </summary>
		new void GetUnknown([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.IUnknown)] out object ppv);

		/// <summary>
		/// Associates an attribute value with a key.
		/// </summary>
		new void SetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value);

		/// <summary>
		/// Removes a key/value pair from the object's attribute list.
		/// </summary>
		new void DeleteItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey);

		/// <summary>
		/// Removes all key/value pairs from the object's attribute list.
		/// </summary>
		new void DeleteAllItems();

		/// <summary>
		/// Associates a UINT32 value with a key.
		/// </summary>
		new void SetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, int unValue);

		/// <summary>
		/// Associates a UINT64 value with a key.
		/// </summary>
		new void SetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, long unValue);

		/// <summary>
		/// Associates a double value with a key.
		/// </summary>
		new void SetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, double fValue);

		/// <summary>
		/// Associates a GUID value with a key.
		/// </summary>
		new void SetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidValue);

		/// <summary>
		/// Associates a wide-character string with a key.
		/// </summary>
		new void SetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPWStr)] string wszValue);

		/// <summary>
		/// Associates a byte array with a key.
		/// </summary>
		new void SetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 2)] byte[] pBuf, int cbBufSize);

		/// <summary>
		/// Associates an IUnknown pointer with a key.
		/// </summary>
		new void SetUnknown([MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Locks the attribute store so that no other thread can access it.
		/// </summary>
		new void LockStore();

		/// <summary>
		/// Unlocks the attribute store.
		/// </summary>
		new void UnlockStore();

		/// <summary>
		/// Retrieves the number of attributes that are set on this object.
		/// </summary>
		new void GetCount(out int pcItems);

		/// <summary>
		/// Retrieves an attribute at the specified index.
		/// </summary>
		new void GetItemByIndex(int unIndex, out Guid pGuidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Copies all of the attributes from this object into another attribute store.
		/// </summary>
		new void CopyAllItems([In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pDest);

		/// <summary>
		/// Retrieves the major type of the format.
		/// </summary>
		void GetMajorType(out Guid pguidMajorType);

		/// <summary>
		/// Queries whether the media type is a compressed format.
		/// </summary>
		void IsCompressedFormat([MarshalAs(UnmanagedType.Bool)] out bool pfCompressed);

		/// <summary>
		/// Compares two media types and determines whether they are identical.
		/// </summary>
		[PreserveSig]
		int IsEqual([In][MarshalAs(UnmanagedType.Interface)] IMFMediaType pIMediaType, ref int pdwFlags);

		/// <summary>
		/// Retrieves an alternative representation of the media type.
		/// </summary>
		void GetRepresentation([In] Guid guidRepresentation, ref IntPtr ppvRepresentation);

		/// <summary>
		/// Frees memory that was allocated by the GetRepresentation method.
		/// </summary>
		void FreeRepresentation([In] Guid guidRepresentation, [In] IntPtr pvRepresentation);
	}

	/// <summary>
	/// Creates an instance of either the sink writer or the source reader.
	/// </summary>
	[ComImport]
	[Guid("E7FE2E12-661C-40DA-92F9-4F002AB67627")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IMFReadWriteClassFactory
	{
		/// <summary>
		/// Creates an instance of the sink writer or source reader, given a URL.
		/// </summary>
		void CreateInstanceFromURL([In][MarshalAs(UnmanagedType.LPStruct)] Guid clsid, [In][MarshalAs(UnmanagedType.LPWStr)] string pwszURL, [In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pAttributes, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.Interface)] out object ppvObject);

		/// <summary>
		/// Creates an instance of the sink writer or source reader, given an IUnknown pointer. 
		/// </summary>
		void CreateInstanceFromObject([In][MarshalAs(UnmanagedType.LPStruct)] Guid clsid, [In][MarshalAs(UnmanagedType.IUnknown)] object punkObject, [In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pAttributes, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.Interface)] out object ppvObject);
	}

	/// <summary>
	/// http://msdn.microsoft.com/en-gb/library/windows/desktop/ms702192%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("c40a00f2-b93a-4d80-ae8c-5a1c634f58e4")]
	public interface IMFSample : IMFAttributes
	{
		/// <summary>
		/// Retrieves the value associated with a key.
		/// </summary>
		new void GetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Retrieves the data type of the value associated with a key.
		/// </summary>
		new void GetItemType([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pType);

		/// <summary>
		/// Queries whether a stored attribute value equals a specified PROPVARIANT.
		/// </summary>
		new void CompareItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Compares the attributes on this object with the attributes on another object.
		/// </summary>
		new void Compare([MarshalAs(UnmanagedType.Interface)] IMFAttributes pTheirs, int matchType, [MarshalAs(UnmanagedType.Bool)] out bool pbResult);

		/// <summary>
		/// Retrieves a UINT32 value associated with a key.
		/// </summary>
		new void GetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int punValue);

		/// <summary>
		/// Retrieves a UINT64 value associated with a key.
		/// </summary>
		new void GetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out long punValue);

		/// <summary>
		/// Retrieves a double value associated with a key.
		/// </summary>
		new void GetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out double pfValue);

		/// <summary>
		/// Retrieves a GUID value associated with a key.
		/// </summary>
		new void GetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out Guid pguidValue);

		/// <summary>
		/// Retrieves the length of a string value associated with a key.
		/// </summary>
		new void GetStringLength([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key.
		/// </summary>
		new void GetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPWStr)] StringBuilder pwszValue, int cchBufSize, out int pcchLength);

		/// <summary>
		/// Retrieves a wide-character string associated with a key. This method allocates the memory for the string.
		/// </summary>
		new void GetAllocatedString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [MarshalAs(UnmanagedType.LPWStr)] out string ppwszValue, out int pcchLength);

		/// <summary>
		/// Retrieves the length of a byte array associated with a key.
		/// </summary>
		new void GetBlobSize([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key.
		/// </summary>
		new void GetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [Out][MarshalAs(UnmanagedType.LPArray)] byte[] pBuf, int cbBufSize, out int pcbBlobSize);

		/// <summary>
		/// Retrieves a byte array associated with a key. This method allocates the memory for the array.
		/// </summary>
		new void GetAllocatedBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, out IntPtr ip, out int pcbSize);

		/// <summary>
		/// Retrieves an interface pointer associated with a key.
		/// </summary>
		new void GetUnknown([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [MarshalAs(UnmanagedType.IUnknown)] out object ppv);

		/// <summary>
		/// Associates an attribute value with a key.
		/// </summary>
		new void SetItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, IntPtr value);

		/// <summary>
		/// Removes a key/value pair from the object's attribute list.
		/// </summary>
		new void DeleteItem([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey);

		/// <summary>
		/// Removes all key/value pairs from the object's attribute list.
		/// </summary>
		new void DeleteAllItems();

		/// <summary>
		/// Associates a UINT32 value with a key.
		/// </summary>
		new void SetUINT32([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, int unValue);

		/// <summary>
		/// Associates a UINT64 value with a key.
		/// </summary>
		new void SetUINT64([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, long unValue);

		/// <summary>
		/// Associates a double value with a key.
		/// </summary>
		new void SetDouble([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, double fValue);

		/// <summary>
		/// Associates a GUID value with a key.
		/// </summary>
		new void SetGUID([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidValue);

		/// <summary>
		/// Associates a wide-character string with a key.
		/// </summary>
		new void SetString([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPWStr)] string wszValue);

		/// <summary>
		/// Associates a byte array with a key.
		/// </summary>
		new void SetBlob([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 2)] byte[] pBuf, int cbBufSize);

		/// <summary>
		/// Associates an IUnknown pointer with a key.
		/// </summary>
		new void SetUnknown([MarshalAs(UnmanagedType.LPStruct)] Guid guidKey, [In][MarshalAs(UnmanagedType.IUnknown)] object pUnknown);

		/// <summary>
		/// Locks the attribute store so that no other thread can access it.
		/// </summary>
		new void LockStore();

		/// <summary>
		/// Unlocks the attribute store.
		/// </summary>
		new void UnlockStore();

		/// <summary>
		/// Retrieves the number of attributes that are set on this object.
		/// </summary>
		new void GetCount(out int pcItems);

		/// <summary>
		/// Retrieves an attribute at the specified index.
		/// </summary>
		new void GetItemByIndex(int unIndex, out Guid pGuidKey, [In][Out] IntPtr pValue);

		/// <summary>
		/// Copies all of the attributes from this object into another attribute store.
		/// </summary>
		new void CopyAllItems([In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pDest);

		/// <summary>
		/// Retrieves flags associated with the sample.
		/// </summary>
		void GetSampleFlags(out int pdwSampleFlags);

		/// <summary>
		/// Sets flags associated with the sample.
		/// </summary>
		void SetSampleFlags(int dwSampleFlags);

		/// <summary>
		/// Retrieves the presentation time of the sample.
		/// </summary>
		void GetSampleTime(out long phnsSampletime);

		/// <summary>
		/// Sets the presentation time of the sample.
		/// </summary>
		void SetSampleTime(long hnsSampleTime);

		/// <summary>
		/// Retrieves the duration of the sample.
		/// </summary>
		void GetSampleDuration(out long phnsSampleDuration);

		/// <summary>
		/// Sets the duration of the sample.
		/// </summary>
		void SetSampleDuration(long hnsSampleDuration);

		/// <summary>
		/// Retrieves the number of buffers in the sample.
		/// </summary>
		void GetBufferCount(out int pdwBufferCount);

		/// <summary>
		/// Retrieves a buffer from the sample.
		/// </summary>
		void GetBufferByIndex(int dwIndex, out IMFMediaBuffer ppBuffer);

		/// <summary>
		/// Converts a sample with multiple buffers into a sample with a single buffer.
		/// </summary>
		void ConvertToContiguousBuffer(out IMFMediaBuffer ppBuffer);

		/// <summary>
		///  Adds a buffer to the end of the list of buffers in the sample.
		/// </summary>
		void AddBuffer(IMFMediaBuffer pBuffer);

		/// <summary>
		/// Removes a buffer at a specified index from the sample.
		/// </summary>
		void RemoveBufferByIndex(int dwIndex);

		/// <summary>
		/// Removes all buffers from the sample.
		/// </summary>
		void RemoveAllBuffers();

		/// <summary>
		/// Retrieves the total length of the valid data in all of the buffers in the sample.
		/// </summary>
		void GetTotalLength(out int pcbTotalLength);

		/// <summary>
		/// Copies the sample data to a buffer.
		/// </summary>
		void CopyToBuffer(IMFMediaBuffer pBuffer);
	}

	/// <summary>
	/// Implemented by the Microsoft Media Foundation sink writer object.
	/// </summary>
	[ComImport]
	[Guid("3137f1cd-fe5e-4805-a5d8-fb477448cb3d")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	public interface IMFSinkWriter
	{
		/// <summary>
		/// Adds a stream to the sink writer.
		/// </summary>
		void AddStream([In][MarshalAs(UnmanagedType.Interface)] IMFMediaType pTargetMediaType, out int pdwStreamIndex);

		/// <summary>
		/// Sets the input format for a stream on the sink writer.
		/// </summary>
		void SetInputMediaType([In] int dwStreamIndex, [In][MarshalAs(UnmanagedType.Interface)] IMFMediaType pInputMediaType, [In][MarshalAs(UnmanagedType.Interface)] IMFAttributes pEncodingParameters);

		/// <summary>
		/// Initializes the sink writer for writing.
		/// </summary>
		void BeginWriting();

		/// <summary>
		/// Delivers a sample to the sink writer.
		/// </summary>
		void WriteSample([In] int dwStreamIndex, [In][MarshalAs(UnmanagedType.Interface)] IMFSample pSample);

		/// <summary>
		/// Indicates a gap in an input stream.
		/// </summary>
		void SendStreamTick([In] int dwStreamIndex, [In] long llTimestamp);

		/// <summary>
		/// Places a marker in the specified stream.
		/// </summary>
		void PlaceMarker([In] int dwStreamIndex, [In] IntPtr pvContext);

		/// <summary>
		/// Notifies the media sink that a stream has reached the end of a segment.
		/// </summary>
		void NotifyEndOfSegment([In] int dwStreamIndex);

		/// <summary>
		/// Flushes one or more streams.
		/// </summary>
		void Flush([In] int dwStreamIndex);

		/// <summary>
		/// (Finalize) Completes all writing operations on the sink writer.
		/// </summary>
		void DoFinalize();

		/// <summary>
		/// Queries the underlying media sink or encoder for an interface.
		/// </summary>
		void GetServiceForStream([In] int dwStreamIndex, [In] ref Guid guidService, [In] ref Guid riid, out IntPtr ppvObject);

		/// <summary>
		/// Gets statistics about the performance of the sink writer.
		/// </summary>
		void GetStatistics([In] int dwStreamIndex, [In][Out] MF_SINK_WRITER_STATISTICS pStats);
	}

	/// <summary>
	/// IMFSourceReader interface
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd374655%28v=vs.85%29.aspx
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("70ae66f2-c809-4e4f-8915-bdcb406b7993")]
	public interface IMFSourceReader
	{
		/// <summary>
		/// Queries whether a stream is selected.
		/// </summary>
		void GetStreamSelection([In] int dwStreamIndex, [MarshalAs(UnmanagedType.Bool)] out bool pSelected);

		/// <summary>
		/// Selects or deselects one or more streams.
		/// </summary>
		void SetStreamSelection([In] int dwStreamIndex, [In][MarshalAs(UnmanagedType.Bool)] bool pSelected);

		/// <summary>
		/// Gets a format that is supported natively by the media source.
		/// </summary>
		void GetNativeMediaType([In] int dwStreamIndex, [In] int dwMediaTypeIndex, out IMFMediaType ppMediaType);

		/// <summary>
		/// Gets the current media type for a stream.
		/// </summary>
		void GetCurrentMediaType([In] int dwStreamIndex, out IMFMediaType ppMediaType);

		/// <summary>
		/// Sets the media type for a stream.
		/// </summary>
		void SetCurrentMediaType([In] int dwStreamIndex, IntPtr pdwReserved, [In] IMFMediaType pMediaType);

		/// <summary>
		/// Seeks to a new position in the media source.
		/// </summary>
		void SetCurrentPosition([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidTimeFormat, [In] IntPtr varPosition);

		/// <summary>
		/// Reads the next sample from the media source.
		/// </summary>
		void ReadSample([In] int dwStreamIndex, [In] int dwControlFlags, out int pdwActualStreamIndex, out MF_SOURCE_READER_FLAG pdwStreamFlags, out ulong pllTimestamp, out IMFSample ppSample);

		/// <summary>
		/// Flushes one or more streams.
		/// </summary>
		void Flush([In] int dwStreamIndex);

		/// <summary>
		/// Queries the underlying media source or decoder for an interface.
		/// </summary>
		void GetServiceForStream([In] int dwStreamIndex, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidService, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, out IntPtr ppvObject);

		/// <summary>
		/// Gets an attribute from the underlying media source.
		/// </summary>
		[PreserveSig]
		int GetPresentationAttribute([In] int dwStreamIndex, [In][MarshalAs(UnmanagedType.LPStruct)] Guid guidAttribute, [Out] IntPtr pvarAttribute);
	}

	/// <summary>
	/// IMFTransform, defined in mftransform.h
	/// </summary>
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("bf94c121-5b05-4e6f-8000-ba598961414d")]
	public interface IMFTransform
	{
		/// <summary>
		/// Retrieves the minimum and maximum number of input and output streams.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetStreamLimits( 
		///     /* [out] */ __RPC__out DWORD *pdwInputMinimum,
		///     /* [out] */ __RPC__out DWORD *pdwInputMaximum,
		///     /* [out] */ __RPC__out DWORD *pdwOutputMinimum,
		///     /* [out] */ __RPC__out DWORD *pdwOutputMaximum) = 0;
		/// </remarks>
		void GetStreamLimits(out int pdwInputMinimum, out int pdwInputMaximum, out int pdwOutputMinimum, out int pdwOutputMaximum);

		/// <summary>
		/// Retrieves the current number of input and output streams on this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetStreamCount( 
		///     /* [out] */ __RPC__out DWORD *pcInputStreams,
		///     /* [out] */ __RPC__out DWORD *pcOutputStreams) = 0;
		/// </remarks>
		void GetStreamCount(out int pcInputStreams, out int pcOutputStreams);

		/// <summary>
		/// Retrieves the stream identifiers for the input and output streams on this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetStreamIDs( 
		///     DWORD dwInputIDArraySize,
		///     /* [size_is][out] */ __RPC__out_ecount_full(dwInputIDArraySize) DWORD *pdwInputIDs,
		///     DWORD dwOutputIDArraySize,
		///     /* [size_is][out] */ __RPC__out_ecount_full(dwOutputIDArraySize) DWORD *pdwOutputIDs) = 0;
		/// </remarks>
		void GetStreamIds([In] int dwInputIdArraySize, [In][Out] IntPtr pdwInputIDs, [In] int dwOutputIdArraySize, [In][Out] IntPtr pdwOutputIDs);

		/// <summary>
		/// Gets the buffer requirements and other information for an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetInputStreamInfo( 
		///     DWORD dwInputStreamID,
		///     /* [out] */ __RPC__out MFT_INPUT_STREAM_INFO *pStreamInfo) = 0;
		/// </remarks>
		void GetInputStreamInfo([In] int dwInputStreamId, out MFT_INPUT_STREAM_INFO pStreamInfo);

		/// <summary>
		/// Gets the buffer requirements and other information for an output stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetOutputStreamInfo( 
		///     DWORD dwOutputStreamID,
		///     /* [out] */ __RPC__out MFT_OUTPUT_STREAM_INFO *pStreamInfo) = 0;
		/// </remarks>
		void GetOutputStreamInfo([In] int dwOutputStreamId, out MFT_OUTPUT_STREAM_INFO pStreamInfo);

		/// <summary>
		/// Gets the global attribute store for this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		///  virtual HRESULT STDMETHODCALLTYPE GetAttributes( 
		///     /* [out] */ __RPC__deref_out_opt IMFAttributes **pAttributes) = 0;
		/// </remarks>
		void GetAttributes(out IMFAttributes pAttributes);

		/// <summary>
		/// Retrieves the attribute store for an input stream on this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetInputStreamAttributes( 
		///     DWORD dwInputStreamID,
		///     /* [out] */ __RPC__deref_out_opt IMFAttributes **pAttributes) = 0;
		/// </remarks>
		void GetInputStreamAttributes([In] int dwInputStreamId, out IMFAttributes pAttributes);

		/// <summary>
		/// Retrieves the attribute store for an output stream on this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetOutputStreamAttributes( 
		///     DWORD dwOutputStreamID,
		///     /* [out] */ __RPC__deref_out_opt IMFAttributes **pAttributes) = 0;
		/// </remarks>
		void GetOutputStreamAttributes([In] int dwOutputStreamId, out IMFAttributes pAttributes);

		/// <summary>
		/// Removes an input stream from this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE DeleteInputStream( 
		///     DWORD dwStreamID) = 0;
		/// </remarks>
		void DeleteInputStream([In] int dwOutputStreamId);

		/// <summary>
		/// Adds one or more new input streams to this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE AddInputStreams( 
		///     DWORD cStreams,
		///     /* [in] */ __RPC__in DWORD *adwStreamIDs) = 0;
		/// </remarks>
		void AddInputStreams([In] int cStreams, [In] IntPtr adwStreamIDs);

		/// <summary>
		/// Gets an available media type for an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetInputAvailableType( 
		///     DWORD dwInputStreamID,
		///     DWORD dwTypeIndex,
		///     /* [out] */ __RPC__deref_out_opt IMFMediaType **ppType) = 0;
		/// </remarks>
		void GetInputAvailableType([In] int dwInputStreamId, [In] int dwTypeIndex, out IMFMediaType ppType);

		/// <summary>
		/// Retrieves an available media type for an output stream on this MFT.
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetOutputAvailableType( 
		///     DWORD dwOutputStreamID,
		///     DWORD dwTypeIndex,
		///     /* [out] */ __RPC__deref_out_opt IMFMediaType **ppType) = 0;
		/// </remarks>
		void GetOutputAvailableType([In] int dwOutputStreamId, [In] int dwTypeIndex, out IMFMediaType ppType);

		/// <summary>
		/// Sets, tests, or clears the media type for an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE SetInputType( 
		///     DWORD dwInputStreamID,
		///     /* [in] */ __RPC__in_opt IMFMediaType *pType,
		///     DWORD dwFlags) = 0;
		/// </remarks>
		void SetInputType([In] int dwInputStreamId, [In] IMFMediaType pType, [In] _MFT_SET_TYPE_FLAGS dwFlags);

		/// <summary>
		/// Sets, tests, or clears the media type for an output stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE SetOutputType( 
		///     DWORD dwOutputStreamID,
		///     /* [in] */ __RPC__in_opt IMFMediaType *pType,
		///     DWORD dwFlags) = 0;
		/// </remarks>
		void SetOutputType([In] int dwOutputStreamId, [In] IMFMediaType pType, [In] _MFT_SET_TYPE_FLAGS dwFlags);

		/// <summary>
		/// Gets the current media type for an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetInputCurrentType( 
		///     DWORD dwInputStreamID,
		///     /* [out] */ __RPC__deref_out_opt IMFMediaType **ppType) = 0;
		/// </remarks>
		void GetInputCurrentType([In] int dwInputStreamId, out IMFMediaType ppType);

		/// <summary>
		/// Gets the current media type for an output stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetOutputCurrentType( 
		///     DWORD dwOutputStreamID,
		///     /* [out] */ __RPC__deref_out_opt IMFMediaType **ppType) = 0;
		/// </remarks>
		void GetOutputCurrentType([In] int dwOutputStreamId, out IMFMediaType ppType);

		/// <summary>
		/// Queries whether an input stream on this Media Foundation transform (MFT) can accept more data. 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetInputStatus( 
		///     DWORD dwInputStreamID,
		///     /* [out] */ __RPC__out DWORD *pdwFlags) = 0;
		/// </remarks>
		void GetInputStatus([In] int dwInputStreamId, out _MFT_INPUT_STATUS_FLAGS pdwFlags);

		/// <summary>
		/// Queries whether the Media Foundation transform (MFT) is ready to produce output data. 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE GetOutputStatus( 
		///     /* [out] */ __RPC__out DWORD *pdwFlags) = 0;
		/// </remarks>
		void GetOutputStatus([In] int dwInputStreamId, out _MFT_OUTPUT_STATUS_FLAGS pdwFlags);

		/// <summary>
		/// Sets the range of time stamps the client needs for output. 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE SetOutputBounds( 
		///     LONGLONG hnsLowerBound,
		///     LONGLONG hnsUpperBound) = 0;
		/// </remarks>
		void SetOutputBounds([In] long hnsLowerBound, [In] long hnsUpperBound);

		/// <summary>
		/// Sends an event to an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE ProcessEvent( 
		///     DWORD dwInputStreamID,
		///     /* [in] */ __RPC__in_opt IMFMediaEvent *pEvent) = 0;
		/// </remarks>
		void ProcessEvent([In] int dwInputStreamId, [In] IMFMediaEvent pEvent);

		/// <summary>
		/// Sends a message to the Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual HRESULT STDMETHODCALLTYPE ProcessMessage( 
		///     MFT_MESSAGE_TYPE eMessage,
		///     ULONG_PTR ulParam) = 0;
		/// </remarks>
		void ProcessMessage([In] MFT_MESSAGE_TYPE eMessage, [In] IntPtr ulParam);

		/// <summary>
		/// Delivers data to an input stream on this Media Foundation transform (MFT). 
		/// </summary>
		/// <remarks>
		/// virtual /* [local] */ HRESULT STDMETHODCALLTYPE ProcessInput( 
		///     DWORD dwInputStreamID,
		///     IMFSample *pSample,
		///     DWORD dwFlags) = 0;
		/// </remarks>
		void ProcessInput([In] int dwInputStreamId, [In] IMFSample pSample, int dwFlags);

		/// <summary>
		/// Generates output from the current input data. 
		/// </summary>
		/// <remarks>
		/// virtual /* [local] */ HRESULT STDMETHODCALLTYPE ProcessOutput( 
		///     DWORD dwFlags,
		///     DWORD cOutputBufferCount,
		///     /* [size_is][out][in] */ MFT_OUTPUT_DATA_BUFFER *pOutputSamples,
		///     /* [out] */ DWORD *pdwStatus) = 0;
		/// </remarks>
		[PreserveSig]
		int ProcessOutput([In] _MFT_PROCESS_OUTPUT_FLAGS dwFlags, [In] int cOutputBufferCount, [In][Out][MarshalAs(UnmanagedType.LPArray, SizeParamIndex = 1)] MFT_OUTPUT_DATA_BUFFER[] pOutputSamples, out _MFT_PROCESS_OUTPUT_STATUS pdwStatus);
	}

	/// <summary>
	/// See mfobjects.h
	/// </summary>
	public enum MediaEventType
	{
		/// <summary>
		/// Unknown event type.
		/// </summary>
		MEUnknown = 0,
		/// <summary>
		/// Signals a serious error.
		/// </summary>
		MEError = 1,
		/// <summary>
		/// Custom event type.
		/// </summary>
		MEExtendedType = 2,
		/// <summary>
		/// A non-fatal error occurred during streaming.
		/// </summary>
		MENonFatalError = 3,
		/// <summary>
		/// Session Unknown
		/// </summary>
		MESessionUnknown = 100,
		/// <summary>
		/// Raised after the IMFMediaSession::SetTopology method completes asynchronously
		/// </summary>
		MESessionTopologySet = 101,
		/// <summary>
		/// Raised by the Media Session when the IMFMediaSession::ClearTopologies method completes asynchronously.
		/// </summary>
		MESessionTopologiesCleared = 102,
		/// <summary>
		/// Raised when the IMFMediaSession::Start method completes asynchronously.
		/// </summary>
		MESessionStarted = 103,
		/// <summary>
		/// Raised when the IMFMediaSession::Pause method completes asynchronously.
		/// </summary>
		MESessionPaused = 104,
		/// <summary>
		/// Raised when the IMFMediaSession::Stop method completes asynchronously.
		/// </summary>
		MESessionStopped = 105,
		/// <summary>
		/// Raised when the IMFMediaSession::Close method completes asynchronously.
		/// </summary>
		MESessionClosed = 106,
		/// <summary>
		/// Raised by the Media Session when it has finished playing the last presentation in the playback queue.
		/// </summary>
		MESessionEnded = 107,
		/// <summary>
		/// Raised by the Media Session when the playback rate changes.
		/// </summary>
		MESessionRateChanged = 108,
		/// <summary>
		/// Raised by the Media Session when it completes a scrubbing request.
		/// </summary>
		MESessionScrubSampleComplete = 109,
		/// <summary>
		/// Raised by the Media Session when the session capabilities change.
		/// </summary>
		MESessionCapabilitiesChanged = 110,
		/// <summary>
		/// Raised by the Media Session when the status of a topology changes.
		/// </summary>
		MESessionTopologyStatus = 111,
		/// <summary>
		/// Raised by the Media Session when a new presentation starts.
		/// </summary>
		MESessionNotifyPresentationTime = 112,
		/// <summary>
		/// Raised by a media source a new presentation is ready.
		/// </summary>
		MENewPresentation = 113,
		/// <summary>
		/// License acquisition is about to begin.
		/// </summary>
		MELicenseAcquisitionStart = 114,
		/// <summary>
		/// License acquisition is complete.
		/// </summary>
		MELicenseAcquisitionCompleted = 115,
		/// <summary>
		/// Individualization is about to begin.
		/// </summary>
		MEIndividualizationStart = 116,
		/// <summary>
		/// Individualization is complete.
		/// </summary>
		MEIndividualizationCompleted = 117,
		/// <summary>
		/// Signals the progress of a content enabler object.
		/// </summary>
		MEEnablerProgress = 118,
		/// <summary>
		/// A content enabler object's action is complete.
		/// </summary>
		MEEnablerCompleted = 119,
		/// <summary>
		/// Raised by a trusted output if an error occurs while enforcing the output policy.
		/// </summary>
		MEPolicyError = 120,
		/// <summary>
		/// Contains status information about the enforcement of an output policy.
		/// </summary>
		MEPolicyReport = 121,
		/// <summary>
		/// A media source started to buffer data.
		/// </summary>
		MEBufferingStarted = 122,
		/// <summary>
		/// A media source stopped buffering data.
		/// </summary>
		MEBufferingStopped = 123,
		/// <summary>
		/// The network source started opening a URL.
		/// </summary>
		MEConnectStart = 124,
		/// <summary>
		/// The network source finished opening a URL.
		/// </summary>
		MEConnectEnd = 125,
		/// <summary>
		/// Raised by a media source at the start of a reconnection attempt.
		/// </summary>
		MEReconnectStart = 126,
		/// <summary>
		/// Raised by a media source at the end of a reconnection attempt.
		/// </summary>
		MEReconnectEnd = 127,
		/// <summary>
		/// Raised by the enhanced video renderer (EVR) when it receives a user event from the presenter.
		/// </summary>
		MERendererEvent = 128,
		/// <summary>
		/// Raised by the Media Session when the format changes on a media sink.
		/// </summary>
		MESessionStreamSinkFormatChanged = 129,
		/// <summary>
		/// Source Unknown
		/// </summary>
		MESourceUnknown = 200,
		/// <summary>
		/// Raised when a media source starts without seeking.
		/// </summary>
		MESourceStarted = 201,
		/// <summary>
		/// Raised by a media stream when the source starts without seeking.
		/// </summary>
		MEStreamStarted = 202,
		/// <summary>
		/// Raised when a media source seeks to a new position.
		/// </summary>
		MESourceSeeked = 203,
		/// <summary>
		/// Raised by a media stream after a call to IMFMediaSource::Start causes a seek in the stream.
		/// </summary>
		MEStreamSeeked = 204,
		/// <summary>
		/// Raised by a media source when it starts a new stream.
		/// </summary>
		MENewStream = 205,
		/// <summary>
		/// Raised by a media source when it restarts or seeks a stream that is already active.
		/// </summary>
		MEUpdatedStream = 206,
		/// <summary>
		/// Raised by a media source when the IMFMediaSource::Stop method completes asynchronously.
		/// </summary>
		MESourceStopped = 207,
		/// <summary>
		/// Raised by a media stream when the IMFMediaSource::Stop method completes asynchronously.
		/// </summary>
		MEStreamStopped = 208,
		/// <summary>
		/// Raised by a media source when the IMFMediaSource::Pause method completes asynchronously.
		/// </summary>
		MESourcePaused = 209,
		/// <summary>
		/// Raised by a media stream when the IMFMediaSource::Pause method completes asynchronously.
		/// </summary>
		MEStreamPaused = 210,
		/// <summary>
		/// Raised by a media source when a presentation ends.
		/// </summary>
		MEEndOfPresentation = 211,
		/// <summary>
		/// Raised by a media stream when the stream ends.
		/// </summary>
		MEEndOfStream = 212,
		/// <summary>
		/// Raised when a media stream delivers a new sample.
		/// </summary>
		MEMediaSample = 213,
		/// <summary>
		/// Signals that a media stream does not have data available at a specified time.
		/// </summary>
		MEStreamTick = 214,
		/// <summary>
		/// Raised by a media stream when it starts or stops thinning the stream.
		/// </summary>
		MEStreamThinMode = 215,
		/// <summary>
		/// Raised by a media stream when the media type of the stream changes.
		/// </summary>
		MEStreamFormatChanged = 216,
		/// <summary>
		/// Raised by a media source when the playback rate changes.
		/// </summary>
		MESourceRateChanged = 217,
		/// <summary>
		/// Raised by the sequencer source when a segment is completed and is followed by another segment.
		/// </summary>
		MEEndOfPresentationSegment = 218,
		/// <summary>
		/// Raised by a media source when the source's characteristics change.
		/// </summary>
		MESourceCharacteristicsChanged = 219,
		/// <summary>
		/// Raised by a media source to request a new playback rate.
		/// </summary>
		MESourceRateChangeRequested = 220,
		/// <summary>
		/// Raised by a media source when it updates its metadata.
		/// </summary>
		MESourceMetadataChanged = 221,
		/// <summary>
		/// Raised by the sequencer source when the IMFSequencerSource::UpdateTopology method completes asynchronously.
		/// </summary>
		MESequencerSourceTopologyUpdated = 222,
		/// <summary>
		/// Sink Unknown
		/// </summary>
		MESinkUnknown = 300,
		/// <summary>
		/// Raised by a stream sink when it completes the transition to the running state.
		/// </summary>
		MEStreamSinkStarted = 301,
		/// <summary>
		/// Raised by a stream sink when it completes the transition to the stopped state.
		/// </summary>
		MEStreamSinkStopped = 302,
		/// <summary>
		/// Raised by a stream sink when it completes the transition to the paused state.
		/// </summary>
		MEStreamSinkPaused = 303,
		/// <summary>
		/// Raised by a stream sink when the rate has changed.
		/// </summary>
		MEStreamSinkRateChanged = 304,
		/// <summary>
		/// Raised by a stream sink to request a new media sample from the pipeline.
		/// </summary>
		MEStreamSinkRequestSample = 305,
		/// <summary>
		/// Raised by a stream sink after the IMFStreamSink::PlaceMarker method is called.
		/// </summary>
		MEStreamSinkMarker = 306,
		/// <summary>
		/// Raised by a stream sink when the stream has received enough preroll data to begin rendering.
		/// </summary>
		MEStreamSinkPrerolled = 307,
		/// <summary>
		/// Raised by a stream sink when it completes a scrubbing request.
		/// </summary>
		MEStreamSinkScrubSampleComplete = 308,
		/// <summary>
		/// Raised by a stream sink when the sink's media type is no longer valid.
		/// </summary>
		MEStreamSinkFormatChanged = 309,
		/// <summary>
		/// Raised by the stream sinks of the EVR if the video device changes.
		/// </summary>
		MEStreamSinkDeviceChanged = 310,
		/// <summary>
		/// Provides feedback about playback quality to the quality manager.
		/// </summary>
		MEQualityNotify = 311,
		/// <summary>
		/// Raised when a media sink becomes invalid.
		/// </summary>
		MESinkInvalidated = 312,
		/// <summary>
		/// The audio session display name changed.
		/// </summary>
		MEAudioSessionNameChanged = 313,
		/// <summary>
		/// The volume or mute state of the audio session changed
		/// </summary>
		MEAudioSessionVolumeChanged = 314,
		/// <summary>
		/// The audio device was removed.
		/// </summary>
		MEAudioSessionDeviceRemoved = 315,
		/// <summary>
		/// The Windows audio server system was shut down.
		/// </summary>
		MEAudioSessionServerShutdown = 316,
		/// <summary>
		/// The grouping parameters changed for the audio session.
		/// </summary>
		MEAudioSessionGroupingParamChanged = 317,
		/// <summary>
		/// The audio session icon changed.
		/// </summary>
		MEAudioSessionIconChanged = 318,
		/// <summary>
		/// The default audio format for the audio device changed.
		/// </summary>
		MEAudioSessionFormatChanged = 319,
		/// <summary>
		/// The audio session was disconnected from a Windows Terminal Services session
		/// </summary>
		MEAudioSessionDisconnected = 320,
		/// <summary>
		/// The audio session was preempted by an exclusive-mode connection.
		/// </summary>
		MEAudioSessionExclusiveModeOverride = 321,
		/// <summary>
		/// Trust Unknown
		/// </summary>
		METrustUnknown = 400,
		/// <summary>
		/// The output policy for a stream changed.
		/// </summary>
		MEPolicyChanged = 401,
		/// <summary>
		/// Content protection message
		/// </summary>
		MEContentProtectionMessage = 402,
		/// <summary>
		/// The IMFOutputTrustAuthority::SetPolicy method completed.
		/// </summary>
		MEPolicySet = 403,
		/// <summary>
		/// DRM License Backup Completed
		/// </summary>
		MEWMDRMLicenseBackupCompleted = 500,
		/// <summary>
		/// DRM License Backup Progress
		/// </summary>
		MEWMDRMLicenseBackupProgress = 501,
		/// <summary>
		/// DRM License Restore Completed
		/// </summary>
		MEWMDRMLicenseRestoreCompleted = 502,
		/// <summary>
		/// DRM License Restore Progress
		/// </summary>
		MEWMDRMLicenseRestoreProgress = 503,
		/// <summary>
		/// DRM License Acquisition Completed
		/// </summary>
		MEWMDRMLicenseAcquisitionCompleted = 506,
		/// <summary>
		/// DRM Individualization Completed
		/// </summary>
		MEWMDRMIndividualizationCompleted = 508,
		/// <summary>
		/// DRM Individualization Progress
		/// </summary>
		MEWMDRMIndividualizationProgress = 513,
		/// <summary>
		/// DRM Proximity Completed
		/// </summary>
		MEWMDRMProximityCompleted = 514,
		/// <summary>
		/// DRM License Store Cleaned
		/// </summary>
		MEWMDRMLicenseStoreCleaned = 515,
		/// <summary>
		/// DRM Revocation Download Completed
		/// </summary>
		MEWMDRMRevocationDownloadCompleted = 516,
		/// <summary>
		/// Transform Unknown
		/// </summary>
		METransformUnknown = 600,
		/// <summary>
		/// Sent by an asynchronous MFT to request a new input sample.
		/// </summary>
		METransformNeedInput = 601,
		/// <summary>
		/// Sent by an asynchronous MFT when new output data is available from the MFT.
		/// </summary>
		METransformHaveOutput = 602,
		/// <summary>
		/// Sent by an asynchronous Media Foundation transform (MFT) when a drain operation is complete.
		/// </summary>
		METransformDrainComplete = 603,
		/// <summary>
		/// Sent by an asynchronous MFT in response to an MFT_MESSAGE_COMMAND_MARKER message.
		/// </summary>
		METransformMarker = 604
	}

	/// <summary>
	/// Main interface for using Media Foundation with NAudio
	/// </summary>
	public static class MediaFoundationApi
	{
		private static bool initialized;

		/// <summary>
		/// initializes MediaFoundation - only needs to be called once per process
		/// </summary>
		public static void Startup()
		{
			if (!initialized)
			{
				int num = 2;
				OperatingSystem oSVersion = Environment.OSVersion;
				if (oSVersion.Version.Major == 6 && oSVersion.Version.Minor == 0)
				{
					num = 1;
				}
				MediaFoundationInterop.MFStartup((num << 16) | 0x70);
				initialized = true;
			}
		}

		/// <summary>
		/// Enumerate the installed MediaFoundation transforms in the specified category
		/// </summary>
		/// <param name="category">A category from MediaFoundationTransformCategories</param>
		/// <returns></returns>
		public static IEnumerable<IMFActivate> EnumerateTransforms(Guid category)
		{
			MediaFoundationInterop.MFTEnumEx(category, _MFT_ENUM_FLAG.MFT_ENUM_FLAG_ALL, null, null, out var interfacesPointer, out var pcMFTActivate);
			IMFActivate[] array = new IMFActivate[pcMFTActivate];
			for (int i = 0; i < pcMFTActivate; i++)
			{
				IntPtr pUnk = Marshal.ReadIntPtr(new IntPtr(interfacesPointer.ToInt64() + i * Marshal.SizeOf(interfacesPointer)));
				array[i] = (IMFActivate)Marshal.GetObjectForIUnknown(pUnk);
			}
			IMFActivate[] array2 = array;
			for (int j = 0; j < array2.Length; j++)
			{
				yield return array2[j];
			}
			Marshal.FreeCoTaskMem(interfacesPointer);
		}

		/// <summary>
		/// uninitializes MediaFoundation
		/// </summary>
		public static void Shutdown()
		{
			if (initialized)
			{
				MediaFoundationInterop.MFShutdown();
				initialized = false;
			}
		}

		/// <summary>
		/// Creates a Media type
		/// </summary>
		public static IMFMediaType CreateMediaType()
		{
			MediaFoundationInterop.MFCreateMediaType(out var ppMFType);
			return ppMFType;
		}

		/// <summary>
		/// Creates a media type from a WaveFormat
		/// </summary>
		public static IMFMediaType CreateMediaTypeFromWaveFormat(WaveFormat waveFormat)
		{
			IMFMediaType iMFMediaType = CreateMediaType();
			try
			{
				MediaFoundationInterop.MFInitMediaTypeFromWaveFormatEx(iMFMediaType, waveFormat, Marshal.SizeOf(waveFormat));
				return iMFMediaType;
			}
			catch (Exception)
			{
				Marshal.ReleaseComObject(iMFMediaType);
				throw;
			}
		}

		/// <summary>
		/// Creates a memory buffer of the specified size
		/// </summary>
		/// <param name="bufferSize">Memory buffer size in bytes</param>
		/// <returns>The memory buffer</returns>
		public static IMFMediaBuffer CreateMemoryBuffer(int bufferSize)
		{
			MediaFoundationInterop.MFCreateMemoryBuffer(bufferSize, out var ppBuffer);
			return ppBuffer;
		}

		/// <summary>
		/// Creates a sample object
		/// </summary>
		/// <returns>The sample object</returns>
		public static IMFSample CreateSample()
		{
			MediaFoundationInterop.MFCreateSample(out var ppIMFSample);
			return ppIMFSample;
		}

		/// <summary>
		/// Creates a new attributes store
		/// </summary>
		/// <param name="initialSize">Initial size</param>
		/// <returns>The attributes store</returns>
		public static IMFAttributes CreateAttributes(int initialSize)
		{
			MediaFoundationInterop.MFCreateAttributes(out var ppMFAttributes, initialSize);
			return ppMFAttributes;
		}

		/// <summary>
		/// Creates a media foundation byte stream based on a stream object
		/// (usable with WinRT streams)
		/// </summary>
		/// <param name="stream">The input stream</param>
		/// <returns>A media foundation byte stream</returns>
		public static IMFByteStream CreateByteStream(object stream)
		{
			if (stream is IStream)
			{
				MediaFoundationInterop.MFCreateMFByteStreamOnStream(stream as IStream, out var ppByteStream);
				return ppByteStream;
			}
			throw new ArgumentException("Stream must be IStream in desktop apps");
		}

		/// <summary>
		/// Creates a source reader based on a byte stream
		/// </summary>
		/// <param name="byteStream">The byte stream</param>
		/// <returns>A media foundation source reader</returns>
		public static IMFSourceReader CreateSourceReaderFromByteStream(IMFByteStream byteStream)
		{
			MediaFoundationInterop.MFCreateSourceReaderFromByteStream(byteStream, null, out var ppSourceReader);
			return ppSourceReader;
		}
	}

	/// <summary>
	/// Media Foundation attribute guids
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/ms696989%28v=vs.85%29.aspx
	/// </summary>
	public static class MediaFoundationAttributes
	{
		/// <summary>
		/// Specifies whether an MFT performs asynchronous processing.
		/// </summary>
		public static readonly Guid MF_TRANSFORM_ASYNC = new Guid("f81a699a-649a-497d-8c73-29f8fed6ad7a");

		/// <summary>
		/// Enables the use of an asynchronous MFT.
		/// </summary>
		public static readonly Guid MF_TRANSFORM_ASYNC_UNLOCK = new Guid("e5666d6b-3422-4eb6-a421-da7db1f8e207");

		/// <summary>
		/// Contains flags for an MFT activation object.
		/// </summary>
		[FieldDescription("Transform Flags")]
		public static readonly Guid MF_TRANSFORM_FLAGS_Attribute = new Guid("9359bb7e-6275-46c4-a025-1c01e45f1a86");

		/// <summary>
		/// Specifies the category for an MFT.
		/// </summary>
		[FieldDescription("Transform Category")]
		public static readonly Guid MF_TRANSFORM_CATEGORY_Attribute = new Guid("ceabba49-506d-4757-a6ff-66c184987e4e");

		/// <summary>
		/// Contains the class identifier (CLSID) of an MFT.
		/// </summary>
		[FieldDescription("Class identifier")]
		public static readonly Guid MFT_TRANSFORM_CLSID_Attribute = new Guid("6821c42b-65a4-4e82-99bc-9a88205ecd0c");

		/// <summary>
		/// Specifies the container type of an encoded file. The container types are supported by Media Foundation.
		/// </summary>
		[FieldDescription("Container type")]
		public static readonly Guid MF_TRANSCODE_CONTAINERTYPE = new Guid(353366591, 19132, 18315, 172, 79, 225, 145, 111, 186, 28, 202);

		/// <summary>
		/// Contains the registered input types for a Media Foundation transform (MFT).
		/// </summary>
		[FieldDescription("Input Types")]
		public static readonly Guid MFT_INPUT_TYPES_Attributes = new Guid("4276c9b1-759d-4bf3-9cd0-0d723d138f96");

		/// <summary>
		/// Contains the registered output types for a Media Foundation transform (MFT).
		/// </summary>
		[FieldDescription("Output Types")]
		public static readonly Guid MFT_OUTPUT_TYPES_Attributes = new Guid("8eae8cf3-a44f-4306-ba5c-bf5dda242818");

		/// <summary>
		/// Contains the symbolic link for a hardware-based MFT.
		/// </summary>
		public static readonly Guid MFT_ENUM_HARDWARE_URL_Attribute = new Guid("2fb866ac-b078-4942-ab6c-003d05cda674");

		/// <summary>
		/// Contains the display name for a hardware-based MFT.
		/// </summary>
		[FieldDescription("Name")]
		public static readonly Guid MFT_FRIENDLY_NAME_Attribute = new Guid("314ffbae-5b41-4c95-9c19-4e7d586face3");

		/// <summary>
		/// Contains a pointer to the stream attributes of the connected stream on a hardware-based MFT.
		/// </summary>
		public static readonly Guid MFT_CONNECTED_STREAM_ATTRIBUTE = new Guid("71eeb820-a59f-4de2-bcec-38db1dd611a4");

		/// <summary>
		/// Specifies whether a hardware-based MFT is connected to another hardware-based MFT.
		/// </summary>
		public static readonly Guid MFT_CONNECTED_TO_HW_STREAM = new Guid("34e6e728-06d6-4491-a553-4795650db912");

		/// <summary>
		/// Specifies the preferred output format for an encoder.
		/// </summary>
		[FieldDescription("Preferred Output Format")]
		public static readonly Guid MFT_PREFERRED_OUTPUTTYPE_Attribute = new Guid("7e700499-396a-49ee-b1b4-f628021e8c9d");

		/// <summary>
		/// Specifies whether an MFT is registered only in the application's process.
		/// </summary>
		public static readonly Guid MFT_PROCESS_LOCAL_Attribute = new Guid("543186e4-4649-4e65-b588-4aa352aff379");

		/// <summary>
		/// Contains configuration properties for an encoder.
		/// </summary>
		public static readonly Guid MFT_PREFERRED_ENCODER_PROFILE = new Guid("53004909-1ef5-46d7-a18e-5a75f8b5905f");

		/// <summary>
		/// Specifies whether a hardware device source uses the system time for time stamps.
		/// </summary>
		public static readonly Guid MFT_HW_TIMESTAMP_WITH_QPC_Attribute = new Guid("8d030fb8-cc43-4258-a22e-9210bef89be4");

		/// <summary>
		/// Contains an IMFFieldOfUseMFTUnlock pointer, which can be used to unlock the MFT.
		/// </summary>
		public static readonly Guid MFT_FIELDOFUSE_UNLOCK_Attribute = new Guid("8ec2e9fd-9148-410d-831e-702439461a8e");

		/// <summary>
		/// Contains the merit value of a hardware codec.
		/// </summary>
		public static readonly Guid MFT_CODEC_MERIT_Attribute = new Guid("88a7cb15-7b07-4a34-9128-e64c6703c4d3");

		/// <summary>
		/// Specifies whether a decoder is optimized for transcoding rather than for playback.
		/// </summary>
		public static readonly Guid MFT_ENUM_TRANSCODE_ONLY_ATTRIBUTE = new Guid("111ea8cd-b62a-4bdb-89f6-67ffcdc2458b");

		/// <summary>
		/// Contains a pointer to the proxy object for the application's presentation descriptor.
		/// </summary>
		[FieldDescription("PMP Host Context")]
		public static readonly Guid MF_PD_PMPHOST_CONTEXT = new Guid("6c990d31-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Contains a pointer to the presentation descriptor from the protected media path (PMP).
		/// </summary>
		[FieldDescription("App Context")]
		public static readonly Guid MF_PD_APP_CONTEXT = new Guid("6c990d32-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies the duration of a presentation, in 100-nanosecond units.
		/// </summary>
		[FieldDescription("Duration")]
		public static readonly Guid MF_PD_DURATION = new Guid("6c990d33-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies the total size of the source file, in bytes. 
		/// </summary>
		[FieldDescription("Total File Size")]
		public static readonly Guid MF_PD_TOTAL_FILE_SIZE = new Guid("6c990d34-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies the audio encoding bit rate for the presentation, in bits per second.
		/// </summary>
		[FieldDescription("Audio encoding bitrate")]
		public static readonly Guid MF_PD_AUDIO_ENCODING_BITRATE = new Guid("6c990d35-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies the video encoding bit rate for the presentation, in bits per second.
		/// </summary>
		[FieldDescription("Video Encoding Bitrate")]
		public static readonly Guid MF_PD_VIDEO_ENCODING_BITRATE = new Guid("6c990d36-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies the MIME type of the content.
		/// </summary>
		[FieldDescription("MIME Type")]
		public static readonly Guid MF_PD_MIME_TYPE = new Guid("6c990d37-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies when a presentation was last modified.
		/// </summary>
		[FieldDescription("Last Modified Time")]
		public static readonly Guid MF_PD_LAST_MODIFIED_TIME = new Guid("6c990d38-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// The identifier of the playlist element in the presentation.
		/// </summary>
		[FieldDescription("Element ID")]
		public static readonly Guid MF_PD_PLAYBACK_ELEMENT_ID = new Guid("6c990d39-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Contains the preferred RFC 1766 language of the media source.
		/// </summary>
		[FieldDescription("Preferred Language")]
		public static readonly Guid MF_PD_PREFERRED_LANGUAGE = new Guid("6c990d3a-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// The time at which the presentation must begin, relative to the start of the media source.
		/// </summary>
		[FieldDescription("Playback boundary time")]
		public static readonly Guid MF_PD_PLAYBACK_BOUNDARY_TIME = new Guid("6c990d3b-bb8e-477a-8598-0d5d96fcd88a");

		/// <summary>
		/// Specifies whether the audio streams in the presentation have a variable bit rate.
		/// </summary>
		[FieldDescription("Audio is variable bitrate")]
		public static readonly Guid MF_PD_AUDIO_ISVARIABLEBITRATE = new Guid("33026ee0-e387-4582-ae0a-34a2ad3baa18");

		/// <summary>
		/// Media type Major Type
		/// </summary>
		[FieldDescription("Major Media Type")]
		public static readonly Guid MF_MT_MAJOR_TYPE = new Guid("48eba18e-f8c9-4687-bf11-0a74c9f96a8f");

		/// <summary>
		/// Media Type subtype
		/// </summary>
		[FieldDescription("Media Subtype")]
		public static readonly Guid MF_MT_SUBTYPE = new Guid("f7e34c9a-42e8-4714-b74b-cb29d72c35e5");

		/// <summary>
		/// Audio block alignment
		/// </summary>
		[FieldDescription("Audio block alignment")]
		public static readonly Guid MF_MT_AUDIO_BLOCK_ALIGNMENT = new Guid("322de230-9eeb-43bd-ab7a-ff412251541d");

		/// <summary>
		/// Audio average bytes per second
		/// </summary>
		[FieldDescription("Audio average bytes per second")]
		public static readonly Guid MF_MT_AUDIO_AVG_BYTES_PER_SECOND = new Guid("1aab75c8-cfef-451c-ab95-ac034b8e1731");

		/// <summary>
		/// Audio number of channels
		/// </summary>
		[FieldDescription("Audio number of channels")]
		public static readonly Guid MF_MT_AUDIO_NUM_CHANNELS = new Guid("37e48bf5-645e-4c5b-89de-ada9e29b696a");

		/// <summary>
		/// Audio samples per second
		/// </summary>
		[FieldDescription("Audio samples per second")]
		public static readonly Guid MF_MT_AUDIO_SAMPLES_PER_SECOND = new Guid("5faeeae7-0290-4c31-9e8a-c534f68d9dba");

		/// <summary>
		/// Audio bits per sample
		/// </summary>
		[FieldDescription("Audio bits per sample")]
		public static readonly Guid MF_MT_AUDIO_BITS_PER_SAMPLE = new Guid("f2deb57f-40fa-4764-aa33-ed4f2d1ff669");

		/// <summary>
		/// Enables the source reader or sink writer to use hardware-based Media Foundation transforms (MFTs).
		/// </summary>
		[FieldDescription("Enable Hardware Transforms")]
		public static readonly Guid MF_READWRITE_ENABLE_HARDWARE_TRANSFORMS = new Guid("a634a91c-822b-41b9-a494-4de4643612b0");

		/// <summary>
		/// Specifies whether the sink writer limits the rate of incoming data.
		/// </summary>
		[FieldDescription("Disable Sink Writer Throttling")]
		public static readonly Guid MF_SINK_WRITER_DISABLE_THROTTLING = new Guid("08b845d8-2b74-4afe-9d53-be16d2d5ae4f");

		/// <summary>
		/// Contains additional format data for a media type. 
		/// </summary>
		[FieldDescription("User data")]
		public static readonly Guid MF_MT_USER_DATA = new Guid("b6bc765f-4c3b-40a4-bd51-2535b66fe09d");

		/// <summary>
		/// Specifies for a media type whether each sample is independent of the other samples in the stream. 
		/// </summary>
		[FieldDescription("All samples independent")]
		public static readonly Guid MF_MT_ALL_SAMPLES_INDEPENDENT = new Guid("c9173739-5e56-461c-b713-46fb995cb95f");

		/// <summary>
		/// Specifies for a media type whether the samples have a fixed size. 
		/// </summary>
		[FieldDescription("Fixed size samples")]
		public static readonly Guid MF_MT_FIXED_SIZE_SAMPLES = new Guid("b8ebefaf-b718-4e04-b0a9-116775e3321b");

		/// <summary>
		/// Contains a DirectShow format GUID for a media type. 
		/// </summary>
		[FieldDescription("DirectShow Format Guid")]
		public static readonly Guid MF_MT_AM_FORMAT_TYPE = new Guid("73d1072d-1870-4174-a063-29ff4ff6c11e");

		/// <summary>
		/// Specifies the preferred legacy format structure to use when converting an audio media type. 
		/// </summary>
		[FieldDescription("Preferred legacy format structure")]
		public static readonly Guid MF_MT_AUDIO_PREFER_WAVEFORMATEX = new Guid("a901aaba-e037-458a-bdf6-545be2074042");

		/// <summary>
		/// Specifies for a media type whether the media data is compressed. 
		/// </summary>
		[FieldDescription("Is Compressed")]
		public static readonly Guid MF_MT_COMPRESSED = new Guid("3afd0cee-18f2-4ba5-a110-8bea502e1f92");

		/// <summary>
		/// Approximate data rate of the video stream, in bits per second, for a video media type. 
		/// </summary>
		[FieldDescription("Average bitrate")]
		public static readonly Guid MF_MT_AVG_BITRATE = new Guid("20332624-fb0d-4d9e-bd0d-cbf6786c102e");

		/// <summary>
		/// Specifies the payload type of an Advanced Audio Coding (AAC) stream.
		/// 0 - The stream contains raw_data_block elements only
		/// 1 - Audio Data Transport Stream (ADTS). The stream contains an adts_sequence, as defined by MPEG-2.
		/// 2 - Audio Data Interchange Format (ADIF). The stream contains an adif_sequence, as defined by MPEG-2.
		/// 3 - The stream contains an MPEG-4 audio transport stream with a synchronization layer (LOAS) and a multiplex layer (LATM).
		/// </summary>
		[FieldDescription("AAC payload type")]
		public static readonly Guid MF_MT_AAC_PAYLOAD_TYPE = new Guid("bfbabe79-7434-4d1c-94f0-72a3b9e17188");

		/// <summary>
		/// Specifies the audio profile and level of an Advanced Audio Coding (AAC) stream, as defined by ISO/IEC 14496-3.
		/// </summary>
		[FieldDescription("AAC Audio Profile Level Indication")]
		public static readonly Guid MF_MT_AAC_AUDIO_PROFILE_LEVEL_INDICATION = new Guid("7632f0e6-9538-4d61-acda-ea29c8c14456");
	}

	/// <summary>
	/// Media Foundation Errors
	///
	/// </summary>
	/// <remarks>
	///  RANGES
	///  14000 - 14999 = General Media Foundation errors
	///  15000 - 15999 = ASF parsing errors
	///  16000 - 16999 = Media Source errors
	///  17000 - 17999 = MEDIAFOUNDATION Network Error Events
	///  18000 - 18999 = MEDIAFOUNDATION WMContainer Error Events
	///  19000 - 19999 = MEDIAFOUNDATION Media Sink Error Events
	///  20000 - 20999 = Renderer errors
	///  21000 - 21999 = Topology Errors
	///  25000 - 25999 = Timeline Errors
	///  26000 - 26999 = Unused
	///  28000 - 28999 = Transform errors
	///  29000 - 29999 = Content Protection errors
	///  40000 - 40999 = Clock errors
	///  41000 - 41999 = MF Quality Management Errors
	///  42000 - 42999 = MF Transcode API Errors
	/// </remarks>
	public static class MediaFoundationErrors
	{
		/// MessageId: MF_E_PLATFORM_NOT_INITIALIZED
		///
		/// MessageText:
		///
		/// Platform not initialized. Please call MFStartup().%0
		public const int MF_E_PLATFORM_NOT_INITIALIZED = -1072875856;

		/// MessageId: MF_E_BUFFERTOOSMALL
		///
		/// MessageText:
		///
		/// The buffer was too small to carry out the requested action.%0
		public const int MF_E_BUFFERTOOSMALL = -1072875855;

		/// MessageId: MF_E_INVALIDREQUEST
		///
		/// MessageText:
		///
		/// The request is invalid in the current state.%0
		public const int MF_E_INVALIDREQUEST = -1072875854;

		/// MessageId: MF_E_INVALIDSTREAMNUMBER
		///
		/// MessageText:
		///
		/// The stream number provided was invalid.%0
		public const int MF_E_INVALIDSTREAMNUMBER = -1072875853;

		/// MessageId: MF_E_INVALIDMEDIATYPE
		///
		/// MessageText:
		///
		/// The data specified for the media type is invalid, inconsistent, or not supported by this object.%0
		public const int MF_E_INVALIDMEDIATYPE = -1072875852;

		/// MessageId: MF_E_NOTACCEPTING
		///
		/// MessageText:
		///
		/// The callee is currently not accepting further input.%0
		public const int MF_E_NOTACCEPTING = -1072875851;

		/// MessageId: MF_E_NOT_INITIALIZED
		///
		/// MessageText:
		///
		/// This object needs to be initialized before the requested operation can be carried out.%0
		public const int MF_E_NOT_INITIALIZED = -1072875850;

		/// MessageId: MF_E_UNSUPPORTED_REPRESENTATION
		///
		/// MessageText:
		///
		/// The requested representation is not supported by this object.%0
		public const int MF_E_UNSUPPORTED_REPRESENTATION = -1072875849;

		/// MessageId: MF_E_NO_MORE_TYPES
		///
		/// MessageText:
		///
		/// An object ran out of media types to suggest therefore the requested chain of streaming objects cannot be completed.%0
		public const int MF_E_NO_MORE_TYPES = -1072875847;

		/// MessageId: MF_E_UNSUPPORTED_SERVICE
		///
		/// MessageText:
		///
		/// The object does not support the specified service.%0
		public const int MF_E_UNSUPPORTED_SERVICE = -1072875846;

		/// MessageId: MF_E_UNEXPECTED
		///
		/// MessageText:
		///
		/// An unexpected error has occurred in the operation requested.%0
		public const int MF_E_UNEXPECTED = -1072875845;

		/// MessageId: MF_E_INVALIDNAME
		///
		/// MessageText:
		///
		/// Invalid name.%0
		public const int MF_E_INVALIDNAME = -1072875844;

		/// MessageId: MF_E_INVALIDTYPE
		///
		/// MessageText:
		///
		/// Invalid type.%0
		public const int MF_E_INVALIDTYPE = -1072875843;

		/// MessageId: MF_E_INVALID_FILE_FORMAT
		///
		/// MessageText:
		///
		/// The file does not conform to the relevant file format specification.
		public const int MF_E_INVALID_FILE_FORMAT = -1072875842;

		/// MessageId: MF_E_INVALIDINDEX
		///
		/// MessageText:
		///
		/// Invalid index.%0
		public const int MF_E_INVALIDINDEX = -1072875841;

		/// MessageId: MF_E_INVALID_TIMESTAMP
		///
		/// MessageText:
		///
		/// An invalid timestamp was given.%0
		public const int MF_E_INVALID_TIMESTAMP = -1072875840;

		/// MessageId: MF_E_UNSUPPORTED_SCHEME
		///
		/// MessageText:
		///
		/// The scheme of the given URL is unsupported.%0
		public const int MF_E_UNSUPPORTED_SCHEME = -1072875837;

		/// MessageId: MF_E_UNSUPPORTED_BYTESTREAM_TYPE
		///
		/// MessageText:
		///
		/// The byte stream type of the given URL is unsupported.%0
		public const int MF_E_UNSUPPORTED_BYTESTREAM_TYPE = -1072875836;

		/// MessageId: MF_E_UNSUPPORTED_TIME_FORMAT
		///
		/// MessageText:
		///
		/// The given time format is unsupported.%0
		public const int MF_E_UNSUPPORTED_TIME_FORMAT = -1072875835;

		/// MessageId: MF_E_NO_SAMPLE_TIMESTAMP
		///
		/// MessageText:
		///
		/// The Media Sample does not have a timestamp.%0
		public const int MF_E_NO_SAMPLE_TIMESTAMP = -1072875832;

		/// MessageId: MF_E_NO_SAMPLE_DURATION
		///
		/// MessageText:
		///
		/// The Media Sample does not have a duration.%0
		public const int MF_E_NO_SAMPLE_DURATION = -1072875831;

		/// MessageId: MF_E_INVALID_STREAM_DATA
		///
		/// MessageText:
		///
		/// The request failed because the data in the stream is corrupt.%0\n.
		public const int MF_E_INVALID_STREAM_DATA = -1072875829;

		/// MessageId: MF_E_RT_UNAVAILABLE
		///
		/// MessageText:
		///
		/// Real time services are not available.%0
		public const int MF_E_RT_UNAVAILABLE = -1072875825;

		/// MessageId: MF_E_UNSUPPORTED_RATE
		///
		/// MessageText:
		///
		/// The specified rate is not supported.%0
		public const int MF_E_UNSUPPORTED_RATE = -1072875824;

		/// MessageId: MF_E_THINNING_UNSUPPORTED
		///
		/// MessageText:
		///
		/// This component does not support stream-thinning.%0
		public const int MF_E_THINNING_UNSUPPORTED = -1072875823;

		/// MessageId: MF_E_REVERSE_UNSUPPORTED
		///
		/// MessageText:
		///
		/// The call failed because no reverse playback rates are available.%0
		public const int MF_E_REVERSE_UNSUPPORTED = -1072875822;

		/// MessageId: MF_E_UNSUPPORTED_RATE_TRANSITION
		///
		/// MessageText:
		///
		/// The requested rate transition cannot occur in the current state.%0
		public const int MF_E_UNSUPPORTED_RATE_TRANSITION = -1072875821;

		/// MessageId: MF_E_RATE_CHANGE_PREEMPTED
		///
		/// MessageText:
		///
		/// The requested rate change has been pre-empted and will not occur.%0
		public const int MF_E_RATE_CHANGE_PREEMPTED = -1072875820;

		/// MessageId: MF_E_NOT_FOUND
		///
		/// MessageText:
		///
		/// The specified object or value does not exist.%0
		public const int MF_E_NOT_FOUND = -1072875819;

		/// MessageId: MF_E_NOT_AVAILABLE
		///
		/// MessageText:
		///
		/// The requested value is not available.%0
		public const int MF_E_NOT_AVAILABLE = -1072875818;

		/// MessageId: MF_E_NO_CLOCK
		///
		/// MessageText:
		///
		/// The specified operation requires a clock and no clock is available.%0
		public const int MF_E_NO_CLOCK = -1072875817;

		/// MessageId: MF_S_MULTIPLE_BEGIN
		///
		/// MessageText:
		///
		/// This callback and state had already been passed in to this event generator earlier.%0
		public const int MF_S_MULTIPLE_BEGIN = 866008;

		/// MessageId: MF_E_MULTIPLE_BEGIN
		///
		/// MessageText:
		///
		/// This callback has already been passed in to this event generator.%0
		public const int MF_E_MULTIPLE_BEGIN = -1072875815;

		/// MessageId: MF_E_MULTIPLE_SUBSCRIBERS
		///
		/// MessageText:
		///
		/// Some component is already listening to events on this event generator.%0
		public const int MF_E_MULTIPLE_SUBSCRIBERS = -1072875814;

		/// MessageId: MF_E_TIMER_ORPHANED
		///
		/// MessageText:
		///
		/// This timer was orphaned before its callback time arrived.%0
		public const int MF_E_TIMER_ORPHANED = -1072875813;

		/// MessageId: MF_E_STATE_TRANSITION_PENDING
		///
		/// MessageText:
		///
		/// A state transition is already pending.%0
		public const int MF_E_STATE_TRANSITION_PENDING = -1072875812;

		/// MessageId: MF_E_UNSUPPORTED_STATE_TRANSITION
		///
		/// MessageText:
		///
		/// The requested state transition is unsupported.%0
		public const int MF_E_UNSUPPORTED_STATE_TRANSITION = -1072875811;

		/// MessageId: MF_E_UNRECOVERABLE_ERROR_OCCURRED
		///
		/// MessageText:
		///
		/// An unrecoverable error has occurred.%0
		public const int MF_E_UNRECOVERABLE_ERROR_OCCURRED = -1072875810;

		/// MessageId: MF_E_SAMPLE_HAS_TOO_MANY_BUFFERS
		///
		/// MessageText:
		///
		/// The provided sample has too many buffers.%0
		public const int MF_E_SAMPLE_HAS_TOO_MANY_BUFFERS = -1072875809;

		/// MessageId: MF_E_SAMPLE_NOT_WRITABLE
		///
		/// MessageText:
		///
		/// The provided sample is not writable.%0
		public const int MF_E_SAMPLE_NOT_WRITABLE = -1072875808;

		/// MessageId: MF_E_INVALID_KEY
		///
		/// MessageText:
		///
		/// The specified key is not valid.
		public const int MF_E_INVALID_KEY = -1072875806;

		/// MessageId: MF_E_BAD_STARTUP_VERSION
		///
		/// MessageText:
		///
		/// You are calling MFStartup with the wrong MF_VERSION. Mismatched bits?
		public const int MF_E_BAD_STARTUP_VERSION = -1072875805;

		/// MessageId: MF_E_UNSUPPORTED_CAPTION
		///
		/// MessageText:
		///
		/// The caption of the given URL is unsupported.%0
		public const int MF_E_UNSUPPORTED_CAPTION = -1072875804;

		/// MessageId: MF_E_INVALID_POSITION
		///
		/// MessageText:
		///
		/// The operation on the current offset is not permitted.%0
		public const int MF_E_INVALID_POSITION = -1072875803;

		/// MessageId: MF_E_ATTRIBUTENOTFOUND
		///
		/// MessageText:
		///
		/// The requested attribute was not found.%0
		public const int MF_E_ATTRIBUTENOTFOUND = -1072875802;

		/// MessageId: MF_E_PROPERTY_TYPE_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// The specified property type is not allowed in this context.%0
		public const int MF_E_PROPERTY_TYPE_NOT_ALLOWED = -1072875801;

		/// MessageId: MF_E_PROPERTY_TYPE_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// The specified property type is not supported.%0
		public const int MF_E_PROPERTY_TYPE_NOT_SUPPORTED = -1072875800;

		/// MessageId: MF_E_PROPERTY_EMPTY
		///
		/// MessageText:
		///
		/// The specified property is empty.%0
		public const int MF_E_PROPERTY_EMPTY = -1072875799;

		/// MessageId: MF_E_PROPERTY_NOT_EMPTY
		///
		/// MessageText:
		///
		/// The specified property is not empty.%0
		public const int MF_E_PROPERTY_NOT_EMPTY = -1072875798;

		/// MessageId: MF_E_PROPERTY_VECTOR_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// The vector property specified is not allowed in this context.%0
		public const int MF_E_PROPERTY_VECTOR_NOT_ALLOWED = -1072875797;

		/// MessageId: MF_E_PROPERTY_VECTOR_REQUIRED
		///
		/// MessageText:
		///
		/// A vector property is required in this context.%0
		public const int MF_E_PROPERTY_VECTOR_REQUIRED = -1072875796;

		/// MessageId: MF_E_OPERATION_CANCELLED
		///
		/// MessageText:
		///
		/// The operation is cancelled.%0
		public const int MF_E_OPERATION_CANCELLED = -1072875795;

		/// MessageId: MF_E_BYTESTREAM_NOT_SEEKABLE
		///
		/// MessageText:
		///
		/// The provided bytestream was expected to be seekable and it is not.%0
		public const int MF_E_BYTESTREAM_NOT_SEEKABLE = -1072875794;

		/// MessageId: MF_E_DISABLED_IN_SAFEMODE
		///
		/// MessageText:
		///
		/// The Media Foundation platform is disabled when the system is running in Safe Mode.%0
		public const int MF_E_DISABLED_IN_SAFEMODE = -1072875793;

		/// MessageId: MF_E_CANNOT_PARSE_BYTESTREAM
		///
		/// MessageText:
		///
		/// The Media Source could not parse the byte stream.%0
		public const int MF_E_CANNOT_PARSE_BYTESTREAM = -1072875792;

		/// MessageId: MF_E_SOURCERESOLVER_MUTUALLY_EXCLUSIVE_FLAGS
		///
		/// MessageText:
		///
		/// Mutually exclusive flags have been specified to source resolver. This flag combination is invalid.%0
		public const int MF_E_SOURCERESOLVER_MUTUALLY_EXCLUSIVE_FLAGS = -1072875791;

		/// MessageId: MF_E_MEDIAPROC_WRONGSTATE
		///
		/// MessageText:
		///
		/// MediaProc is in the wrong state%0
		public const int MF_E_MEDIAPROC_WRONGSTATE = -1072875790;

		/// MessageId: MF_E_RT_THROUGHPUT_NOT_AVAILABLE
		///
		/// MessageText:
		///
		/// Real time I/O service can not provide requested throughput.%0
		public const int MF_E_RT_THROUGHPUT_NOT_AVAILABLE = -1072875789;

		/// MessageId: MF_E_RT_TOO_MANY_CLASSES
		///
		/// MessageText:
		///
		/// The workqueue cannot be registered with more classes.%0
		public const int MF_E_RT_TOO_MANY_CLASSES = -1072875788;

		/// MessageId: MF_E_RT_WOULDBLOCK
		///
		/// MessageText:
		///
		/// This operation cannot succeed because another thread owns this object.%0
		public const int MF_E_RT_WOULDBLOCK = -1072875787;

		/// MessageId: MF_E_NO_BITPUMP
		///
		/// MessageText:
		///
		/// Internal. Bitpump not found.%0
		public const int MF_E_NO_BITPUMP = -1072875786;

		/// MessageId: MF_E_RT_OUTOFMEMORY
		///
		/// MessageText:
		///
		/// No more RT memory available.%0
		public const int MF_E_RT_OUTOFMEMORY = -1072875785;

		/// MessageId: MF_E_RT_WORKQUEUE_CLASS_NOT_SPECIFIED
		///
		/// MessageText:
		///
		/// An MMCSS class has not been set for this work queue.%0
		public const int MF_E_RT_WORKQUEUE_CLASS_NOT_SPECIFIED = -1072875784;

		/// MessageId: MF_E_INSUFFICIENT_BUFFER
		///
		/// MessageText:
		///
		/// Insufficient memory for response.%0
		public const int MF_E_INSUFFICIENT_BUFFER = -1072860816;

		/// MessageId: MF_E_CANNOT_CREATE_SINK
		///
		/// MessageText:
		///
		/// Activate failed to create mediasink. Call OutputNode::GetUINT32(MF_TOPONODE_MAJORTYPE) for more information. %0
		public const int MF_E_CANNOT_CREATE_SINK = -1072875782;

		/// MessageId: MF_E_BYTESTREAM_UNKNOWN_LENGTH
		///
		/// MessageText:
		///
		/// The length of the provided bytestream is unknown.%0
		public const int MF_E_BYTESTREAM_UNKNOWN_LENGTH = -1072875781;

		/// MessageId: MF_E_SESSION_PAUSEWHILESTOPPED
		///
		/// MessageText:
		///
		/// The media session cannot pause from a stopped state.%0
		public const int MF_E_SESSION_PAUSEWHILESTOPPED = -1072875780;

		/// MessageId: MF_S_ACTIVATE_REPLACED
		///
		/// MessageText:
		///
		/// The activate could not be created in the remote process for some reason it was replaced with empty one.%0
		public const int MF_S_ACTIVATE_REPLACED = 866045;

		/// MessageId: MF_E_FORMAT_CHANGE_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// The data specified for the media type is supported, but would require a format change, which is not supported by this object.%0
		public const int MF_E_FORMAT_CHANGE_NOT_SUPPORTED = -1072875778;

		/// MessageId: MF_E_INVALID_WORKQUEUE
		///
		/// MessageText:
		///
		/// The operation failed because an invalid combination of workqueue ID and flags was specified.%0
		public const int MF_E_INVALID_WORKQUEUE = -1072875777;

		/// MessageId: MF_E_DRM_UNSUPPORTED
		///
		/// MessageText:
		///
		/// No DRM support is available.%0
		public const int MF_E_DRM_UNSUPPORTED = -1072875776;

		/// MessageId: MF_E_UNAUTHORIZED
		///
		/// MessageText:
		///
		/// This operation is not authorized.%0
		public const int MF_E_UNAUTHORIZED = -1072875775;

		/// MessageId: MF_E_OUT_OF_RANGE
		///
		/// MessageText:
		///
		/// The value is not in the specified or valid range.%0
		public const int MF_E_OUT_OF_RANGE = -1072875774;

		/// MessageId: MF_E_INVALID_CODEC_MERIT
		///
		/// MessageText:
		///
		/// The registered codec merit is not valid.%0
		public const int MF_E_INVALID_CODEC_MERIT = -1072875773;

		/// MessageId: MF_E_HW_MFT_FAILED_START_STREAMING
		///
		/// MessageText:
		///
		/// Hardware MFT failed to start streaming due to lack of hardware resources.%0
		public const int MF_E_HW_MFT_FAILED_START_STREAMING = -1072875772;

		/// MessageId: MF_S_ASF_PARSEINPROGRESS
		///
		/// MessageText:
		///
		/// Parsing is still in progress and is not yet complete.%0
		public const int MF_S_ASF_PARSEINPROGRESS = 1074608792;

		/// MessageId: MF_E_ASF_PARSINGINCOMPLETE
		///
		/// MessageText:
		///
		/// Not enough data have been parsed to carry out the requested action.%0
		public const int MF_E_ASF_PARSINGINCOMPLETE = -1072874856;

		/// MessageId: MF_E_ASF_MISSINGDATA
		///
		/// MessageText:
		///
		/// There is a gap in the ASF data provided.%0
		public const int MF_E_ASF_MISSINGDATA = -1072874855;

		/// MessageId: MF_E_ASF_INVALIDDATA
		///
		/// MessageText:
		///
		/// The data provided are not valid ASF.%0
		public const int MF_E_ASF_INVALIDDATA = -1072874854;

		/// MessageId: MF_E_ASF_OPAQUEPACKET
		///
		/// MessageText:
		///
		/// The packet is opaque, so the requested information cannot be returned.%0
		public const int MF_E_ASF_OPAQUEPACKET = -1072874853;

		/// MessageId: MF_E_ASF_NOINDEX
		///
		/// MessageText:
		///
		/// The requested operation failed since there is no appropriate ASF index.%0
		public const int MF_E_ASF_NOINDEX = -1072874852;

		/// MessageId: MF_E_ASF_OUTOFRANGE
		///
		/// MessageText:
		///
		/// The value supplied is out of range for this operation.%0
		public const int MF_E_ASF_OUTOFRANGE = -1072874851;

		/// MessageId: MF_E_ASF_INDEXNOTLOADED
		///
		/// MessageText:
		///
		/// The index entry requested needs to be loaded before it can be available.%0
		public const int MF_E_ASF_INDEXNOTLOADED = -1072874850;

		/// MessageId: MF_E_ASF_TOO_MANY_PAYLOADS
		///
		/// MessageText:
		///
		/// The packet has reached the maximum number of payloads.%0
		public const int MF_E_ASF_TOO_MANY_PAYLOADS = -1072874849;

		/// MessageId: MF_E_ASF_UNSUPPORTED_STREAM_TYPE
		///
		/// MessageText:
		///
		/// Stream type is not supported.%0
		public const int MF_E_ASF_UNSUPPORTED_STREAM_TYPE = -1072874848;

		/// MessageId: MF_E_ASF_DROPPED_PACKET
		///
		/// MessageText:
		///
		/// One or more ASF packets were dropped.%0
		public const int MF_E_ASF_DROPPED_PACKET = -1072874847;

		/// MessageId: MF_E_NO_EVENTS_AVAILABLE
		///
		/// MessageText:
		///
		/// There are no events available in the queue.%0
		public const int MF_E_NO_EVENTS_AVAILABLE = -1072873856;

		/// MessageId: MF_E_INVALID_STATE_TRANSITION
		///
		/// MessageText:
		///
		/// A media source cannot go from the stopped state to the paused state.%0
		public const int MF_E_INVALID_STATE_TRANSITION = -1072873854;

		/// MessageId: MF_E_END_OF_STREAM
		///
		/// MessageText:
		///
		/// The media stream cannot process any more samples because there are no more samples in the stream.%0
		public const int MF_E_END_OF_STREAM = -1072873852;

		/// MessageId: MF_E_SHUTDOWN
		///
		/// MessageText:
		///
		/// The request is invalid because Shutdown() has been called.%0
		public const int MF_E_SHUTDOWN = -1072873851;

		/// MessageId: MF_E_MP3_NOTFOUND
		///
		/// MessageText:
		///
		/// The MP3 object was not found.%0
		public const int MF_E_MP3_NOTFOUND = -1072873850;

		/// MessageId: MF_E_MP3_OUTOFDATA
		///
		/// MessageText:
		///
		/// The MP3 parser ran out of data before finding the MP3 object.%0
		public const int MF_E_MP3_OUTOFDATA = -1072873849;

		/// MessageId: MF_E_MP3_NOTMP3
		///
		/// MessageText:
		///
		/// The file is not really a MP3 file.%0
		public const int MF_E_MP3_NOTMP3 = -1072873848;

		/// MessageId: MF_E_MP3_NOTSUPPORTED
		///
		/// MessageText:
		///
		/// The MP3 file is not supported.%0
		public const int MF_E_MP3_NOTSUPPORTED = -1072873847;

		/// MessageId: MF_E_NO_DURATION
		///
		/// MessageText:
		///
		/// The Media stream has no duration.%0
		public const int MF_E_NO_DURATION = -1072873846;

		/// MessageId: MF_E_INVALID_FORMAT
		///
		/// MessageText:
		///
		/// The Media format is recognized but is invalid.%0
		public const int MF_E_INVALID_FORMAT = -1072873844;

		/// MessageId: MF_E_PROPERTY_NOT_FOUND
		///
		/// MessageText:
		///
		/// The property requested was not found.%0
		public const int MF_E_PROPERTY_NOT_FOUND = -1072873843;

		/// MessageId: MF_E_PROPERTY_READ_ONLY
		///
		/// MessageText:
		///
		/// The property is read only.%0
		public const int MF_E_PROPERTY_READ_ONLY = -1072873842;

		/// MessageId: MF_E_PROPERTY_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// The specified property is not allowed in this context.%0
		public const int MF_E_PROPERTY_NOT_ALLOWED = -1072873841;

		/// MessageId: MF_E_MEDIA_SOURCE_NOT_STARTED
		///
		/// MessageText:
		///
		/// The media source is not started.%0
		public const int MF_E_MEDIA_SOURCE_NOT_STARTED = -1072873839;

		/// MessageId: MF_E_UNSUPPORTED_FORMAT
		///
		/// MessageText:
		///
		/// The Media format is recognized but not supported.%0
		public const int MF_E_UNSUPPORTED_FORMAT = -1072873832;

		/// MessageId: MF_E_MP3_BAD_CRC
		///
		/// MessageText:
		///
		/// The MPEG frame has bad CRC.%0
		public const int MF_E_MP3_BAD_CRC = -1072873831;

		/// MessageId: MF_E_NOT_PROTECTED
		///
		/// MessageText:
		///
		/// The file is not protected.%0
		public const int MF_E_NOT_PROTECTED = -1072873830;

		/// MessageId: MF_E_MEDIA_SOURCE_WRONGSTATE
		///
		/// MessageText:
		///
		/// The media source is in the wrong state%0
		public const int MF_E_MEDIA_SOURCE_WRONGSTATE = -1072873829;

		/// MessageId: MF_E_MEDIA_SOURCE_NO_STREAMS_SELECTED
		///
		/// MessageText:
		///
		/// No streams are selected in source presentation descriptor.%0
		public const int MF_E_MEDIA_SOURCE_NO_STREAMS_SELECTED = -1072873828;

		/// MessageId: MF_E_CANNOT_FIND_KEYFRAME_SAMPLE
		///
		/// MessageText:
		///
		/// No key frame sample was found.%0
		public const int MF_E_CANNOT_FIND_KEYFRAME_SAMPLE = -1072873827;

		/// MessageId: MF_E_NETWORK_RESOURCE_FAILURE
		///
		/// MessageText:
		///
		/// An attempt to acquire a network resource failed.%0
		public const int MF_E_NETWORK_RESOURCE_FAILURE = -1072872856;

		/// MessageId: MF_E_NET_WRITE
		///
		/// MessageText:
		///
		/// Error writing to the network.%0
		public const int MF_E_NET_WRITE = -1072872855;

		/// MessageId: MF_E_NET_READ
		///
		/// MessageText:
		///
		/// Error reading from the network.%0
		public const int MF_E_NET_READ = -1072872854;

		/// MessageId: MF_E_NET_REQUIRE_NETWORK
		///
		/// MessageText:
		///
		/// Internal. Entry cannot complete operation without network.%0
		public const int MF_E_NET_REQUIRE_NETWORK = -1072872853;

		/// MessageId: MF_E_NET_REQUIRE_ASYNC
		///
		/// MessageText:
		///
		/// Internal. Async op is required.%0
		public const int MF_E_NET_REQUIRE_ASYNC = -1072872852;

		/// MessageId: MF_E_NET_BWLEVEL_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// Internal. Bandwidth levels are not supported.%0
		public const int MF_E_NET_BWLEVEL_NOT_SUPPORTED = -1072872851;

		/// MessageId: MF_E_NET_STREAMGROUPS_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// Internal. Stream groups are not supported.%0
		public const int MF_E_NET_STREAMGROUPS_NOT_SUPPORTED = -1072872850;

		/// MessageId: MF_E_NET_MANUALSS_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// Manual stream selection is not supported.%0
		public const int MF_E_NET_MANUALSS_NOT_SUPPORTED = -1072872849;

		/// MessageId: MF_E_NET_INVALID_PRESENTATION_DESCRIPTOR
		///
		/// MessageText:
		///
		/// Invalid presentation descriptor.%0
		public const int MF_E_NET_INVALID_PRESENTATION_DESCRIPTOR = -1072872848;

		/// MessageId: MF_E_NET_CACHESTREAM_NOT_FOUND
		///
		/// MessageText:
		///
		/// Cannot find cache stream.%0
		public const int MF_E_NET_CACHESTREAM_NOT_FOUND = -1072872847;

		/// MessageId: MF_I_MANUAL_PROXY
		///
		/// MessageText:
		///
		/// The proxy setting is manual.%0
		public const int MF_I_MANUAL_PROXY = 1074610802;

		/// duplicate removed
		/// MessageId=17011 Severity=Informational Facility=MEDIAFOUNDATION SymbolicName=MF_E_INVALID_REQUEST
		/// Language=English
		/// The request is invalid in the current state.%0
		/// .
		///
		///  MessageId: MF_E_NET_REQUIRE_INPUT
		///
		///  MessageText:
		///
		///  Internal. Entry cannot complete operation without input.%0
		public const int MF_E_NET_REQUIRE_INPUT = -1072872844;

		/// MessageId: MF_E_NET_REDIRECT
		///
		/// MessageText:
		///
		/// The client redirected to another server.%0
		public const int MF_E_NET_REDIRECT = -1072872843;

		/// MessageId: MF_E_NET_REDIRECT_TO_PROXY
		///
		/// MessageText:
		///
		/// The client is redirected to a proxy server.%0
		public const int MF_E_NET_REDIRECT_TO_PROXY = -1072872842;

		/// MessageId: MF_E_NET_TOO_MANY_REDIRECTS
		///
		/// MessageText:
		///
		/// The client reached maximum redirection limit.%0
		public const int MF_E_NET_TOO_MANY_REDIRECTS = -1072872841;

		/// MessageId: MF_E_NET_TIMEOUT
		///
		/// MessageText:
		///
		/// The server, a computer set up to offer multimedia content to other computers, could not handle your request for multimedia content in a timely manner.  Please try again later.%0
		public const int MF_E_NET_TIMEOUT = -1072872840;

		/// MessageId: MF_E_NET_CLIENT_CLOSE
		///
		/// MessageText:
		///
		/// The control socket is closed by the client.%0
		public const int MF_E_NET_CLIENT_CLOSE = -1072872839;

		/// MessageId: MF_E_NET_BAD_CONTROL_DATA
		///
		/// MessageText:
		///
		/// The server received invalid data from the client on the control connection.%0
		public const int MF_E_NET_BAD_CONTROL_DATA = -1072872838;

		/// MessageId: MF_E_NET_INCOMPATIBLE_SERVER
		///
		/// MessageText:
		///
		/// The server is not a compatible streaming media server.%0
		public const int MF_E_NET_INCOMPATIBLE_SERVER = -1072872837;

		/// MessageId: MF_E_NET_UNSAFE_URL
		///
		/// MessageText:
		///
		/// Url.%0
		public const int MF_E_NET_UNSAFE_URL = -1072872836;

		/// MessageId: MF_E_NET_CACHE_NO_DATA
		///
		/// MessageText:
		///
		/// Data is not available.%0
		public const int MF_E_NET_CACHE_NO_DATA = -1072872835;

		/// MessageId: MF_E_NET_EOL
		///
		/// MessageText:
		///
		/// End of line.%0
		public const int MF_E_NET_EOL = -1072872834;

		/// MessageId: MF_E_NET_BAD_REQUEST
		///
		/// MessageText:
		///
		/// The request could not be understood by the server.%0
		public const int MF_E_NET_BAD_REQUEST = -1072872833;

		/// MessageId: MF_E_NET_INTERNAL_SERVER_ERROR
		///
		/// MessageText:
		///
		/// The server encountered an unexpected condition which prevented it from fulfilling the request.%0
		public const int MF_E_NET_INTERNAL_SERVER_ERROR = -1072872832;

		/// MessageId: MF_E_NET_SESSION_NOT_FOUND
		///
		/// MessageText:
		///
		/// Session not found.%0
		public const int MF_E_NET_SESSION_NOT_FOUND = -1072872831;

		/// MessageId: MF_E_NET_NOCONNECTION
		///
		/// MessageText:
		///
		/// There is no connection established with the Windows Media server. The operation failed.%0
		public const int MF_E_NET_NOCONNECTION = -1072872830;

		/// MessageId: MF_E_NET_CONNECTION_FAILURE
		///
		/// MessageText:
		///
		/// The network connection has failed.%0
		public const int MF_E_NET_CONNECTION_FAILURE = -1072872829;

		/// MessageId: MF_E_NET_INCOMPATIBLE_PUSHSERVER
		///
		/// MessageText:
		///
		/// The Server service that received the HTTP push request is not a compatible version of Windows Media Services (WMS).  This error may indicate the push request was received by IIS instead of WMS.  Ensure WMS is started and has the HTTP Server control protocol properly enabled and try again.%0
		public const int MF_E_NET_INCOMPATIBLE_PUSHSERVER = -1072872828;

		/// MessageId: MF_E_NET_SERVER_ACCESSDENIED
		///
		/// MessageText:
		///
		/// The Windows Media server is denying access.  The username and/or password might be incorrect.%0
		public const int MF_E_NET_SERVER_ACCESSDENIED = -1072872827;

		/// MessageId: MF_E_NET_PROXY_ACCESSDENIED
		///
		/// MessageText:
		///
		/// The proxy server is denying access.  The username and/or password might be incorrect.%0
		public const int MF_E_NET_PROXY_ACCESSDENIED = -1072872826;

		/// MessageId: MF_E_NET_CANNOTCONNECT
		///
		/// MessageText:
		///
		/// Unable to establish a connection to the server.%0
		public const int MF_E_NET_CANNOTCONNECT = -1072872825;

		/// MessageId: MF_E_NET_INVALID_PUSH_TEMPLATE
		///
		/// MessageText:
		///
		/// The specified push template is invalid.%0
		public const int MF_E_NET_INVALID_PUSH_TEMPLATE = -1072872824;

		/// MessageId: MF_E_NET_INVALID_PUSH_PUBLISHING_POINT
		///
		/// MessageText:
		///
		/// The specified push publishing point is invalid.%0
		public const int MF_E_NET_INVALID_PUSH_PUBLISHING_POINT = -1072872823;

		/// MessageId: MF_E_NET_BUSY
		///
		/// MessageText:
		///
		/// The requested resource is in use.%0
		public const int MF_E_NET_BUSY = -1072872822;

		/// MessageId: MF_E_NET_RESOURCE_GONE
		///
		/// MessageText:
		///
		/// The Publishing Point or file on the Windows Media Server is no longer available.%0
		public const int MF_E_NET_RESOURCE_GONE = -1072872821;

		/// MessageId: MF_E_NET_ERROR_FROM_PROXY
		///
		/// MessageText:
		///
		/// The proxy experienced an error while attempting to contact the media server.%0
		public const int MF_E_NET_ERROR_FROM_PROXY = -1072872820;

		/// MessageId: MF_E_NET_PROXY_TIMEOUT
		///
		/// MessageText:
		///
		/// The proxy did not receive a timely response while attempting to contact the media server.%0
		public const int MF_E_NET_PROXY_TIMEOUT = -1072872819;

		/// MessageId: MF_E_NET_SERVER_UNAVAILABLE
		///
		/// MessageText:
		///
		/// The server is currently unable to handle the request due to a temporary overloading or maintenance of the server.%0
		public const int MF_E_NET_SERVER_UNAVAILABLE = -1072872818;

		/// MessageId: MF_E_NET_TOO_MUCH_DATA
		///
		/// MessageText:
		///
		/// The encoding process was unable to keep up with the amount of supplied data.%0
		public const int MF_E_NET_TOO_MUCH_DATA = -1072872817;

		/// MessageId: MF_E_NET_SESSION_INVALID
		///
		/// MessageText:
		///
		/// Session not found.%0
		public const int MF_E_NET_SESSION_INVALID = -1072872816;

		/// MessageId: MF_E_OFFLINE_MODE
		///
		/// MessageText:
		///
		/// The requested URL is not available in offline mode.%0
		public const int MF_E_OFFLINE_MODE = -1072872815;

		/// MessageId: MF_E_NET_UDP_BLOCKED
		///
		/// MessageText:
		///
		/// A device in the network is blocking UDP traffic.%0
		public const int MF_E_NET_UDP_BLOCKED = -1072872814;

		/// MessageId: MF_E_NET_UNSUPPORTED_CONFIGURATION
		///
		/// MessageText:
		///
		/// The specified configuration value is not supported.%0
		public const int MF_E_NET_UNSUPPORTED_CONFIGURATION = -1072872813;

		/// MessageId: MF_E_NET_PROTOCOL_DISABLED
		///
		/// MessageText:
		///
		/// The networking protocol is disabled.%0
		public const int MF_E_NET_PROTOCOL_DISABLED = -1072872812;

		/// MessageId: MF_E_ALREADY_INITIALIZED
		///
		/// MessageText:
		///
		/// This object has already been initialized and cannot be re-initialized at this time.%0
		public const int MF_E_ALREADY_INITIALIZED = -1072871856;

		/// MessageId: MF_E_BANDWIDTH_OVERRUN
		///
		/// MessageText:
		///
		/// The amount of data passed in exceeds the given bitrate and buffer window.%0
		public const int MF_E_BANDWIDTH_OVERRUN = -1072871855;

		/// MessageId: MF_E_LATE_SAMPLE
		///
		/// MessageText:
		///
		/// The sample was passed in too late to be correctly processed.%0
		public const int MF_E_LATE_SAMPLE = -1072871854;

		/// MessageId: MF_E_FLUSH_NEEDED
		///
		/// MessageText:
		///
		/// The requested action cannot be carried out until the object is flushed and the queue is emptied.%0
		public const int MF_E_FLUSH_NEEDED = -1072871853;

		/// MessageId: MF_E_INVALID_PROFILE
		///
		/// MessageText:
		///
		/// The profile is invalid.%0
		public const int MF_E_INVALID_PROFILE = -1072871852;

		/// MessageId: MF_E_INDEX_NOT_COMMITTED
		///
		/// MessageText:
		///
		/// The index that is being generated needs to be committed before the requested action can be carried out.%0
		public const int MF_E_INDEX_NOT_COMMITTED = -1072871851;

		/// MessageId: MF_E_NO_INDEX
		///
		/// MessageText:
		///
		/// The index that is necessary for the requested action is not found.%0
		public const int MF_E_NO_INDEX = -1072871850;

		/// MessageId: MF_E_CANNOT_INDEX_IN_PLACE
		///
		/// MessageText:
		///
		/// The requested index cannot be added in-place to the specified ASF content.%0
		public const int MF_E_CANNOT_INDEX_IN_PLACE = -1072871849;

		/// MessageId: MF_E_MISSING_ASF_LEAKYBUCKET
		///
		/// MessageText:
		///
		/// The ASF leaky bucket parameters must be specified in order to carry out this request.%0
		public const int MF_E_MISSING_ASF_LEAKYBUCKET = -1072871848;

		/// MessageId: MF_E_INVALID_ASF_STREAMID
		///
		/// MessageText:
		///
		/// The stream id is invalid. The valid range for ASF stream id is from 1 to 127.%0
		public const int MF_E_INVALID_ASF_STREAMID = -1072871847;

		/// MessageId: MF_E_STREAMSINK_REMOVED
		///
		/// MessageText:
		///
		/// The requested Stream Sink has been removed and cannot be used.%0
		public const int MF_E_STREAMSINK_REMOVED = -1072870856;

		/// MessageId: MF_E_STREAMSINKS_OUT_OF_SYNC
		///
		/// MessageText:
		///
		/// The various Stream Sinks in this Media Sink are too far out of sync for the requested action to take place.%0
		public const int MF_E_STREAMSINKS_OUT_OF_SYNC = -1072870854;

		/// MessageId: MF_E_STREAMSINKS_FIXED
		///
		/// MessageText:
		///
		/// Stream Sinks cannot be added to or removed from this Media Sink because its set of streams is fixed.%0
		public const int MF_E_STREAMSINKS_FIXED = -1072870853;

		/// MessageId: MF_E_STREAMSINK_EXISTS
		///
		/// MessageText:
		///
		/// The given Stream Sink already exists.%0
		public const int MF_E_STREAMSINK_EXISTS = -1072870852;

		/// MessageId: MF_E_SAMPLEALLOCATOR_CANCELED
		///
		/// MessageText:
		///
		/// Sample allocations have been canceled.%0
		public const int MF_E_SAMPLEALLOCATOR_CANCELED = -1072870851;

		/// MessageId: MF_E_SAMPLEALLOCATOR_EMPTY
		///
		/// MessageText:
		///
		/// The sample allocator is currently empty, due to outstanding requests.%0
		public const int MF_E_SAMPLEALLOCATOR_EMPTY = -1072870850;

		/// MessageId: MF_E_SINK_ALREADYSTOPPED
		///
		/// MessageText:
		///
		/// When we try to sopt a stream sink, it is already stopped %0
		public const int MF_E_SINK_ALREADYSTOPPED = -1072870849;

		/// MessageId: MF_E_ASF_FILESINK_BITRATE_UNKNOWN
		///
		/// MessageText:
		///
		/// The ASF file sink could not reserve AVIO because the bitrate is unknown.%0
		public const int MF_E_ASF_FILESINK_BITRATE_UNKNOWN = -1072870848;

		/// MessageId: MF_E_SINK_NO_STREAMS
		///
		/// MessageText:
		///
		/// No streams are selected in sink presentation descriptor.%0
		public const int MF_E_SINK_NO_STREAMS = -1072870847;

		/// MessageId: MF_S_SINK_NOT_FINALIZED
		///
		/// MessageText:
		///
		/// The sink has not been finalized before shut down. This may cause sink generate a corrupted content.%0
		public const int MF_S_SINK_NOT_FINALIZED = 870978;

		/// MessageId: MF_E_METADATA_TOO_LONG
		///
		/// MessageText:
		///
		/// A metadata item was too long to write to the output container.%0
		public const int MF_E_METADATA_TOO_LONG = -1072870845;

		/// MessageId: MF_E_SINK_NO_SAMPLES_PROCESSED
		///
		/// MessageText:
		///
		/// The operation failed because no samples were processed by the sink.%0
		public const int MF_E_SINK_NO_SAMPLES_PROCESSED = -1072870844;

		/// MessageId: MF_E_VIDEO_REN_NO_PROCAMP_HW
		///
		/// MessageText:
		///
		/// There is no available procamp hardware with which to perform color correction.%0
		public const int MF_E_VIDEO_REN_NO_PROCAMP_HW = -1072869856;

		/// MessageId: MF_E_VIDEO_REN_NO_DEINTERLACE_HW
		///
		/// MessageText:
		///
		/// There is no available deinterlacing hardware with which to deinterlace the video stream.%0
		public const int MF_E_VIDEO_REN_NO_DEINTERLACE_HW = -1072869855;

		/// MessageId: MF_E_VIDEO_REN_COPYPROT_FAILED
		///
		/// MessageText:
		///
		/// A video stream requires copy protection to be enabled, but there was a failure in attempting to enable copy protection.%0
		public const int MF_E_VIDEO_REN_COPYPROT_FAILED = -1072869854;

		/// MessageId: MF_E_VIDEO_REN_SURFACE_NOT_SHARED
		///
		/// MessageText:
		///
		/// A component is attempting to access a surface for sharing that is not shared.%0
		public const int MF_E_VIDEO_REN_SURFACE_NOT_SHARED = -1072869853;

		/// MessageId: MF_E_VIDEO_DEVICE_LOCKED
		///
		/// MessageText:
		///
		/// A component is attempting to access a shared device that is already locked by another component.%0
		public const int MF_E_VIDEO_DEVICE_LOCKED = -1072869852;

		/// MessageId: MF_E_NEW_VIDEO_DEVICE
		///
		/// MessageText:
		///
		/// The device is no longer available. The handle should be closed and a new one opened.%0
		public const int MF_E_NEW_VIDEO_DEVICE = -1072869851;

		/// MessageId: MF_E_NO_VIDEO_SAMPLE_AVAILABLE
		///
		/// MessageText:
		///
		/// A video sample is not currently queued on a stream that is required for mixing.%0
		public const int MF_E_NO_VIDEO_SAMPLE_AVAILABLE = -1072869850;

		/// MessageId: MF_E_NO_AUDIO_PLAYBACK_DEVICE
		///
		/// MessageText:
		///
		/// No audio playback device was found.%0
		public const int MF_E_NO_AUDIO_PLAYBACK_DEVICE = -1072869756;

		/// MessageId: MF_E_AUDIO_PLAYBACK_DEVICE_IN_USE
		///
		/// MessageText:
		///
		/// The requested audio playback device is currently in use.%0
		public const int MF_E_AUDIO_PLAYBACK_DEVICE_IN_USE = -1072869755;

		/// MessageId: MF_E_AUDIO_PLAYBACK_DEVICE_INVALIDATED
		///
		/// MessageText:
		///
		/// The audio playback device is no longer present.%0
		public const int MF_E_AUDIO_PLAYBACK_DEVICE_INVALIDATED = -1072869754;

		/// MessageId: MF_E_AUDIO_SERVICE_NOT_RUNNING
		///
		/// MessageText:
		///
		/// The audio service is not running.%0
		public const int MF_E_AUDIO_SERVICE_NOT_RUNNING = -1072869753;

		/// MessageId: MF_E_TOPO_INVALID_OPTIONAL_NODE
		///
		/// MessageText:
		///
		/// The topology contains an invalid optional node.  Possible reasons are incorrect number of outputs and inputs or optional node is at the beginning or end of a segment. %0
		public const int MF_E_TOPO_INVALID_OPTIONAL_NODE = -1072868850;

		/// MessageId: MF_E_TOPO_CANNOT_FIND_DECRYPTOR
		///
		/// MessageText:
		///
		/// No suitable transform was found to decrypt the content. %0
		public const int MF_E_TOPO_CANNOT_FIND_DECRYPTOR = -1072868847;

		/// MessageId: MF_E_TOPO_CODEC_NOT_FOUND
		///
		/// MessageText:
		///
		/// No suitable transform was found to encode or decode the content. %0
		public const int MF_E_TOPO_CODEC_NOT_FOUND = -1072868846;

		/// MessageId: MF_E_TOPO_CANNOT_CONNECT
		///
		/// MessageText:
		///
		/// Unable to find a way to connect nodes%0
		public const int MF_E_TOPO_CANNOT_CONNECT = -1072868845;

		/// MessageId: MF_E_TOPO_UNSUPPORTED
		///
		/// MessageText:
		///
		/// Unsupported operations in topoloader%0
		public const int MF_E_TOPO_UNSUPPORTED = -1072868844;

		/// MessageId: MF_E_TOPO_INVALID_TIME_ATTRIBUTES
		///
		/// MessageText:
		///
		/// The topology or its nodes contain incorrectly set time attributes%0
		public const int MF_E_TOPO_INVALID_TIME_ATTRIBUTES = -1072868843;

		/// MessageId: MF_E_TOPO_LOOPS_IN_TOPOLOGY
		///
		/// MessageText:
		///
		/// The topology contains loops, which are unsupported in media foundation topologies%0
		public const int MF_E_TOPO_LOOPS_IN_TOPOLOGY = -1072868842;

		/// MessageId: MF_E_TOPO_MISSING_PRESENTATION_DESCRIPTOR
		///
		/// MessageText:
		///
		/// A source stream node in the topology does not have a presentation descriptor%0
		public const int MF_E_TOPO_MISSING_PRESENTATION_DESCRIPTOR = -1072868841;

		/// MessageId: MF_E_TOPO_MISSING_STREAM_DESCRIPTOR
		///
		/// MessageText:
		///
		/// A source stream node in the topology does not have a stream descriptor%0
		public const int MF_E_TOPO_MISSING_STREAM_DESCRIPTOR = -1072868840;

		/// MessageId: MF_E_TOPO_STREAM_DESCRIPTOR_NOT_SELECTED
		///
		/// MessageText:
		///
		/// A stream descriptor was set on a source stream node but it was not selected on the presentation descriptor%0
		public const int MF_E_TOPO_STREAM_DESCRIPTOR_NOT_SELECTED = -1072868839;

		/// MessageId: MF_E_TOPO_MISSING_SOURCE
		///
		/// MessageText:
		///
		/// A source stream node in the topology does not have a source%0
		public const int MF_E_TOPO_MISSING_SOURCE = -1072868838;

		/// MessageId: MF_E_TOPO_SINK_ACTIVATES_UNSUPPORTED
		///
		/// MessageText:
		///
		/// The topology loader does not support sink activates on output nodes.%0
		public const int MF_E_TOPO_SINK_ACTIVATES_UNSUPPORTED = -1072868837;

		/// MessageId: MF_E_SEQUENCER_UNKNOWN_SEGMENT_ID
		///
		/// MessageText:
		///
		/// The sequencer cannot find a segment with the given ID.%0\n.
		public const int MF_E_SEQUENCER_UNKNOWN_SEGMENT_ID = -1072864852;

		/// MessageId: MF_S_SEQUENCER_CONTEXT_CANCELED
		///
		/// MessageText:
		///
		/// The context was canceled.%0\n.
		public const int MF_S_SEQUENCER_CONTEXT_CANCELED = 876973;

		/// MessageId: MF_E_NO_SOURCE_IN_CACHE
		///
		/// MessageText:
		///
		/// Cannot find source in source cache.%0\n.
		public const int MF_E_NO_SOURCE_IN_CACHE = -1072864850;

		/// MessageId: MF_S_SEQUENCER_SEGMENT_AT_END_OF_STREAM
		///
		/// MessageText:
		///
		/// Cannot update topology flags.%0\n.
		public const int MF_S_SEQUENCER_SEGMENT_AT_END_OF_STREAM = 876975;

		/// MessageId: MF_E_TRANSFORM_TYPE_NOT_SET
		///
		/// MessageText:
		///
		/// A valid type has not been set for this stream or a stream that it depends on.%0
		public const int MF_E_TRANSFORM_TYPE_NOT_SET = -1072861856;

		/// MessageId: MF_E_TRANSFORM_STREAM_CHANGE
		///
		/// MessageText:
		///
		/// A stream change has occurred. Output cannot be produced until the streams have been renegotiated.%0
		public const int MF_E_TRANSFORM_STREAM_CHANGE = -1072861855;

		/// MessageId: MF_E_TRANSFORM_INPUT_REMAINING
		///
		/// MessageText:
		///
		/// The transform cannot take the requested action until all of the input data it currently holds is processed or flushed.%0
		public const int MF_E_TRANSFORM_INPUT_REMAINING = -1072861854;

		/// MessageId: MF_E_TRANSFORM_PROFILE_MISSING
		///
		/// MessageText:
		///
		/// The transform requires a profile but no profile was supplied or found.%0
		public const int MF_E_TRANSFORM_PROFILE_MISSING = -1072861853;

		/// MessageId: MF_E_TRANSFORM_PROFILE_INVALID_OR_CORRUPT
		///
		/// MessageText:
		///
		/// The transform requires a profile but the supplied profile was invalid or corrupt.%0
		public const int MF_E_TRANSFORM_PROFILE_INVALID_OR_CORRUPT = -1072861852;

		/// MessageId: MF_E_TRANSFORM_PROFILE_TRUNCATED
		///
		/// MessageText:
		///
		/// The transform requires a profile but the supplied profile ended unexpectedly while parsing.%0
		public const int MF_E_TRANSFORM_PROFILE_TRUNCATED = -1072861851;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_PID_NOT_RECOGNIZED
		///
		/// MessageText:
		///
		/// The property ID does not match any property supported by the transform.%0
		public const int MF_E_TRANSFORM_PROPERTY_PID_NOT_RECOGNIZED = -1072861850;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_VARIANT_TYPE_WRONG
		///
		/// MessageText:
		///
		/// The variant does not have the type expected for this property ID.%0
		public const int MF_E_TRANSFORM_PROPERTY_VARIANT_TYPE_WRONG = -1072861849;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_NOT_WRITEABLE
		///
		/// MessageText:
		///
		/// An attempt was made to set the value on a read-only property.%0
		public const int MF_E_TRANSFORM_PROPERTY_NOT_WRITEABLE = -1072861848;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_ARRAY_VALUE_WRONG_NUM_DIM
		///
		/// MessageText:
		///
		/// The array property value has an unexpected number of dimensions.%0
		public const int MF_E_TRANSFORM_PROPERTY_ARRAY_VALUE_WRONG_NUM_DIM = -1072861847;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_VALUE_SIZE_WRONG
		///
		/// MessageText:
		///
		/// The array or blob property value has an unexpected size.%0
		public const int MF_E_TRANSFORM_PROPERTY_VALUE_SIZE_WRONG = -1072861846;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_VALUE_OUT_OF_RANGE
		///
		/// MessageText:
		///
		/// The property value is out of range for this transform.%0
		public const int MF_E_TRANSFORM_PROPERTY_VALUE_OUT_OF_RANGE = -1072861845;

		/// MessageId: MF_E_TRANSFORM_PROPERTY_VALUE_INCOMPATIBLE
		///
		/// MessageText:
		///
		/// The property value is incompatible with some other property or mediatype set on the transform.%0
		public const int MF_E_TRANSFORM_PROPERTY_VALUE_INCOMPATIBLE = -1072861844;

		/// MessageId: MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_OUTPUT_MEDIATYPE
		///
		/// MessageText:
		///
		/// The requested operation is not supported for the currently set output mediatype.%0
		public const int MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_OUTPUT_MEDIATYPE = -1072861843;

		/// MessageId: MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_INPUT_MEDIATYPE
		///
		/// MessageText:
		///
		/// The requested operation is not supported for the currently set input mediatype.%0
		public const int MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_INPUT_MEDIATYPE = -1072861842;

		/// MessageId: MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_MEDIATYPE_COMBINATION
		///
		/// MessageText:
		///
		/// The requested operation is not supported for the currently set combination of mediatypes.%0
		public const int MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_MEDIATYPE_COMBINATION = -1072861841;

		/// MessageId: MF_E_TRANSFORM_CONFLICTS_WITH_OTHER_CURRENTLY_ENABLED_FEATURES
		///
		/// MessageText:
		///
		/// The requested feature is not supported in combination with some other currently enabled feature.%0
		public const int MF_E_TRANSFORM_CONFLICTS_WITH_OTHER_CURRENTLY_ENABLED_FEATURES = -1072861840;

		/// MessageId: MF_E_TRANSFORM_NEED_MORE_INPUT
		///
		/// MessageText:
		///
		/// The transform cannot produce output until it gets more input samples.%0
		public const int MF_E_TRANSFORM_NEED_MORE_INPUT = -1072861838;

		/// MessageId: MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_SPKR_CONFIG
		///
		/// MessageText:
		///
		/// The requested operation is not supported for the current speaker configuration.%0
		public const int MF_E_TRANSFORM_NOT_POSSIBLE_FOR_CURRENT_SPKR_CONFIG = -1072861837;

		/// MessageId: MF_E_TRANSFORM_CANNOT_CHANGE_MEDIATYPE_WHILE_PROCESSING
		///
		/// MessageText:
		///
		/// The transform cannot accept mediatype changes in the middle of processing.%0
		public const int MF_E_TRANSFORM_CANNOT_CHANGE_MEDIATYPE_WHILE_PROCESSING = -1072861836;

		/// MessageId: MF_S_TRANSFORM_DO_NOT_PROPAGATE_EVENT
		///
		/// MessageText:
		///
		/// The caller should not propagate this event to downstream components.%0
		public const int MF_S_TRANSFORM_DO_NOT_PROPAGATE_EVENT = 879989;

		/// MessageId: MF_E_UNSUPPORTED_D3D_TYPE
		///
		/// MessageText:
		///
		/// The input type is not supported for D3D device.%0
		public const int MF_E_UNSUPPORTED_D3D_TYPE = -1072861834;

		/// MessageId: MF_E_TRANSFORM_ASYNC_LOCKED
		///
		/// MessageText:
		///
		/// The caller does not appear to support this transform's asynchronous capabilities.%0
		public const int MF_E_TRANSFORM_ASYNC_LOCKED = -1072861833;

		/// MessageId: MF_E_TRANSFORM_CANNOT_INITIALIZE_ACM_DRIVER
		///
		/// MessageText:
		///
		/// An audio compression manager driver could not be initialized by the transform.%0
		public const int MF_E_TRANSFORM_CANNOT_INITIALIZE_ACM_DRIVER = -1072861832;

		/// MessageId: MF_E_LICENSE_INCORRECT_RIGHTS
		///
		/// MessageText:
		///
		/// You are not allowed to open this file. Contact the content provider for further assistance.%0
		public const int MF_E_LICENSE_INCORRECT_RIGHTS = -1072860856;

		/// MessageId: MF_E_LICENSE_OUTOFDATE
		///
		/// MessageText:
		///
		/// The license for this media file has expired. Get a new license or contact the content provider for further assistance.%0
		public const int MF_E_LICENSE_OUTOFDATE = -1072860855;

		/// MessageId: MF_E_LICENSE_REQUIRED
		///
		/// MessageText:
		///
		/// You need a license to perform the requested operation on this media file.%0
		public const int MF_E_LICENSE_REQUIRED = -1072860854;

		/// MessageId: MF_E_DRM_HARDWARE_INCONSISTENT
		///
		/// MessageText:
		///
		/// The licenses for your media files are corrupted. Contact Microsoft product support.%0
		public const int MF_E_DRM_HARDWARE_INCONSISTENT = -1072860853;

		/// MessageId: MF_E_NO_CONTENT_PROTECTION_MANAGER
		///
		/// MessageText:
		///
		/// The APP needs to provide IMFContentProtectionManager callback to access the protected media file.%0
		public const int MF_E_NO_CONTENT_PROTECTION_MANAGER = -1072860852;

		/// MessageId: MF_E_LICENSE_RESTORE_NO_RIGHTS
		///
		/// MessageText:
		///
		/// Client does not have rights to restore licenses.%0
		public const int MF_E_LICENSE_RESTORE_NO_RIGHTS = -1072860851;

		/// MessageId: MF_E_BACKUP_RESTRICTED_LICENSE
		///
		/// MessageText:
		///
		/// Licenses are restricted and hence can not be backed up.%0
		public const int MF_E_BACKUP_RESTRICTED_LICENSE = -1072860850;

		/// MessageId: MF_E_LICENSE_RESTORE_NEEDS_INDIVIDUALIZATION
		///
		/// MessageText:
		///
		/// License restore requires machine to be individualized.%0
		public const int MF_E_LICENSE_RESTORE_NEEDS_INDIVIDUALIZATION = -1072860849;

		/// MessageId: MF_S_PROTECTION_NOT_REQUIRED
		///
		/// MessageText:
		///
		/// Protection for stream is not required.%0
		public const int MF_S_PROTECTION_NOT_REQUIRED = 880976;

		/// MessageId: MF_E_COMPONENT_REVOKED
		///
		/// MessageText:
		///
		/// Component is revoked.%0
		public const int MF_E_COMPONENT_REVOKED = -1072860847;

		/// MessageId: MF_E_TRUST_DISABLED
		///
		/// MessageText:
		///
		/// Trusted functionality is currently disabled on this component.%0
		public const int MF_E_TRUST_DISABLED = -1072860846;

		/// MessageId: MF_E_WMDRMOTA_NO_ACTION
		///
		/// MessageText:
		///
		/// No Action is set on WMDRM Output Trust Authority.%0
		public const int MF_E_WMDRMOTA_NO_ACTION = -1072860845;

		/// MessageId: MF_E_WMDRMOTA_ACTION_ALREADY_SET
		///
		/// MessageText:
		///
		/// Action is already set on WMDRM Output Trust Authority.%0
		public const int MF_E_WMDRMOTA_ACTION_ALREADY_SET = -1072860844;

		/// MessageId: MF_E_WMDRMOTA_DRM_HEADER_NOT_AVAILABLE
		///
		/// MessageText:
		///
		/// DRM Heaader is not available.%0
		public const int MF_E_WMDRMOTA_DRM_HEADER_NOT_AVAILABLE = -1072860843;

		/// MessageId: MF_E_WMDRMOTA_DRM_ENCRYPTION_SCHEME_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// Current encryption scheme is not supported.%0
		public const int MF_E_WMDRMOTA_DRM_ENCRYPTION_SCHEME_NOT_SUPPORTED = -1072860842;

		/// MessageId: MF_E_WMDRMOTA_ACTION_MISMATCH
		///
		/// MessageText:
		///
		/// Action does not match with current configuration.%0
		public const int MF_E_WMDRMOTA_ACTION_MISMATCH = -1072860841;

		/// MessageId: MF_E_WMDRMOTA_INVALID_POLICY
		///
		/// MessageText:
		///
		/// Invalid policy for WMDRM Output Trust Authority.%0
		public const int MF_E_WMDRMOTA_INVALID_POLICY = -1072860840;

		/// MessageId: MF_E_POLICY_UNSUPPORTED
		///
		/// MessageText:
		///
		/// The policies that the Input Trust Authority requires to be enforced are unsupported by the outputs.%0
		public const int MF_E_POLICY_UNSUPPORTED = -1072860839;

		/// MessageId: MF_E_OPL_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// The OPL that the license requires to be enforced are not supported by the Input Trust Authority.%0
		public const int MF_E_OPL_NOT_SUPPORTED = -1072860838;

		/// MessageId: MF_E_TOPOLOGY_VERIFICATION_FAILED
		///
		/// MessageText:
		///
		/// The topology could not be successfully verified.%0
		public const int MF_E_TOPOLOGY_VERIFICATION_FAILED = -1072860837;

		/// MessageId: MF_E_SIGNATURE_VERIFICATION_FAILED
		///
		/// MessageText:
		///
		/// Signature verification could not be completed successfully for this component.%0
		public const int MF_E_SIGNATURE_VERIFICATION_FAILED = -1072860836;

		/// MessageId: MF_E_DEBUGGING_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// Running this process under a debugger while using protected content is not allowed.%0
		public const int MF_E_DEBUGGING_NOT_ALLOWED = -1072860835;

		/// MessageId: MF_E_CODE_EXPIRED
		///
		/// MessageText:
		///
		/// MF component has expired.%0
		public const int MF_E_CODE_EXPIRED = -1072860834;

		/// MessageId: MF_E_GRL_VERSION_TOO_LOW
		///
		/// MessageText:
		///
		/// The current GRL on the machine does not meet the minimum version requirements.%0
		public const int MF_E_GRL_VERSION_TOO_LOW = -1072860833;

		/// MessageId: MF_E_GRL_RENEWAL_NOT_FOUND
		///
		/// MessageText:
		///
		/// The current GRL on the machine does not contain any renewal entries for the specified revocation.%0
		public const int MF_E_GRL_RENEWAL_NOT_FOUND = -1072860832;

		/// MessageId: MF_E_GRL_EXTENSIBLE_ENTRY_NOT_FOUND
		///
		/// MessageText:
		///
		/// The current GRL on the machine does not contain any extensible entries for the specified extension GUID.%0
		public const int MF_E_GRL_EXTENSIBLE_ENTRY_NOT_FOUND = -1072860831;

		/// MessageId: MF_E_KERNEL_UNTRUSTED
		///
		/// MessageText:
		///
		/// The kernel isn't secure for high security level content.%0
		public const int MF_E_KERNEL_UNTRUSTED = -1072860830;

		/// MessageId: MF_E_PEAUTH_UNTRUSTED
		///
		/// MessageText:
		///
		/// The response from protected environment driver isn't valid.%0
		public const int MF_E_PEAUTH_UNTRUSTED = -1072860829;

		/// MessageId: MF_E_NON_PE_PROCESS
		///
		/// MessageText:
		///
		/// A non-PE process tried to talk to PEAuth.%0
		public const int MF_E_NON_PE_PROCESS = -1072860827;

		/// MessageId: MF_E_REBOOT_REQUIRED
		///
		/// MessageText:
		///
		/// We need to reboot the machine.%0
		public const int MF_E_REBOOT_REQUIRED = -1072860825;

		/// MessageId: MF_S_WAIT_FOR_POLICY_SET
		///
		/// MessageText:
		///
		/// Protection for this stream is not guaranteed to be enforced until the MEPolicySet event is fired.%0
		public const int MF_S_WAIT_FOR_POLICY_SET = 881000;

		/// MessageId: MF_S_VIDEO_DISABLED_WITH_UNKNOWN_SOFTWARE_OUTPUT
		///
		/// MessageText:
		///
		/// This video stream is disabled because it is being sent to an unknown software output.%0
		public const int MF_S_VIDEO_DISABLED_WITH_UNKNOWN_SOFTWARE_OUTPUT = 881001;

		/// MessageId: MF_E_GRL_INVALID_FORMAT
		///
		/// MessageText:
		///
		/// The GRL file is not correctly formed, it may have been corrupted or overwritten.%0
		public const int MF_E_GRL_INVALID_FORMAT = -1072860822;

		/// MessageId: MF_E_GRL_UNRECOGNIZED_FORMAT
		///
		/// MessageText:
		///
		/// The GRL file is in a format newer than those recognized by this GRL Reader.%0
		public const int MF_E_GRL_UNRECOGNIZED_FORMAT = -1072860821;

		/// MessageId: MF_E_ALL_PROCESS_RESTART_REQUIRED
		///
		/// MessageText:
		///
		/// The GRL was reloaded and required all processes that can run protected media to restart.%0
		public const int MF_E_ALL_PROCESS_RESTART_REQUIRED = -1072860820;

		/// MessageId: MF_E_PROCESS_RESTART_REQUIRED
		///
		/// MessageText:
		///
		/// The GRL was reloaded and the current process needs to restart.%0
		public const int MF_E_PROCESS_RESTART_REQUIRED = -1072860819;

		/// MessageId: MF_E_USERMODE_UNTRUSTED
		///
		/// MessageText:
		///
		/// The user space is untrusted for protected content play.%0
		public const int MF_E_USERMODE_UNTRUSTED = -1072860818;

		/// MessageId: MF_E_PEAUTH_SESSION_NOT_STARTED
		///
		/// MessageText:
		///
		/// PEAuth communication session hasn't been started.%0
		public const int MF_E_PEAUTH_SESSION_NOT_STARTED = -1072860817;

		/// MessageId: MF_E_PEAUTH_PUBLICKEY_REVOKED
		///
		/// MessageText:
		///
		/// PEAuth's public key is revoked.%0
		public const int MF_E_PEAUTH_PUBLICKEY_REVOKED = -1072860815;

		/// MessageId: MF_E_GRL_ABSENT
		///
		/// MessageText:
		///
		/// The GRL is absent.%0
		public const int MF_E_GRL_ABSENT = -1072860814;

		/// MessageId: MF_S_PE_TRUSTED
		///
		/// MessageText:
		///
		/// The Protected Environment is trusted.%0
		public const int MF_S_PE_TRUSTED = 881011;

		/// MessageId: MF_E_PE_UNTRUSTED
		///
		/// MessageText:
		///
		/// The Protected Environment is untrusted.%0
		public const int MF_E_PE_UNTRUSTED = -1072860812;

		/// MessageId: MF_E_PEAUTH_NOT_STARTED
		///
		/// MessageText:
		///
		/// The Protected Environment Authorization service (PEAUTH) has not been started.%0
		public const int MF_E_PEAUTH_NOT_STARTED = -1072860811;

		/// MessageId: MF_E_INCOMPATIBLE_SAMPLE_PROTECTION
		///
		/// MessageText:
		///
		/// The sample protection algorithms supported by components are not compatible.%0
		public const int MF_E_INCOMPATIBLE_SAMPLE_PROTECTION = -1072860810;

		/// MessageId: MF_E_PE_SESSIONS_MAXED
		///
		/// MessageText:
		///
		/// No more protected environment sessions can be supported.%0
		public const int MF_E_PE_SESSIONS_MAXED = -1072860809;

		/// MessageId: MF_E_HIGH_SECURITY_LEVEL_CONTENT_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// WMDRM ITA does not allow protected content with high security level for this release.%0
		public const int MF_E_HIGH_SECURITY_LEVEL_CONTENT_NOT_ALLOWED = -1072860808;

		/// MessageId: MF_E_TEST_SIGNED_COMPONENTS_NOT_ALLOWED
		///
		/// MessageText:
		///
		/// WMDRM ITA cannot allow the requested action for the content as one or more components is not properly signed.%0
		public const int MF_E_TEST_SIGNED_COMPONENTS_NOT_ALLOWED = -1072860807;

		/// MessageId: MF_E_ITA_UNSUPPORTED_ACTION
		///
		/// MessageText:
		///
		/// WMDRM ITA does not support the requested action.%0
		public const int MF_E_ITA_UNSUPPORTED_ACTION = -1072860806;

		/// MessageId: MF_E_ITA_ERROR_PARSING_SAP_PARAMETERS
		///
		/// MessageText:
		///
		/// WMDRM ITA encountered an error in parsing the Secure Audio Path parameters.%0
		public const int MF_E_ITA_ERROR_PARSING_SAP_PARAMETERS = -1072860805;

		/// MessageId: MF_E_POLICY_MGR_ACTION_OUTOFBOUNDS
		///
		/// MessageText:
		///
		/// The Policy Manager action passed in is invalid.%0
		public const int MF_E_POLICY_MGR_ACTION_OUTOFBOUNDS = -1072860804;

		/// MessageId: MF_E_BAD_OPL_STRUCTURE_FORMAT
		///
		/// MessageText:
		///
		/// The structure specifying Output Protection Level is not the correct format.%0
		public const int MF_E_BAD_OPL_STRUCTURE_FORMAT = -1072860803;

		/// MessageId: MF_E_ITA_UNRECOGNIZED_ANALOG_VIDEO_PROTECTION_GUID
		///
		/// MessageText:
		///
		/// WMDRM ITA does not recognize the Explicite Analog Video Output Protection guid specified in the license.%0
		public const int MF_E_ITA_UNRECOGNIZED_ANALOG_VIDEO_PROTECTION_GUID = -1072860802;

		/// MessageId: MF_E_NO_PMP_HOST
		///
		/// MessageText:
		///
		/// IMFPMPHost object not available.%0
		public const int MF_E_NO_PMP_HOST = -1072860801;

		/// MessageId: MF_E_ITA_OPL_DATA_NOT_INITIALIZED
		///
		/// MessageText:
		///
		/// WMDRM ITA could not initialize the Output Protection Level data.%0
		public const int MF_E_ITA_OPL_DATA_NOT_INITIALIZED = -1072860800;

		/// MessageId: MF_E_ITA_UNRECOGNIZED_ANALOG_VIDEO_OUTPUT
		///
		/// MessageText:
		///
		/// WMDRM ITA does not recognize the Analog Video Output specified by the OTA.%0
		public const int MF_E_ITA_UNRECOGNIZED_ANALOG_VIDEO_OUTPUT = -1072860799;

		/// MessageId: MF_E_ITA_UNRECOGNIZED_DIGITAL_VIDEO_OUTPUT
		///
		/// MessageText:
		///
		/// WMDRM ITA does not recognize the Digital Video Output specified by the OTA.%0
		public const int MF_E_ITA_UNRECOGNIZED_DIGITAL_VIDEO_OUTPUT = -1072860798;

		/// MessageId: MF_E_CLOCK_INVALID_CONTINUITY_KEY
		///
		/// MessageText:
		///
		/// The continuity key supplied is not currently valid.%0
		public const int MF_E_CLOCK_INVALID_CONTINUITY_KEY = -1072849856;

		/// MessageId: MF_E_CLOCK_NO_TIME_SOURCE
		///
		/// MessageText:
		///
		/// No Presentation Time Source has been specified.%0
		public const int MF_E_CLOCK_NO_TIME_SOURCE = -1072849855;

		/// MessageId: MF_E_CLOCK_STATE_ALREADY_SET
		///
		/// MessageText:
		///
		/// The clock is already in the requested state.%0
		public const int MF_E_CLOCK_STATE_ALREADY_SET = -1072849854;

		/// MessageId: MF_E_CLOCK_NOT_SIMPLE
		///
		/// MessageText:
		///
		/// The clock has too many advanced features to carry out the request.%0
		public const int MF_E_CLOCK_NOT_SIMPLE = -1072849853;

		/// MessageId: MF_S_CLOCK_STOPPED
		///
		/// MessageText:
		///
		/// Timer::SetTimer returns this success code if called happened while timer is stopped. Timer is not going to be dispatched until clock is running%0
		public const int MF_S_CLOCK_STOPPED = 891972;

		/// MessageId: MF_E_NO_MORE_DROP_MODES
		///
		/// MessageText:
		///
		/// The component does not support any more drop modes.%0
		public const int MF_E_NO_MORE_DROP_MODES = -1072848856;

		/// MessageId: MF_E_NO_MORE_QUALITY_LEVELS
		///
		/// MessageText:
		///
		/// The component does not support any more quality levels.%0
		public const int MF_E_NO_MORE_QUALITY_LEVELS = -1072848855;

		/// MessageId: MF_E_DROPTIME_NOT_SUPPORTED
		///
		/// MessageText:
		///
		/// The component does not support drop time functionality.%0
		public const int MF_E_DROPTIME_NOT_SUPPORTED = -1072848854;

		/// MessageId: MF_E_QUALITYKNOB_WAIT_LONGER
		///
		/// MessageText:
		///
		/// Quality Manager needs to wait longer before bumping the Quality Level up.%0
		public const int MF_E_QUALITYKNOB_WAIT_LONGER = -1072848853;

		/// MessageId: MF_E_QM_INVALIDSTATE
		///
		/// MessageText:
		///
		/// Quality Manager is in an invalid state. Quality Management is off at this moment.%0
		public const int MF_E_QM_INVALIDSTATE = -1072848852;

		/// MessageId: MF_E_TRANSCODE_NO_CONTAINERTYPE
		///
		/// MessageText:
		///
		/// No transcode output container type is specified.%0
		public const int MF_E_TRANSCODE_NO_CONTAINERTYPE = -1072847856;

		/// MessageId: MF_E_TRANSCODE_PROFILE_NO_MATCHING_STREAMS
		///
		/// MessageText:
		///
		/// The profile does not have a media type configuration for any selected source streams.%0
		public const int MF_E_TRANSCODE_PROFILE_NO_MATCHING_STREAMS = -1072847855;

		/// MessageId: MF_E_TRANSCODE_NO_MATCHING_ENCODER
		///
		/// MessageText:
		///
		/// Cannot find an encoder MFT that accepts the user preferred output type.%0
		public const int MF_E_TRANSCODE_NO_MATCHING_ENCODER = -1072847854;

		/// MessageId: MF_E_ALLOCATOR_NOT_INITIALIZED
		///
		/// MessageText:
		///
		/// Memory allocator is not initialized.%0
		public const int MF_E_ALLOCATOR_NOT_INITIALIZED = -1072846856;

		/// MessageId: MF_E_ALLOCATOR_NOT_COMMITED
		///
		/// MessageText:
		///
		/// Memory allocator is not committed yet.%0
		public const int MF_E_ALLOCATOR_NOT_COMMITED = -1072846855;

		/// MessageId: MF_E_ALLOCATOR_ALREADY_COMMITED
		///
		/// MessageText:
		///
		/// Memory allocator has already been committed.%0
		public const int MF_E_ALLOCATOR_ALREADY_COMMITED = -1072846854;

		/// MessageId: MF_E_STREAM_ERROR
		///
		/// MessageText:
		///
		/// An error occurred in media stream.%0
		public const int MF_E_STREAM_ERROR = -1072846853;

		/// MessageId: MF_E_INVALID_STREAM_STATE
		///
		/// MessageText:
		///
		/// Stream is not in a state to handle the request.%0
		public const int MF_E_INVALID_STREAM_STATE = -1072846852;

		/// MessageId: MF_E_HW_STREAM_NOT_CONNECTED
		///
		/// MessageText:
		///
		/// Hardware stream is not connected yet.%0
		public const int MF_E_HW_STREAM_NOT_CONNECTED = -1072846851;
	}

	/// <summary>
	/// Interop definitions for MediaFoundation
	/// thanks to Lucian Wischik for the initial work on many of these definitions (also various interfaces)
	/// n.b. the goal is to make as much of this internal as possible, and provide
	/// better .NET APIs using the MediaFoundationApi class instead
	/// </summary>
	public static class MediaFoundationInterop
	{
		/// <summary>
		/// All streams
		/// </summary>
		public const int MF_SOURCE_READER_ALL_STREAMS = -2;

		/// <summary>
		/// First audio stream
		/// </summary>
		public const int MF_SOURCE_READER_FIRST_AUDIO_STREAM = -3;

		/// <summary>
		/// First video stream
		/// </summary>
		public const int MF_SOURCE_READER_FIRST_VIDEO_STREAM = -4;

		/// <summary>
		/// Media source
		/// </summary>
		public const int MF_SOURCE_READER_MEDIASOURCE = -1;

		/// <summary>
		/// Media Foundation SDK Version
		/// </summary>
		public const int MF_SDK_VERSION = 2;

		/// <summary>
		/// Media Foundation API Version
		/// </summary>
		public const int MF_API_VERSION = 112;

		/// <summary>
		/// Media Foundation Version
		/// </summary>
		public const int MF_VERSION = 131184;

		/// <summary>
		/// Initializes Microsoft Media Foundation.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFStartup(int version, int dwFlags = 0);

		/// <summary>
		/// Shuts down the Microsoft Media Foundation platform
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFShutdown();

		/// <summary>
		/// Creates an empty media type.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFCreateMediaType(out IMFMediaType ppMFType);

		/// <summary>
		/// Initializes a media type from a WAVEFORMATEX structure. 
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFInitMediaTypeFromWaveFormatEx([In] IMFMediaType pMFType, [In] WaveFormat pWaveFormat, [In] int cbBufSize);

		/// <summary>
		/// Converts a Media Foundation audio media type to a WAVEFORMATEX structure.
		/// </summary>
		/// TODO: try making second parameter out WaveFormatExtraData
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFCreateWaveFormatExFromMFMediaType(IMFMediaType pMFType, ref IntPtr ppWF, ref int pcbSize, int flags = 0);

		/// <summary>
		/// Creates the source reader from a URL.
		/// </summary>
		[DllImport("mfreadwrite.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFCreateSourceReaderFromURL([In][MarshalAs(UnmanagedType.LPWStr)] string pwszURL, [In] IMFAttributes pAttributes, [MarshalAs(UnmanagedType.Interface)] out IMFSourceReader ppSourceReader);

		/// <summary>
		/// Creates the source reader from a byte stream.
		/// </summary>
		[DllImport("mfreadwrite.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFCreateSourceReaderFromByteStream([In] IMFByteStream pByteStream, [In] IMFAttributes pAttributes, [MarshalAs(UnmanagedType.Interface)] out IMFSourceReader ppSourceReader);

		/// <summary>
		/// Creates the sink writer from a URL or byte stream.
		/// </summary>
		[DllImport("mfreadwrite.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFCreateSinkWriterFromURL([In][MarshalAs(UnmanagedType.LPWStr)] string pwszOutputURL, [In] IMFByteStream pByteStream, [In] IMFAttributes pAttributes, out IMFSinkWriter ppSinkWriter);

		/// <summary>
		/// Creates a Microsoft Media Foundation byte stream that wraps an IRandomAccessStream object.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFCreateMFByteStreamOnStreamEx([MarshalAs(UnmanagedType.IUnknown)] object punkStream, out IMFByteStream ppByteStream);

		/// <summary>
		/// Creates a Microsoft Media Foundation byte stream that wraps an IRandomAccessStream object.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFCreateMFByteStreamOnStream([In] IStream punkStream, out IMFByteStream ppByteStream);

		/// <summary>
		/// Gets a list of Microsoft Media Foundation transforms (MFTs) that match specified search criteria. 
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFTEnumEx([In] Guid guidCategory, [In] _MFT_ENUM_FLAG flags, [In] MFT_REGISTER_TYPE_INFO pInputType, [In] MFT_REGISTER_TYPE_INFO pOutputType, out IntPtr pppMFTActivate, out int pcMFTActivate);

		/// <summary>
		/// Creates an empty media sample.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFCreateSample(out IMFSample ppIMFSample);

		/// <summary>
		/// Allocates system memory and creates a media buffer to manage it.
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFCreateMemoryBuffer(int cbMaxLength, out IMFMediaBuffer ppBuffer);

		/// <summary>
		/// Creates an empty attribute store. 
		/// </summary>
		[DllImport("mfplat.dll", ExactSpelling = true, PreserveSig = false)]
		internal static extern void MFCreateAttributes([MarshalAs(UnmanagedType.Interface)] out IMFAttributes ppMFAttributes, [In] int cInitialSize);

		/// <summary>
		/// Gets a list of output formats from an audio encoder.
		/// </summary>
		[DllImport("mf.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void MFTranscodeGetAudioOutputAvailableTypes([In][MarshalAs(UnmanagedType.LPStruct)] Guid guidSubType, [In] _MFT_ENUM_FLAG dwMFTFlags, [In] IMFAttributes pCodecConfig, [MarshalAs(UnmanagedType.Interface)] out IMFCollection ppAvailableTypes);
	}

	/// <summary>
	/// An abstract base class for simplifying working with Media Foundation Transforms
	/// You need to override the method that actually creates and configures the transform
	/// </summary>
	public abstract class MediaFoundationTransform : IWaveProvider, IDisposable
	{
		/// <summary>
		/// The Source Provider
		/// </summary>
		protected readonly IWaveProvider sourceProvider;

		/// <summary>
		/// The Output WaveFormat
		/// </summary>
		protected readonly WaveFormat outputWaveFormat;

		private readonly byte[] sourceBuffer;

		private byte[] outputBuffer;

		private int outputBufferOffset;

		private int outputBufferCount;

		private IMFTransform transform;

		private bool disposed;

		private long inputPosition;

		private long outputPosition;

		private bool initializedForStreaming;

		/// <summary>
		/// The output WaveFormat of this Media Foundation Transform
		/// </summary>
		public WaveFormat WaveFormat => outputWaveFormat;

		/// <summary>
		/// Constructs a new MediaFoundationTransform wrapper
		/// Will read one second at a time
		/// </summary>
		/// <param name="sourceProvider">The source provider for input data to the transform</param>
		/// <param name="outputFormat">The desired output format</param>
		public MediaFoundationTransform(IWaveProvider sourceProvider, WaveFormat outputFormat)
		{
			outputWaveFormat = outputFormat;
			this.sourceProvider = sourceProvider;
			sourceBuffer = new byte[sourceProvider.WaveFormat.AverageBytesPerSecond];
			outputBuffer = new byte[outputWaveFormat.AverageBytesPerSecond + outputWaveFormat.BlockAlign];
		}

		private void InitializeTransformForStreaming()
		{
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_COMMAND_FLUSH, IntPtr.Zero);
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_NOTIFY_BEGIN_STREAMING, IntPtr.Zero);
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_NOTIFY_START_OF_STREAM, IntPtr.Zero);
			initializedForStreaming = true;
		}

		/// <summary>
		/// To be implemented by overriding classes. Create the transform object, set up its input and output types,
		/// and configure any custom properties in here
		/// </summary>
		/// <returns>An object implementing IMFTrasform</returns>
		protected abstract IMFTransform CreateTransform();

		/// <summary>
		/// Disposes this MediaFoundation transform
		/// </summary>
		protected virtual void Dispose(bool disposing)
		{
			if (transform != null)
			{
				Marshal.ReleaseComObject(transform);
			}
		}

		/// <summary>
		/// Disposes this Media Foundation Transform
		/// </summary>
		public void Dispose()
		{
			if (!disposed)
			{
				disposed = true;
				Dispose(disposing: true);
				GC.SuppressFinalize(this);
			}
		}

		/// <summary>
		/// Destructor
		/// </summary>
		~MediaFoundationTransform()
		{
			Dispose(disposing: false);
		}

		/// <summary>
		/// Reads data out of the source, passing it through the transform
		/// </summary>
		/// <param name="buffer">Output buffer</param>
		/// <param name="offset">Offset within buffer to write to</param>
		/// <param name="count">Desired byte count</param>
		/// <returns>Number of bytes read</returns>
		public int Read(byte[] buffer, int offset, int count)
		{
			if (transform == null)
			{
				transform = CreateTransform();
				InitializeTransformForStreaming();
			}
			int i = 0;
			if (outputBufferCount > 0)
			{
				i += ReadFromOutputBuffer(buffer, offset, count - i);
			}
			for (; i < count; i += ReadFromOutputBuffer(buffer, offset + i, count - i))
			{
				IMFSample iMFSample = ReadFromSource();
				if (iMFSample == null)
				{
					EndStreamAndDrain();
					i += ReadFromOutputBuffer(buffer, offset + i, count - i);
					ClearOutputBuffer();
					break;
				}
				if (!initializedForStreaming)
				{
					InitializeTransformForStreaming();
				}
				transform.ProcessInput(0, iMFSample, 0);
				Marshal.ReleaseComObject(iMFSample);
				ReadFromTransform();
			}
			return i;
		}

		private void EndStreamAndDrain()
		{
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_NOTIFY_END_OF_STREAM, IntPtr.Zero);
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_COMMAND_DRAIN, IntPtr.Zero);
			int num;
			do
			{
				num = ReadFromTransform();
			}
			while (num > 0);
			inputPosition = 0L;
			outputPosition = 0L;
			transform.ProcessMessage(MFT_MESSAGE_TYPE.MFT_MESSAGE_NOTIFY_END_STREAMING, IntPtr.Zero);
			initializedForStreaming = false;
		}

		private void ClearOutputBuffer()
		{
			outputBufferCount = 0;
			outputBufferOffset = 0;
		}

		/// <summary>
		/// Attempts to read from the transform
		/// Some useful info here:
		/// http://msdn.microsoft.com/en-gb/library/windows/desktop/aa965264%28v=vs.85%29.aspx#process_data
		/// </summary>
		/// <returns></returns>
		private int ReadFromTransform()
		{
			MFT_OUTPUT_DATA_BUFFER[] array = new MFT_OUTPUT_DATA_BUFFER[1];
			IMFSample iMFSample = MediaFoundationApi.CreateSample();
			IMFMediaBuffer iMFMediaBuffer = MediaFoundationApi.CreateMemoryBuffer(outputBuffer.Length);
			iMFSample.AddBuffer(iMFMediaBuffer);
			iMFSample.SetSampleTime(outputPosition);
			array[0].pSample = iMFSample;
			_MFT_PROCESS_OUTPUT_STATUS pdwStatus;
			int num = transform.ProcessOutput(_MFT_PROCESS_OUTPUT_FLAGS.None, 1, array, out pdwStatus);
			switch (num)
			{
			case -1072861838:
				Marshal.ReleaseComObject(iMFMediaBuffer);
				Marshal.ReleaseComObject(iMFSample);
				return 0;
			default:
				Marshal.ThrowExceptionForHR(num);
				break;
			case 0:
				break;
			}
			array[0].pSample.ConvertToContiguousBuffer(out var ppBuffer);
			ppBuffer.Lock(out var ppbBuffer, out var _, out var pcbCurrentLength);
			outputBuffer = BufferHelpers.Ensure(outputBuffer, pcbCurrentLength);
			Marshal.Copy(ppbBuffer, outputBuffer, 0, pcbCurrentLength);
			outputBufferOffset = 0;
			outputBufferCount = pcbCurrentLength;
			ppBuffer.Unlock();
			outputPosition += BytesToNsPosition(outputBufferCount, WaveFormat);
			Marshal.ReleaseComObject(iMFMediaBuffer);
			iMFSample.RemoveAllBuffers();
			Marshal.ReleaseComObject(iMFSample);
			Marshal.ReleaseComObject(ppBuffer);
			return pcbCurrentLength;
		}

		private static long BytesToNsPosition(int bytes, WaveFormat waveFormat)
		{
			return 10000000L * (long)bytes / waveFormat.AverageBytesPerSecond;
		}

		private IMFSample ReadFromSource()
		{
			int num = sourceProvider.Read(sourceBuffer, 0, sourceBuffer.Length);
			if (num == 0)
			{
				return null;
			}
			IMFMediaBuffer iMFMediaBuffer = MediaFoundationApi.CreateMemoryBuffer(num);
			iMFMediaBuffer.Lock(out var ppbBuffer, out var _, out var _);
			Marshal.Copy(sourceBuffer, 0, ppbBuffer, num);
			iMFMediaBuffer.Unlock();
			iMFMediaBuffer.SetCurrentLength(num);
			IMFSample iMFSample = MediaFoundationApi.CreateSample();
			iMFSample.AddBuffer(iMFMediaBuffer);
			iMFSample.SetSampleTime(inputPosition);
			long num2 = BytesToNsPosition(num, sourceProvider.WaveFormat);
			iMFSample.SetSampleDuration(num2);
			inputPosition += num2;
			Marshal.ReleaseComObject(iMFMediaBuffer);
			return iMFSample;
		}

		private int ReadFromOutputBuffer(byte[] buffer, int offset, int needed)
		{
			int num = Math.Min(needed, outputBufferCount);
			Array.Copy(outputBuffer, outputBufferOffset, buffer, offset, num);
			outputBufferOffset += num;
			outputBufferCount -= num;
			if (outputBufferCount == 0)
			{
				outputBufferOffset = 0;
			}
			return num;
		}

		/// <summary>
		/// Indicate that the source has been repositioned and completely drain out the transforms buffers
		/// </summary>
		public void Reposition()
		{
			if (initializedForStreaming)
			{
				EndStreamAndDrain();
				ClearOutputBuffer();
				InitializeTransformForStreaming();
			}
		}
	}

	/// <summary>
	/// Media Foundation Transform Categories
	/// </summary>
	public static class MediaFoundationTransformCategories
	{
		/// <summary>
		/// MFT_CATEGORY_VIDEO_DECODER
		/// </summary>
		[FieldDescription("Video Decoder")]
		public static readonly Guid VideoDecoder = new Guid("{d6c02d4b-6833-45b4-971a-05a4b04bab91}");

		/// <summary>
		/// MFT_CATEGORY_VIDEO_ENCODER
		/// </summary>
		[FieldDescription("Video Encoder")]
		public static readonly Guid VideoEncoder = new Guid("{f79eac7d-e545-4387-bdee-d647d7bde42a}");

		/// <summary>
		/// MFT_CATEGORY_VIDEO_EFFECT
		/// </summary>
		[FieldDescription("Video Effect")]
		public static readonly Guid VideoEffect = new Guid("{12e17c21-532c-4a6e-8a1c-40825a736397}");

		/// <summary>
		/// MFT_CATEGORY_MULTIPLEXER
		/// </summary>
		[FieldDescription("Multiplexer")]
		public static readonly Guid Multiplexer = new Guid("{059c561e-05ae-4b61-b69d-55b61ee54a7b}");

		/// <summary>
		/// MFT_CATEGORY_DEMULTIPLEXER
		/// </summary>
		[FieldDescription("Demultiplexer")]
		public static readonly Guid Demultiplexer = new Guid("{a8700a7a-939b-44c5-99d7-76226b23b3f1}");

		/// <summary>
		/// MFT_CATEGORY_AUDIO_DECODER
		/// </summary>
		[FieldDescription("Audio Decoder")]
		public static readonly Guid AudioDecoder = new Guid("{9ea73fb4-ef7a-4559-8d5d-719d8f0426c7}");

		/// <summary>
		/// MFT_CATEGORY_AUDIO_ENCODER
		/// </summary>
		[FieldDescription("Audio Encoder")]
		public static readonly Guid AudioEncoder = new Guid("{91c64bd0-f91e-4d8c-9276-db248279d975}");

		/// <summary>
		/// MFT_CATEGORY_AUDIO_EFFECT
		/// </summary>
		[FieldDescription("Audio Effect")]
		public static readonly Guid AudioEffect = new Guid("{11064c48-3648-4ed0-932e-05ce8ac811b7}");

		/// <summary>
		/// MFT_CATEGORY_VIDEO_PROCESSOR
		/// </summary>
		[FieldDescription("Video Processor")]
		public static readonly Guid VideoProcessor = new Guid("{302EA3FC-AA5F-47f9-9F7A-C2188BB16302}");

		/// <summary>
		/// MFT_CATEGORY_OTHER
		/// </summary>
		[FieldDescription("Other")]
		public static readonly Guid Other = new Guid("{90175d57-b7ea-4901-aeb3-933a8747756f}");
	}

	/// <summary>
	/// Media Type helper class, simplifying working with IMFMediaType
	/// (will probably change in the future, to inherit from an attributes class)
	/// Currently does not release the COM object, so you must do that yourself
	/// </summary>
	public class MediaType
	{
		private readonly IMFMediaType mediaType;

		/// <summary>
		/// The Sample Rate (valid for audio media types)
		/// </summary>
		public int SampleRate
		{
			get
			{
				return GetUInt32(MediaFoundationAttributes.MF_MT_AUDIO_SAMPLES_PER_SECOND);
			}
			set
			{
				mediaType.SetUINT32(MediaFoundationAttributes.MF_MT_AUDIO_SAMPLES_PER_SECOND, value);
			}
		}

		/// <summary>
		/// The number of Channels (valid for audio media types)
		/// </summary>
		public int ChannelCount
		{
			get
			{
				return GetUInt32(MediaFoundationAttributes.MF_MT_AUDIO_NUM_CHANNELS);
			}
			set
			{
				mediaType.SetUINT32(MediaFoundationAttributes.MF_MT_AUDIO_NUM_CHANNELS, value);
			}
		}

		/// <summary>
		/// The number of bits per sample (n.b. not always valid for compressed audio types)
		/// </summary>
		public int BitsPerSample
		{
			get
			{
				return GetUInt32(MediaFoundationAttributes.MF_MT_AUDIO_BITS_PER_SAMPLE);
			}
			set
			{
				mediaType.SetUINT32(MediaFoundationAttributes.MF_MT_AUDIO_BITS_PER_SAMPLE, value);
			}
		}

		/// <summary>
		/// The average bytes per second (valid for audio media types)
		/// </summary>
		public int AverageBytesPerSecond => GetUInt32(MediaFoundationAttributes.MF_MT_AUDIO_AVG_BYTES_PER_SECOND);

		/// <summary>
		/// The Media Subtype. For audio, is a value from the AudioSubtypes class
		/// </summary>
		public Guid SubType
		{
			get
			{
				return GetGuid(MediaFoundationAttributes.MF_MT_SUBTYPE);
			}
			set
			{
				mediaType.SetGUID(MediaFoundationAttributes.MF_MT_SUBTYPE, value);
			}
		}

		/// <summary>
		/// The Major type, e.g. audio or video (from the MediaTypes class)
		/// </summary>
		public Guid MajorType
		{
			get
			{
				return GetGuid(MediaFoundationAttributes.MF_MT_MAJOR_TYPE);
			}
			set
			{
				mediaType.SetGUID(MediaFoundationAttributes.MF_MT_MAJOR_TYPE, value);
			}
		}

		/// <summary>
		/// Access to the actual IMFMediaType object
		/// Use to pass to MF APIs or Marshal.ReleaseComObject when you are finished with it
		/// </summary>
		public IMFMediaType MediaFoundationObject => mediaType;

		/// <summary>
		/// Wraps an existing IMFMediaType object
		/// </summary>
		/// <param name="mediaType">The IMFMediaType object</param>
		public MediaType(IMFMediaType mediaType)
		{
			this.mediaType = mediaType;
		}

		/// <summary>
		/// Creates and wraps a new IMFMediaType object
		/// </summary>
		public MediaType()
		{
			mediaType = MediaFoundationApi.CreateMediaType();
		}

		/// <summary>
		/// Creates and wraps a new IMFMediaType object based on a WaveFormat
		/// </summary>
		/// <param name="waveFormat">WaveFormat</param>
		public MediaType(WaveFormat waveFormat)
		{
			mediaType = MediaFoundationApi.CreateMediaTypeFromWaveFormat(waveFormat);
		}

		private int GetUInt32(Guid key)
		{
			mediaType.GetUINT32(key, out var punValue);
			return punValue;
		}

		private Guid GetGuid(Guid key)
		{
			mediaType.GetGUID(key, out var pguidValue);
			return pguidValue;
		}

		/// <summary>
		/// Tries to get a UINT32 value, returning a default value if it doesn't exist
		/// </summary>
		/// <param name="key">Attribute key</param>
		/// <param name="defaultValue">Default value</param>
		/// <returns>Value or default if key doesn't exist</returns>
		public int TryGetUInt32(Guid key, int defaultValue = -1)
		{
			int punValue = defaultValue;
			try
			{
				mediaType.GetUINT32(key, out punValue);
			}
			catch (COMException exception)
			{
				if (exception.GetHResult() != -1072875802)
				{
					if (exception.GetHResult() == -1072875843)
					{
						throw new ArgumentException("Not a UINT32 parameter");
					}
					throw;
				}
			}
			return punValue;
		}

		/// <summary>
		/// Sets a UINT32 attribute on this media type
		/// </summary>
		/// <param name="key">Attribute key</param>
		/// <param name="value">Attribute value (e.g. 1 for TRUE)</param>
		public void SetUInt32(Guid key, int value)
		{
			mediaType.SetUINT32(key, value);
		}
	}

	/// <summary>
	/// Major Media Types
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/aa367377%28v=vs.85%29.aspx
	/// </summary>
	public static class MediaTypes
	{
		/// <summary>
		/// Default
		/// </summary>
		public static readonly Guid MFMediaType_Default = new Guid("81A412E6-8103-4B06-857F-1862781024AC");

		/// <summary>
		/// Audio
		/// </summary>
		[FieldDescription("Audio")]
		public static readonly Guid MFMediaType_Audio = new Guid("73647561-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Video
		/// </summary>
		[FieldDescription("Video")]
		public static readonly Guid MFMediaType_Video = new Guid("73646976-0000-0010-8000-00aa00389b71");

		/// <summary>
		/// Protected Media
		/// </summary>
		[FieldDescription("Protected Media")]
		public static readonly Guid MFMediaType_Protected = new Guid("7b4b6fe6-9d04-4494-be14-7e0bd076c8e4");

		/// <summary>
		/// Synchronized Accessible Media Interchange (SAMI) captions.
		/// </summary>
		[FieldDescription("SAMI captions")]
		public static readonly Guid MFMediaType_SAMI = new Guid("e69669a0-3dcd-40cb-9e2e-3708387c0616");

		/// <summary>
		/// Script stream
		/// </summary>
		[FieldDescription("Script stream")]
		public static readonly Guid MFMediaType_Script = new Guid("72178c22-e45b-11d5-bc2a-00b0d0f3f4ab");

		/// <summary>
		/// Still image stream.
		/// </summary>
		[FieldDescription("Still image stream")]
		public static readonly Guid MFMediaType_Image = new Guid("72178c23-e45b-11d5-bc2a-00b0d0f3f4ab");

		/// <summary>
		/// HTML stream.
		/// </summary>
		[FieldDescription("HTML stream")]
		public static readonly Guid MFMediaType_HTML = new Guid("72178c24-e45b-11d5-bc2a-00b0d0f3f4ab");

		/// <summary>
		/// Binary stream.
		/// </summary>
		[FieldDescription("Binary stream")]
		public static readonly Guid MFMediaType_Binary = new Guid("72178c25-e45b-11d5-bc2a-00b0d0f3f4ab");

		/// <summary>
		/// A stream that contains data files.
		/// </summary>
		[FieldDescription("File transfer")]
		public static readonly Guid MFMediaType_FileTransfer = new Guid("72178c26-e45b-11d5-bc2a-00b0d0f3f4ab");
	}

	/// <summary>
	/// CLSID_MFReadWriteClassFactory
	/// </summary>
	[ComImport]
	[Guid("48e2ed0f-98c2-4a37-bed5-166312ddd83f")]
	public class MFReadWriteClassFactory { }

	/// <summary>
	/// Contains information about an input stream on a Media Foundation transform (MFT)
	/// </summary>
	public struct MFT_INPUT_STREAM_INFO
	{
		/// <summary>
		/// Maximum amount of time between an input sample and the corresponding output sample, in 100-nanosecond units.
		/// </summary>
		public long hnsMaxLatency;

		/// <summary>
		/// Bitwise OR of zero or more flags from the _MFT_INPUT_STREAM_INFO_FLAGS enumeration.
		/// </summary>
		public _MFT_INPUT_STREAM_INFO_FLAGS dwFlags;

		/// <summary>
		/// The minimum size of each input buffer, in bytes.
		/// </summary>
		public int cbSize;

		/// <summary>
		/// Maximum amount of input data, in bytes, that the MFT holds to perform lookahead.
		/// </summary>
		public int cbMaxLookahead;

		/// <summary>
		/// The memory alignment required for input buffers. If the MFT does not require a specific alignment, the value is zero.
		/// </summary>
		public int cbAlignment;
	}

	/// <summary>
	/// Defines messages for a Media Foundation transform (MFT).
	/// </summary>
	public enum MFT_MESSAGE_TYPE
	{
		/// <summary>
		/// Requests the MFT to flush all stored data. 
		/// </summary>
		MFT_MESSAGE_COMMAND_FLUSH = 0,
		/// <summary>
		/// Requests the MFT to drain any stored data.
		/// </summary>
		MFT_MESSAGE_COMMAND_DRAIN = 1,
		/// <summary>
		/// Sets or clears the Direct3D Device Manager for DirectX Video Accereration (DXVA). 
		/// </summary>
		MFT_MESSAGE_SET_D3D_MANAGER = 2,
		/// <summary>
		/// Drop samples - requires Windows 7
		/// </summary>
		MFT_MESSAGE_DROP_SAMPLES = 3,
		/// <summary>
		/// Command Tick - requires Windows 8
		/// </summary>
		MFT_MESSAGE_COMMAND_TICK = 4,
		/// <summary>
		/// Notifies the MFT that streaming is about to begin. 
		/// </summary>
		MFT_MESSAGE_NOTIFY_BEGIN_STREAMING = 268435456,
		/// <summary>
		/// Notifies the MFT that streaming is about to end. 
		/// </summary>
		MFT_MESSAGE_NOTIFY_END_STREAMING = 268435457,
		/// <summary>
		/// Notifies the MFT that an input stream has ended. 
		/// </summary>
		MFT_MESSAGE_NOTIFY_END_OF_STREAM = 268435458,
		/// <summary>
		/// Notifies the MFT that the first sample is about to be processed. 
		/// </summary>
		MFT_MESSAGE_NOTIFY_START_OF_STREAM = 268435459,
		/// <summary>
		/// Marks a point in the stream. This message applies only to asynchronous MFTs. Requires Windows 7 
		/// </summary>
		MFT_MESSAGE_COMMAND_MARKER = 536870912
	}

	/// <summary>
	/// Contains information about an output buffer for a Media Foundation transform. 
	/// </summary>
	public struct MFT_OUTPUT_DATA_BUFFER
	{
		/// <summary>
		/// Output stream identifier.
		/// </summary>
		public int dwStreamID;

		/// <summary>
		/// Pointer to the IMFSample interface. 
		/// </summary>
		public IMFSample pSample;

		/// <summary>
		/// Before calling ProcessOutput, set this member to zero.
		/// </summary>
		public _MFT_OUTPUT_DATA_BUFFER_FLAGS dwStatus;

		/// <summary>
		/// Before calling ProcessOutput, set this member to NULL.
		/// </summary>
		public IMFCollection pEvents;
	}

	/// <summary>
	/// Contains information about an output stream on a Media Foundation transform (MFT).
	/// </summary>
	public struct MFT_OUTPUT_STREAM_INFO
	{
		/// <summary>
		/// Bitwise OR of zero or more flags from the _MFT_OUTPUT_STREAM_INFO_FLAGS enumeration.
		/// </summary>
		public _MFT_OUTPUT_STREAM_INFO_FLAGS dwFlags;

		/// <summary>
		/// Minimum size of each output buffer, in bytes.
		/// </summary>
		public int cbSize;

		/// <summary>
		/// The memory alignment required for output buffers.
		/// </summary>
		public int cbAlignment;
	}

	/// <summary>
	/// Contains media type information for registering a Media Foundation transform (MFT). 
	/// </summary>
	[StructLayout(LayoutKind.Sequential)]
	public class MFT_REGISTER_TYPE_INFO
	{
		/// <summary>
		/// The major media type.
		/// </summary>
		public Guid guidMajorType;

		/// <summary>
		/// The Media Subtype
		/// </summary>
		public Guid guidSubtype;
	}

	/// <summary>
	/// Contains statistics about the performance of the sink writer.
	/// </summary>
	[StructLayout(LayoutKind.Sequential)]
	public class MF_SINK_WRITER_STATISTICS
	{
		/// <summary>
		/// The size of the structure, in bytes.
		/// </summary>
		public int cb;

		/// <summary>
		/// The time stamp of the most recent sample given to the sink writer.
		/// </summary>
		public long llLastTimestampReceived;

		/// <summary>
		/// The time stamp of the most recent sample to be encoded.
		/// </summary>
		public long llLastTimestampEncoded;

		/// <summary>
		/// The time stamp of the most recent sample given to the media sink.
		/// </summary>
		public long llLastTimestampProcessed;

		/// <summary>
		/// The time stamp of the most recent stream tick. 
		/// </summary>
		public long llLastStreamTickReceived;

		/// <summary>
		/// The system time of the most recent sample request from the media sink. 
		/// </summary>
		public long llLastSinkSampleRequest;

		/// <summary>
		/// The number of samples received.
		/// </summary>
		public long qwNumSamplesReceived;

		/// <summary>
		/// The number of samples encoded.
		/// </summary>
		public long qwNumSamplesEncoded;

		/// <summary>
		/// The number of samples given to the media sink.
		/// </summary>
		public long qwNumSamplesProcessed;

		/// <summary>
		/// The number of stream ticks received.
		/// </summary>
		public long qwNumStreamTicksReceived;

		/// <summary>
		/// The amount of data, in bytes, currently waiting to be processed. 
		/// </summary>
		public int dwByteCountQueued;

		/// <summary>
		/// The total amount of data, in bytes, that has been sent to the media sink.
		/// </summary>
		public long qwByteCountProcessed;

		/// <summary>
		/// The number of pending sample requests.
		/// </summary>
		public int dwNumOutstandingSinkSampleRequests;

		/// <summary>
		/// The average rate, in media samples per 100-nanoseconds, at which the application sent samples to the sink writer.
		/// </summary>
		public int dwAverageSampleRateReceived;

		/// <summary>
		/// The average rate, in media samples per 100-nanoseconds, at which the sink writer sent samples to the encoder
		/// </summary>
		public int dwAverageSampleRateEncoded;

		/// <summary>
		/// The average rate, in media samples per 100-nanoseconds, at which the sink writer sent samples to the media sink.
		/// </summary>
		public int dwAverageSampleRateProcessed;
	}

	/// <summary>
	/// Contains flags that indicate the status of the IMFSourceReader::ReadSample method
	/// http://msdn.microsoft.com/en-us/library/windows/desktop/dd375773(v=vs.85).aspx
	/// </summary>
	[Flags]
	public enum MF_SOURCE_READER_FLAG
	{
		/// <summary>
		/// No Error
		/// </summary>
		None = 0,
		/// <summary>
		/// An error occurred. If you receive this flag, do not make any further calls to IMFSourceReader methods.
		/// </summary>
		MF_SOURCE_READERF_ERROR = 1,
		/// <summary>
		/// The source reader reached the end of the stream.
		/// </summary>
		MF_SOURCE_READERF_ENDOFSTREAM = 2,
		/// <summary>
		/// One or more new streams were created
		/// </summary>
		MF_SOURCE_READERF_NEWSTREAM = 4,
		/// <summary>
		/// The native format has changed for one or more streams. The native format is the format delivered by the media source before any decoders are inserted.
		/// </summary>
		MF_SOURCE_READERF_NATIVEMEDIATYPECHANGED = 0x10,
		/// <summary>
		/// The current media has type changed for one or more streams. To get the current media type, call the IMFSourceReader::GetCurrentMediaType method.
		/// </summary>
		MF_SOURCE_READERF_CURRENTMEDIATYPECHANGED = 0x20,
		/// <summary>
		/// There is a gap in the stream. This flag corresponds to an MEStreamTick event from the media source.
		/// </summary>
		MF_SOURCE_READERF_STREAMTICK = 0x100,
		/// <summary>
		/// All transforms inserted by the application have been removed for a particular stream.
		/// </summary>
		MF_SOURCE_READERF_ALLEFFECTSREMOVED = 0x200
	}

	/// <summary>
	/// https://docs.microsoft.com/en-us/windows/win32/medfound/mf-transcode-containertype
	/// </summary>
	public static class TranscodeContainerTypes
	{
		/// <summary>
		/// ASF
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_ASF = new Guid(1125085038u, 46783, 20417, 160, 189, 158, 228, 110, 238, 42, 251);

		/// <summary>
		/// MPEG4
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_MPEG4 = new Guid(3698118749u, 47568, 16623, 189, 53, 250, 98, 44, 26, 178, 138);

		/// <summary>
		/// MP3
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_MP3 = new Guid(3828922642u, 33777, 19942, 158, 58, 159, 251, 198, 221, 36, 209);

		/// <summary>
		/// 3GP
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_3GP = new Guid(885326183, 17522, 20276, 158, 160, 196, 159, 186, 207, 3, 125);

		/// <summary>
		/// AC3
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_AC3 = new Guid(1837994435u, 35985, 20177, 135, 66, 140, 52, 125, 91, 68, 208);

		/// <summary>
		/// ADTS
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_ADTS = new Guid(321901181, 3842, 17374, 163, 1, 56, 251, 187, 179, 131, 78);

		/// <summary>
		/// MPEG2
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_MPEG2 = new Guid(3217218553u, 31668, 20367, 175, 222, 225, 18, 196, 75, 168, 130);

		/// <summary>
		/// FMPEG4
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_FMPEG4 = new Guid(2611508977u, 16799, 19319, 161, 224, 53, 149, 157, 157, 64, 4);

		/// <summary>
		/// WAVE
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_WAVE = new Guid(1690518844, 3878, 18241, 190, 99, 135, 189, 248, 187, 147, 91);

		/// <summary>
		/// AVI
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_AVI = new Guid(2128603311, 16431, 19830, 163, 60, 97, 159, 209, 87, 208, 241);

		/// <summary>
		/// AMR
		/// </summary>
		public static readonly Guid MFTranscodeContainerType_AMR = new Guid(39672531, 25114, 18267, 150, 77, 102, 177, 200, 36, 240, 121);
	}

	/// <summary>
	/// Contains flags for registering and enumeration Media Foundation transforms (MFTs).
	/// </summary>
	[Flags]
	public enum _MFT_ENUM_FLAG
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// The MFT performs synchronous data processing in software. 
		/// </summary>
		MFT_ENUM_FLAG_SYNCMFT = 1,
		/// <summary>
		/// The MFT performs asynchronous data processing in software.
		/// </summary>
		MFT_ENUM_FLAG_ASYNCMFT = 2,
		/// <summary>
		/// The MFT performs hardware-based data processing, using either the AVStream driver or a GPU-based proxy MFT. 
		/// </summary>
		MFT_ENUM_FLAG_HARDWARE = 4,
		/// <summary>
		/// The MFT that must be unlocked by the application before use.
		/// </summary>
		MFT_ENUM_FLAG_FIELDOFUSE = 8,
		/// <summary>
		/// For enumeration, include MFTs that were registered in the caller's process.
		/// </summary>
		MFT_ENUM_FLAG_LOCALMFT = 0x10,
		/// <summary>
		/// The MFT is optimized for transcoding rather than playback.
		/// </summary>
		MFT_ENUM_FLAG_TRANSCODE_ONLY = 0x20,
		/// <summary>
		/// For enumeration, sort and filter the results.
		/// </summary>
		MFT_ENUM_FLAG_SORTANDFILTER = 0x40,
		/// <summary>
		/// Bitwise OR of all the flags, excluding MFT_ENUM_FLAG_SORTANDFILTER.
		/// </summary>
		MFT_ENUM_FLAG_ALL = 0x3F
	}

	/// <summary>
	/// Indicates the status of an input stream on a Media Foundation transform (MFT).
	/// </summary>
	[Flags]
	public enum _MFT_INPUT_STATUS_FLAGS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// The input stream can receive more data at this time.
		/// </summary>
		MFT_INPUT_STATUS_ACCEPT_DATA = 1
	}

	/// <summary>
	/// Describes an input stream on a Media Foundation transform (MFT).
	/// </summary>
	[Flags]
	public enum _MFT_INPUT_STREAM_INFO_FLAGS
    {
        /// <summary>
        /// No flags set
        /// </summary>
        None = 0,
        /// <summary>
        /// Each media sample (IMFSample interface) of input data must contain complete, unbroken units of data. 
        /// </summary>
        MFT_INPUT_STREAM_WHOLE_SAMPLES = 1,
        /// <summary>
        /// Each media sample that the client provides as input must contain exactly one unit of data, as defined for the MFT_INPUT_STREAM_WHOLE_SAMPLES flag.
        /// </summary>
        MFT_INPUT_STREAM_SINGLE_SAMPLE_PER_BUFFER = 2,
        /// <summary>
        /// All input samples must be the same size.
        /// </summary>
        MFT_INPUT_STREAM_FIXED_SAMPLE_SIZE = 4,
        /// <summary>
        /// MTF Input Stream Holds buffers
        /// </summary>
        MFT_INPUT_STREAM_HOLDS_BUFFERS = 8,
        /// <summary>
        /// The MFT does not hold input samples after the IMFTransform::ProcessInput method returns.
        /// </summary>
        MFT_INPUT_STREAM_DOES_NOT_ADDREF = 0x100,
        /// <summary>
        /// This input stream can be removed by calling IMFTransform::DeleteInputStream.
        /// </summary>
        MFT_INPUT_STREAM_REMOVABLE = 0x200,
        /// <summary>
        /// This input stream is optional. 
        /// </summary>
        MFT_INPUT_STREAM_OPTIONAL = 0x400,
        /// <summary>
        /// The MFT can perform in-place processing.
        /// </summary>
        MFT_INPUT_STREAM_PROCESSES_IN_PLACE = 0x800
    }

    /// <summary>
    /// Defines flags for the IMFTransform::ProcessOutput method. 
    /// </summary>
    [Flags]
	public enum _MFT_OUTPUT_DATA_BUFFER_FLAGS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// The MFT can still generate output from this stream without receiving any more input. 
		/// </summary>
		MFT_OUTPUT_DATA_BUFFER_INCOMPLETE = 0x1000000,
		/// <summary>
		/// The format has changed on this output stream, or there is a new preferred format for this stream. 
		/// </summary>
		MFT_OUTPUT_DATA_BUFFER_FORMAT_CHANGE = 0x100,
		/// <summary>
		/// The MFT has removed this output stream. 
		/// </summary>
		MFT_OUTPUT_DATA_BUFFER_STREAM_END = 0x200,
		/// <summary>
		/// There is no sample ready for this stream.
		/// </summary>
		MFT_OUTPUT_DATA_BUFFER_NO_SAMPLE = 0x300
	}

	/// <summary>
	/// Indicates whether a Media Foundation transform (MFT) can produce output data.
	/// </summary>
	[Flags]
	public enum _MFT_OUTPUT_STATUS_FLAGS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// There is a sample available for at least one output stream.
		/// </summary>
		MFT_OUTPUT_STATUS_SAMPLE_READY = 1
	}

	/// <summary>
	/// Describes an output stream on a Media Foundation transform (MFT).
	/// </summary>
	[Flags]
	public enum _MFT_OUTPUT_STREAM_INFO_FLAGS
	{
		/// <summary>
		/// No flags set
		/// </summary>
		None = 0,
		/// <summary>
		/// Each media sample (IMFSample interface) of output data from the MFT contains complete, unbroken units of data.
		/// </summary>
		MFT_OUTPUT_STREAM_WHOLE_SAMPLES = 1,
		/// <summary>
		/// Each output sample contains exactly one unit of data, as defined for the MFT_OUTPUT_STREAM_WHOLE_SAMPLES flag.
		/// </summary>
		MFT_OUTPUT_STREAM_SINGLE_SAMPLE_PER_BUFFER = 2,
		/// <summary>
		/// All output samples are the same size.
		/// </summary>
		MFT_OUTPUT_STREAM_FIXED_SAMPLE_SIZE = 4,
		/// <summary>
		/// The MFT can discard the output data from this output stream, if requested by the client.
		/// </summary>
		MFT_OUTPUT_STREAM_DISCARDABLE = 8,
		/// <summary>
		/// This output stream is optional.
		/// </summary>
		MFT_OUTPUT_STREAM_OPTIONAL = 0x10,
		/// <summary>
		/// The MFT provides the output samples for this stream, either by allocating them internally or by operating directly on the input samples.
		/// </summary>
		MFT_OUTPUT_STREAM_PROVIDES_SAMPLES = 0x100,
		/// <summary>
		/// The MFT can either provide output samples for this stream or it can use samples that the client allocates. 
		/// </summary>
		MFT_OUTPUT_STREAM_CAN_PROVIDE_SAMPLES = 0x200,
		/// <summary>
		/// The MFT does not require the client to process the output for this stream. 
		/// </summary>
		MFT_OUTPUT_STREAM_LAZY_READ = 0x400,
		/// <summary>
		/// The MFT might remove this output stream during streaming.
		/// </summary>
		MFT_OUTPUT_STREAM_REMOVABLE = 0x800
	}

	/// <summary>
	/// Defines flags for processing output samples in a Media Foundation transform (MFT).
	/// </summary>
	[Flags]
	public enum _MFT_PROCESS_OUTPUT_FLAGS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// Do not produce output for streams in which the pSample member of the MFT_OUTPUT_DATA_BUFFER structure is NULL. 
		/// </summary>
		MFT_PROCESS_OUTPUT_DISCARD_WHEN_NO_BUFFER = 1,
		/// <summary>
		/// Regenerates the last output sample.
		/// </summary>
		MFT_PROCESS_OUTPUT_REGENERATE_LAST_OUTPUT = 2
	}

	/// <summary>
	/// Process Output Status flags
	/// </summary>
	[Flags]
	public enum _MFT_PROCESS_OUTPUT_STATUS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// The Media Foundation transform (MFT) has created one or more new output streams.
		/// </summary>
		MFT_PROCESS_OUTPUT_STATUS_NEW_STREAMS = 0x100
	}

	/// <summary>
	/// Defines flags for the setting or testing the media type on a Media Foundation transform (MFT).
	/// </summary>
	[Flags]
	public enum _MFT_SET_TYPE_FLAGS
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// Test the proposed media type, but do not set it.
		/// </summary>
		MFT_SET_TYPE_TEST_ONLY = 1
	}
}

namespace NAudio.Wasapi.CoreAudioApi
{
	using NAudio.CoreAudioApi.Interfaces;
	using NAudio.Wasapi.CoreAudioApi.Interfaces;
	
	internal class ActivateAudioInterfaceCompletionHandler : IActivateAudioInterfaceCompletionHandler, IAgileObject
	{
		private Action<IAudioClient2> initializeAction;

		private TaskCompletionSource<IAudioClient2> tcs = new TaskCompletionSource<IAudioClient2>();

		public ActivateAudioInterfaceCompletionHandler(Action<IAudioClient2> initializeAction)
		{
			this.initializeAction = initializeAction;
		}

		public void ActivateCompleted(IActivateAudioInterfaceAsyncOperation activateOperation)
		{
			activateOperation.GetActivateResult(out var activateResult, out var activateInterface);
			if (activateResult != 0)
			{
				tcs.TrySetException(Marshal.GetExceptionForHR(activateResult, new IntPtr(-1)));
				return;
			}
			IAudioClient2 audioClient = (IAudioClient2)activateInterface;
			try
			{
				initializeAction(audioClient);
				tcs.SetResult(audioClient);
			}
			catch (Exception exception)
			{
				tcs.TrySetException(exception);
			}
		}

		public TaskAwaiter<IAudioClient2> GetAwaiter()
		{
			return tcs.Task.GetAwaiter();
		}
	}

	/// <summary>
	/// Audio Volume Level
	/// </summary>
	public class AudioVolumeLevel
	{
		private readonly IAudioVolumeLevel audioVolumeLevelInterface;

		public uint ChannelCount
		{
			get
			{
				audioVolumeLevelInterface.GetChannelCount(out var channels);
				return channels;
			}
		}

		internal AudioVolumeLevel(IAudioVolumeLevel audioVolumeLevel)
		{
			audioVolumeLevelInterface = audioVolumeLevel;
		}

		public void GetLevelRange(uint channel, out float minLevelDb, out float maxLevelDb, out float stepping)
		{
			audioVolumeLevelInterface.GetLevelRange(channel, out minLevelDb, out maxLevelDb, out stepping);
		}

		public float GetLevel(uint channel)
		{
			audioVolumeLevelInterface.GetLevel(channel, out var levelDb);
			return levelDb;
		}

		public void SetLevel(uint channel, float value)
		{
			Guid eventGuidContext = Guid.Empty;
			audioVolumeLevelInterface.SetLevel(channel, value, ref eventGuidContext);
		}

		public void SetLevelUniform(float value)
		{
			Guid eventGuidContext = Guid.Empty;
			audioVolumeLevelInterface.SetLevelUniform(value, ref eventGuidContext);
		}

		public void SetLevelAllChannel(float[] values, uint channels)
		{
			Guid eventGuidContext = Guid.Empty;
			audioVolumeLevelInterface.SetLevelAllChannel(values, channels, ref eventGuidContext);
		}
	}

	internal static class NativeMethods
	{
		/// <summary>
		/// Enables Windows Store apps to access preexisting Component Object Model (COM) interfaces in the WASAPI family.
		/// </summary>
		/// <param name="deviceInterfacePath">A device interface ID for an audio device. This is normally retrieved from a DeviceInformation object or one of the methods of the MediaDevice class.</param>
		/// <param name="riid">The IID of a COM interface in the WASAPI family, such as IAudioClient.</param>
		/// <param name="activationParams">Interface-specific activation parameters. For more information, see the pActivationParams parameter in IMMDevice::Activate. </param>
		/// <param name="completionHandler"></param>
		/// <param name="activationOperation"></param>
		[DllImport("Mmdevapi.dll", ExactSpelling = true, PreserveSig = false)]
		public static extern void ActivateAudioInterfaceAsync([In][MarshalAs(UnmanagedType.LPWStr)] string deviceInterfacePath, [In][MarshalAs(UnmanagedType.LPStruct)] Guid riid, [In] IntPtr activationParams, [In] IActivateAudioInterfaceCompletionHandler completionHandler, out IActivateAudioInterfaceAsyncOperation activationOperation);
	}
}

namespace NAudio.Wasapi.CoreAudioApi.Interfaces
{
	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("72A22D78-CDE4-431D-B8CC-843A71199B6D")]
	public interface IActivateAudioInterfaceAsyncOperation
	{
		void GetActivateResult(out int activateResult, [MarshalAs(UnmanagedType.IUnknown)] out object activateInterface);
	}

	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("41D949AB-9862-444A-80F6-C261334DA5EB")]
	public interface IActivateAudioInterfaceCompletionHandler
	{
		void ActivateCompleted(IActivateAudioInterfaceAsyncOperation activateOperation);
	}

	[ComImport]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	[Guid("94ea2b94-e9cc-49e0-c0ff-ee64ca8f5b90")]
	internal interface IAgileObject { }

	[ComImport]
	[Guid("9c2c4058-23f5-41de-877a-df3af236a09e")]
	[InterfaceType(ComInterfaceType.InterfaceIsIUnknown)]
	internal interface IControlChangeNotify
	{
		[PreserveSig]
		int OnNotify([In] uint controlId, [In] IntPtr context);
	}
}

namespace NAudio.Wave
{
	using NAudio.Dmo;
	using NAudio.Utils;
	using NAudio.Dmo.Effect;
	using NAudio.CoreAudioApi;
	using NAudio.MediaFoundation;
	using NAudio.CoreAudioApi.Interfaces;
	using System.Runtime.InteropServices.ComTypes;
	
	/// <summary>
	/// Implementation of Com IStream
	/// </summary>
	internal class ComStream : Stream, IStream
	{
		private Stream stream;

		public override bool CanRead => stream.CanRead;

		public override bool CanSeek => stream.CanSeek;

		public override bool CanWrite => stream.CanWrite;

		public override long Length => stream.Length;

		public override long Position
		{
			get
			{
				return stream.Position;
			}
			set
			{
				stream.Position = value;
			}
		}

		public ComStream(Stream stream)
			: this(stream, synchronizeStream: true)
		{
		}

		internal ComStream(Stream stream, bool synchronizeStream)
		{
			if (stream == null)
			{
				throw new ArgumentNullException("stream");
			}
			if (synchronizeStream)
			{
				stream = Stream.Synchronized(stream);
			}
			this.stream = stream;
		}

		void IStream.Clone(out IStream ppstm)
		{
			ppstm = null;
		}

		void IStream.Commit(int grfCommitFlags)
		{
			stream.Flush();
		}

		void IStream.CopyTo(IStream pstm, long cb, IntPtr pcbRead, IntPtr pcbWritten)
		{
		}

		void IStream.LockRegion(long libOffset, long cb, int dwLockType)
		{
		}

		void IStream.Read(byte[] pv, int cb, IntPtr pcbRead)
		{
			if (!CanRead)
			{
				throw new InvalidOperationException("Stream is not readable.");
			}
			int val = Read(pv, 0, cb);
			if (pcbRead != IntPtr.Zero)
			{
				Marshal.WriteInt32(pcbRead, val);
			}
		}

		void IStream.Revert()
		{
		}

		void IStream.Seek(long dlibMove, int dwOrigin, IntPtr plibNewPosition)
		{
			long val = Seek(dlibMove, (SeekOrigin)dwOrigin);
			if (plibNewPosition != IntPtr.Zero)
			{
				Marshal.WriteInt64(plibNewPosition, val);
			}
		}

		void IStream.SetSize(long libNewSize)
		{
			SetLength(libNewSize);
		}

		void IStream.Stat(out STATSTG pstatstg, int grfStatFlag)
		{
			STATSTG sTATSTG = default(STATSTG);
			sTATSTG.type = 2;
			sTATSTG.cbSize = Length;
			sTATSTG.grfMode = 0;
			STATSTG sTATSTG2 = sTATSTG;
			if (CanWrite && CanRead)
			{
				sTATSTG2.grfMode |= 2;
			}
			else if (CanRead)
			{
				sTATSTG2.grfMode |= 0;
			}
			else
			{
				if (!CanWrite)
				{
					throw new ObjectDisposedException("Stream");
				}
				sTATSTG2.grfMode |= 1;
			}
			pstatstg = sTATSTG2;
		}

		void IStream.UnlockRegion(long libOffset, long cb, int dwLockType)
		{
		}

		void IStream.Write(byte[] pv, int cb, IntPtr pcbWritten)
		{
			if (!CanWrite)
			{
				throw new InvalidOperationException("Stream is not writeable.");
			}
			Write(pv, 0, cb);
			if (pcbWritten != IntPtr.Zero)
			{
				Marshal.WriteInt32(pcbWritten, cb);
			}
		}

		public override void Flush()
		{
			stream.Flush();
		}

		public override int Read(byte[] buffer, int offset, int count)
		{
			return stream.Read(buffer, offset, count);
		}

		public override long Seek(long offset, SeekOrigin origin)
		{
			return stream.Seek(offset, origin);
		}

		public override void SetLength(long value)
		{
			stream.SetLength(value);
		}

		public override void Write(byte[] buffer, int offset, int count)
		{
			stream.Write(buffer, offset, count);
		}

		protected override void Dispose(bool disposing)
		{
			base.Dispose(disposing);
			if (stream != null)
			{
				stream.Dispose();
				stream = null;
			}
		}

		public override void Close()
		{
			base.Close();
			if (stream != null)
			{
				stream.Close();
				stream = null;
			}
		}
	}

	/// <summary>
	/// Provide WaveProvider that can apply effects in real time using DMO.
	///
	/// If the audio thread is running on the STA thread, please generate and operate from the same thread.
	/// If the audio thread is running on the MTA thread, please operate on any MTA thread.
	/// </summary>
	/// <typeparam name="TDmoEffector">Types of DMO effectors to use</typeparam>
	/// <typeparam name="TEffectorParam">Parameters of the effect to be used</typeparam>
	public class DmoEffectWaveProvider<TDmoEffector, TEffectorParam> : IWaveProvider, IDisposable where TDmoEffector : IDmoEffector<TEffectorParam>, new()
	{
		private readonly IWaveProvider inputProvider;

		private readonly IDmoEffector<TEffectorParam> effector;

		/// <summary>
		/// Stream Wave Format
		/// </summary>
		public WaveFormat WaveFormat => inputProvider.WaveFormat;

		/// <summary>
		/// Get Effector Parameters
		/// </summary>
		public TEffectorParam EffectParams => effector.EffectParams;

		/// <summary>
		/// Create a new DmoEffectWaveProvider
		/// </summary>
		/// <param name="inputProvider">Input Stream</param>
		public DmoEffectWaveProvider(IWaveProvider inputProvider)
		{
			this.inputProvider = inputProvider;
			effector = new TDmoEffector();
			MediaObject obj = effector.MediaObject ?? throw new NotSupportedException("Dmo Effector Not Supported: TDmoEffector");
			if (!obj.SupportsInputWaveFormat(0, inputProvider.WaveFormat))
			{
				throw new ArgumentException("Unsupported Input Stream format", "inputProvider");
			}
			obj.AllocateStreamingResources();
			obj.SetInputWaveFormat(0, this.inputProvider.WaveFormat);
			obj.SetOutputWaveFormat(0, this.inputProvider.WaveFormat);
		}

		/// <summary>
		/// Reads data from input stream
		/// </summary>
		/// <param name="buffer">buffer</param>
		/// <param name="offset">offset into buffer</param>
		/// <param name="count">Bytes required</param>
		/// <returns>Number of bytes read</returns>
		public int Read(byte[] buffer, int offset, int count)
		{
			int num = inputProvider.Read(buffer, offset, count);
			if (effector == null)
			{
				return num;
			}
			if (effector.MediaObjectInPlace.Process(num, offset, buffer, 0L, DmoInPlaceProcessFlags.Normal) == DmoInPlaceProcessReturn.HasEffectTail)
			{
				byte[] data = new byte[num];
				while (effector.MediaObjectInPlace.Process(num, 0, data, 0L, DmoInPlaceProcessFlags.Zero) == DmoInPlaceProcessReturn.HasEffectTail)
				{
				}
			}
			return num;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (effector != null)
			{
				effector.MediaObject.FreeStreamingResources();
				effector.Dispose();
			}
		}
	}

	/// <summary>
	/// Media Foundation Encoder class allows you to use Media Foundation to encode an IWaveProvider
	/// to any supported encoding format
	/// </summary>
	public class MediaFoundationEncoder : IDisposable
	{
		private readonly MediaType outputMediaType;

		private bool disposed;

		public int DefaultReadBufferSize { get; set; }

		/// <summary>
		/// Queries the available bitrates for a given encoding output type, sample rate and number of channels
		/// </summary>
		/// <param name="audioSubtype">Audio subtype - a value from the AudioSubtypes class</param>
		/// <param name="sampleRate">The sample rate of the PCM to encode</param>
		/// <param name="channels">The number of channels of the PCM to encode</param>
		/// <returns>An array of available bitrates in average bits per second</returns>
		public static int[] GetEncodeBitrates(Guid audioSubtype, int sampleRate, int channels)
		{
			return (from br in (from mt in GetOutputMediaTypes(audioSubtype)
					where mt.SampleRate == sampleRate && mt.ChannelCount == channels
					select mt.AverageBytesPerSecond * 8).Distinct()
				orderby br
				select br).ToArray();
		}

		/// <summary>
		/// Gets all the available media types for a particular 
		/// </summary>
		/// <param name="audioSubtype">Audio subtype - a value from the AudioSubtypes class</param>
		/// <returns>An array of available media types that can be encoded with this subtype</returns>
		public static MediaType[] GetOutputMediaTypes(Guid audioSubtype)
		{
			MediaFoundationApi.Startup();
			IMFCollection ppAvailableTypes;
			try
			{
				MediaFoundationInterop.MFTranscodeGetAudioOutputAvailableTypes(audioSubtype, _MFT_ENUM_FLAG.MFT_ENUM_FLAG_ALL, null, out ppAvailableTypes);
			}
			catch (COMException exception)
			{
				if (exception.GetHResult() == -1072875819)
				{
					return new MediaType[0];
				}
				throw;
			}
			ppAvailableTypes.GetElementCount(out var pcElements);
			List<MediaType> list = new List<MediaType>(pcElements);
			for (int i = 0; i < pcElements; i++)
			{
				ppAvailableTypes.GetElement(i, out var ppUnkElement);
				IMFMediaType mediaType = (IMFMediaType)ppUnkElement;
				list.Add(new MediaType(mediaType));
			}
			Marshal.ReleaseComObject(ppAvailableTypes);
			return list.ToArray();
		}

		/// <summary>
		/// Helper function to simplify encoding Window Media Audio
		/// Should be supported on Vista and above (not tested)
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputFile">Output file path, should end with .wma</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToWma(IWaveProvider inputProvider, string outputFile, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_WMAudioV8, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable WMA encoders available"));
			mediaFoundationEncoder.Encode(outputFile, inputProvider);
		}

		/// <summary>
		/// Helper function to simplify encoding Window Media Audio
		/// Should be supported on Vista and above (not tested)
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputStream">Output stream</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToWma(IWaveProvider inputProvider, Stream outputStream, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_WMAudioV8, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable WMA encoders available"));
			mediaFoundationEncoder.Encode(outputStream, inputProvider, TranscodeContainerTypes.MFTranscodeContainerType_ASF);
		}

		/// <summary>
		/// Helper function to simplify encoding to MP3
		/// By default, will only be available on Windows 8 and above
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputFile">Output file path, should end with .mp3</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToMp3(IWaveProvider inputProvider, string outputFile, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_MP3, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable MP3 encoders available"));
			mediaFoundationEncoder.Encode(outputFile, inputProvider);
		}

		/// <summary>
		/// Helper function to simplify encoding to MP3
		/// By default, will only be available on Windows 8 and above
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputStream">Output stream</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToMp3(IWaveProvider inputProvider, Stream outputStream, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_MP3, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable MP3 encoders available"));
			mediaFoundationEncoder.Encode(outputStream, inputProvider, TranscodeContainerTypes.MFTranscodeContainerType_MP3);
		}

		/// <summary>
		/// Helper function to simplify encoding to AAC
		/// By default, will only be available on Windows 7 and above
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputFile">Output file path, should end with .mp4 (or .aac on Windows 8)</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToAac(IWaveProvider inputProvider, string outputFile, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_AAC, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable AAC encoders available"));
			mediaFoundationEncoder.Encode(outputFile, inputProvider);
		}

		/// <summary>
		/// Helper function to simplify encoding to AAC
		/// By default, will only be available on Windows 7 and above
		/// </summary>
		/// <param name="inputProvider">Input provider, must be PCM</param>
		/// <param name="outputStream">Output stream</param>
		/// <param name="desiredBitRate">Desired bitrate. Use GetEncodeBitrates to find the possibilities for your input type</param>
		public static void EncodeToAac(IWaveProvider inputProvider, Stream outputStream, int desiredBitRate = 192000)
		{
			using MediaFoundationEncoder mediaFoundationEncoder = new MediaFoundationEncoder(SelectMediaType(AudioSubtypes.MFAudioFormat_AAC, inputProvider.WaveFormat, desiredBitRate) ?? throw new InvalidOperationException("No suitable AAC encoders available"));
			mediaFoundationEncoder.Encode(outputStream, inputProvider, TranscodeContainerTypes.MFTranscodeContainerType_MPEG4);
		}

		/// <summary>
		/// Tries to find the encoding media type with the closest bitrate to that specified
		/// </summary>
		/// <param name="audioSubtype">Audio subtype, a value from AudioSubtypes</param>
		/// <param name="inputFormat">Your encoder input format (used to check sample rate and channel count)</param>
		/// <param name="desiredBitRate">Your desired bitrate</param>
		/// <returns>The closest media type, or null if none available</returns>
		public static MediaType SelectMediaType(Guid audioSubtype, WaveFormat inputFormat, int desiredBitRate)
		{
			MediaFoundationApi.Startup();
			return (from mt in GetOutputMediaTypes(audioSubtype)
				where mt.SampleRate == inputFormat.SampleRate && mt.ChannelCount == inputFormat.Channels
				select new
				{
					MediaType = mt,
					Delta = Math.Abs(desiredBitRate - mt.AverageBytesPerSecond * 8)
				} into mt
				orderby mt.Delta
				select mt.MediaType).FirstOrDefault();
		}

		/// <summary>
		/// Creates a new encoder that encodes to the specified output media type
		/// </summary>
		/// <param name="outputMediaType">Desired output media type</param>
		public MediaFoundationEncoder(MediaType outputMediaType)
		{
			if (outputMediaType == null)
			{
				throw new ArgumentNullException("outputMediaType");
			}
			this.outputMediaType = outputMediaType;
		}

		/// <summary>
		/// Encodes a file
		/// </summary>
		/// <param name="outputFile">Output filename (container type is deduced from the filename)</param>
		/// <param name="inputProvider">Input provider (should be PCM, some encoders will also allow IEEE float)</param>
		public void Encode(string outputFile, IWaveProvider inputProvider)
		{
			if (inputProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm && inputProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Encode input format must be PCM or IEEE float");
			}
			MediaType mediaType = new MediaType(inputProvider.WaveFormat);
			IMFSinkWriter iMFSinkWriter = CreateSinkWriter(outputFile);
			try
			{
				iMFSinkWriter.AddStream(outputMediaType.MediaFoundationObject, out var pdwStreamIndex);
				iMFSinkWriter.SetInputMediaType(pdwStreamIndex, mediaType.MediaFoundationObject, null);
				PerformEncode(iMFSinkWriter, pdwStreamIndex, inputProvider);
			}
			finally
			{
				if (iMFSinkWriter != null)
				{
					Marshal.ReleaseComObject(iMFSinkWriter);
				}
				if (mediaType.MediaFoundationObject != null)
				{
					Marshal.ReleaseComObject(mediaType.MediaFoundationObject);
				}
			}
		}

		/// <summary>
		/// Encodes a file
		/// </summary>
		/// <param name="outputStream">Output stream</param>
		/// <param name="inputProvider">Input provider (should be PCM, some encoders will also allow IEEE float)</param>
		/// <param name="transcodeContainerType">One of <see cref="T:NAudio.MediaFoundation.TranscodeContainerTypes" /></param>
		public void Encode(Stream outputStream, IWaveProvider inputProvider, Guid transcodeContainerType)
		{
			if (inputProvider.WaveFormat.Encoding != WaveFormatEncoding.Pcm && inputProvider.WaveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				throw new ArgumentException("Encode input format must be PCM or IEEE float");
			}
			MediaType mediaType = new MediaType(inputProvider.WaveFormat);
			IMFSinkWriter iMFSinkWriter = CreateSinkWriter(new ComStream(outputStream), transcodeContainerType);
			try
			{
				iMFSinkWriter.AddStream(outputMediaType.MediaFoundationObject, out var pdwStreamIndex);
				iMFSinkWriter.SetInputMediaType(pdwStreamIndex, mediaType.MediaFoundationObject, null);
				PerformEncode(iMFSinkWriter, pdwStreamIndex, inputProvider);
			}
			finally
			{
				if (iMFSinkWriter != null)
				{
					Marshal.ReleaseComObject(iMFSinkWriter);
				}
				if (mediaType.MediaFoundationObject != null)
				{
					Marshal.ReleaseComObject(mediaType.MediaFoundationObject);
				}
			}
		}

		private static IMFSinkWriter CreateSinkWriter(string outputFile)
		{
			IMFAttributes iMFAttributes = MediaFoundationApi.CreateAttributes(1);
			iMFAttributes.SetUINT32(MediaFoundationAttributes.MF_READWRITE_ENABLE_HARDWARE_TRANSFORMS, 1);
			try
			{
				MediaFoundationInterop.MFCreateSinkWriterFromURL(outputFile, null, iMFAttributes, out var ppSinkWriter);
				return ppSinkWriter;
			}
			catch (COMException exception)
			{
				if (exception.GetHResult() == -1072875819)
				{
					throw new ArgumentException("Was not able to create a sink writer for this file extension");
				}
				throw;
			}
			finally
			{
				Marshal.ReleaseComObject(iMFAttributes);
			}
		}

		private static IMFSinkWriter CreateSinkWriter(IStream outputStream, Guid TranscodeContainerType)
		{
			IMFAttributes iMFAttributes = MediaFoundationApi.CreateAttributes(1);
			iMFAttributes.SetGUID(MediaFoundationAttributes.MF_TRANSCODE_CONTAINERTYPE, TranscodeContainerType);
			try
			{
				MediaFoundationInterop.MFCreateMFByteStreamOnStream(outputStream, out var ppByteStream);
				MediaFoundationInterop.MFCreateSinkWriterFromURL(null, ppByteStream, iMFAttributes, out var ppSinkWriter);
				return ppSinkWriter;
			}
			finally
			{
				Marshal.ReleaseComObject(iMFAttributes);
			}
		}

		private void PerformEncode(IMFSinkWriter writer, int streamIndex, IWaveProvider inputProvider)
		{
			if (DefaultReadBufferSize == 0)
			{
				DefaultReadBufferSize = inputProvider.WaveFormat.AverageBytesPerSecond * 4;
			}
			byte[] managedBuffer = new byte[DefaultReadBufferSize];
			writer.BeginWriting();
			long num = 0L;
			long num2;
			do
			{
				num2 = ConvertOneBuffer(writer, streamIndex, inputProvider, num, managedBuffer);
				num += num2;
			}
			while (num2 > 0);
			writer.DoFinalize();
		}

		private static long BytesToNsPosition(int bytes, WaveFormat waveFormat)
		{
			return 10000000L * (long)bytes / waveFormat.AverageBytesPerSecond;
		}

		private long ConvertOneBuffer(IMFSinkWriter writer, int streamIndex, IWaveProvider inputProvider, long position, byte[] managedBuffer)
		{
			long num = 0L;
			IMFMediaBuffer iMFMediaBuffer = MediaFoundationApi.CreateMemoryBuffer(managedBuffer.Length);
			iMFMediaBuffer.GetMaxLength(out var pcbMaxLength);
			IMFSample iMFSample = MediaFoundationApi.CreateSample();
			iMFSample.AddBuffer(iMFMediaBuffer);
			int num2 = inputProvider.Read(managedBuffer, 0, pcbMaxLength);
			if (num2 > 0)
			{
				iMFMediaBuffer.Lock(out var ppbBuffer, out pcbMaxLength, out var _);
				num = BytesToNsPosition(num2, inputProvider.WaveFormat);
				Marshal.Copy(managedBuffer, 0, ppbBuffer, num2);
				iMFMediaBuffer.SetCurrentLength(num2);
				iMFMediaBuffer.Unlock();
				iMFSample.SetSampleTime(position);
				iMFSample.SetSampleDuration(num);
				writer.WriteSample(streamIndex, iMFSample);
			}
			Marshal.ReleaseComObject(iMFSample);
			Marshal.ReleaseComObject(iMFMediaBuffer);
			return num;
		}

		/// <summary>
		/// Disposes this instance
		/// </summary>
		/// <param name="disposing"></param>
		protected void Dispose(bool disposing)
		{
			Marshal.ReleaseComObject(outputMediaType.MediaFoundationObject);
		}

		/// <summary>
		/// Disposes this instance
		/// </summary>
		public void Dispose()
		{
			if (!disposed)
			{
				disposed = true;
				Dispose(disposing: true);
			}
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~MediaFoundationEncoder()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// Class for reading any file that Media Foundation can play
	/// Will only work in Windows Vista and above
	/// Automatically converts to PCM
	/// If it is a video file with multiple audio streams, it will pick out the first audio stream
	/// </summary>
	public class MediaFoundationReader : WaveStream
	{
		/// <summary>
		/// Allows customisation of this reader class
		/// </summary>
		public class MediaFoundationReaderSettings
		{
			/// <summary>
			/// Allows us to request IEEE float output (n.b. no guarantee this will be accepted)
			/// </summary>
			public bool RequestFloatOutput { get; set; }

			/// <summary>
			/// If true, the reader object created in the constructor is used in Read
			/// Should only be set to true if you are working entirely on an STA thread, or 
			/// entirely with MTA threads.
			/// </summary>
			public bool SingleReaderObject { get; set; }

			/// <summary>
			/// If true, the reposition does not happen immediately, but waits until the
			/// next call to read to be processed.
			/// </summary>
			public bool RepositionInRead { get; set; }

			/// <summary>
			/// Sets up the default settings for MediaFoundationReader
			/// </summary>
			public MediaFoundationReaderSettings()
			{
				RepositionInRead = true;
			}
		}

		private WaveFormat waveFormat;

		private long length;

		private MediaFoundationReaderSettings settings;

		private readonly string file;

		private IMFSourceReader pReader;

		private long position;

		private byte[] decoderOutputBuffer;

		private int decoderOutputOffset;

		private int decoderOutputCount;

		private long repositionTo = -1L;

		/// <summary>
		/// WaveFormat of this stream (n.b. this is after converting to PCM)
		/// </summary>
		public override WaveFormat WaveFormat => waveFormat;

		/// <summary>
		/// The bytesRequired of this stream in bytes (n.b may not be accurate)
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Current position within this stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				if (value < 0)
				{
					throw new ArgumentOutOfRangeException("value", "Position cannot be less than 0");
				}
				if (settings.RepositionInRead)
				{
					repositionTo = value;
					position = value;
				}
				else
				{
					Reposition(value);
				}
			}
		}

		/// <summary>
		/// WaveFormat has changed
		/// </summary>
		public event EventHandler WaveFormatChanged;

		/// <summary>
		/// Default constructor
		/// </summary>
		protected MediaFoundationReader()
		{
		}

		/// <summary>
		/// Creates a new MediaFoundationReader based on the supplied file
		/// </summary>
		/// <param name="file">Filename (can also be a URL  e.g. http:// mms:// file://)</param>
		public MediaFoundationReader(string file)
			: this(file, null)
		{
		}

		/// <summary>
		/// Creates a new MediaFoundationReader based on the supplied file
		/// </summary>
		/// <param name="file">Filename</param>
		/// <param name="settings">Advanced settings</param>
		public MediaFoundationReader(string file, MediaFoundationReaderSettings settings)
		{
			this.file = file;
			Init(settings);
		}

		/// <summary>
		/// Initializes 
		/// </summary>
		protected void Init(MediaFoundationReaderSettings initialSettings)
		{
			MediaFoundationApi.Startup();
			settings = initialSettings ?? new MediaFoundationReaderSettings();
			IMFSourceReader iMFSourceReader = CreateReader(settings);
			waveFormat = GetCurrentWaveFormat(iMFSourceReader);
			iMFSourceReader.SetStreamSelection(-3, pSelected: true);
			length = GetLength(iMFSourceReader);
			if (settings.SingleReaderObject)
			{
				pReader = iMFSourceReader;
			}
			else
			{
				Marshal.ReleaseComObject(iMFSourceReader);
			}
		}

		private WaveFormat GetCurrentWaveFormat(IMFSourceReader reader)
		{
			reader.GetCurrentMediaType(-3, out var ppMediaType);
			MediaType mediaType = new MediaType(ppMediaType);
			_ = mediaType.MajorType;
			Guid subType = mediaType.SubType;
			int channelCount = mediaType.ChannelCount;
			int bitsPerSample = mediaType.BitsPerSample;
			int sampleRate = mediaType.SampleRate;
			if (subType == AudioSubtypes.MFAudioFormat_PCM)
			{
				return new WaveFormat(sampleRate, bitsPerSample, channelCount);
			}
			if (subType == AudioSubtypes.MFAudioFormat_Float)
			{
				return WaveFormat.CreateIeeeFloatWaveFormat(sampleRate, channelCount);
			}
			string text = FieldDescriptionHelper.Describe(typeof(AudioSubtypes), subType);
			throw new InvalidDataException("Unsupported audio sub Type " + text);
		}

		private static MediaType GetCurrentMediaType(IMFSourceReader reader)
		{
			reader.GetCurrentMediaType(-3, out var ppMediaType);
			return new MediaType(ppMediaType);
		}

		/// <summary>
		/// Creates the reader (overridable by )
		/// </summary>
		protected virtual IMFSourceReader CreateReader(MediaFoundationReaderSettings settings)
		{
			MediaFoundationInterop.MFCreateSourceReaderFromURL(file, null, out var ppSourceReader);
			ppSourceReader.SetStreamSelection(-2, pSelected: false);
			ppSourceReader.SetStreamSelection(-3, pSelected: true);
			MediaType mediaType = new MediaType();
			mediaType.MajorType = NAudio.MediaFoundation.MediaTypes.MFMediaType_Audio;
			mediaType.SubType = (settings.RequestFloatOutput ? AudioSubtypes.MFAudioFormat_Float : AudioSubtypes.MFAudioFormat_PCM);
			MediaType currentMediaType = GetCurrentMediaType(ppSourceReader);
			mediaType.ChannelCount = currentMediaType.ChannelCount;
			mediaType.SampleRate = currentMediaType.SampleRate;
			try
			{
				ppSourceReader.SetCurrentMediaType(-3, IntPtr.Zero, mediaType.MediaFoundationObject);
			}
			catch (COMException exception) when (exception.GetHResult() == -1072875852)
			{
				if (!(currentMediaType.SubType == AudioSubtypes.MFAudioFormat_AAC) || currentMediaType.ChannelCount != 1)
				{
					throw;
				}
				mediaType.SampleRate = (currentMediaType.SampleRate *= 2);
				mediaType.ChannelCount = (currentMediaType.ChannelCount *= 2);
				ppSourceReader.SetCurrentMediaType(-3, IntPtr.Zero, mediaType.MediaFoundationObject);
			}
			Marshal.ReleaseComObject(currentMediaType.MediaFoundationObject);
			return ppSourceReader;
		}

		private long GetLength(IMFSourceReader reader)
		{
			IntPtr intPtr = Marshal.AllocHGlobal(Marshal.SizeOf<PropVariant>());
			try
			{
				int presentationAttribute = reader.GetPresentationAttribute(-1, MediaFoundationAttributes.MF_PD_DURATION, intPtr);
				switch (presentationAttribute)
				{
				case -1072875802:
					return 0L;
				default:
					Marshal.ThrowExceptionForHR(presentationAttribute);
					break;
				case 0:
					break;
				}
				return (long)Marshal.PtrToStructure<PropVariant>(intPtr).Value * waveFormat.AverageBytesPerSecond / 10000000;
			}
			finally
			{
				PropVariant.Clear(intPtr);
				Marshal.FreeHGlobal(intPtr);
			}
		}

		private void EnsureBuffer(int bytesRequired)
		{
			if (decoderOutputBuffer == null || decoderOutputBuffer.Length < bytesRequired)
			{
				decoderOutputBuffer = new byte[bytesRequired];
			}
		}

		/// <summary>
		/// Reads from this wave stream
		/// </summary>
		/// <param name="buffer">Buffer to read into</param>
		/// <param name="offset">Offset in buffer</param>
		/// <param name="count">Bytes required</param>
		/// <returns>Number of bytes read; 0 indicates end of stream</returns>
		public override int Read(byte[] buffer, int offset, int count)
		{
			if (pReader == null)
			{
				pReader = CreateReader(settings);
			}
			if (repositionTo != -1)
			{
				Reposition(repositionTo);
			}
			int num = 0;
			if (decoderOutputCount > 0)
			{
				num += ReadFromDecoderBuffer(buffer, offset, count - num);
			}
			while (num < count)
			{
				pReader.ReadSample(-3, 0, out var _, out var pdwStreamFlags, out var _, out var ppSample);
				if ((pdwStreamFlags & MF_SOURCE_READER_FLAG.MF_SOURCE_READERF_ENDOFSTREAM) != 0)
				{
					break;
				}
				if ((pdwStreamFlags & MF_SOURCE_READER_FLAG.MF_SOURCE_READERF_CURRENTMEDIATYPECHANGED) != 0)
				{
					waveFormat = GetCurrentWaveFormat(pReader);
					OnWaveFormatChanged();
				}
				else if (pdwStreamFlags != 0)
				{
					throw new InvalidOperationException($"MediaFoundationReadError {pdwStreamFlags}");
				}
				ppSample.ConvertToContiguousBuffer(out var ppBuffer);
				ppBuffer.Lock(out var ppbBuffer, out var _, out var pcbCurrentLength);
				EnsureBuffer(pcbCurrentLength);
				Marshal.Copy(ppbBuffer, decoderOutputBuffer, 0, pcbCurrentLength);
				decoderOutputOffset = 0;
				decoderOutputCount = pcbCurrentLength;
				num += ReadFromDecoderBuffer(buffer, offset + num, count - num);
				ppBuffer.Unlock();
				Marshal.ReleaseComObject(ppBuffer);
				Marshal.ReleaseComObject(ppSample);
			}
			position += num;
			return num;
		}

		private int ReadFromDecoderBuffer(byte[] buffer, int offset, int needed)
		{
			int num = Math.Min(needed, decoderOutputCount);
			Array.Copy(decoderOutputBuffer, decoderOutputOffset, buffer, offset, num);
			decoderOutputOffset += num;
			decoderOutputCount -= num;
			if (decoderOutputCount == 0)
			{
				decoderOutputOffset = 0;
			}
			return num;
		}

		private void Reposition(long desiredPosition)
		{
			PropVariant structure = PropVariant.FromLong(10000000 * repositionTo / waveFormat.AverageBytesPerSecond);
			IntPtr intPtr = Marshal.AllocHGlobal(Marshal.SizeOf(structure));
			try
			{
				Marshal.StructureToPtr(structure, intPtr, fDeleteOld: false);
				pReader.SetCurrentPosition(Guid.Empty, intPtr);
			}
			finally
			{
				Marshal.FreeHGlobal(intPtr);
			}
			decoderOutputCount = 0;
			decoderOutputOffset = 0;
			position = desiredPosition;
			repositionTo = -1L;
		}

		/// <summary>
		/// Cleans up after finishing with this reader
		/// </summary>
		/// <param name="disposing">true if called from Dispose</param>
		protected override void Dispose(bool disposing)
		{
			if (pReader != null)
			{
				Marshal.ReleaseComObject(pReader);
				pReader = null;
			}
			base.Dispose(disposing);
		}

		private void OnWaveFormatChanged()
		{
			this.WaveFormatChanged?.Invoke(this, EventArgs.Empty);
		}
	}

	/// <summary>
	/// The Media Foundation Resampler Transform
	/// </summary>
	public class MediaFoundationResampler : MediaFoundationTransform
	{
		private int resamplerQuality;

		private static readonly Guid ResamplerClsid = new Guid("f447b69e-1884-4a7e-8055-346f74d6edb3");

		private static readonly Guid IMFTransformIid = new Guid("bf94c121-5b05-4e6f-8000-ba598961414d");

		private IMFActivate activate;

		/// <summary>
		/// Gets or sets the Resampler quality. n.b. set the quality before starting to resample.
		/// 1 is lowest quality (linear interpolation) and 60 is best quality
		/// </summary>
		public int ResamplerQuality
		{
			get
			{
				return resamplerQuality;
			}
			set
			{
				if (value < 1 || value > 60)
				{
					throw new ArgumentOutOfRangeException("Resampler Quality must be between 1 and 60");
				}
				resamplerQuality = value;
			}
		}

		private static bool IsPcmOrIeeeFloat(WaveFormat waveFormat)
		{
			WaveFormatExtensible waveFormatExtensible = waveFormat as WaveFormatExtensible;
			if (waveFormat.Encoding != WaveFormatEncoding.Pcm && waveFormat.Encoding != WaveFormatEncoding.IeeeFloat)
			{
				if (waveFormatExtensible != null)
				{
					if (!(waveFormatExtensible.SubFormat == AudioSubtypes.MFAudioFormat_PCM))
					{
						return waveFormatExtensible.SubFormat == AudioSubtypes.MFAudioFormat_Float;
					}
					return true;
				}
				return false;
			}
			return true;
		}

		/// <summary>
		/// Creates the Media Foundation Resampler, allowing modifying of sample rate, bit depth and channel count
		/// </summary>
		/// <param name="sourceProvider">Source provider, must be PCM</param>
		/// <param name="outputFormat">Output format, must also be PCM</param>
		public MediaFoundationResampler(IWaveProvider sourceProvider, WaveFormat outputFormat)
			: base(sourceProvider, outputFormat)
		{
			if (!IsPcmOrIeeeFloat(sourceProvider.WaveFormat))
			{
				throw new ArgumentException("Input must be PCM or IEEE float", "sourceProvider");
			}
			if (!IsPcmOrIeeeFloat(outputFormat))
			{
				throw new ArgumentException("Output must be PCM or IEEE float", "outputFormat");
			}
			MediaFoundationApi.Startup();
			ResamplerQuality = 60;
			object comObject = CreateResamplerComObject();
			FreeComObject(comObject);
		}

		private void FreeComObject(object comObject)
		{
			if (activate != null)
			{
				activate.ShutdownObject();
			}
			Marshal.ReleaseComObject(comObject);
		}

		private object CreateResamplerComObject()
		{
			return new ResamplerMediaComObject();
		}

		private object CreateResamplerComObjectUsingActivator()
		{
			foreach (IMFActivate item in MediaFoundationApi.EnumerateTransforms(MediaFoundationTransformCategories.AudioEffect))
			{
				item.GetGUID(MediaFoundationAttributes.MFT_TRANSFORM_CLSID_Attribute, out var pguidValue);
				if (pguidValue.Equals(ResamplerClsid))
				{
					item.ActivateObject(IMFTransformIid, out var ppv);
					activate = item;
					return ppv;
				}
			}
			return null;
		}

		/// <summary>
		/// Creates a resampler with a specified target output sample rate
		/// </summary>
		/// <param name="sourceProvider">Source provider</param>
		/// <param name="outputSampleRate">Output sample rate</param>
		public MediaFoundationResampler(IWaveProvider sourceProvider, int outputSampleRate)
			: this(sourceProvider, CreateOutputFormat(sourceProvider.WaveFormat, outputSampleRate))
		{
		}

		/// <summary>
		/// Creates and configures the actual Resampler transform
		/// </summary>
		/// <returns>A newly created and configured resampler MFT</returns>
		protected override IMFTransform CreateTransform()
		{
			object obj = CreateResamplerComObject();
			IMFTransform obj2 = (IMFTransform)obj;
			IMFMediaType iMFMediaType = MediaFoundationApi.CreateMediaTypeFromWaveFormat(sourceProvider.WaveFormat);
			obj2.SetInputType(0, iMFMediaType, _MFT_SET_TYPE_FLAGS.None);
			Marshal.ReleaseComObject(iMFMediaType);
			IMFMediaType iMFMediaType2 = MediaFoundationApi.CreateMediaTypeFromWaveFormat(outputWaveFormat);
			obj2.SetOutputType(0, iMFMediaType2, _MFT_SET_TYPE_FLAGS.None);
			Marshal.ReleaseComObject(iMFMediaType2);
			((IWMResamplerProps)obj).SetHalfFilterLength(ResamplerQuality);
			return obj2;
		}

		private static WaveFormat CreateOutputFormat(WaveFormat inputFormat, int outputSampleRate)
		{
			if (inputFormat.Encoding == WaveFormatEncoding.Pcm)
			{
				return new WaveFormat(outputSampleRate, inputFormat.BitsPerSample, inputFormat.Channels);
			}
			if (inputFormat.Encoding == WaveFormatEncoding.IeeeFloat)
			{
				return WaveFormat.CreateIeeeFloatWaveFormat(outputSampleRate, inputFormat.Channels);
			}
			throw new ArgumentException("Can only resample PCM or IEEE float");
		}

		/// <summary>
		/// Disposes this resampler
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (activate != null)
			{
				activate.ShutdownObject();
				activate = null;
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// Wave Stream for converting between sample rates
	/// </summary>
	public class ResamplerDmoStream : WaveStream
	{
		private readonly IWaveProvider inputProvider;

		private readonly WaveStream inputStream;

		private readonly WaveFormat outputFormat;

		private DmoOutputDataBuffer outputBuffer;

		private DmoResampler dmoResampler;

		private MediaBuffer inputMediaBuffer;

		private long position;

		/// <summary>
		/// Stream Wave Format
		/// </summary>
		public override WaveFormat WaveFormat => outputFormat;

		/// <summary>
		/// Stream length in bytes
		/// </summary>
		public override long Length
		{
			get
			{
				if (inputStream == null)
				{
					throw new InvalidOperationException("Cannot report length if the input was an IWaveProvider");
				}
				return InputToOutputPosition(inputStream.Length);
			}
		}

		/// <summary>
		/// Stream position in bytes
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				if (inputStream == null)
				{
					throw new InvalidOperationException("Cannot set position if the input was not a WaveStream");
				}
				inputStream.Position = OutputToInputPosition(value);
				position = InputToOutputPosition(inputStream.Position);
				dmoResampler.MediaObject.Discontinuity(0);
			}
		}

		/// <summary>
		/// WaveStream to resample using the DMO Resampler
		/// </summary>
		/// <param name="inputProvider">Input Stream</param>
		/// <param name="outputFormat">Desired Output Format</param>
		public ResamplerDmoStream(IWaveProvider inputProvider, WaveFormat outputFormat)
		{
			this.inputProvider = inputProvider;
			inputStream = inputProvider as WaveStream;
			this.outputFormat = outputFormat;
			dmoResampler = new DmoResampler();
			if (!dmoResampler.MediaObject.SupportsInputWaveFormat(0, inputProvider.WaveFormat))
			{
				throw new ArgumentException("Unsupported Input Stream format", "inputProvider");
			}
			dmoResampler.MediaObject.SetInputWaveFormat(0, inputProvider.WaveFormat);
			if (!dmoResampler.MediaObject.SupportsOutputWaveFormat(0, outputFormat))
			{
				throw new ArgumentException("Unsupported Output Stream format", "outputFormat");
			}
			dmoResampler.MediaObject.SetOutputWaveFormat(0, outputFormat);
			if (inputStream != null)
			{
				position = InputToOutputPosition(inputStream.Position);
			}
			inputMediaBuffer = new MediaBuffer(inputProvider.WaveFormat.AverageBytesPerSecond);
			outputBuffer = new DmoOutputDataBuffer(outputFormat.AverageBytesPerSecond);
		}

		private long InputToOutputPosition(long inputPosition)
		{
			double num = (double)outputFormat.AverageBytesPerSecond / (double)inputProvider.WaveFormat.AverageBytesPerSecond;
			long num2 = (long)((double)inputPosition * num);
			if (num2 % outputFormat.BlockAlign != 0L)
			{
				num2 -= num2 % outputFormat.BlockAlign;
			}
			return num2;
		}

		private long OutputToInputPosition(long outputPosition)
		{
			double num = (double)outputFormat.AverageBytesPerSecond / (double)inputProvider.WaveFormat.AverageBytesPerSecond;
			long num2 = (long)((double)outputPosition / num);
			if (num2 % inputProvider.WaveFormat.BlockAlign != 0L)
			{
				num2 -= num2 % inputProvider.WaveFormat.BlockAlign;
			}
			return num2;
		}

		/// <summary>
		/// Reads data from input stream
		/// </summary>
		/// <param name="buffer">buffer</param>
		/// <param name="offset">offset into buffer</param>
		/// <param name="count">Bytes required</param>
		/// <returns>Number of bytes read</returns>
		public override int Read(byte[] buffer, int offset, int count)
		{
			int num = 0;
			while (num < count)
			{
				if (dmoResampler.MediaObject.IsAcceptingData(0))
				{
					int num2 = (int)OutputToInputPosition(count - num);
					byte[] array = new byte[num2];
					int num3 = inputProvider.Read(array, 0, num2);
					if (num3 == 0)
					{
						break;
					}
					inputMediaBuffer.LoadData(array, num3);
					dmoResampler.MediaObject.ProcessInput(0, inputMediaBuffer, DmoInputDataBufferFlags.None, 0L, 0L);
					outputBuffer.MediaBuffer.SetLength(0);
					outputBuffer.StatusFlags = DmoOutputDataBufferFlags.None;
					dmoResampler.MediaObject.ProcessOutput(DmoProcessOutputFlags.None, 1, new DmoOutputDataBuffer[1] { outputBuffer });
					if (outputBuffer.Length == 0)
					{
						break;
					}
					outputBuffer.RetrieveData(buffer, offset + num);
					num += outputBuffer.Length;
				}
			}
			position += num;
			return num;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		/// <param name="disposing">True if disposing (not from finalizer)</param>
		protected override void Dispose(bool disposing)
		{
			if (inputMediaBuffer != null)
			{
				inputMediaBuffer.Dispose();
				inputMediaBuffer = null;
			}
			outputBuffer.Dispose();
			if (dmoResampler != null)
			{
				dmoResampler = null;
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// MediaFoundationReader supporting reading from a stream
	/// </summary>
	public class StreamMediaFoundationReader : MediaFoundationReader
	{
		private readonly Stream stream;

		/// <summary>
		/// Constructs a new media foundation reader from a stream
		/// </summary>
		public StreamMediaFoundationReader(Stream stream, MediaFoundationReaderSettings settings = null)
		{
			this.stream = stream;
			Init(settings);
		}

		/// <summary>
		/// Creates the reader
		/// </summary>
		protected override IMFSourceReader CreateReader(MediaFoundationReaderSettings settings)
		{
			IMFSourceReader iMFSourceReader = MediaFoundationApi.CreateSourceReaderFromByteStream(MediaFoundationApi.CreateByteStream(new ComStream(stream)));
			iMFSourceReader.SetStreamSelection(-2, pSelected: false);
			iMFSourceReader.SetStreamSelection(-3, pSelected: true);
			iMFSourceReader.SetCurrentMediaType(-3, IntPtr.Zero, new MediaType
			{
				MajorType = NAudio.MediaFoundation.MediaTypes.MFMediaType_Audio,
				SubType = (settings.RequestFloatOutput ? AudioSubtypes.MFAudioFormat_Float : AudioSubtypes.MFAudioFormat_PCM)
			}.MediaFoundationObject);
			return iMFSourceReader;
		}
	}

	/// <summary>
	/// WASAPI Loopback Capture
	/// based on a contribution from "Pygmy" - http://naudio.codeplex.com/discussions/203605
	/// </summary>
	public class WasapiLoopbackCapture : WasapiCapture
	{
		/// <summary>
		/// Initialises a new instance of the WASAPI capture class
		/// </summary>
		public WasapiLoopbackCapture()
			: this(GetDefaultLoopbackCaptureDevice())
		{
		}

		/// <summary>
		/// Initialises a new instance of the WASAPI capture class
		/// </summary>
		/// <param name="captureDevice">Capture device to use</param>
		public WasapiLoopbackCapture(MMDevice captureDevice)
			: base(captureDevice)
		{
		}

		/// <summary>
		/// Gets the default audio loopback capture device
		/// </summary>
		/// <returns>The default audio loopback capture device</returns>
		public static MMDevice GetDefaultLoopbackCaptureDevice()
		{
			return new MMDeviceEnumerator().GetDefaultAudioEndpoint(DataFlow.Render, Role.Multimedia);
		}

		/// <summary>
		/// Specify loopback
		/// </summary>
		protected override AudioClientStreamFlags GetAudioClientStreamFlags()
		{
			return AudioClientStreamFlags.Loopback | base.GetAudioClientStreamFlags();
		}
	}

	/// <summary>
	/// Support for playback using Wasapi
	/// </summary>
	public class WasapiOut : IWavePlayer, IDisposable, IWavePosition
	{
		private AudioClient audioClient;

		private readonly MMDevice mmDevice;

		private readonly AudioClientShareMode shareMode;

		private AudioRenderClient renderClient;

		private IWaveProvider sourceProvider;

		private int latencyMilliseconds;

		private int bufferFrameCount;

		private int bytesPerFrame;

		private readonly bool isUsingEventSync;

		private EventWaitHandle frameEventWaitHandle;

		private byte[] readBuffer;

		private volatile PlaybackState playbackState;

		private Thread playThread;

		private readonly SynchronizationContext syncContext;

		private bool dmoResamplerNeeded;

		/// <summary>
		/// Gets a <see cref="T:NAudio.Wave.WaveFormat" /> instance indicating the format the hardware is using.
		/// </summary>
		public WaveFormat OutputWaveFormat { get; private set; }

		/// <summary>
		/// Playback State
		/// </summary>
		public PlaybackState PlaybackState => playbackState;

		/// <summary>
		/// Volume
		/// </summary>
		public float Volume
		{
			get
			{
				return mmDevice.AudioEndpointVolume.MasterVolumeLevelScalar;
			}
			set
			{
				if (value < 0f)
				{
					throw new ArgumentOutOfRangeException("value", "Volume must be between 0.0 and 1.0");
				}
				if (value > 1f)
				{
					throw new ArgumentOutOfRangeException("value", "Volume must be between 0.0 and 1.0");
				}
				mmDevice.AudioEndpointVolume.MasterVolumeLevelScalar = value;
			}
		}

		/// <summary>
		/// Retrieve the AudioStreamVolume object for this audio stream
		/// </summary>
		/// <remarks>
		/// This returns the AudioStreamVolume object ONLY for shared audio streams.
		/// </remarks>
		/// <exception cref="T:System.InvalidOperationException">
		/// This is thrown when an exclusive audio stream is being used.
		/// </exception>
		public AudioStreamVolume AudioStreamVolume
		{
			get
			{
				if (shareMode == AudioClientShareMode.Exclusive)
				{
					throw new InvalidOperationException("AudioStreamVolume is ONLY supported for shared audio streams.");
				}
				return audioClient.AudioStreamVolume;
			}
		}

		/// <summary>
		/// Playback Stopped
		/// </summary>
		public event EventHandler<StoppedEventArgs> PlaybackStopped;

		/// <summary>
		/// WASAPI Out shared mode, default
		/// </summary>
		public WasapiOut()
			: this(GetDefaultAudioEndpoint(), AudioClientShareMode.Shared, useEventSync: true, 200)
		{
		}

		/// <summary>
		/// WASAPI Out using default audio endpoint
		/// </summary>
		/// <param name="shareMode">ShareMode - shared or exclusive</param>
		/// <param name="latency">Desired latency in milliseconds</param>
		public WasapiOut(AudioClientShareMode shareMode, int latency)
			: this(GetDefaultAudioEndpoint(), shareMode, useEventSync: true, latency)
		{
		}

		/// <summary>
		/// WASAPI Out using default audio endpoint
		/// </summary>
		/// <param name="shareMode">ShareMode - shared or exclusive</param>
		/// <param name="useEventSync">true if sync is done with event. false use sleep.</param>
		/// <param name="latency">Desired latency in milliseconds</param>
		public WasapiOut(AudioClientShareMode shareMode, bool useEventSync, int latency)
			: this(GetDefaultAudioEndpoint(), shareMode, useEventSync, latency)
		{
		}

		/// <summary>
		/// Creates a new WASAPI Output
		/// </summary>
		/// <param name="device">Device to use</param>
		/// <param name="shareMode"></param>
		/// <param name="useEventSync">true if sync is done with event. false use sleep.</param>
		/// <param name="latency">Desired latency in milliseconds</param>
		public WasapiOut(MMDevice device, AudioClientShareMode shareMode, bool useEventSync, int latency)
		{
			audioClient = device.AudioClient;
			mmDevice = device;
			this.shareMode = shareMode;
			isUsingEventSync = useEventSync;
			latencyMilliseconds = latency;
			syncContext = SynchronizationContext.Current;
			OutputWaveFormat = audioClient.MixFormat;
		}

		private static MMDevice GetDefaultAudioEndpoint()
		{
			if (Environment.OSVersion.Version.Major < 6)
			{
				throw new NotSupportedException("WASAPI supported only on Windows Vista and above");
			}
			return new MMDeviceEnumerator().GetDefaultAudioEndpoint(DataFlow.Render, Role.Console);
		}

		private void PlayThread()
		{
			ResamplerDmoStream resamplerDmoStream = null;
			IWaveProvider playbackProvider = sourceProvider;
			Exception e = null;
			try
			{
				if (dmoResamplerNeeded)
				{
					resamplerDmoStream = new ResamplerDmoStream(sourceProvider, OutputWaveFormat);
					playbackProvider = resamplerDmoStream;
				}
				bufferFrameCount = audioClient.BufferSize;
				bytesPerFrame = OutputWaveFormat.Channels * OutputWaveFormat.BitsPerSample / 8;
				readBuffer = BufferHelpers.Ensure(readBuffer, bufferFrameCount * bytesPerFrame);
				if (FillBuffer(playbackProvider, bufferFrameCount))
				{
					return;
				}
				WaitHandle[] waitHandles = new WaitHandle[1] { frameEventWaitHandle };
				audioClient.Start();
				while (playbackState != 0)
				{
					if (isUsingEventSync)
					{
						WaitHandle.WaitAny(waitHandles, 3 * latencyMilliseconds, exitContext: false);
					}
					else
					{
						Thread.Sleep(latencyMilliseconds / 2);
					}
					if (playbackState == PlaybackState.Playing)
					{
						int num = ((!isUsingEventSync) ? audioClient.CurrentPadding : ((shareMode == AudioClientShareMode.Shared) ? audioClient.CurrentPadding : 0));
						int num2 = bufferFrameCount - num;
						if (num2 > 10 && FillBuffer(playbackProvider, num2))
						{
							break;
						}
					}
				}
				if (playbackState == PlaybackState.Playing)
				{
					Thread.Sleep(isUsingEventSync ? latencyMilliseconds : (latencyMilliseconds / 2));
				}
				audioClient.Stop();
				playbackState = PlaybackState.Stopped;
				audioClient.Reset();
			}
			catch (Exception ex)
			{
				e = ex;
			}
			finally
			{
				resamplerDmoStream?.Dispose();
				RaisePlaybackStopped(e);
			}
		}

		private void RaisePlaybackStopped(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.PlaybackStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		/// <summary>
		/// returns true if reached the end
		/// </summary>
		private unsafe bool FillBuffer(IWaveProvider playbackProvider, int frameCount)
		{
			int num = frameCount * bytesPerFrame;
			int num2 = playbackProvider.Read(readBuffer, 0, num);
			if (num2 == 0)
			{
				return true;
			}
			IntPtr buffer = renderClient.GetBuffer(frameCount);
			Marshal.Copy(readBuffer, 0, buffer, num2);
			if (isUsingEventSync && shareMode == AudioClientShareMode.Exclusive)
			{
				if (num2 < num)
				{
					byte* ptr = (byte*)(void*)buffer;
					while (num2 < num)
					{
						ptr[num2++] = 0;
					}
				}
				renderClient.ReleaseBuffer(frameCount, AudioClientBufferFlags.None);
			}
			else
			{
				int numFramesWritten = num2 / bytesPerFrame;
				renderClient.ReleaseBuffer(numFramesWritten, AudioClientBufferFlags.None);
			}
			return false;
		}

		private WaveFormat GetFallbackFormat()
		{
			int sampleRate = audioClient.MixFormat.SampleRate;
			int channels = audioClient.MixFormat.Channels;
			List<int> list = new List<int> { OutputWaveFormat.SampleRate };
			if (!list.Contains(sampleRate))
			{
				list.Add(sampleRate);
			}
			if (!list.Contains(44100))
			{
				list.Add(44100);
			}
			if (!list.Contains(48000))
			{
				list.Add(48000);
			}
			List<int> list2 = new List<int> { OutputWaveFormat.Channels };
			if (!list2.Contains(channels))
			{
				list2.Add(channels);
			}
			if (!list2.Contains(2))
			{
				list2.Add(2);
			}
			List<int> list3 = new List<int> { OutputWaveFormat.BitsPerSample };
			if (!list3.Contains(32))
			{
				list3.Add(32);
			}
			if (!list3.Contains(24))
			{
				list3.Add(24);
			}
			if (!list3.Contains(16))
			{
				list3.Add(16);
			}
			foreach (int item in list)
			{
				foreach (int item2 in list2)
				{
					foreach (int item3 in list3)
					{
						WaveFormatExtensible waveFormatExtensible = new WaveFormatExtensible(item, item3, item2);
						if (audioClient.IsFormatSupported(shareMode, waveFormatExtensible))
						{
							return waveFormatExtensible;
						}
					}
				}
			}
			throw new NotSupportedException("Can't find a supported format to use");
		}

		/// <summary>
		/// Gets the current position in bytes from the wave output device.
		/// (n.b. this is not the same thing as the position within your reader
		/// stream)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			ulong position;
			switch (playbackState)
			{
			case PlaybackState.Stopped:
				return 0L;
			case PlaybackState.Playing:
				position = audioClient.AudioClockClient.AdjustedPosition;
				break;
			default:
			{
				audioClient.AudioClockClient.GetPosition(out position, out var _);
				break;
			}
			}
			return (long)position * (long)OutputWaveFormat.AverageBytesPerSecond / (long)audioClient.AudioClockClient.Frequency;
		}

		/// <summary>
		/// Begin Playback
		/// </summary>
		public void Play()
		{
			if (playbackState != PlaybackState.Playing)
			{
				if (playbackState == PlaybackState.Stopped)
				{
					playThread = new Thread(PlayThread)
					{
						IsBackground = true
					};
					playbackState = PlaybackState.Playing;
					playThread.Start();
				}
				else
				{
					playbackState = PlaybackState.Playing;
				}
			}
		}

		/// <summary>
		/// Stop playback and flush buffers
		/// </summary>
		public void Stop()
		{
			if (playbackState != 0)
			{
				playbackState = PlaybackState.Stopped;
				playThread.Join();
				playThread = null;
			}
		}

		/// <summary>
		/// Stop playback without flushing buffers
		/// </summary>
		public void Pause()
		{
			if (playbackState == PlaybackState.Playing)
			{
				playbackState = PlaybackState.Paused;
			}
		}

		/// <summary>
		/// Initialize for playing the specified wave stream
		/// </summary>
		/// <param name="waveProvider">IWaveProvider to play</param>
		public void Init(IWaveProvider waveProvider)
		{
			long num = (long)latencyMilliseconds * 10000L;
			OutputWaveFormat = waveProvider.WaveFormat;
			AudioClientStreamFlags audioClientStreamFlags = AudioClientStreamFlags.SrcDefaultQuality | AudioClientStreamFlags.AutoConvertPcm;
			sourceProvider = waveProvider;
			if (shareMode == AudioClientShareMode.Exclusive)
			{
				audioClientStreamFlags = AudioClientStreamFlags.None;
				if (!audioClient.IsFormatSupported(shareMode, OutputWaveFormat, out var closestMatchFormat))
				{
					if (closestMatchFormat == null)
					{
						OutputWaveFormat = GetFallbackFormat();
					}
					else
					{
						OutputWaveFormat = closestMatchFormat;
					}
					try
					{
						using (new ResamplerDmoStream(waveProvider, OutputWaveFormat))
						{
						}
					}
					catch (Exception)
					{
						OutputWaveFormat = GetFallbackFormat();
						using (new ResamplerDmoStream(waveProvider, OutputWaveFormat))
						{
						}
					}
					dmoResamplerNeeded = true;
				}
				else
				{
					dmoResamplerNeeded = false;
				}
			}
			if (isUsingEventSync)
			{
				if (shareMode == AudioClientShareMode.Shared)
				{
					audioClient.Initialize(shareMode, AudioClientStreamFlags.EventCallback | audioClientStreamFlags, num, 0L, OutputWaveFormat, Guid.Empty);
					long streamLatency = audioClient.StreamLatency;
					if (streamLatency != 0L)
					{
						latencyMilliseconds = (int)(streamLatency / 10000);
					}
				}
				else
				{
					try
					{
						audioClient.Initialize(shareMode, AudioClientStreamFlags.EventCallback | audioClientStreamFlags, num, num, OutputWaveFormat, Guid.Empty);
					}
					catch (COMException ex2)
					{
						if (ex2.ErrorCode != -2004287463)
						{
							throw;
						}
						long num2 = (long)(10000000.0 / (double)OutputWaveFormat.SampleRate * (double)audioClient.BufferSize + 0.5);
						audioClient.Dispose();
						audioClient = mmDevice.AudioClient;
						audioClient.Initialize(shareMode, AudioClientStreamFlags.EventCallback | audioClientStreamFlags, num2, num2, OutputWaveFormat, Guid.Empty);
					}
				}
				frameEventWaitHandle = new EventWaitHandle(initialState: false, EventResetMode.AutoReset);
				audioClient.SetEventHandle(frameEventWaitHandle.SafeWaitHandle.DangerousGetHandle());
			}
			else
			{
				audioClient.Initialize(shareMode, audioClientStreamFlags, num, 0L, OutputWaveFormat, Guid.Empty);
			}
			renderClient = audioClient.AudioRenderClient;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (audioClient != null)
			{
				Stop();
				audioClient.Dispose();
				audioClient = null;
				renderClient = null;
			}
		}
	}
}

namespace NAudio.Mixer
{
	/// <summary>
	/// Boolean mixer control
	/// </summary>
	public class BooleanMixerControl : MixerControl
	{
		private MixerInterop.MIXERCONTROLDETAILS_BOOLEAN boolDetails;

		/// <summary>
		/// The current value of the control
		/// </summary>
		public bool Value
		{
			get
			{
				GetControlDetails();
				return boolDetails.fValue == 1;
			}
			set
			{
				boolDetails.fValue = (value ? 1 : 0);
				mixerControlDetails.paDetails = Marshal.AllocHGlobal(Marshal.SizeOf(boolDetails));
				Marshal.StructureToPtr(boolDetails, mixerControlDetails.paDetails, fDeleteOld: false);
				MmException.Try(MixerInterop.mixerSetControlDetails(mixerHandle, ref mixerControlDetails, MixerFlags.Mixer | mixerHandleType), "mixerSetControlDetails");
				Marshal.FreeHGlobal(mixerControlDetails.paDetails);
			}
		}

		internal BooleanMixerControl(MixerInterop.MIXERCONTROL mixerControl, IntPtr mixerHandle, MixerFlags mixerHandleType, int nChannels)
		{
			base.mixerControl = mixerControl;
			base.mixerHandle = mixerHandle;
			base.mixerHandleType = mixerHandleType;
			base.nChannels = nChannels;
			mixerControlDetails = default(MixerInterop.MIXERCONTROLDETAILS);
			GetControlDetails();
		}

		/// <summary>
		/// Gets the details for this control
		/// </summary>
		/// <param name="pDetails">memory pointer</param>
		protected override void GetDetails(IntPtr pDetails)
		{
			boolDetails = Marshal.PtrToStructure<MixerInterop.MIXERCONTROLDETAILS_BOOLEAN>(pDetails);
		}
	}

	/// <summary>
	/// Custom Mixer control
	/// </summary>
	public class CustomMixerControl : MixerControl
	{
		internal CustomMixerControl(MixerInterop.MIXERCONTROL mixerControl, IntPtr mixerHandle, MixerFlags mixerHandleType, int nChannels)
		{
			base.mixerControl = mixerControl;
			base.mixerHandle = mixerHandle;
			base.mixerHandleType = mixerHandleType;
			base.nChannels = nChannels;
			mixerControlDetails = default(MixerInterop.MIXERCONTROLDETAILS);
			GetControlDetails();
		}

		/// <summary>
		/// Get the data for this custom control
		/// </summary>
		/// <param name="pDetails">pointer to memory to receive data</param>
		protected override void GetDetails(IntPtr pDetails)
		{
		}
	}

	/// <summary>
	/// List text mixer control
	/// </summary>
	public class ListTextMixerControl : MixerControl
	{
		internal ListTextMixerControl(MixerInterop.MIXERCONTROL mixerControl, IntPtr mixerHandle, MixerFlags mixerHandleType, int nChannels)
		{
			base.mixerControl = mixerControl;
			base.mixerHandle = mixerHandle;
			base.mixerHandleType = mixerHandleType;
			base.nChannels = nChannels;
			mixerControlDetails = default(MixerInterop.MIXERCONTROLDETAILS);
			GetControlDetails();
		}

		/// <summary>
		/// Get the details for this control
		/// </summary>
		/// <param name="pDetails">Memory location to read to</param>
		protected override void GetDetails(IntPtr pDetails)
		{
		}
	}

	/// <summary>Represents a Windows mixer device</summary>
	public class Mixer
	{
		private MixerInterop.MIXERCAPS caps;

		private IntPtr mixerHandle;

		private MixerFlags mixerHandleType;

		/// <summary>The number of mixer devices available</summary>	
		public static int NumberOfDevices => MixerInterop.mixerGetNumDevs();

		/// <summary>The number of destinations this mixer supports</summary>
		public int DestinationCount => (int)caps.cDestinations;

		/// <summary>The name of this mixer device</summary>
		public string Name => caps.szPname;

		/// <summary>The manufacturer code for this mixer device</summary>
		public Manufacturers Manufacturer => (Manufacturers)caps.wMid;

		/// <summary>The product identifier code for this mixer device</summary>
		public int ProductID => caps.wPid;

		/// <summary>
		/// A way to enumerate the destinations
		/// </summary>
		public IEnumerable<MixerLine> Destinations
		{
			get
			{
				for (int destination = 0; destination < DestinationCount; destination++)
				{
					yield return GetDestination(destination);
				}
			}
		}

		/// <summary>
		/// A way to enumerate all available devices
		/// </summary>
		public static IEnumerable<Mixer> Mixers
		{
			get
			{
				for (int device = 0; device < NumberOfDevices; device++)
				{
					yield return new Mixer(device);
				}
			}
		}

		/// <summary>Connects to the specified mixer</summary>
		/// <param name="mixerIndex">The index of the mixer to use. 
		/// This should be between zero and NumberOfDevices - 1</param>
		public Mixer(int mixerIndex)
		{
			if (mixerIndex < 0 || mixerIndex >= NumberOfDevices)
			{
				throw new ArgumentOutOfRangeException("mixerID");
			}
			caps = default(MixerInterop.MIXERCAPS);
			MmException.Try(MixerInterop.mixerGetDevCaps((IntPtr)mixerIndex, ref caps, Marshal.SizeOf(caps)), "mixerGetDevCaps");
			mixerHandle = (IntPtr)mixerIndex;
			mixerHandleType = MixerFlags.Mixer;
		}

		/// <summary>Retrieve the specified MixerDestination object</summary>
		/// <param name="destinationIndex">The ID of the destination to use.
		/// Should be between 0 and DestinationCount - 1</param>
		public MixerLine GetDestination(int destinationIndex)
		{
			if (destinationIndex < 0 || destinationIndex >= DestinationCount)
			{
				throw new ArgumentOutOfRangeException("destinationIndex");
			}
			return new MixerLine(mixerHandle, destinationIndex, mixerHandleType);
		}
	}

	/// <summary>
	/// Represents a mixer control
	/// </summary>
	public abstract class MixerControl
	{
		internal MixerInterop.MIXERCONTROL mixerControl;

		internal MixerInterop.MIXERCONTROLDETAILS mixerControlDetails;

		/// <summary>
		/// Mixer Handle
		/// </summary>
		protected IntPtr mixerHandle;

		/// <summary>
		/// Number of Channels
		/// </summary>
		protected int nChannels;

		/// <summary>
		/// Mixer Handle Type
		/// </summary>
		protected MixerFlags mixerHandleType;

		/// <summary>
		/// Mixer control name
		/// </summary>
		public string Name => mixerControl.szName;

		/// <summary>
		/// Mixer control type
		/// </summary>
		public MixerControlType ControlType => mixerControl.dwControlType;

		/// <summary>
		/// Is this a boolean control
		/// </summary>
		public bool IsBoolean => IsControlBoolean(mixerControl.dwControlType);

		/// <summary>
		/// True if this is a list text control
		/// </summary>
		public bool IsListText => IsControlListText(mixerControl.dwControlType);

		/// <summary>
		/// True if this is a signed control
		/// </summary>
		public bool IsSigned => IsControlSigned(mixerControl.dwControlType);

		/// <summary>
		/// True if this is an unsigned control
		/// </summary>
		public bool IsUnsigned => IsControlUnsigned(mixerControl.dwControlType);

		/// <summary>
		/// True if this is a custom control
		/// </summary>
		public bool IsCustom => IsControlCustom(mixerControl.dwControlType);

		/// <summary>
		/// Gets all the mixer controls
		/// </summary>
		/// <param name="mixerHandle">Mixer Handle</param>
		/// <param name="mixerLine">Mixer Line</param>
		/// <param name="mixerHandleType">Mixer Handle Type</param>
		/// <returns></returns>
		public static IList<MixerControl> GetMixerControls(IntPtr mixerHandle, MixerLine mixerLine, MixerFlags mixerHandleType)
		{
			List<MixerControl> list = new List<MixerControl>();
			if (mixerLine.ControlsCount > 0)
			{
				int num = Marshal.SizeOf<MixerInterop.MIXERCONTROL>();
				MixerInterop.MIXERLINECONTROLS mixerLineControls = default(MixerInterop.MIXERLINECONTROLS);
				IntPtr intPtr = Marshal.AllocHGlobal(num * mixerLine.ControlsCount);
				mixerLineControls.cbStruct = Marshal.SizeOf(mixerLineControls);
				mixerLineControls.dwLineID = mixerLine.LineId;
				mixerLineControls.cControls = mixerLine.ControlsCount;
				mixerLineControls.pamxctrl = intPtr;
				mixerLineControls.cbmxctrl = Marshal.SizeOf<MixerInterop.MIXERCONTROL>();
				try
				{
					MmResult mmResult = MixerInterop.mixerGetLineControls(mixerHandle, ref mixerLineControls, MixerFlags.Mixer | mixerHandleType);
					if (mmResult != 0)
					{
						throw new MmException(mmResult, "mixerGetLineControls");
					}
					for (int i = 0; i < mixerLineControls.cControls; i++)
					{
						MixerInterop.MIXERCONTROL mIXERCONTROL = Marshal.PtrToStructure<MixerInterop.MIXERCONTROL>((IntPtr)(intPtr.ToInt64() + num * i));
						MixerControl item = GetMixerControl(mixerHandle, mixerLine.LineId, mIXERCONTROL.dwControlID, mixerLine.Channels, mixerHandleType);
						list.Add(item);
					}
				}
				finally
				{
					Marshal.FreeHGlobal(intPtr);
				}
			}
			return list;
		}

		/// <summary>
		/// Gets a specified Mixer Control
		/// </summary>
		/// <param name="mixerHandle">Mixer Handle</param>
		/// <param name="nLineId">Line ID</param>
		/// <param name="controlId">Control ID</param>
		/// <param name="nChannels">Number of Channels</param>
		/// <param name="mixerFlags">Flags to use (indicates the meaning of mixerHandle)</param>
		/// <returns></returns>
		public static MixerControl GetMixerControl(IntPtr mixerHandle, int nLineId, int controlId, int nChannels, MixerFlags mixerFlags)
		{
			MixerInterop.MIXERLINECONTROLS mixerLineControls = default(MixerInterop.MIXERLINECONTROLS);
			MixerInterop.MIXERCONTROL structure = default(MixerInterop.MIXERCONTROL);
			IntPtr intPtr = Marshal.AllocCoTaskMem(Marshal.SizeOf(structure));
			mixerLineControls.cbStruct = Marshal.SizeOf(mixerLineControls);
			mixerLineControls.cControls = 1;
			mixerLineControls.dwControlID = controlId;
			mixerLineControls.cbmxctrl = Marshal.SizeOf(structure);
			mixerLineControls.pamxctrl = intPtr;
			mixerLineControls.dwLineID = nLineId;
			MmResult mmResult = MixerInterop.mixerGetLineControls(mixerHandle, ref mixerLineControls, MixerFlags.ListText | mixerFlags);
			if (mmResult != 0)
			{
				Marshal.FreeCoTaskMem(intPtr);
				throw new MmException(mmResult, "mixerGetLineControls");
			}
			structure = Marshal.PtrToStructure<MixerInterop.MIXERCONTROL>(mixerLineControls.pamxctrl);
			Marshal.FreeCoTaskMem(intPtr);
			if (IsControlBoolean(structure.dwControlType))
			{
				return new BooleanMixerControl(structure, mixerHandle, mixerFlags, nChannels);
			}
			if (IsControlSigned(structure.dwControlType))
			{
				return new SignedMixerControl(structure, mixerHandle, mixerFlags, nChannels);
			}
			if (IsControlUnsigned(structure.dwControlType))
			{
				return new UnsignedMixerControl(structure, mixerHandle, mixerFlags, nChannels);
			}
			if (IsControlListText(structure.dwControlType))
			{
				return new ListTextMixerControl(structure, mixerHandle, mixerFlags, nChannels);
			}
			if (IsControlCustom(structure.dwControlType))
			{
				return new CustomMixerControl(structure, mixerHandle, mixerFlags, nChannels);
			}
			throw new InvalidOperationException($"Unknown mixer control type {structure.dwControlType}");
		}

		/// <summary>
		/// Gets the control details
		/// </summary>
		protected void GetControlDetails()
		{
			mixerControlDetails.cbStruct = Marshal.SizeOf(mixerControlDetails);
			mixerControlDetails.dwControlID = mixerControl.dwControlID;
			if (IsCustom)
			{
				mixerControlDetails.cChannels = 0;
			}
			else if ((mixerControl.fdwControl & (true ? 1u : 0u)) != 0)
			{
				mixerControlDetails.cChannels = 1;
			}
			else
			{
				mixerControlDetails.cChannels = nChannels;
			}
			if ((mixerControl.fdwControl & 2u) != 0)
			{
				mixerControlDetails.hwndOwner = (IntPtr)mixerControl.cMultipleItems;
			}
			else if (IsCustom)
			{
				mixerControlDetails.hwndOwner = IntPtr.Zero;
			}
			else
			{
				mixerControlDetails.hwndOwner = IntPtr.Zero;
			}
			if (IsBoolean)
			{
				mixerControlDetails.cbDetails = Marshal.SizeOf<MixerInterop.MIXERCONTROLDETAILS_BOOLEAN>();
			}
			else if (IsListText)
			{
				mixerControlDetails.cbDetails = Marshal.SizeOf<MixerInterop.MIXERCONTROLDETAILS_LISTTEXT>();
			}
			else if (IsSigned)
			{
				mixerControlDetails.cbDetails = Marshal.SizeOf<MixerInterop.MIXERCONTROLDETAILS_SIGNED>();
			}
			else if (IsUnsigned)
			{
				mixerControlDetails.cbDetails = Marshal.SizeOf<MixerInterop.MIXERCONTROLDETAILS_UNSIGNED>();
			}
			else
			{
				mixerControlDetails.cbDetails = mixerControl.Metrics.customData;
			}
			int num = mixerControlDetails.cbDetails * mixerControlDetails.cChannels;
			if ((mixerControl.fdwControl & 2u) != 0)
			{
				num *= (int)mixerControl.cMultipleItems;
			}
			IntPtr intPtr = Marshal.AllocCoTaskMem(num);
			mixerControlDetails.paDetails = intPtr;
			MmResult mmResult = MixerInterop.mixerGetControlDetails(mixerHandle, ref mixerControlDetails, MixerFlags.Mixer | mixerHandleType);
			if (mmResult == MmResult.NoError)
			{
				GetDetails(mixerControlDetails.paDetails);
			}
			Marshal.FreeCoTaskMem(intPtr);
			if (mmResult != 0)
			{
				throw new MmException(mmResult, "mixerGetControlDetails");
			}
		}

		/// <summary>
		/// Gets the control details
		/// </summary>
		/// <param name="pDetails"></param>
		protected abstract void GetDetails(IntPtr pDetails);

		/// <summary>
		/// Returns true if this is a boolean control
		/// </summary>
		/// <param name="controlType">Control type</param>
		private static bool IsControlBoolean(MixerControlType controlType)
		{
			switch (controlType)
			{
			case MixerControlType.BooleanMeter:
			case MixerControlType.Boolean:
			case MixerControlType.OnOff:
			case MixerControlType.Mute:
			case MixerControlType.Mono:
			case MixerControlType.Loudness:
			case MixerControlType.StereoEnhance:
			case MixerControlType.Button:
			case MixerControlType.SingleSelect:
			case MixerControlType.Mux:
			case MixerControlType.MultipleSelect:
			case MixerControlType.Mixer:
				return true;
			default:
				return false;
			}
		}

		/// <summary>
		/// Determines whether a specified mixer control type is a list text control
		/// </summary>
		private static bool IsControlListText(MixerControlType controlType)
		{
			if (controlType == MixerControlType.Equalizer || (uint)(controlType - 1879113728) <= 1u || (uint)(controlType - 1895890944) <= 1u)
			{
				return true;
			}
			return false;
		}

		private static bool IsControlSigned(MixerControlType controlType)
		{
			switch (controlType)
			{
			case MixerControlType.SignedMeter:
			case MixerControlType.PeakMeter:
			case MixerControlType.Signed:
			case MixerControlType.Decibels:
			case MixerControlType.Slider:
			case MixerControlType.Pan:
			case MixerControlType.QSoundPan:
				return true;
			default:
				return false;
			}
		}

		private static bool IsControlUnsigned(MixerControlType controlType)
		{
			switch (controlType)
			{
			case MixerControlType.UnsignedMeter:
			case MixerControlType.Unsigned:
			case MixerControlType.Percent:
			case MixerControlType.Fader:
			case MixerControlType.Volume:
			case MixerControlType.Bass:
			case MixerControlType.Treble:
			case MixerControlType.Equalizer:
			case MixerControlType.MicroTime:
			case MixerControlType.MilliTime:
				return true;
			default:
				return false;
			}
		}

		private static bool IsControlCustom(MixerControlType controlType)
		{
			return controlType == MixerControlType.Custom;
		}

		/// <summary>
		/// String representation for debug purposes
		/// </summary>
		public override string ToString()
		{
			return $"{Name} {ControlType}";
		}
	}

	[Flags]
	internal enum MixerControlClass
	{
		Custom = 0,
		Meter = 0x10000000,
		Switch = 0x20000000,
		Number = 0x30000000,
		Slider = 0x40000000,
		Fader = 0x50000000,
		Time = 0x60000000,
		List = 0x70000000,
		Mask = 0x70000000
	}

	[Flags]
	internal enum MixerControlSubclass
	{
		SwitchBoolean = 0,
		SwitchButton = 0x1000000,
		MeterPolled = 0,
		TimeMicrosecs = 0,
		TimeMillisecs = 0x1000000,
		ListSingle = 0,
		ListMultiple = 0x1000000,
		Mask = 0xF000000
	}

	/// <summary>
	/// Mixer control types
	/// </summary>
	public enum MixerControlType
	{
		/// <summary>Custom</summary>
		Custom = 0,
		/// <summary>Boolean meter</summary>
		BooleanMeter = 268500992,
		/// <summary>Signed meter</summary>
		SignedMeter = 268566528,
		/// <summary>Peak meter</summary>
		PeakMeter = 268566529,
		/// <summary>Unsigned meter</summary>
		UnsignedMeter = 268632064,
		/// <summary>Boolean</summary>
		Boolean = 536936448,
		/// <summary>On Off</summary>
		OnOff = 536936449,
		/// <summary>Mute</summary>
		Mute = 536936450,
		/// <summary>Mono</summary>
		Mono = 536936451,
		/// <summary>Loudness</summary>
		Loudness = 536936452,
		/// <summary>Stereo Enhance</summary>
		StereoEnhance = 536936453,
		/// <summary>Button</summary>
		Button = 553713664,
		/// <summary>Decibels</summary>
		Decibels = 805568512,
		/// <summary>Signed</summary>
		Signed = 805437440,
		/// <summary>Unsigned</summary>
		Unsigned = 805502976,
		/// <summary>Percent</summary>
		Percent = 805634048,
		/// <summary>Slider</summary>
		Slider = 1073872896,
		/// <summary>Pan</summary>
		Pan = 1073872897,
		/// <summary>Q-sound pan</summary>
		QSoundPan = 1073872898,
		/// <summary>Fader</summary>
		Fader = 1342373888,
		/// <summary>Volume</summary>
		Volume = 1342373889,
		/// <summary>Bass</summary>
		Bass = 1342373890,
		/// <summary>Treble</summary>
		Treble = 1342373891,
		/// <summary>Equaliser</summary>
		Equalizer = 1342373892,
		/// <summary>Single Select</summary>
		SingleSelect = 1879113728,
		/// <summary>Mux</summary>
		Mux = 1879113729,
		/// <summary>Multiple select</summary>
		MultipleSelect = 1895890944,
		/// <summary>Mixer</summary>
		Mixer = 1895890945,
		/// <summary>Micro time</summary>
		MicroTime = 1610809344,
		/// <summary>Milli time</summary>
		MilliTime = 1627586560
	}

	[Flags]
	internal enum MixerControlUnits
	{
		Custom = 0,
		Boolean = 0x10000,
		Signed = 0x20000,
		Unsigned = 0x30000,
		Decibels = 0x40000,
		Percent = 0x50000,
		Mask = 0xFF0000
	}

	/// <summary>
	/// Mixer Interop Flags
	/// </summary>
	[Flags]
	public enum MixerFlags
	{
		/// <summary>
		/// MIXER_OBJECTF_HANDLE 	= 0x80000000;
		/// </summary>
		Handle = int.MinValue,
		/// <summary>
		/// MIXER_OBJECTF_MIXER 	= 0x00000000;
		/// </summary>
		Mixer = 0,
		/// <summary>
		/// MIXER_OBJECTF_HMIXER
		/// </summary>
		MixerHandle = int.MinValue,
		/// <summary>
		/// MIXER_OBJECTF_WAVEOUT
		/// </summary>
		WaveOut = 0x10000000,
		/// <summary>
		/// MIXER_OBJECTF_HWAVEOUT
		/// </summary>
		WaveOutHandle = -1879048192,
		/// <summary>
		/// MIXER_OBJECTF_WAVEIN
		/// </summary>
		WaveIn = 0x20000000,
		/// <summary>
		/// MIXER_OBJECTF_HWAVEIN
		/// </summary>
		WaveInHandle = -1610612736,
		/// <summary>
		/// MIXER_OBJECTF_MIDIOUT
		/// </summary>
		MidiOut = 0x30000000,
		/// <summary>
		/// MIXER_OBJECTF_HMIDIOUT
		/// </summary>
		MidiOutHandle = -1342177280,
		/// <summary>
		/// MIXER_OBJECTF_MIDIIN
		/// </summary>
		MidiIn = 0x40000000,
		/// <summary>
		/// MIXER_OBJECTF_HMIDIIN
		/// </summary>
		MidiInHandle = -1073741824,
		/// <summary>
		/// MIXER_OBJECTF_AUX
		/// </summary>
		Aux = 0x50000000,
		/// <summary>
		/// MIXER_GETCONTROLDETAILSF_VALUE      	= 0x00000000;
		/// MIXER_SETCONTROLDETAILSF_VALUE      	= 0x00000000;
		/// </summary>
		Value = 0,
		/// <summary>
		/// MIXER_GETCONTROLDETAILSF_LISTTEXT   	= 0x00000001;
		/// MIXER_SETCONTROLDETAILSF_LISTTEXT   	= 0x00000001;
		/// </summary>
		ListText = 1,
		/// <summary>
		/// MIXER_GETCONTROLDETAILSF_QUERYMASK  	= 0x0000000F;
		/// MIXER_SETCONTROLDETAILSF_QUERYMASK  	= 0x0000000F;
		/// MIXER_GETLINECONTROLSF_QUERYMASK    	= 0x0000000F;
		/// </summary>
		QueryMask = 0xF,
		/// <summary>
		/// MIXER_GETLINECONTROLSF_ALL          	= 0x00000000;
		/// </summary>
		All = 0,
		/// <summary>
		/// MIXER_GETLINECONTROLSF_ONEBYID      	= 0x00000001;
		/// </summary>
		OneById = 1,
		/// <summary>
		/// MIXER_GETLINECONTROLSF_ONEBYTYPE    	= 0x00000002;
		/// </summary>
		OneByType = 2,
		/// <summary>
		/// MIXER_GETLINEINFOF_DESTINATION      	= 0x00000000;
		/// </summary>
		GetLineInfoOfDestination = 0,
		/// <summary>
		/// MIXER_GETLINEINFOF_SOURCE           	= 0x00000001;
		/// </summary>
		GetLineInfoOfSource = 1,
		/// <summary>
		/// MIXER_GETLINEINFOF_LINEID           	= 0x00000002;
		/// </summary>
		GetLineInfoOfLineId = 2,
		/// <summary>
		/// MIXER_GETLINEINFOF_COMPONENTTYPE    	= 0x00000003;
		/// </summary>
		GetLineInfoOfComponentType = 3,
		/// <summary>
		/// MIXER_GETLINEINFOF_TARGETTYPE       	= 0x00000004;
		/// </summary>
		GetLineInfoOfTargetType = 4,
		/// <summary>
		/// MIXER_GETLINEINFOF_QUERYMASK        	= 0x0000000F;
		/// </summary>
		GetLineInfoOfQueryMask = 0xF
	}

	internal class MixerInterop
	{
		[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto, Pack = 1)]
		public struct MIXERCONTROLDETAILS
		{
			public int cbStruct;

			public int dwControlID;

			public int cChannels;

			public IntPtr hwndOwner;

			public int cbDetails;

			public IntPtr paDetails;
		}

		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct MIXERCAPS
		{
			public ushort wMid;

			public ushort wPid;

			public uint vDriverVersion;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
			public string szPname;

			public uint fdwSupport;

			public uint cDestinations;
		}

		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct MIXERLINECONTROLS
		{
			public int cbStruct;

			public int dwLineID;

			public int dwControlID;

			public int cControls;

			public int cbmxctrl;

			public IntPtr pamxctrl;
		}

		/// <summary>
		/// Mixer Line Flags
		/// </summary>
		[Flags]
		public enum MIXERLINE_LINEF
		{
			/// <summary>
			/// Audio line is active. An active line indicates that a signal is probably passing 
			/// through the line.
			/// </summary>
			MIXERLINE_LINEF_ACTIVE = 1,
			/// <summary>
			/// Audio line is disconnected. A disconnected line's associated controls can still be 
			/// modified, but the changes have no effect until the line is connected.
			/// </summary>
			MIXERLINE_LINEF_DISCONNECTED = 0x8000,
			/// <summary>
			/// Audio line is an audio source line associated with a single audio destination line. 
			/// If this flag is not set, this line is an audio destination line associated with zero 
			/// or more audio source lines.
			/// </summary>
			MIXERLINE_LINEF_SOURCE = int.MinValue
		}

		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct MIXERLINE
		{
			public int cbStruct;

			public int dwDestination;

			public int dwSource;

			public int dwLineID;

			public MIXERLINE_LINEF fdwLine;

			public IntPtr dwUser;

			public MixerLineComponentType dwComponentType;

			public int cChannels;

			public int cConnections;

			public int cControls;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 16)]
			public string szShortName;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 64)]
			public string szName;

			public uint dwType;

			public uint dwDeviceID;

			public ushort wMid;

			public ushort wPid;

			public uint vDriverVersion;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
			public string szPname;
		}

		/// <summary>
		/// BOUNDS structure
		/// </summary>
		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct Bounds
		{
			/// <summary>
			/// dwMinimum / lMinimum / reserved 0
			/// </summary>
			public int minimum;

			/// <summary>
			/// dwMaximum / lMaximum / reserved 1
			/// </summary>
			public int maximum;

			/// <summary>
			/// reserved 2
			/// </summary>
			public int reserved2;

			/// <summary>
			/// reserved 3
			/// </summary>
			public int reserved3;

			/// <summary>
			/// reserved 4
			/// </summary>
			public int reserved4;

			/// <summary>
			/// reserved 5
			/// </summary>
			public int reserved5;
		}

		/// <summary>
		/// METRICS structure
		/// </summary>
		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct Metrics
		{
			/// <summary>
			/// cSteps / reserved[0]
			/// </summary>
			public int step;

			/// <summary>
			/// cbCustomData / reserved[1], number of bytes for control details
			/// </summary>
			public int customData;

			/// <summary>
			/// reserved 2
			/// </summary>
			public int reserved2;

			/// <summary>
			/// reserved 3
			/// </summary>
			public int reserved3;

			/// <summary>
			/// reserved 4
			/// </summary>
			public int reserved4;

			/// <summary>
			/// reserved 5
			/// </summary>
			public int reserved5;
		}

		/// <summary>
		/// MIXERCONTROL struct
		/// http://msdn.microsoft.com/en-us/library/dd757293%28VS.85%29.aspx
		/// </summary>
		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct MIXERCONTROL
		{
			public uint cbStruct;

			public int dwControlID;

			public MixerControlType dwControlType;

			public uint fdwControl;

			public uint cMultipleItems;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 16)]
			public string szShortName;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 64)]
			public string szName;

			public Bounds Bounds;

			public Metrics Metrics;
		}

		public struct MIXERCONTROLDETAILS_BOOLEAN
		{
			public int fValue;
		}

		public struct MIXERCONTROLDETAILS_SIGNED
		{
			public int lValue;
		}

		[StructLayout(LayoutKind.Sequential, Pack = 1)]
		public struct MIXERCONTROLDETAILS_LISTTEXT
		{
			public uint dwParam1;

			public uint dwParam2;

			[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 64)]
			public string szName;
		}

		public struct MIXERCONTROLDETAILS_UNSIGNED
		{
			public uint dwValue;
		}

		public const uint MIXERCONTROL_CONTROLF_UNIFORM = 1u;

		public const uint MIXERCONTROL_CONTROLF_MULTIPLE = 2u;

		public const uint MIXERCONTROL_CONTROLF_DISABLED = 2147483648u;

		public const int MAXPNAMELEN = 32;

		public const int MIXER_SHORT_NAME_CHARS = 16;

		public const int MIXER_LONG_NAME_CHARS = 64;

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern int mixerGetNumDevs();

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerOpen(out IntPtr hMixer, int uMxId, IntPtr dwCallback, IntPtr dwInstance, MixerFlags dwOpenFlags);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerClose(IntPtr hMixer);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerGetControlDetails(IntPtr hMixer, ref MIXERCONTROLDETAILS mixerControlDetails, MixerFlags dwDetailsFlags);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerGetDevCaps(IntPtr nMixerID, ref MIXERCAPS mixerCaps, int mixerCapsSize);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerGetID(IntPtr hMixer, out int mixerID, MixerFlags dwMixerIDFlags);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerGetLineControls(IntPtr hMixer, ref MIXERLINECONTROLS mixerLineControls, MixerFlags dwControlFlags);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerGetLineInfo(IntPtr hMixer, ref MIXERLINE mixerLine, MixerFlags dwInfoFlags);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerMessage(IntPtr hMixer, uint nMessage, IntPtr dwParam1, IntPtr dwParam2);

		[DllImport("winmm.dll", CharSet = CharSet.Ansi)]
		public static extern MmResult mixerSetControlDetails(IntPtr hMixer, ref MIXERCONTROLDETAILS mixerControlDetails, MixerFlags dwDetailsFlags);
	}

	/// <summary>
	/// Represents a mixer line (source or destination)
	/// </summary>
	public class MixerLine
	{
		private MixerInterop.MIXERLINE mixerLine;

		private IntPtr mixerHandle;

		private MixerFlags mixerHandleType;

		/// <summary>
		/// Mixer Line Name
		/// </summary>
		public string Name => mixerLine.szName;

		/// <summary>
		/// Mixer Line short name
		/// </summary>
		public string ShortName => mixerLine.szShortName;

		/// <summary>
		/// The line ID
		/// </summary>
		public int LineId => mixerLine.dwLineID;

		/// <summary>
		/// Component Type
		/// </summary>
		public MixerLineComponentType ComponentType => mixerLine.dwComponentType;

		/// <summary>
		/// Mixer destination type description
		/// </summary>
		public string TypeDescription => mixerLine.dwComponentType switch
		{
			MixerLineComponentType.DestinationUndefined => "Undefined Destination", 
			MixerLineComponentType.DestinationDigital => "Digital Destination", 
			MixerLineComponentType.DestinationLine => "Line Level Destination", 
			MixerLineComponentType.DestinationMonitor => "Monitor Destination", 
			MixerLineComponentType.DestinationSpeakers => "Speakers Destination", 
			MixerLineComponentType.DestinationHeadphones => "Headphones Destination", 
			MixerLineComponentType.DestinationTelephone => "Telephone Destination", 
			MixerLineComponentType.DestinationWaveIn => "Wave Input Destination", 
			MixerLineComponentType.DestinationVoiceIn => "Voice Recognition Destination", 
			MixerLineComponentType.SourceUndefined => "Undefined Source", 
			MixerLineComponentType.SourceDigital => "Digital Source", 
			MixerLineComponentType.SourceLine => "Line Level Source", 
			MixerLineComponentType.SourceMicrophone => "Microphone Source", 
			MixerLineComponentType.SourceSynthesizer => "Synthesizer Source", 
			MixerLineComponentType.SourceCompactDisc => "Compact Disk Source", 
			MixerLineComponentType.SourceTelephone => "Telephone Source", 
			MixerLineComponentType.SourcePcSpeaker => "PC Speaker Source", 
			MixerLineComponentType.SourceWaveOut => "Wave Out Source", 
			MixerLineComponentType.SourceAuxiliary => "Auxiliary Source", 
			MixerLineComponentType.SourceAnalog => "Analog Source", 
			_ => "Invalid Component Type", 
		};

		/// <summary>
		/// Number of channels
		/// </summary>
		public int Channels => mixerLine.cChannels;

		/// <summary>
		/// Number of sources
		/// </summary>
		public int SourceCount => mixerLine.cConnections;

		/// <summary>
		/// Number of controls
		/// </summary>
		public int ControlsCount => mixerLine.cControls;

		/// <summary>
		/// Is this destination active
		/// </summary>
		public bool IsActive => (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_ACTIVE) != 0;

		/// <summary>
		/// Is this destination disconnected
		/// </summary>
		public bool IsDisconnected => (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_DISCONNECTED) != 0;

		/// <summary>
		/// Is this destination a source
		/// </summary>
		public bool IsSource => (mixerLine.fdwLine & MixerInterop.MIXERLINE_LINEF.MIXERLINE_LINEF_SOURCE) != 0;

		/// <summary>
		/// Enumerator for the controls on this Mixer Limne
		/// </summary>
		public IEnumerable<MixerControl> Controls => MixerControl.GetMixerControls(mixerHandle, this, mixerHandleType);

		/// <summary>
		/// Enumerator for the sources on this Mixer Line
		/// </summary>
		public IEnumerable<MixerLine> Sources
		{
			get
			{
				for (int source = 0; source < SourceCount; source++)
				{
					yield return GetSource(source);
				}
			}
		}

		/// <summary>
		/// The name of the target output device
		/// </summary>
		public string TargetName => mixerLine.szPname;

		/// <summary>
		/// Creates a new mixer destination
		/// </summary>
		/// <param name="mixerHandle">Mixer Handle</param>
		/// <param name="destinationIndex">Destination Index</param>
		/// <param name="mixerHandleType">Mixer Handle Type</param>
		public MixerLine(IntPtr mixerHandle, int destinationIndex, MixerFlags mixerHandleType)
		{
			this.mixerHandle = mixerHandle;
			this.mixerHandleType = mixerHandleType;
			mixerLine = default(MixerInterop.MIXERLINE);
			mixerLine.cbStruct = Marshal.SizeOf(mixerLine);
			mixerLine.dwDestination = destinationIndex;
			MmException.Try(MixerInterop.mixerGetLineInfo(mixerHandle, ref mixerLine, mixerHandleType | MixerFlags.Mixer), "mixerGetLineInfo");
		}

		/// <summary>
		/// Creates a new Mixer Source For a Specified Source
		/// </summary>
		/// <param name="mixerHandle">Mixer Handle</param>
		/// <param name="destinationIndex">Destination Index</param>
		/// <param name="sourceIndex">Source Index</param>
		/// <param name="mixerHandleType">Flag indicating the meaning of mixerHandle</param>
		public MixerLine(IntPtr mixerHandle, int destinationIndex, int sourceIndex, MixerFlags mixerHandleType)
		{
			this.mixerHandle = mixerHandle;
			this.mixerHandleType = mixerHandleType;
			mixerLine = default(MixerInterop.MIXERLINE);
			mixerLine.cbStruct = Marshal.SizeOf(mixerLine);
			mixerLine.dwDestination = destinationIndex;
			mixerLine.dwSource = sourceIndex;
			MmException.Try(MixerInterop.mixerGetLineInfo(mixerHandle, ref mixerLine, mixerHandleType | MixerFlags.ListText), "mixerGetLineInfo");
		}

		/// <summary>
		/// Creates a new Mixer Source
		/// </summary>
		/// <param name="waveInDevice">Wave In Device</param>
		public static int GetMixerIdForWaveIn(int waveInDevice)
		{
			int mixerID = -1;
			MmException.Try(MixerInterop.mixerGetID((IntPtr)waveInDevice, out mixerID, MixerFlags.WaveIn), "mixerGetID");
			return mixerID;
		}

		/// <summary>
		/// Gets the specified source
		/// </summary>
		public MixerLine GetSource(int sourceIndex)
		{
			if (sourceIndex < 0 || sourceIndex >= SourceCount)
			{
				throw new ArgumentOutOfRangeException("sourceIndex");
			}
			return new MixerLine(mixerHandle, mixerLine.dwDestination, sourceIndex, mixerHandleType);
		}

		/// <summary>
		/// Describes this Mixer Line (for diagnostic purposes)
		/// </summary>
		public override string ToString()
		{
			return $"{Name} {TypeDescription} ({ControlsCount} controls, ID={mixerLine.dwLineID})";
		}
	}

	/// <summary>
	/// Mixer Line Component type enumeration
	/// </summary>
	public enum MixerLineComponentType
	{
		/// <summary>
		/// Audio line is a destination that cannot be defined by one of the standard component types. A mixer device is required to use this component type for line component types that have not been defined by Microsoft Corporation.
		/// MIXERLINE_COMPONENTTYPE_DST_UNDEFINED
		/// </summary>
		DestinationUndefined = 0,
		/// <summary>
		/// Audio line is a digital destination (for example, digital input to a DAT or CD audio device).
		/// MIXERLINE_COMPONENTTYPE_DST_DIGITAL 
		/// </summary>
		DestinationDigital = 1,
		/// <summary>
		/// Audio line is a line level destination (for example, line level input from a CD audio device) that will be the final recording source for the analog-to-digital converter (ADC). Because most audio cards for personal computers provide some sort of gain for the recording audio source line, the mixer device will use the MIXERLINE_COMPONENTTYPE_DST_WAVEIN type.
		/// MIXERLINE_COMPONENTTYPE_DST_LINE
		/// </summary>
		DestinationLine = 2,
		/// <summary>
		/// Audio line is a destination used for a monitor.
		/// MIXERLINE_COMPONENTTYPE_DST_MONITOR
		/// </summary>
		DestinationMonitor = 3,
		/// <summary>
		/// Audio line is an adjustable (gain and/or attenuation) destination intended to drive speakers. This is the typical component type for the audio output of audio cards for personal computers.
		/// MIXERLINE_COMPONENTTYPE_DST_SPEAKERS
		/// </summary>
		DestinationSpeakers = 4,
		/// <summary>
		/// Audio line is an adjustable (gain and/or attenuation) destination intended to drive headphones. Most audio cards use the same audio destination line for speakers and headphones, in which case the mixer device simply uses the MIXERLINE_COMPONENTTYPE_DST_SPEAKERS type.
		/// MIXERLINE_COMPONENTTYPE_DST_HEADPHONES
		/// </summary>
		DestinationHeadphones = 5,
		/// <summary>
		/// Audio line is a destination that will be routed to a telephone line.
		/// MIXERLINE_COMPONENTTYPE_DST_TELEPHONE
		/// </summary>
		DestinationTelephone = 6,
		/// <summary>
		/// Audio line is a destination that will be the final recording source for the waveform-audio input (ADC). This line typically provides some sort of gain or attenuation. This is the typical component type for the recording line of most audio cards for personal computers.
		/// MIXERLINE_COMPONENTTYPE_DST_WAVEIN
		/// </summary>
		DestinationWaveIn = 7,
		/// <summary>
		/// Audio line is a destination that will be the final recording source for voice input. This component type is exactly like MIXERLINE_COMPONENTTYPE_DST_WAVEIN but is intended specifically for settings used during voice recording/recognition. Support for this line is optional for a mixer device. Many mixer devices provide only MIXERLINE_COMPONENTTYPE_DST_WAVEIN.
		/// MIXERLINE_COMPONENTTYPE_DST_VOICEIN
		/// </summary>
		DestinationVoiceIn = 8,
		/// <summary>
		/// Audio line is a source that cannot be defined by one of the standard component types. A mixer device is required to use this component type for line component types that have not been defined by Microsoft Corporation.
		/// MIXERLINE_COMPONENTTYPE_SRC_UNDEFINED
		/// </summary>
		SourceUndefined = 4096,
		/// <summary>
		/// Audio line is a digital source (for example, digital output from a DAT or audio CD).
		/// MIXERLINE_COMPONENTTYPE_SRC_DIGITAL
		/// </summary>
		SourceDigital = 4097,
		/// <summary>
		/// Audio line is a line-level source (for example, line-level input from an external stereo) that can be used as an optional recording source. Because most audio cards for personal computers provide some sort of gain for the recording source line, the mixer device will use the MIXERLINE_COMPONENTTYPE_SRC_AUXILIARY type.
		/// MIXERLINE_COMPONENTTYPE_SRC_LINE
		/// </summary>
		SourceLine = 4098,
		/// <summary>
		/// Audio line is a microphone recording source. Most audio cards for personal computers provide at least two types of recording sources: an auxiliary audio line and microphone input. A microphone audio line typically provides some sort of gain. Audio cards that use a single input for use with a microphone or auxiliary audio line should use the MIXERLINE_COMPONENTTYPE_SRC_MICROPHONE component type.
		/// MIXERLINE_COMPONENTTYPE_SRC_MICROPHONE
		/// </summary>
		SourceMicrophone = 4099,
		/// <summary>
		/// Audio line is a source originating from the output of an internal synthesizer. Most audio cards for personal computers provide some sort of MIDI synthesizer (for example, an Adlib®-compatible or OPL/3 FM synthesizer).
		/// MIXERLINE_COMPONENTTYPE_SRC_SYNTHESIZER
		/// </summary>
		SourceSynthesizer = 4100,
		/// <summary>
		/// Audio line is a source originating from the output of an internal audio CD. This component type is provided for audio cards that provide an audio source line intended to be connected to an audio CD (or CD-ROM playing an audio CD).
		/// MIXERLINE_COMPONENTTYPE_SRC_COMPACTDISC
		/// </summary>
		SourceCompactDisc = 4101,
		/// <summary>
		/// Audio line is a source originating from an incoming telephone line.
		/// MIXERLINE_COMPONENTTYPE_SRC_TELEPHONE
		/// </summary>
		SourceTelephone = 4102,
		/// <summary>
		/// Audio line is a source originating from personal computer speaker. Several audio cards for personal computers provide the ability to mix what would typically be played on the internal speaker with the output of an audio card. Some audio cards support the ability to use this output as a recording source.
		/// MIXERLINE_COMPONENTTYPE_SRC_PCSPEAKER
		/// </summary>
		SourcePcSpeaker = 4103,
		/// <summary>
		/// Audio line is a source originating from the waveform-audio output digital-to-analog converter (DAC). Most audio cards for personal computers provide this component type as a source to the MIXERLINE_COMPONENTTYPE_DST_SPEAKERS destination. Some cards also allow this source to be routed to the MIXERLINE_COMPONENTTYPE_DST_WAVEIN destination.
		/// MIXERLINE_COMPONENTTYPE_SRC_WAVEOUT
		/// </summary>
		SourceWaveOut = 4104,
		/// <summary>
		/// Audio line is a source originating from the auxiliary audio line. This line type is intended as a source with gain or attenuation that can be routed to the MIXERLINE_COMPONENTTYPE_DST_SPEAKERS destination and/or recorded from the MIXERLINE_COMPONENTTYPE_DST_WAVEIN destination.
		/// MIXERLINE_COMPONENTTYPE_SRC_AUXILIARY
		/// </summary>
		SourceAuxiliary = 4105,
		/// <summary>
		/// Audio line is an analog source (for example, analog output from a video-cassette tape).
		/// MIXERLINE_COMPONENTTYPE_SRC_ANALOG
		/// </summary>
		SourceAnalog = 4106
	}

	/// <summary>
	/// Represents a signed mixer control
	/// </summary>
	public class SignedMixerControl : MixerControl
	{
		private MixerInterop.MIXERCONTROLDETAILS_SIGNED signedDetails;

		/// <summary>
		/// The value of the control
		/// </summary>
		public int Value
		{
			get
			{
				GetControlDetails();
				return signedDetails.lValue;
			}
			set
			{
				signedDetails.lValue = value;
				mixerControlDetails.paDetails = Marshal.AllocHGlobal(Marshal.SizeOf(signedDetails));
				Marshal.StructureToPtr(signedDetails, mixerControlDetails.paDetails, fDeleteOld: false);
				MmException.Try(MixerInterop.mixerSetControlDetails(mixerHandle, ref mixerControlDetails, MixerFlags.Mixer | mixerHandleType), "mixerSetControlDetails");
				Marshal.FreeHGlobal(mixerControlDetails.paDetails);
			}
		}

		/// <summary>
		/// Minimum value for this control
		/// </summary>
		public int MinValue => mixerControl.Bounds.minimum;

		/// <summary>
		/// Maximum value for this control
		/// </summary>
		public int MaxValue => mixerControl.Bounds.maximum;

		/// <summary>
		/// Value of the control represented as a percentage
		/// </summary>
		public double Percent
		{
			get
			{
				return 100.0 * (double)(Value - MinValue) / (double)(MaxValue - MinValue);
			}
			set
			{
				Value = (int)((double)MinValue + value / 100.0 * (double)(MaxValue - MinValue));
			}
		}

		internal SignedMixerControl(MixerInterop.MIXERCONTROL mixerControl, IntPtr mixerHandle, MixerFlags mixerHandleType, int nChannels)
		{
			base.mixerControl = mixerControl;
			base.mixerHandle = mixerHandle;
			base.mixerHandleType = mixerHandleType;
			base.nChannels = nChannels;
			mixerControlDetails = default(MixerInterop.MIXERCONTROLDETAILS);
			GetControlDetails();
		}

		/// <summary>
		/// Gets details for this contrl
		/// </summary>
		protected override void GetDetails(IntPtr pDetails)
		{
			signedDetails = Marshal.PtrToStructure<MixerInterop.MIXERCONTROLDETAILS_SIGNED>(mixerControlDetails.paDetails);
		}

		/// <summary>
		/// String Representation for debugging purposes
		/// </summary>
		/// <returns></returns>
		public override string ToString()
		{
			return $"{base.ToString()} {Percent}%";
		}
	}

	/// <summary>
	/// Represents an unsigned mixer control
	/// </summary>
	public class UnsignedMixerControl : MixerControl
	{
		private MixerInterop.MIXERCONTROLDETAILS_UNSIGNED[] unsignedDetails;

		/// <summary>
		/// The control value
		/// </summary>
		public uint Value
		{
			get
			{
				GetControlDetails();
				return unsignedDetails[0].dwValue;
			}
			set
			{
				int num = Marshal.SizeOf(unsignedDetails[0]);
				mixerControlDetails.paDetails = Marshal.AllocHGlobal(num * nChannels);
				for (int i = 0; i < nChannels; i++)
				{
					unsignedDetails[i].dwValue = value;
					long num2 = mixerControlDetails.paDetails.ToInt64() + num * i;
					Marshal.StructureToPtr(unsignedDetails[i], (IntPtr)num2, fDeleteOld: false);
				}
				MmException.Try(MixerInterop.mixerSetControlDetails(mixerHandle, ref mixerControlDetails, MixerFlags.Mixer | mixerHandleType), "mixerSetControlDetails");
				Marshal.FreeHGlobal(mixerControlDetails.paDetails);
			}
		}

		/// <summary>
		/// The control's minimum value
		/// </summary>
		public uint MinValue => (uint)mixerControl.Bounds.minimum;

		/// <summary>
		/// The control's maximum value
		/// </summary>
		public uint MaxValue => (uint)mixerControl.Bounds.maximum;

		/// <summary>
		/// Value of the control represented as a percentage
		/// </summary>
		public double Percent
		{
			get
			{
				return 100.0 * (double)(Value - MinValue) / (double)(MaxValue - MinValue);
			}
			set
			{
				Value = (uint)((double)MinValue + value / 100.0 * (double)(MaxValue - MinValue));
			}
		}

		internal UnsignedMixerControl(MixerInterop.MIXERCONTROL mixerControl, IntPtr mixerHandle, MixerFlags mixerHandleType, int nChannels)
		{
			base.mixerControl = mixerControl;
			base.mixerHandle = mixerHandle;
			base.mixerHandleType = mixerHandleType;
			base.nChannels = nChannels;
			mixerControlDetails = default(MixerInterop.MIXERCONTROLDETAILS);
			GetControlDetails();
		}

		/// <summary>
		/// Gets the details for this control
		/// </summary>
		protected override void GetDetails(IntPtr pDetails)
		{
			unsignedDetails = new MixerInterop.MIXERCONTROLDETAILS_UNSIGNED[nChannels];
			for (int i = 0; i < nChannels; i++)
			{
				unsignedDetails[i] = Marshal.PtrToStructure<MixerInterop.MIXERCONTROLDETAILS_UNSIGNED>(mixerControlDetails.paDetails);
			}
		}

		/// <summary>
		/// String Representation for debugging purposes
		/// </summary>
		public override string ToString()
		{
			return $"{base.ToString()} {Percent}%";
		}
	}
}

namespace NAudio.Wave
{
	using NAudio.Utils;
	using NAudio.Mixer;
	using NAudio.CoreAudioApi;
	using NAudio.Wave.Compression;
	
	internal enum AcmMetrics
	{
		/// <summary>ACM_METRIC_COUNT_DRIVERS</summary>
		CountDrivers = 1,
		/// <summary>ACM_METRIC_COUNT_CODECS</summary>
		CountCodecs = 2,
		/// <summary>ACM_METRIC_COUNT_CONVERTERS</summary>
		CountConverters = 3,
		/// <summary>ACM_METRIC_COUNT_FILTERS</summary>
		CountFilters = 4,
		/// <summary>ACM_METRIC_COUNT_DISABLED</summary>
		CountDisabled = 5,
		/// <summary>ACM_METRIC_COUNT_HARDWARE</summary>
		CountHardware = 6,
		/// <summary>ACM_METRIC_COUNT_LOCAL_DRIVERS</summary>
		CountLocalDrivers = 20,
		/// <summary>ACM_METRIC_COUNT_LOCAL_CODECS</summary>
		CountLocalCodecs = 21,
		/// <summary>ACM_METRIC_COUNT_LOCAL_CONVERTERS</summary>
		CountLocalConverters = 22,
		/// <summary>ACM_METRIC_COUNT_LOCAL_FILTERS</summary>
		CountLocalFilters = 23,
		/// <summary>ACM_METRIC_COUNT_LOCAL_DISABLED</summary>
		CountLocalDisabled = 24,
		/// <summary>ACM_METRIC_HARDWARE_WAVE_INPUT</summary>
		HardwareWaveInput = 30,
		/// <summary>ACM_METRIC_HARDWARE_WAVE_OUTPUT</summary>
		HardwareWaveOutput = 31,
		/// <summary>ACM_METRIC_MAX_SIZE_FORMAT</summary>
		MaxSizeFormat = 50,
		/// <summary>ACM_METRIC_MAX_SIZE_FILTER</summary>
		MaxSizeFilter = 51,
		/// <summary>ACM_METRIC_DRIVER_SUPPORT</summary>
		DriverSupport = 100,
		/// <summary>ACM_METRIC_DRIVER_PRIORITY</summary>
		DriverPriority = 101
	}

	/// <summary>
	/// MP3 Frame Decompressor using ACM
	/// </summary>
	public class AcmMp3FrameDecompressor : IMp3FrameDecompressor, IDisposable
	{
		private readonly AcmStream conversionStream;

		private readonly WaveFormat pcmFormat;

		private bool disposed;

		/// <summary>
		/// Output format (PCM)
		/// </summary>
		public WaveFormat OutputFormat => pcmFormat;

		/// <summary>
		/// Creates a new ACM frame decompressor
		/// </summary>
		/// <param name="sourceFormat">The MP3 source format</param>
		public AcmMp3FrameDecompressor(WaveFormat sourceFormat)
		{
			pcmFormat = AcmStream.SuggestPcmFormat(sourceFormat);
			try
			{
				conversionStream = new AcmStream(sourceFormat, pcmFormat);
			}
			catch (Exception)
			{
				disposed = true;
				GC.SuppressFinalize(this);
				throw;
			}
		}

		/// <summary>
		/// Decompresses a frame
		/// </summary>
		/// <param name="frame">The MP3 frame</param>
		/// <param name="dest">destination buffer</param>
		/// <param name="destOffset">Offset within destination buffer</param>
		/// <returns>Bytes written into destination buffer</returns>
		public int DecompressFrame(Mp3Frame frame, byte[] dest, int destOffset)
		{
			if (frame == null)
			{
				throw new ArgumentNullException("frame", "You must provide a non-null Mp3Frame to decompress");
			}
			Array.Copy(frame.RawData, conversionStream.SourceBuffer, frame.FrameLength);
			int sourceBytesConverted;
			int num = conversionStream.Convert(frame.FrameLength, out sourceBytesConverted);
			if (sourceBytesConverted != frame.FrameLength)
			{
				throw new InvalidOperationException($"Couldn't convert the whole MP3 frame (converted {sourceBytesConverted}/{frame.FrameLength})");
			}
			Array.Copy(conversionStream.DestBuffer, 0, dest, destOffset, num);
			return num;
		}

		/// <summary>
		/// Resets the MP3 Frame Decompressor after a reposition operation
		/// </summary>
		public void Reset()
		{
			conversionStream.Reposition();
		}

		/// <summary>
		/// Disposes of this MP3 frame decompressor
		/// </summary>
		public void Dispose()
		{
			if (!disposed)
			{
				disposed = true;
				if (conversionStream != null)
				{
					conversionStream.Dispose();
				}
				GC.SuppressFinalize(this);
			}
		}

		/// <summary>
		/// Finalizer ensuring that resources get released properly
		/// </summary>
		~AcmMp3FrameDecompressor()
		{
			Dispose();
		}
	}

	[Flags]
	internal enum AcmStreamConvertFlags
	{
		/// <summary>
		/// ACM_STREAMCONVERTF_BLOCKALIGN
		/// </summary>
		BlockAlign = 4,
		/// <summary>
		/// ACM_STREAMCONVERTF_START
		/// </summary>
		Start = 0x10,
		/// <summary>
		/// ACM_STREAMCONVERTF_END
		/// </summary>
		End = 0x20
	}

	/// <summary>
	/// MmTime
	/// http://msdn.microsoft.com/en-us/library/dd757347(v=VS.85).aspx
	/// </summary>
	[StructLayout(LayoutKind.Explicit)]
	public struct MmTime
	{
		public const int TIME_MS = 1;

		public const int TIME_SAMPLES = 2;

		public const int TIME_BYTES = 4;

		[FieldOffset(0)]
		public uint wType;

		[FieldOffset(4)]
		public uint ms;

		[FieldOffset(4)]
		public uint sample;

		[FieldOffset(4)]
		public uint cb;

		[FieldOffset(4)]
		public uint ticks;

		[FieldOffset(4)]
		public byte smpteHour;

		[FieldOffset(5)]
		public byte smpteMin;

		[FieldOffset(6)]
		public byte smpteSec;

		[FieldOffset(7)]
		public byte smpteFrame;

		[FieldOffset(8)]
		public byte smpteFps;

		[FieldOffset(9)]
		public byte smpteDummy;

		[FieldOffset(10)]
		public byte smptePad0;

		[FieldOffset(11)]
		public byte smptePad1;

		[FieldOffset(4)]
		public uint midiSongPtrPos;
	}

	/// <summary>
	/// Supported wave formats for WaveOutCapabilities
	/// </summary>
	[Flags]
	public enum SupportedWaveFormat
	{
		/// <summary>
		/// 11.025 kHz, Mono,   8-bit
		/// </summary>
		WAVE_FORMAT_1M08 = 1,
		/// <summary>
		/// 11.025 kHz, Stereo, 8-bit
		/// </summary>
		WAVE_FORMAT_1S08 = 2,
		/// <summary>
		/// 11.025 kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_1M16 = 4,
		/// <summary>
		/// 11.025 kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_1S16 = 8,
		/// <summary>
		/// 22.05  kHz, Mono,   8-bit
		/// </summary>
		WAVE_FORMAT_2M08 = 0x10,
		/// <summary>
		/// 22.05  kHz, Stereo, 8-bit 
		/// </summary>
		WAVE_FORMAT_2S08 = 0x20,
		/// <summary>
		/// 22.05  kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_2M16 = 0x40,
		/// <summary>
		/// 22.05  kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_2S16 = 0x80,
		/// <summary>
		/// 44.1   kHz, Mono,   8-bit 
		/// </summary>
		WAVE_FORMAT_4M08 = 0x100,
		/// <summary>
		/// 44.1   kHz, Stereo, 8-bit 
		/// </summary>
		WAVE_FORMAT_4S08 = 0x200,
		/// <summary>
		/// 44.1   kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_4M16 = 0x400,
		/// <summary>
		///  44.1   kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_4S16 = 0x800,
		/// <summary>
		/// 44.1   kHz, Mono,   8-bit 
		/// </summary>
		WAVE_FORMAT_44M08 = 0x100,
		/// <summary>
		/// 44.1   kHz, Stereo, 8-bit 
		/// </summary>
		WAVE_FORMAT_44S08 = 0x200,
		/// <summary>
		/// 44.1   kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_44M16 = 0x400,
		/// <summary>
		/// 44.1   kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_44S16 = 0x800,
		/// <summary>
		/// 48     kHz, Mono,   8-bit 
		/// </summary>
		WAVE_FORMAT_48M08 = 0x1000,
		/// <summary>
		///  48     kHz, Stereo, 8-bit
		/// </summary>
		WAVE_FORMAT_48S08 = 0x2000,
		/// <summary>
		/// 48     kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_48M16 = 0x4000,
		/// <summary>
		/// 48     kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_48S16 = 0x8000,
		/// <summary>
		/// 96     kHz, Mono,   8-bit 
		/// </summary>
		WAVE_FORMAT_96M08 = 0x10000,
		/// <summary>
		/// 96     kHz, Stereo, 8-bit
		/// </summary>
		WAVE_FORMAT_96S08 = 0x20000,
		/// <summary>
		/// 96     kHz, Mono,   16-bit
		/// </summary>
		WAVE_FORMAT_96M16 = 0x40000,
		/// <summary>
		/// 96     kHz, Stereo, 16-bit
		/// </summary>
		WAVE_FORMAT_96S16 = 0x80000
	}

	/// <summary>
	/// Wave Callback Strategy
	/// </summary>
	public enum WaveCallbackStrategy
	{
		/// <summary>
		/// Use a function
		/// </summary>
		FunctionCallback,
		/// <summary>
		/// Create a new window (should only be done if on GUI thread)
		/// </summary>
		NewWindow,
		/// <summary>
		/// Use an existing window handle
		/// </summary>
		ExistingWindow,
		/// <summary>
		/// Use an event handle
		/// </summary>
		Event
	}

	public static class WaveCapabilitiesHelpers
	{
		public static readonly Guid MicrosoftDefaultManufacturerId = new Guid("d5a47fa8-6d98-11d1-a21a-00a0c9223196");

		public static readonly Guid DefaultWaveOutGuid = new Guid("E36DC310-6D9A-11D1-A21A-00A0C9223196");

		public static readonly Guid DefaultWaveInGuid = new Guid("E36DC311-6D9A-11D1-A21A-00A0C9223196");

		/// <summary>
		/// The device name from the registry if supported
		/// </summary>
		public static string GetNameFromGuid(Guid guid)
		{
			string result = null;
			using (RegistryKey registryKey = Registry.LocalMachine.OpenSubKey("System\\CurrentControlSet\\Control\\MediaCategories"))
			{
				using RegistryKey registryKey2 = registryKey.OpenSubKey(guid.ToString("B"));
				if (registryKey2 != null)
				{
					result = registryKey2.GetValue("Name") as string;
				}
			}
			return result;
		}
	}

	/// <summary>
	/// IWaveProvider that passes through an ACM Codec
	/// </summary>
	public class WaveFormatConversionProvider : IWaveProvider, IDisposable
	{
		private readonly AcmStream conversionStream;

		private readonly IWaveProvider sourceProvider;

		private readonly int preferredSourceReadSize;

		private int leftoverDestBytes;

		private int leftoverDestOffset;

		private int leftoverSourceBytes;

		private bool isDisposed;

		/// <summary>
		/// Gets the WaveFormat of this stream
		/// </summary>
		public WaveFormat WaveFormat { get; }

		/// <summary>
		/// Create a new WaveFormat conversion stream
		/// </summary>
		/// <param name="targetFormat">Desired output format</param>
		/// <param name="sourceProvider">Source Provider</param>
		public WaveFormatConversionProvider(WaveFormat targetFormat, IWaveProvider sourceProvider)
		{
			this.sourceProvider = sourceProvider;
			WaveFormat = targetFormat;
			conversionStream = new AcmStream(sourceProvider.WaveFormat, targetFormat);
			preferredSourceReadSize = Math.Min(sourceProvider.WaveFormat.AverageBytesPerSecond, conversionStream.SourceBuffer.Length);
			preferredSourceReadSize -= preferredSourceReadSize % sourceProvider.WaveFormat.BlockAlign;
		}

		/// <summary>
		/// Indicates that a reposition has taken place, and internal buffers should be reset
		/// </summary>
		public void Reposition()
		{
			leftoverDestBytes = 0;
			leftoverDestOffset = 0;
			leftoverSourceBytes = 0;
			conversionStream.Reposition();
		}

		/// <summary>
		/// Reads bytes from this stream
		/// </summary>
		/// <param name="buffer">Buffer to read into</param>
		/// <param name="offset">Offset in buffer to read into</param>
		/// <param name="count">Number of bytes to read</param>
		/// <returns>Number of bytes read</returns>
		public int Read(byte[] buffer, int offset, int count)
		{
			int i = 0;
			if (count % WaveFormat.BlockAlign != 0)
			{
				count -= count % WaveFormat.BlockAlign;
			}
			int num4;
			for (; i < count; i += num4)
			{
				int num = Math.Min(count - i, leftoverDestBytes);
				if (num > 0)
				{
					Array.Copy(conversionStream.DestBuffer, leftoverDestOffset, buffer, offset + i, num);
					leftoverDestOffset += num;
					leftoverDestBytes -= num;
					i += num;
				}
				if (i >= count)
				{
					break;
				}
				int count2 = Math.Min(preferredSourceReadSize, conversionStream.SourceBuffer.Length - leftoverSourceBytes);
				int num2 = sourceProvider.Read(conversionStream.SourceBuffer, leftoverSourceBytes, count2) + leftoverSourceBytes;
				if (num2 == 0)
				{
					break;
				}
				int sourceBytesConverted;
				int num3 = conversionStream.Convert(num2, out sourceBytesConverted);
				if (sourceBytesConverted == 0)
				{
					break;
				}
				leftoverSourceBytes = num2 - sourceBytesConverted;
				if (leftoverSourceBytes > 0)
				{
					Buffer.BlockCopy(conversionStream.SourceBuffer, sourceBytesConverted, conversionStream.SourceBuffer, 0, leftoverSourceBytes);
				}
				if (num3 <= 0)
				{
					break;
				}
				int val = count - i;
				num4 = Math.Min(num3, val);
				if (num4 < num3)
				{
					leftoverDestBytes = num3 - num4;
					leftoverDestOffset = num4;
				}
				Array.Copy(conversionStream.DestBuffer, 0, buffer, i + offset, num4);
			}
			return i;
		}

		/// <summary>
		/// Disposes this stream
		/// </summary>
		/// <param name="disposing">true if the user called this</param>
		protected virtual void Dispose(bool disposing)
		{
			if (!isDisposed)
			{
				isDisposed = true;
				conversionStream?.Dispose();
			}
		}

		/// <summary>
		/// Disposes this resource
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		/// <summary>
		/// Finalizer
		/// </summary>
		~WaveFormatConversionProvider()
		{
			Dispose(disposing: false);
		}
	}

	/// <summary>
	/// WaveStream that passes through an ACM Codec
	/// </summary>
	public class WaveFormatConversionStream : WaveStream
	{
		private readonly WaveFormatConversionProvider conversionProvider;

		private readonly WaveFormat targetFormat;

		private readonly long length;

		private long position;

		private readonly WaveStream sourceStream;

		private bool isDisposed;

		/// <summary>
		/// Gets or sets the current position in the stream
		/// </summary>
		public override long Position
		{
			get
			{
				return position;
			}
			set
			{
				value -= value % BlockAlign;
				long num = EstimateDestToSource(value);
				sourceStream.Position = num;
				position = EstimateSourceToDest(sourceStream.Position);
				conversionProvider.Reposition();
			}
		}

		/// <summary>
		/// Returns the stream length
		/// </summary>
		public override long Length => length;

		/// <summary>
		/// Gets the WaveFormat of this stream
		/// </summary>
		public override WaveFormat WaveFormat => targetFormat;

		/// <summary>
		/// Create a new WaveFormat conversion stream
		/// </summary>
		/// <param name="targetFormat">Desired output format</param>
		/// <param name="sourceStream">Source stream</param>
		public WaveFormatConversionStream(WaveFormat targetFormat, WaveStream sourceStream)
		{
			this.sourceStream = sourceStream;
			this.targetFormat = targetFormat;
			conversionProvider = new WaveFormatConversionProvider(targetFormat, sourceStream);
			length = EstimateSourceToDest((int)sourceStream.Length);
			position = 0L;
		}

		/// <summary>
		/// Creates a stream that can convert to PCM
		/// </summary>
		/// <param name="sourceStream">The source stream</param>
		/// <returns>A PCM stream</returns>
		public static WaveStream CreatePcmStream(WaveStream sourceStream)
		{
			if (sourceStream.WaveFormat.Encoding == WaveFormatEncoding.Pcm)
			{
				return sourceStream;
			}
			WaveFormat waveFormat = AcmStream.SuggestPcmFormat(sourceStream.WaveFormat);
			if (waveFormat.SampleRate < 8000)
			{
				if (sourceStream.WaveFormat.Encoding != WaveFormatEncoding.G723)
				{
					throw new InvalidOperationException("Invalid suggested output format, please explicitly provide a target format");
				}
				waveFormat = new WaveFormat(8000, 16, 1);
			}
			return new WaveFormatConversionStream(waveFormat, sourceStream);
		}

		/// <summary>
		/// Converts source bytes to destination bytes
		/// </summary>
		[Obsolete("can be unreliable, use of this method not encouraged")]
		public int SourceToDest(int source)
		{
			return (int)EstimateSourceToDest(source);
		}

		private long EstimateSourceToDest(long source)
		{
			long num = source * targetFormat.AverageBytesPerSecond / sourceStream.WaveFormat.AverageBytesPerSecond;
			return num - num % targetFormat.BlockAlign;
		}

		private long EstimateDestToSource(long dest)
		{
			long num = dest * sourceStream.WaveFormat.AverageBytesPerSecond / targetFormat.AverageBytesPerSecond;
			return (int)(num - num % sourceStream.WaveFormat.BlockAlign);
		}

		/// <summary>
		/// Converts destination bytes to source bytes
		/// </summary>
		[Obsolete("can be unreliable, use of this method not encouraged")]
		public int DestToSource(int dest)
		{
			return (int)EstimateDestToSource(dest);
		}

		/// <summary>
		///
		/// </summary>
		/// <param name="buffer">Buffer to read into</param>
		/// <param name="offset">Offset within buffer to write to</param>
		/// <param name="count">Number of bytes to read</param>
		/// <returns>Bytes read</returns>
		public override int Read(byte[] buffer, int offset, int count)
		{
			int num = conversionProvider.Read(buffer, offset, count);
			position += num;
			return num;
		}

		/// <summary>
		/// Disposes this stream
		/// </summary>
		/// <param name="disposing">true if the user called this</param>
		protected override void Dispose(bool disposing)
		{
			if (!isDisposed)
			{
				isDisposed = true;
				if (disposing)
				{
					sourceStream.Dispose();
					conversionProvider.Dispose();
				}
			}
			base.Dispose(disposing);
		}
	}

	/// <summary>
	/// WaveHeader interop structure (WAVEHDR)
	/// http://msdn.microsoft.com/en-us/library/dd743837%28VS.85%29.aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential)]
	public sealed class WaveHeader
	{
		/// <summary>pointer to locked data buffer (lpData)</summary>
		public IntPtr dataBuffer;

		/// <summary>length of data buffer (dwBufferLength)</summary>
		public int bufferLength;

		/// <summary>used for input only (dwBytesRecorded)</summary>
		public int bytesRecorded;

		/// <summary>for client's use (dwUser)</summary>
		public IntPtr userData;

		/// <summary>assorted flags (dwFlags)</summary>
		public WaveHeaderFlags flags;

		/// <summary>loop control counter (dwLoops)</summary>
		public int loops;

		/// <summary>PWaveHdr, reserved for driver (lpNext)</summary>
		public IntPtr next;

		/// <summary>reserved for driver</summary>
		public IntPtr reserved;
	}

	/// <summary>
	/// Wave Header Flags enumeration
	/// </summary>
	[Flags]
	public enum WaveHeaderFlags
	{
		/// <summary>
		/// WHDR_BEGINLOOP
		/// This buffer is the first buffer in a loop.  This flag is used only with output buffers.
		/// </summary>
		BeginLoop = 4,
		/// <summary>
		/// WHDR_DONE
		/// Set by the device driver to indicate that it is finished with the buffer and is returning it to the application.
		/// </summary>
		Done = 1,
		/// <summary>
		/// WHDR_ENDLOOP
		/// This buffer is the last buffer in a loop.  This flag is used only with output buffers.
		/// </summary>
		EndLoop = 8,
		/// <summary>
		/// WHDR_INQUEUE
		/// Set by Windows to indicate that the buffer is queued for playback.
		/// </summary>
		InQueue = 0x10,
		/// <summary>
		/// WHDR_PREPARED
		/// Set by Windows to indicate that the buffer has been prepared with the waveInPrepareHeader or waveOutPrepareHeader function.
		/// </summary>
		Prepared = 2
	}

	/// <summary>
	/// A buffer of Wave samples
	/// </summary>
	public class WaveInBuffer : IDisposable
	{
		private readonly WaveHeader header;

		private readonly int bufferSize;

		private readonly byte[] buffer;

		private GCHandle hBuffer;

		private IntPtr waveInHandle;

		private GCHandle hHeader;

		private GCHandle hThis;

		/// <summary>
		/// Provides access to the actual record buffer (for reading only)
		/// </summary>
		public byte[] Data => buffer;

		/// <summary>
		/// Indicates whether the Done flag is set on this buffer
		/// </summary>
		public bool Done => (header.flags & WaveHeaderFlags.Done) == WaveHeaderFlags.Done;

		/// <summary>
		/// Indicates whether the InQueue flag is set on this buffer
		/// </summary>
		public bool InQueue => (header.flags & WaveHeaderFlags.InQueue) == WaveHeaderFlags.InQueue;

		/// <summary>
		/// Number of bytes recorded
		/// </summary>
		public int BytesRecorded => header.bytesRecorded;

		/// <summary>
		/// The buffer size in bytes
		/// </summary>
		public int BufferSize => bufferSize;

		/// <summary>
		/// creates a new wavebuffer
		/// </summary>
		/// <param name="waveInHandle">WaveIn device to write to</param>
		/// <param name="bufferSize">Buffer size in bytes</param>
		public WaveInBuffer(IntPtr waveInHandle, int bufferSize)
		{
			this.bufferSize = bufferSize;
			buffer = new byte[bufferSize];
			hBuffer = GCHandle.Alloc(buffer, GCHandleType.Pinned);
			this.waveInHandle = waveInHandle;
			header = new WaveHeader();
			hHeader = GCHandle.Alloc(header, GCHandleType.Pinned);
			header.dataBuffer = hBuffer.AddrOfPinnedObject();
			header.bufferLength = bufferSize;
			header.loops = 1;
			hThis = GCHandle.Alloc(this);
			header.userData = (IntPtr)hThis;
			MmException.Try(WaveInterop.waveInPrepareHeader(waveInHandle, header, Marshal.SizeOf(header)), "waveInPrepareHeader");
		}

		/// <summary>
		/// Place this buffer back to record more audio
		/// </summary>
		public void Reuse()
		{
			MmException.Try(WaveInterop.waveInUnprepareHeader(waveInHandle, header, Marshal.SizeOf(header)), "waveUnprepareHeader");
			MmException.Try(WaveInterop.waveInPrepareHeader(waveInHandle, header, Marshal.SizeOf(header)), "waveInPrepareHeader");
			MmException.Try(WaveInterop.waveInAddBuffer(waveInHandle, header, Marshal.SizeOf(header)), "waveInAddBuffer");
		}

		/// <summary>
		/// Finalizer for this wave buffer
		/// </summary>
		~WaveInBuffer()
		{
			Dispose(disposing: false);
		}

		/// <summary>
		/// Releases resources held by this WaveBuffer
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		/// <summary>
		/// Releases resources held by this WaveBuffer
		/// </summary>
		protected void Dispose(bool disposing)
		{
			if (waveInHandle != IntPtr.Zero)
			{
				WaveInterop.waveInUnprepareHeader(waveInHandle, header, Marshal.SizeOf(header));
				waveInHandle = IntPtr.Zero;
			}
			if (hHeader.IsAllocated)
			{
				hHeader.Free();
			}
			if (hBuffer.IsAllocated)
			{
				hBuffer.Free();
			}
			if (hThis.IsAllocated)
			{
				hThis.Free();
			}
		}
	}

	/// <summary>
	/// WaveInCapabilities structure (based on WAVEINCAPS2 from mmsystem.h)
	/// http://msdn.microsoft.com/en-us/library/ms713726(VS.85).aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto)]
	public struct WaveInCapabilities
	{
		/// <summary>
		/// wMid
		/// </summary>
		private short manufacturerId;

		/// <summary>
		/// wPid
		/// </summary>
		private short productId;

		/// <summary>
		/// vDriverVersion
		/// </summary>
		private int driverVersion;

		/// <summary>
		/// Product Name (szPname)
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		private string productName;

		/// <summary>
		/// Supported formats (bit flags) dwFormats 
		/// </summary>
		private SupportedWaveFormat supportedFormats;

		/// <summary>
		/// Supported channels (1 for mono 2 for stereo) (wChannels)
		/// Seems to be set to -1 on a lot of devices
		/// </summary>
		private short channels;

		/// <summary>
		/// wReserved1
		/// </summary>
		private short reserved;

		private Guid manufacturerGuid;

		private Guid productGuid;

		private Guid nameGuid;

		private const int MaxProductNameLength = 32;

		/// <summary>
		/// Number of channels supported
		/// </summary>
		public int Channels => channels;

		/// <summary>
		/// The product name
		/// </summary>
		public string ProductName => productName;

		/// <summary>
		/// The device name Guid (if provided)
		/// </summary>
		public Guid NameGuid => nameGuid;

		/// <summary>
		/// The product name Guid (if provided)
		/// </summary>
		public Guid ProductGuid => productGuid;

		/// <summary>
		/// The manufacturer guid (if provided)
		/// </summary>
		public Guid ManufacturerGuid => manufacturerGuid;

		/// <summary>
		/// Checks to see if a given SupportedWaveFormat is supported
		/// </summary>
		/// <param name="waveFormat">The SupportedWaveFormat</param>
		/// <returns>true if supported</returns>
		public bool SupportsWaveFormat(SupportedWaveFormat waveFormat)
		{
			return (supportedFormats & waveFormat) == waveFormat;
		}
	}

	/// <summary>
	/// Recording using waveIn api with event callbacks.
	/// Use this for recording in non-gui applications
	/// Events are raised as recorded buffers are made available
	/// </summary>
	public class WaveInEvent : IWaveIn, IDisposable
	{
		private readonly AutoResetEvent callbackEvent;

		private readonly SynchronizationContext syncContext;

		private IntPtr waveInHandle;

		private volatile CaptureState captureState;

		private WaveInBuffer[] buffers;

		/// <summary>
		/// Returns the number of Wave In devices available in the system
		/// </summary>
		public static int DeviceCount => WaveInterop.waveInGetNumDevs();

		/// <summary>
		/// Milliseconds for the buffer. Recommended value is 100ms
		/// </summary>
		public int BufferMilliseconds { get; set; }

		/// <summary>
		/// Number of Buffers to use (usually 2 or 3)
		/// </summary>
		public int NumberOfBuffers { get; set; }

		/// <summary>
		/// The device number to use
		/// </summary>
		public int DeviceNumber { get; set; }

		/// <summary>
		/// WaveFormat we are recording in
		/// </summary>
		public WaveFormat WaveFormat { get; set; }

		/// <summary>
		/// Indicates recorded data is available 
		/// </summary>
		public event EventHandler<WaveInEventArgs> DataAvailable;

		/// <summary>
		/// Indicates that all recorded data has now been received.
		/// </summary>
		public event EventHandler<StoppedEventArgs> RecordingStopped;

		/// <summary>
		/// Prepares a Wave input device for recording
		/// </summary>
		public WaveInEvent()
		{
			callbackEvent = new AutoResetEvent(initialState: false);
			syncContext = SynchronizationContext.Current;
			DeviceNumber = 0;
			WaveFormat = new WaveFormat(8000, 16, 1);
			BufferMilliseconds = 100;
			NumberOfBuffers = 3;
			captureState = CaptureState.Stopped;
		}

		/// <summary>
		/// Retrieves the capabilities of a waveIn device
		/// </summary>
		/// <param name="devNumber">Device to test</param>
		/// <returns>The WaveIn device capabilities</returns>
		public static WaveInCapabilities GetCapabilities(int devNumber)
		{
			WaveInCapabilities waveInCaps = default(WaveInCapabilities);
			int waveInCapsSize = Marshal.SizeOf(waveInCaps);
			MmException.Try(WaveInterop.waveInGetDevCaps((IntPtr)devNumber, out waveInCaps, waveInCapsSize), "waveInGetDevCaps");
			return waveInCaps;
		}

		private void CreateBuffers()
		{
			int num = BufferMilliseconds * WaveFormat.AverageBytesPerSecond / 1000;
			if (num % WaveFormat.BlockAlign != 0)
			{
				num -= num % WaveFormat.BlockAlign;
			}
			buffers = new WaveInBuffer[NumberOfBuffers];
			for (int i = 0; i < buffers.Length; i++)
			{
				buffers[i] = new WaveInBuffer(waveInHandle, num);
			}
		}

		private void OpenWaveInDevice()
		{
			CloseWaveInDevice();
			MmException.Try(WaveInterop.waveInOpenWindow(out waveInHandle, (IntPtr)DeviceNumber, WaveFormat, callbackEvent.SafeWaitHandle.DangerousGetHandle(), IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackEvent), "waveInOpen");
			CreateBuffers();
		}

		/// <summary>
		/// Start recording
		/// </summary>
		public void StartRecording()
		{
			if (captureState != 0)
			{
				throw new InvalidOperationException("Already recording");
			}
			OpenWaveInDevice();
			MmException.Try(WaveInterop.waveInStart(waveInHandle), "waveInStart");
			captureState = CaptureState.Starting;
			ThreadPool.QueueUserWorkItem(delegate
			{
				RecordThread();
			}, null);
		}

		private void RecordThread()
		{
			Exception e = null;
			try
			{
				DoRecording();
			}
			catch (Exception ex)
			{
				e = ex;
			}
			finally
			{
				captureState = CaptureState.Stopped;
				RaiseRecordingStoppedEvent(e);
			}
		}

		private void DoRecording()
		{
			captureState = CaptureState.Capturing;
			WaveInBuffer[] array = buffers;
			foreach (WaveInBuffer waveInBuffer in array)
			{
				if (!waveInBuffer.InQueue)
				{
					waveInBuffer.Reuse();
				}
			}
			while (captureState == CaptureState.Capturing)
			{
				if (!callbackEvent.WaitOne())
				{
					continue;
				}
				array = buffers;
				foreach (WaveInBuffer waveInBuffer2 in array)
				{
					if (waveInBuffer2.Done)
					{
						if (waveInBuffer2.BytesRecorded > 0)
						{
							this.DataAvailable?.Invoke(this, new WaveInEventArgs(waveInBuffer2.Data, waveInBuffer2.BytesRecorded));
						}
						if (captureState == CaptureState.Capturing)
						{
							waveInBuffer2.Reuse();
						}
					}
				}
			}
		}

		private void RaiseRecordingStoppedEvent(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.RecordingStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		/// <summary>
		/// Stop recording
		/// </summary>
		public void StopRecording()
		{
			if (captureState != 0)
			{
				captureState = CaptureState.Stopping;
				MmException.Try(WaveInterop.waveInStop(waveInHandle), "waveInStop");
				MmException.Try(WaveInterop.waveInReset(waveInHandle), "waveInReset");
				callbackEvent.Set();
			}
		}

		/// <summary>
		/// Gets the current position in bytes from the wave input device.
		/// it calls directly into waveInGetPosition)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			MmTime mmTime = default(MmTime);
			mmTime.wType = 4u;
			MmException.Try(WaveInterop.waveInGetPosition(waveInHandle, out mmTime, Marshal.SizeOf(mmTime)), "waveInGetPosition");
			if (mmTime.wType != 4)
			{
				throw new Exception($"waveInGetPosition: wType -> Expected {4}, Received {mmTime.wType}");
			}
			return mmTime.cb;
		}

		/// <summary>
		/// Dispose pattern
		/// </summary>
		protected virtual void Dispose(bool disposing)
		{
			if (disposing)
			{
				if (captureState != 0)
				{
					StopRecording();
				}
				CloseWaveInDevice();
			}
		}

		private void CloseWaveInDevice()
		{
			WaveInterop.waveInReset(waveInHandle);
			if (buffers != null)
			{
				for (int i = 0; i < buffers.Length; i++)
				{
					buffers[i].Dispose();
				}
				buffers = null;
			}
			WaveInterop.waveInClose(waveInHandle);
			waveInHandle = IntPtr.Zero;
		}

		/// <summary>
		/// Microphone Level
		/// </summary>
		public MixerLine GetMixerLine()
		{
			if (waveInHandle != IntPtr.Zero)
			{
				return new MixerLine(waveInHandle, 0, MixerFlags.WaveInHandle);
			}
			return new MixerLine((IntPtr)DeviceNumber, 0, MixerFlags.WaveIn);
		}

		/// <summary>
		/// Dispose method
		/// </summary>
		public void Dispose()
		{
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}
	}

	/// <summary>
	/// MME Wave function interop
	/// </summary>
	public class WaveInterop
	{
		[Flags]
		public enum WaveInOutOpenFlags
		{
			/// <summary>
			/// CALLBACK_NULL
			/// No callback
			/// </summary>
			CallbackNull = 0,
			/// <summary>
			/// CALLBACK_FUNCTION
			/// dwCallback is a FARPROC 
			/// </summary>
			CallbackFunction = 0x30000,
			/// <summary>
			/// CALLBACK_EVENT
			/// dwCallback is an EVENT handle 
			/// </summary>
			CallbackEvent = 0x50000,
			/// <summary>
			/// CALLBACK_WINDOW
			/// dwCallback is a HWND 
			/// </summary>
			CallbackWindow = 0x10000,
			/// <summary>
			/// CALLBACK_THREAD
			/// callback is a thread ID 
			/// </summary>
			CallbackThread = 0x20000
		}

		public enum WaveMessage
		{
			/// <summary>
			/// WIM_OPEN
			/// </summary>
			WaveInOpen = 958,
			/// <summary>
			/// WIM_CLOSE
			/// </summary>
			WaveInClose = 959,
			/// <summary>
			/// WIM_DATA
			/// </summary>
			WaveInData = 960,
			/// <summary>
			/// WOM_CLOSE
			/// </summary>
			WaveOutClose = 956,
			/// <summary>
			/// WOM_DONE
			/// </summary>
			WaveOutDone = 957,
			/// <summary>
			/// WOM_OPEN
			/// </summary>
			WaveOutOpen = 955
		}

		public delegate void WaveCallback(IntPtr hWaveOut, WaveMessage message, IntPtr dwInstance, WaveHeader wavhdr, IntPtr dwReserved);

		[DllImport("winmm.dll")]
		public static extern int mmioStringToFOURCC([MarshalAs(UnmanagedType.LPStr)] string s, int flags);

		[DllImport("winmm.dll")]
		public static extern int waveOutGetNumDevs();

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutPrepareHeader(IntPtr hWaveOut, WaveHeader lpWaveOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutUnprepareHeader(IntPtr hWaveOut, WaveHeader lpWaveOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutWrite(IntPtr hWaveOut, WaveHeader lpWaveOutHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutOpen(out IntPtr hWaveOut, IntPtr uDeviceID, WaveFormat lpFormat, WaveCallback dwCallback, IntPtr dwInstance, WaveInOutOpenFlags dwFlags);

		[DllImport("winmm.dll", EntryPoint = "waveOutOpen")]
		public static extern MmResult waveOutOpenWindow(out IntPtr hWaveOut, IntPtr uDeviceID, WaveFormat lpFormat, IntPtr callbackWindowHandle, IntPtr dwInstance, WaveInOutOpenFlags dwFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutReset(IntPtr hWaveOut);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutClose(IntPtr hWaveOut);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutPause(IntPtr hWaveOut);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutRestart(IntPtr hWaveOut);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutGetPosition(IntPtr hWaveOut, ref MmTime mmTime, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutSetVolume(IntPtr hWaveOut, int dwVolume);

		[DllImport("winmm.dll")]
		public static extern MmResult waveOutGetVolume(IntPtr hWaveOut, out int dwVolume);

		[DllImport("winmm.dll", CharSet = CharSet.Auto)]
		public static extern MmResult waveOutGetDevCaps(IntPtr deviceID, out WaveOutCapabilities waveOutCaps, int waveOutCapsSize);

		[DllImport("winmm.dll")]
		public static extern int waveInGetNumDevs();

		[DllImport("winmm.dll", CharSet = CharSet.Auto)]
		public static extern MmResult waveInGetDevCaps(IntPtr deviceID, out WaveInCapabilities waveInCaps, int waveInCapsSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInAddBuffer(IntPtr hWaveIn, WaveHeader pwh, int cbwh);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInClose(IntPtr hWaveIn);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInOpen(out IntPtr hWaveIn, IntPtr uDeviceID, WaveFormat lpFormat, WaveCallback dwCallback, IntPtr dwInstance, WaveInOutOpenFlags dwFlags);

		[DllImport("winmm.dll", EntryPoint = "waveInOpen")]
		public static extern MmResult waveInOpenWindow(out IntPtr hWaveIn, IntPtr uDeviceID, WaveFormat lpFormat, IntPtr callbackWindowHandle, IntPtr dwInstance, WaveInOutOpenFlags dwFlags);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInPrepareHeader(IntPtr hWaveIn, WaveHeader lpWaveInHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInUnprepareHeader(IntPtr hWaveIn, WaveHeader lpWaveInHdr, int uSize);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInReset(IntPtr hWaveIn);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInStart(IntPtr hWaveIn);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInStop(IntPtr hWaveIn);

		[DllImport("winmm.dll")]
		public static extern MmResult waveInGetPosition(IntPtr hWaveIn, out MmTime mmTime, int uSize);
	}

	/// <summary>
	/// A buffer of Wave samples for streaming to a Wave Output device
	/// </summary>
	public class WaveOutBuffer : IDisposable
	{
		private readonly WaveHeader header;

		private readonly int bufferSize;

		private readonly byte[] buffer;

		private readonly IWaveProvider waveStream;

		private readonly object waveOutLock;

		private GCHandle hBuffer;

		private IntPtr hWaveOut;

		private GCHandle hHeader;

		private GCHandle hThis;

		/// <summary>
		/// Whether the header's in queue flag is set
		/// </summary>
		public bool InQueue => (header.flags & WaveHeaderFlags.InQueue) == WaveHeaderFlags.InQueue;

		/// <summary>
		/// The buffer size in bytes
		/// </summary>
		public int BufferSize => bufferSize;

		/// <summary>
		/// creates a new wavebuffer
		/// </summary>
		/// <param name="hWaveOut">WaveOut device to write to</param>
		/// <param name="bufferSize">Buffer size in bytes</param>
		/// <param name="bufferFillStream">Stream to provide more data</param>
		/// <param name="waveOutLock">Lock to protect WaveOut API's from being called on &gt;1 thread</param>
		public WaveOutBuffer(IntPtr hWaveOut, int bufferSize, IWaveProvider bufferFillStream, object waveOutLock)
		{
			this.bufferSize = bufferSize;
			buffer = new byte[bufferSize];
			hBuffer = GCHandle.Alloc(buffer, GCHandleType.Pinned);
			this.hWaveOut = hWaveOut;
			waveStream = bufferFillStream;
			this.waveOutLock = waveOutLock;
			header = new WaveHeader();
			hHeader = GCHandle.Alloc(header, GCHandleType.Pinned);
			header.dataBuffer = hBuffer.AddrOfPinnedObject();
			header.bufferLength = bufferSize;
			header.loops = 1;
			hThis = GCHandle.Alloc(this);
			header.userData = (IntPtr)hThis;
			lock (waveOutLock)
			{
				MmException.Try(WaveInterop.waveOutPrepareHeader(hWaveOut, header, Marshal.SizeOf(header)), "waveOutPrepareHeader");
			}
		}

		/// <summary>
		/// Finalizer for this wave buffer
		/// </summary>
		~WaveOutBuffer()
		{
			Dispose(disposing: false);
		}

		/// <summary>
		/// Releases resources held by this WaveBuffer
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		/// <summary>
		/// Releases resources held by this WaveBuffer
		/// </summary>
		protected void Dispose(bool disposing)
		{
			if (hHeader.IsAllocated)
			{
				hHeader.Free();
			}
			if (hBuffer.IsAllocated)
			{
				hBuffer.Free();
			}
			if (hThis.IsAllocated)
			{
				hThis.Free();
			}
			if (hWaveOut != IntPtr.Zero)
			{
				lock (waveOutLock)
				{
					WaveInterop.waveOutUnprepareHeader(hWaveOut, header, Marshal.SizeOf(header));
				}
				hWaveOut = IntPtr.Zero;
			}
		}

		/// this is called by the WAVE callback and should be used to refill the buffer
		public bool OnDone()
		{
			int num;
			lock (waveStream)
			{
				num = waveStream.Read(buffer, 0, buffer.Length);
			}
			if (num == 0)
			{
				return false;
			}
			for (int i = num; i < buffer.Length; i++)
			{
				buffer[i] = 0;
			}
			WriteToWaveOut();
			return true;
		}

		private void WriteToWaveOut()
		{
			MmResult mmResult;
			lock (waveOutLock)
			{
				mmResult = WaveInterop.waveOutWrite(hWaveOut, header, Marshal.SizeOf(header));
			}
			if (mmResult != 0)
			{
				throw new MmException(mmResult, "waveOutWrite");
			}
			GC.KeepAlive(this);
		}
	}

	/// <summary>
	/// WaveOutCapabilities structure (based on WAVEOUTCAPS2 from mmsystem.h)
	/// http://msdn.microsoft.com/library/default.asp?url=/library/en-us/multimed/htm/_win32_waveoutcaps_str.asp
	/// </summary>
	[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto)]
	public struct WaveOutCapabilities
	{
		/// <summary>
		/// wMid
		/// </summary>
		private short manufacturerId;

		/// <summary>
		/// wPid
		/// </summary>
		private short productId;

		/// <summary>
		/// vDriverVersion
		/// </summary>
		private int driverVersion;

		/// <summary>
		/// Product Name (szPname)
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		private string productName;

		/// <summary>
		/// Supported formats (bit flags) dwFormats 
		/// </summary>
		private SupportedWaveFormat supportedFormats;

		/// <summary>
		/// Supported channels (1 for mono 2 for stereo) (wChannels)
		/// Seems to be set to -1 on a lot of devices
		/// </summary>
		private short channels;

		/// <summary>
		/// wReserved1
		/// </summary>
		private short reserved;

		/// <summary>
		/// Optional functionality supported by the device
		/// </summary>
		private WaveOutSupport support;

		private Guid manufacturerGuid;

		private Guid productGuid;

		private Guid nameGuid;

		private const int MaxProductNameLength = 32;

		/// <summary>
		/// Number of channels supported
		/// </summary>
		public int Channels => channels;

		/// <summary>
		/// Whether playback control is supported
		/// </summary>
		public bool SupportsPlaybackRateControl => (support & WaveOutSupport.PlaybackRate) == WaveOutSupport.PlaybackRate;

		/// <summary>
		/// The product name
		/// </summary>
		public string ProductName => productName;

		/// <summary>
		/// The device name Guid (if provided)
		/// </summary>
		public Guid NameGuid => nameGuid;

		/// <summary>
		/// The product name Guid (if provided)
		/// </summary>
		public Guid ProductGuid => productGuid;

		/// <summary>
		/// The manufacturer guid (if provided)
		/// </summary>
		public Guid ManufacturerGuid => manufacturerGuid;

		/// <summary>
		/// Checks to see if a given SupportedWaveFormat is supported
		/// </summary>
		/// <param name="waveFormat">The SupportedWaveFormat</param>
		/// <returns>true if supported</returns>
		public bool SupportsWaveFormat(SupportedWaveFormat waveFormat)
		{
			return (supportedFormats & waveFormat) == waveFormat;
		}
	}

	/// <summary>
	/// Alternative WaveOut class, making use of the Event callback
	/// </summary>
	public class WaveOutEvent : IWavePlayer, IDisposable, IWavePosition
	{
		private readonly object waveOutLock;

		private readonly SynchronizationContext syncContext;

		private IntPtr hWaveOut;

		private WaveOutBuffer[] buffers;

		private IWaveProvider waveStream;

		private volatile PlaybackState playbackState;

		private AutoResetEvent callbackEvent;

		/// <summary>
		/// Gets or sets the desired latency in milliseconds
		/// Should be set before a call to Init
		/// </summary>
		public int DesiredLatency { get; set; }

		/// <summary>
		/// Gets or sets the number of buffers used
		/// Should be set before a call to Init
		/// </summary>
		public int NumberOfBuffers { get; set; }

		/// <summary>
		/// Gets or sets the device number
		/// Should be set before a call to Init
		/// This must be between -1 and <see>DeviceCount</see> - 1.
		/// -1 means stick to default device even default device is changed
		/// </summary>
		public int DeviceNumber { get; set; } = -1;


		/// <summary>
		/// Gets a <see cref="T:NAudio.Wave.WaveFormat" /> instance indicating the format the hardware is using.
		/// </summary>
		public WaveFormat OutputWaveFormat => waveStream.WaveFormat;

		/// <summary>
		/// Playback State
		/// </summary>
		public PlaybackState PlaybackState => playbackState;

		/// <summary>
		/// Volume for this device 1.0 is full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return WaveOutUtils.GetWaveOutVolume(hWaveOut, waveOutLock);
			}
			set
			{
				WaveOutUtils.SetWaveOutVolume(value, hWaveOut, waveOutLock);
			}
		}

		/// <summary>
		/// Indicates playback has stopped automatically
		/// </summary>
		public event EventHandler<StoppedEventArgs> PlaybackStopped;

		/// <summary>
		/// Opens a WaveOut device
		/// </summary>
		public WaveOutEvent()
		{
			syncContext = SynchronizationContext.Current;
			if (syncContext != null && (syncContext.GetType().Name == "LegacyAspNetSynchronizationContext" || syncContext.GetType().Name == "AspNetSynchronizationContext"))
			{
				syncContext = null;
			}
			DesiredLatency = 300;
			NumberOfBuffers = 2;
			waveOutLock = new object();
		}

		/// <summary>
		/// Initialises the WaveOut device
		/// </summary>
		/// <param name="waveProvider">WaveProvider to play</param>
		public void Init(IWaveProvider waveProvider)
		{
			if (playbackState != 0)
			{
				throw new InvalidOperationException("Can't re-initialize during playback");
			}
			if (hWaveOut != IntPtr.Zero)
			{
				DisposeBuffers();
				CloseWaveOut();
			}
			callbackEvent = new AutoResetEvent(initialState: false);
			waveStream = waveProvider;
			int bufferSize = waveProvider.WaveFormat.ConvertLatencyToByteSize((DesiredLatency + NumberOfBuffers - 1) / NumberOfBuffers);
			MmResult result;
			lock (waveOutLock)
			{
				result = WaveInterop.waveOutOpenWindow(out hWaveOut, (IntPtr)DeviceNumber, waveStream.WaveFormat, callbackEvent.SafeWaitHandle.DangerousGetHandle(), IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackEvent);
			}
			MmException.Try(result, "waveOutOpen");
			buffers = new WaveOutBuffer[NumberOfBuffers];
			playbackState = PlaybackState.Stopped;
			for (int i = 0; i < NumberOfBuffers; i++)
			{
				buffers[i] = new WaveOutBuffer(hWaveOut, bufferSize, waveStream, waveOutLock);
			}
		}

		/// <summary>
		/// Start playing the audio from the WaveStream
		/// </summary>
		public void Play()
		{
			if (buffers == null || waveStream == null)
			{
				throw new InvalidOperationException("Must call Init first");
			}
			if (playbackState == PlaybackState.Stopped)
			{
				playbackState = PlaybackState.Playing;
				callbackEvent.Set();
				ThreadPool.QueueUserWorkItem(delegate
				{
					PlaybackThread();
				}, null);
			}
			else if (playbackState == PlaybackState.Paused)
			{
				Resume();
				callbackEvent.Set();
			}
		}

		private void PlaybackThread()
		{
			Exception e = null;
			try
			{
				DoPlayback();
			}
			catch (Exception ex)
			{
				e = ex;
			}
			finally
			{
				playbackState = PlaybackState.Stopped;
				RaisePlaybackStoppedEvent(e);
			}
		}

		private void DoPlayback()
		{
			while (playbackState != 0)
			{
				if (!callbackEvent.WaitOne(DesiredLatency))
				{
					_ = playbackState;
					_ = 1;
				}
				if (playbackState != PlaybackState.Playing)
				{
					continue;
				}
				int num = 0;
				WaveOutBuffer[] array = buffers;
				foreach (WaveOutBuffer waveOutBuffer in array)
				{
					if (waveOutBuffer.InQueue || waveOutBuffer.OnDone())
					{
						num++;
					}
				}
				if (num == 0)
				{
					playbackState = PlaybackState.Stopped;
					callbackEvent.Set();
				}
			}
		}

		/// <summary>
		/// Pause the audio
		/// </summary>
		public void Pause()
		{
			if (playbackState == PlaybackState.Playing)
			{
				playbackState = PlaybackState.Paused;
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutPause(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutPause");
				}
			}
		}

		/// <summary>
		/// Resume playing after a pause from the same position
		/// </summary>
		private void Resume()
		{
			if (playbackState == PlaybackState.Paused)
			{
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutRestart(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutRestart");
				}
				playbackState = PlaybackState.Playing;
			}
		}

		/// <summary>
		/// Stop and reset the WaveOut device
		/// </summary>
		public void Stop()
		{
			if (playbackState != 0)
			{
				playbackState = PlaybackState.Stopped;
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutReset(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutReset");
				}
				callbackEvent.Set();
			}
		}

		/// <summary>
		/// Gets the current position in bytes from the wave output device.
		/// (n.b. this is not the same thing as the position within your reader
		/// stream - it calls directly into waveOutGetPosition)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			return WaveOutUtils.GetPositionBytes(hWaveOut, waveOutLock);
		}

		/// <summary>
		/// Closes this WaveOut device
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		/// <summary>
		/// Closes the WaveOut device and disposes of buffers
		/// </summary>
		/// <param name="disposing">True if called from <see>Dispose</see></param>
		protected void Dispose(bool disposing)
		{
			Stop();
			if (disposing)
			{
				DisposeBuffers();
			}
			CloseWaveOut();
		}

		private void CloseWaveOut()
		{
			if (callbackEvent != null)
			{
				callbackEvent.Close();
				callbackEvent = null;
			}
			lock (waveOutLock)
			{
				if (hWaveOut != IntPtr.Zero)
				{
					WaveInterop.waveOutClose(hWaveOut);
					hWaveOut = IntPtr.Zero;
				}
			}
		}

		private void DisposeBuffers()
		{
			if (buffers != null)
			{
				WaveOutBuffer[] array = buffers;
				for (int i = 0; i < array.Length; i++)
				{
					array[i].Dispose();
				}
				buffers = null;
			}
		}

		/// <summary>
		/// Finalizer. Only called when user forgets to call <see>Dispose</see>
		/// </summary>
		~WaveOutEvent()
		{
			Dispose(disposing: false);
		}

		private void RaisePlaybackStoppedEvent(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.PlaybackStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}
	}

	/// <summary>
	/// Flags indicating what features this WaveOut device supports
	/// </summary>
	[Flags]
	internal enum WaveOutSupport
	{
		/// <summary>supports pitch control (WAVECAPS_PITCH)</summary>
		Pitch = 1,
		/// <summary>supports playback rate control (WAVECAPS_PLAYBACKRATE)</summary>
		PlaybackRate = 2,
		/// <summary>supports volume control (WAVECAPS_VOLUME)</summary>
		Volume = 4,
		/// <summary>supports separate left-right volume control (WAVECAPS_LRVOLUME)</summary>
		LRVolume = 8,
		/// <summary>(WAVECAPS_SYNC)</summary>
		Sync = 0x10,
		/// <summary>(WAVECAPS_SAMPLEACCURATE)</summary>
		SampleAccurate = 0x20
	}

	public static class WaveOutUtils
	{
		public static float GetWaveOutVolume(IntPtr hWaveOut, object lockObject)
		{
			MmResult result;
			int dwVolume;
			lock (lockObject)
			{
				result = WaveInterop.waveOutGetVolume(hWaveOut, out dwVolume);
			}
			MmException.Try(result, "waveOutGetVolume");
			return (float)(dwVolume & 0xFFFF) / 65535f;
		}

		public static void SetWaveOutVolume(float value, IntPtr hWaveOut, object lockObject)
		{
			if (value < 0f)
			{
				throw new ArgumentOutOfRangeException("value", "Volume must be between 0.0 and 1.0");
			}
			if (value > 1f)
			{
				throw new ArgumentOutOfRangeException("value", "Volume must be between 0.0 and 1.0");
			}
			int dwVolume = (int)(value * 65535f) + ((int)(value * 65535f) << 16);
			MmResult result;
			lock (lockObject)
			{
				result = WaveInterop.waveOutSetVolume(hWaveOut, dwVolume);
			}
			MmException.Try(result, "waveOutSetVolume");
		}

		public static long GetPositionBytes(IntPtr hWaveOut, object lockObject)
		{
			lock (lockObject)
			{
				MmTime mmTime = default(MmTime);
				mmTime.wType = 4u;
				MmException.Try(WaveInterop.waveOutGetPosition(hWaveOut, ref mmTime, Marshal.SizeOf(mmTime)), "waveOutGetPosition");
				if (mmTime.wType != 4)
				{
					throw new Exception($"waveOutGetPosition: wType -> Expected {4}, Received {mmTime.wType}");
				}
				return mmTime.cb;
			}
		}
	}
}

namespace NAudio.Wave.Compression
{
    using NAudio.Utils;

    /// <summary>
    /// Represents an installed ACM Driver
    /// </summary>
    public class AcmDriver : IDisposable
	{
		private static List<AcmDriver> drivers;

		private AcmDriverDetails details;

		private IntPtr driverId;

		private IntPtr driverHandle;

		private List<AcmFormatTag> formatTags;

		private List<AcmFormat> tempFormatsList;

		private IntPtr localDllHandle;

		/// <summary>
		/// Gets the maximum size needed to store a WaveFormat for ACM interop functions
		/// </summary>
		public int MaxFormatSize
		{
			get
			{
				MmException.Try(AcmInterop.acmMetrics(driverHandle, AcmMetrics.MaxSizeFormat, out var output), "acmMetrics");
				return output;
			}
		}

		/// <summary>
		/// The short name of this driver
		/// </summary>
		public string ShortName => details.shortName;

		/// <summary>
		/// The full name of this driver
		/// </summary>
		public string LongName => details.longName;

		/// <summary>
		/// The driver ID
		/// </summary>
		public IntPtr DriverId => driverId;

		/// <summary>
		/// The list of FormatTags for this ACM Driver
		/// </summary>
		public IEnumerable<AcmFormatTag> FormatTags
		{
			get
			{
				if (formatTags == null)
				{
					if (driverHandle == IntPtr.Zero)
					{
						throw new InvalidOperationException("Driver must be opened first");
					}
					formatTags = new List<AcmFormatTag>();
					AcmFormatTagDetails formatTagDetails = default(AcmFormatTagDetails);
					formatTagDetails.structureSize = Marshal.SizeOf(formatTagDetails);
					MmException.Try(AcmInterop.acmFormatTagEnum(driverHandle, ref formatTagDetails, AcmFormatTagEnumCallback, IntPtr.Zero, 0), "acmFormatTagEnum");
				}
				return formatTags;
			}
		}

		/// <summary>
		/// Helper function to determine whether a particular codec is installed
		/// </summary>
		/// <param name="shortName">The short name of the function</param>
		/// <returns>Whether the codec is installed</returns>
		public static bool IsCodecInstalled(string shortName)
		{
			foreach (AcmDriver item in EnumerateAcmDrivers())
			{
				if (item.ShortName == shortName)
				{
					return true;
				}
			}
			return false;
		}

		/// <summary>
		/// Attempts to add a new ACM driver from a file
		/// </summary>
		/// <param name="driverFile">Full path of the .acm or dll file containing the driver</param>
		/// <returns>Handle to the driver</returns>
		public static AcmDriver AddLocalDriver(string driverFile)
		{
			IntPtr intPtr = NativeMethods.LoadLibrary(driverFile);
			if (intPtr == IntPtr.Zero)
			{
				throw new ArgumentException("Failed to load driver file");
			}
			IntPtr procAddress = NativeMethods.GetProcAddress(intPtr, "DriverProc");
			if (procAddress == IntPtr.Zero)
			{
				NativeMethods.FreeLibrary(intPtr);
				throw new ArgumentException("Failed to discover DriverProc");
			}
			IntPtr hAcmDriver;
			MmResult mmResult = AcmInterop.acmDriverAdd(out hAcmDriver, intPtr, procAddress, 0, AcmDriverAddFlags.Function);
			if (mmResult != 0)
			{
				NativeMethods.FreeLibrary(intPtr);
				throw new MmException(mmResult, "acmDriverAdd");
			}
			AcmDriver acmDriver = new AcmDriver(hAcmDriver);
			if (string.IsNullOrEmpty(acmDriver.details.longName))
			{
				acmDriver.details.longName = "Local driver: " + Path.GetFileName(driverFile);
				acmDriver.localDllHandle = intPtr;
			}
			return acmDriver;
		}

		/// <summary>
		/// Removes a driver previously added using AddLocalDriver
		/// </summary>
		/// <param name="localDriver">Local driver to remove</param>
		public static void RemoveLocalDriver(AcmDriver localDriver)
		{
			if (localDriver.localDllHandle == IntPtr.Zero)
			{
				throw new ArgumentException("Please pass in the AcmDriver returned by the AddLocalDriver method");
			}
			MmResult result = AcmInterop.acmDriverRemove(localDriver.driverId, 0);
			NativeMethods.FreeLibrary(localDriver.localDllHandle);
			MmException.Try(result, "acmDriverRemove");
		}

		/// <summary>
		/// Show Format Choose Dialog
		/// </summary>
		/// <param name="ownerWindowHandle">Owner window handle, can be null</param>
		/// <param name="windowTitle">Window title</param>
		/// <param name="enumFlags">Enumeration flags. None to get everything</param>
		/// <param name="enumFormat">Enumeration format. Only needed with certain enumeration flags</param>
		/// <param name="selectedFormat">The selected format</param>
		/// <param name="selectedFormatDescription">Textual description of the selected format</param>
		/// <param name="selectedFormatTagDescription">Textual description of the selected format tag</param>
		/// <returns>True if a format was selected</returns>
		public static bool ShowFormatChooseDialog(IntPtr ownerWindowHandle, string windowTitle, AcmFormatEnumFlags enumFlags, WaveFormat enumFormat, out WaveFormat selectedFormat, out string selectedFormatDescription, out string selectedFormatTagDescription)
		{
			AcmFormatChoose formatChoose = default(AcmFormatChoose);
			formatChoose.structureSize = Marshal.SizeOf(formatChoose);
			formatChoose.styleFlags = AcmFormatChooseStyleFlags.None;
			formatChoose.ownerWindowHandle = ownerWindowHandle;
			int num = 200;
			formatChoose.selectedWaveFormatPointer = Marshal.AllocHGlobal(num);
			formatChoose.selectedWaveFormatByteSize = num;
			formatChoose.title = windowTitle;
			formatChoose.name = null;
			formatChoose.formatEnumFlags = enumFlags;
			formatChoose.waveFormatEnumPointer = IntPtr.Zero;
			if (enumFormat != null)
			{
				IntPtr intPtr = Marshal.AllocHGlobal(Marshal.SizeOf(enumFormat));
				Marshal.StructureToPtr(enumFormat, intPtr, fDeleteOld: false);
				formatChoose.waveFormatEnumPointer = intPtr;
			}
			formatChoose.instanceHandle = IntPtr.Zero;
			formatChoose.templateName = null;
			MmResult mmResult = AcmInterop.acmFormatChoose(ref formatChoose);
			selectedFormat = null;
			selectedFormatDescription = null;
			selectedFormatTagDescription = null;
			if (mmResult == MmResult.NoError)
			{
				selectedFormat = WaveFormat.MarshalFromPtr(formatChoose.selectedWaveFormatPointer);
				selectedFormatDescription = formatChoose.formatDescription;
				selectedFormatTagDescription = formatChoose.formatTagDescription;
			}
			Marshal.FreeHGlobal(formatChoose.waveFormatEnumPointer);
			Marshal.FreeHGlobal(formatChoose.selectedWaveFormatPointer);
			if (mmResult != MmResult.AcmCancelled && mmResult != 0)
			{
				throw new MmException(mmResult, "acmFormatChoose");
			}
			return mmResult == MmResult.NoError;
		}

		/// <summary>
		/// Finds a Driver by its short name
		/// </summary>
		/// <param name="shortName">Short Name</param>
		/// <returns>The driver, or null if not found</returns>
		public static AcmDriver FindByShortName(string shortName)
		{
			foreach (AcmDriver item in EnumerateAcmDrivers())
			{
				if (item.ShortName == shortName)
				{
					return item;
				}
			}
			return null;
		}

		/// <summary>
		/// Gets a list of the ACM Drivers installed
		/// </summary>
		public static IEnumerable<AcmDriver> EnumerateAcmDrivers()
		{
			drivers = new List<AcmDriver>();
			MmException.Try(AcmInterop.acmDriverEnum(DriverEnumCallback, IntPtr.Zero, (AcmDriverEnumFlags)0), "acmDriverEnum");
			return drivers;
		}

		/// <summary>
		/// The callback for acmDriverEnum
		/// </summary>
		private static bool DriverEnumCallback(IntPtr hAcmDriver, IntPtr dwInstance, AcmDriverDetailsSupportFlags flags)
		{
			drivers.Add(new AcmDriver(hAcmDriver));
			return true;
		}

		/// <summary>
		/// Creates a new ACM Driver object
		/// </summary>
		/// <param name="hAcmDriver">Driver handle</param>
		private AcmDriver(IntPtr hAcmDriver)
		{
			driverId = hAcmDriver;
			details = default(AcmDriverDetails);
			details.structureSize = Marshal.SizeOf(details);
			MmException.Try(AcmInterop.acmDriverDetails(hAcmDriver, ref details, 0), "acmDriverDetails");
		}

		/// <summary>
		/// ToString
		/// </summary>
		public override string ToString()
		{
			return LongName;
		}

		/// <summary>
		/// Gets all the supported formats for a given format tag
		/// </summary>
		/// <param name="formatTag">Format tag</param>
		/// <returns>Supported formats</returns>
		public IEnumerable<AcmFormat> GetFormats(AcmFormatTag formatTag)
		{
			if (driverHandle == IntPtr.Zero)
			{
				throw new InvalidOperationException("Driver must be opened first");
			}
			tempFormatsList = new List<AcmFormat>();
			AcmFormatDetails formatDetails = default(AcmFormatDetails);
			formatDetails.structSize = Marshal.SizeOf(formatDetails);
			formatDetails.waveFormatByteSize = 1024;
			formatDetails.waveFormatPointer = Marshal.AllocHGlobal(formatDetails.waveFormatByteSize);
			formatDetails.formatTag = (int)formatTag.FormatTag;
			MmResult result = AcmInterop.acmFormatEnum(driverHandle, ref formatDetails, AcmFormatEnumCallback, IntPtr.Zero, AcmFormatEnumFlags.None);
			Marshal.FreeHGlobal(formatDetails.waveFormatPointer);
			MmException.Try(result, "acmFormatEnum");
			return tempFormatsList;
		}

		/// <summary>
		/// Opens this driver
		/// </summary>
		public void Open()
		{
			if (driverHandle == IntPtr.Zero)
			{
				MmException.Try(AcmInterop.acmDriverOpen(out driverHandle, DriverId, 0), "acmDriverOpen");
			}
		}

		/// <summary>
		/// Closes this driver
		/// </summary>
		public void Close()
		{
			if (driverHandle != IntPtr.Zero)
			{
				MmException.Try(AcmInterop.acmDriverClose(driverHandle, 0), "acmDriverClose");
				driverHandle = IntPtr.Zero;
			}
		}

		private bool AcmFormatTagEnumCallback(IntPtr hAcmDriverId, ref AcmFormatTagDetails formatTagDetails, IntPtr dwInstance, AcmDriverDetailsSupportFlags flags)
		{
			formatTags.Add(new AcmFormatTag(formatTagDetails));
			return true;
		}

		private bool AcmFormatEnumCallback(IntPtr hAcmDriverId, ref AcmFormatDetails formatDetails, IntPtr dwInstance, AcmDriverDetailsSupportFlags flags)
		{
			tempFormatsList.Add(new AcmFormat(formatDetails));
			return true;
		}

		/// <summary>
		/// Dispose
		/// </summary>
		public void Dispose()
		{
			if (driverHandle != IntPtr.Zero)
			{
				Close();
				GC.SuppressFinalize(this);
			}
		}
	}

	/// <summary>
	/// Flags for use with acmDriverAdd
	/// </summary>
	internal enum AcmDriverAddFlags
	{
		/// <summary>
		/// ACM_DRIVERADDF_LOCAL
		/// </summary>
		Local = 0,
		/// <summary>
		/// ACM_DRIVERADDF_GLOBAL
		/// </summary>
		Global = 8,
		/// <summary>
		/// ACM_DRIVERADDF_FUNCTION
		/// </summary>
		Function = 3,
		/// <summary>
		/// ACM_DRIVERADDF_NOTIFYHWND
		/// </summary>
		NotifyWindowHandle = 4
	}

	/// <summary>
	/// Interop structure for ACM driver details (ACMDRIVERDETAILS)
	/// http://msdn.microsoft.com/en-us/library/dd742889%28VS.85%29.aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 2)]
	internal struct AcmDriverDetails
	{
		/// <summary>
		/// DWORD cbStruct
		/// </summary>
		public int structureSize;

		/// <summary>
		/// FOURCC fccType
		/// </summary>
		public uint fccType;

		/// <summary>
		/// FOURCC fccComp
		/// </summary>
		public uint fccComp;

		/// <summary>
		/// WORD   wMid; 
		/// </summary>
		public ushort manufacturerId;

		/// <summary>
		/// WORD wPid
		/// </summary>
		public ushort productId;

		/// <summary>
		/// DWORD vdwACM
		/// </summary>
		public uint acmVersion;

		/// <summary>
		/// DWORD vdwDriver
		/// </summary>
		public uint driverVersion;

		/// <summary>
		/// DWORD  fdwSupport;
		/// </summary>
		public AcmDriverDetailsSupportFlags supportFlags;

		/// <summary>
		/// DWORD cFormatTags
		/// </summary>
		public int formatTagsCount;

		/// <summary>
		/// DWORD cFilterTags
		/// </summary>
		public int filterTagsCount;

		/// <summary>
		/// HICON hicon
		/// </summary>
		public IntPtr hicon;

		/// <summary>
		/// TCHAR  szShortName[ACMDRIVERDETAILS_SHORTNAME_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 32)]
		public string shortName;

		/// <summary>
		/// TCHAR  szLongName[ACMDRIVERDETAILS_LONGNAME_CHARS];
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 128)]
		public string longName;

		/// <summary>
		/// TCHAR  szCopyright[ACMDRIVERDETAILS_COPYRIGHT_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 80)]
		public string copyright;

		/// <summary>
		/// TCHAR  szLicensing[ACMDRIVERDETAILS_LICENSING_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 128)]
		public string licensing;

		/// <summary>
		/// TCHAR  szFeatures[ACMDRIVERDETAILS_FEATURES_CHARS];
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 512)]
		public string features;

		/// <summary>
		/// ACMDRIVERDETAILS_SHORTNAME_CHARS
		/// </summary>
		private const int ShortNameChars = 32;

		/// <summary>
		/// ACMDRIVERDETAILS_LONGNAME_CHARS
		/// </summary>
		private const int LongNameChars = 128;

		/// <summary>
		/// ACMDRIVERDETAILS_COPYRIGHT_CHARS
		/// </summary>
		private const int CopyrightChars = 80;

		/// <summary>
		/// ACMDRIVERDETAILS_LICENSING_CHARS 
		/// </summary>
		private const int LicensingChars = 128;

		/// <summary>
		/// ACMDRIVERDETAILS_FEATURES_CHARS
		/// </summary>
		private const int FeaturesChars = 512;
	}

	/// <summary>
	/// Flags indicating what support a particular ACM driver has
	/// </summary>
	[Flags]
	public enum AcmDriverDetailsSupportFlags
	{
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_CODEC - Codec</summary>
		Codec = 1,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_CONVERTER - Converter</summary>
		Converter = 2,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_FILTER - Filter</summary>
		Filter = 4,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_HARDWARE - Hardware</summary>
		Hardware = 8,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_ASYNC - Async</summary>
		Async = 0x10,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_LOCAL - Local</summary>
		Local = 0x40000000,
		/// <summary>ACMDRIVERDETAILS_SUPPORTF_DISABLED - Disabled</summary>
		Disabled = int.MinValue
	}

	[Flags]
	internal enum AcmDriverEnumFlags
	{
		/// <summary>
		/// ACM_DRIVERENUMF_NOLOCAL, Only global drivers should be included in the enumeration
		/// </summary>
		NoLocal = 0x40000000,
		/// <summary>
		/// ACM_DRIVERENUMF_DISABLED, Disabled ACM drivers should be included in the enumeration
		/// </summary>
		Disabled = int.MinValue
	}

	/// <summary>
	/// ACM Format
	/// </summary>
	public class AcmFormat
	{
		private readonly AcmFormatDetails formatDetails;

		/// <summary>
		/// Format Index
		/// </summary>
		public int FormatIndex => formatDetails.formatIndex;

		/// <summary>
		/// Format Tag
		/// </summary>
		public WaveFormatEncoding FormatTag => (WaveFormatEncoding)formatDetails.formatTag;

		/// <summary>
		/// Support Flags
		/// </summary>
		public AcmDriverDetailsSupportFlags SupportFlags => formatDetails.supportFlags;

		/// <summary>
		/// WaveFormat
		/// </summary>
		public WaveFormat WaveFormat { get; private set; }

		/// <summary>
		/// WaveFormat Size
		/// </summary>
		public int WaveFormatByteSize => formatDetails.waveFormatByteSize;

		/// <summary>
		/// Format Description
		/// </summary>
		public string FormatDescription => formatDetails.formatDescription;

		internal AcmFormat(AcmFormatDetails formatDetails)
		{
			this.formatDetails = formatDetails;
			WaveFormat = WaveFormat.MarshalFromPtr(formatDetails.waveFormatPointer);
		}
	}

	/// <summary>
	/// ACMFORMATCHOOSE
	/// http://msdn.microsoft.com/en-us/library/dd742911%28VS.85%29.aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto, Pack = 4)]
	internal struct AcmFormatChoose
	{
		/// <summary>
		/// DWORD cbStruct; 
		/// </summary>
		public int structureSize;

		/// <summary>
		/// DWORD fdwStyle; 
		/// </summary>
		public AcmFormatChooseStyleFlags styleFlags;

		/// <summary>
		/// HWND hwndOwner; 
		/// </summary>
		public IntPtr ownerWindowHandle;

		/// <summary>
		/// LPWAVEFORMATEX pwfx; 
		/// </summary>
		public IntPtr selectedWaveFormatPointer;

		/// <summary>
		/// DWORD cbwfx; 
		/// </summary>
		public int selectedWaveFormatByteSize;

		/// <summary>
		/// LPCTSTR pszTitle; 
		/// </summary>
		[MarshalAs(UnmanagedType.LPTStr)]
		public string title;

		/// <summary>
		/// TCHAR szFormatTag[ACMFORMATTAGDETAILS_FORMATTAG_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 48)]
		public string formatTagDescription;

		/// <summary>
		/// TCHAR szFormat[ACMFORMATDETAILS_FORMAT_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 128)]
		public string formatDescription;

		/// <summary>
		/// LPTSTR pszName; 
		/// n.b. can be written into
		/// </summary>
		[MarshalAs(UnmanagedType.LPTStr)]
		public string name;

		/// <summary>
		/// DWORD cchName
		/// Should be at least 128 unless name is zero
		/// </summary>
		public int nameByteSize;

		/// <summary>
		/// DWORD fdwEnum; 
		/// </summary>
		public AcmFormatEnumFlags formatEnumFlags;

		/// <summary>
		/// LPWAVEFORMATEX pwfxEnum; 
		/// </summary>
		public IntPtr waveFormatEnumPointer;

		/// <summary>
		/// HINSTANCE hInstance; 
		/// </summary>
		public IntPtr instanceHandle;

		/// <summary>
		/// LPCTSTR pszTemplateName; 
		/// </summary>
		[MarshalAs(UnmanagedType.LPTStr)]
		public string templateName;

		/// <summary>
		/// LPARAM lCustData; 
		/// </summary>
		public IntPtr customData;

		/// <summary>
		/// ACMFORMATCHOOSEHOOKPROC pfnHook; 
		/// </summary>
		public AcmInterop.AcmFormatChooseHookProc windowCallbackFunction;
	}

	[Flags]
	internal enum AcmFormatChooseStyleFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_SHOWHELP
		/// </summary>
		ShowHelp = 4,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_ENABLEHOOK
		/// </summary>
		EnableHook = 8,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_ENABLETEMPLATE
		/// </summary>
		EnableTemplate = 0x10,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_ENABLETEMPLATEHANDLE
		/// </summary>
		EnableTemplateHandle = 0x20,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_INITTOWFXSTRUCT
		/// </summary>
		InitToWfxStruct = 0x40,
		/// <summary>
		/// ACMFORMATCHOOSE_STYLEF_CONTEXTHELP
		/// </summary>
		ContextHelp = 0x80
	}

	/// <summary>
	/// ACMFORMATDETAILS
	/// http://msdn.microsoft.com/en-us/library/dd742913%28VS.85%29.aspx
	/// </summary>
	[StructLayout(LayoutKind.Sequential, Pack = 4)]
	internal struct AcmFormatDetails
	{
		/// <summary>
		/// DWORD cbStruct; 
		/// </summary>
		public int structSize;

		/// <summary>
		/// DWORD dwFormatIndex; 
		/// </summary>
		public int formatIndex;

		/// <summary>
		/// DWORD dwFormatTag; 
		/// </summary>
		public int formatTag;

		/// <summary>
		/// DWORD fdwSupport; 
		/// </summary>
		public AcmDriverDetailsSupportFlags supportFlags;

		/// <summary>
		/// LPWAVEFORMATEX pwfx; 
		/// </summary>    
		public IntPtr waveFormatPointer;

		/// <summary>
		/// DWORD cbwfx; 
		/// </summary>
		public int waveFormatByteSize;

		/// <summary>
		/// TCHAR szFormat[ACMFORMATDETAILS_FORMAT_CHARS];
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 128)]
		public string formatDescription;

		/// <summary>
		/// ACMFORMATDETAILS_FORMAT_CHARS
		/// </summary>
		public const int FormatDescriptionChars = 128;
	}

	/// <summary>
	/// Format Enumeration Flags
	/// </summary>
	[Flags]
	public enum AcmFormatEnumFlags
	{
		/// <summary>
		/// None
		/// </summary>
		None = 0,
		/// <summary>
		/// ACM_FORMATENUMF_CONVERT
		/// The WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will only enumerate destination formats that can be converted from the given pwfx format. 
		/// </summary>
		Convert = 0x100000,
		/// <summary>
		/// ACM_FORMATENUMF_HARDWARE
		/// The enumerator should only enumerate formats that are supported as native input or output formats on one or more of the installed waveform-audio devices. This flag provides a way for an application to choose only formats native to an installed waveform-audio device. This flag must be used with one or both of the ACM_FORMATENUMF_INPUT and ACM_FORMATENUMF_OUTPUT flags. Specifying both ACM_FORMATENUMF_INPUT and ACM_FORMATENUMF_OUTPUT will enumerate only formats that can be opened for input or output. This is true regardless of whether this flag is specified. 
		/// </summary>
		Hardware = 0x400000,
		/// <summary>
		/// ACM_FORMATENUMF_INPUT
		/// Enumerator should enumerate only formats that are supported for input (recording). 
		/// </summary>
		Input = 0x800000,
		/// <summary>
		/// ACM_FORMATENUMF_NCHANNELS 
		/// The nChannels member of the WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will enumerate only a format that conforms to this attribute. 
		/// </summary>
		Channels = 0x20000,
		/// <summary>
		/// ACM_FORMATENUMF_NSAMPLESPERSEC
		/// The nSamplesPerSec member of the WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will enumerate only a format that conforms to this attribute. 
		/// </summary>
		SamplesPerSecond = 0x40000,
		/// <summary>
		/// ACM_FORMATENUMF_OUTPUT 
		/// Enumerator should enumerate only formats that are supported for output (playback). 
		/// </summary>
		Output = 0x1000000,
		/// <summary>
		/// ACM_FORMATENUMF_SUGGEST
		/// The WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will enumerate all suggested destination formats for the given pwfx format. This mechanism can be used instead of the acmFormatSuggest function to allow an application to choose the best suggested format for conversion. The dwFormatIndex member will always be set to zero on return. 
		/// </summary>
		Suggest = 0x200000,
		/// <summary>
		/// ACM_FORMATENUMF_WBITSPERSAMPLE
		/// The wBitsPerSample member of the WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will enumerate only a format that conforms to this attribute. 
		/// </summary>
		BitsPerSample = 0x80000,
		/// <summary>
		/// ACM_FORMATENUMF_WFORMATTAG
		/// The wFormatTag member of the WAVEFORMATEX structure pointed to by the pwfx member of the ACMFORMATDETAILS structure is valid. The enumerator will enumerate only a format that conforms to this attribute. The dwFormatTag member of the ACMFORMATDETAILS structure must be equal to the wFormatTag member. 
		/// </summary>
		FormatTag = 0x10000
	}

	[Flags]
	internal enum AcmFormatSuggestFlags
	{
		/// <summary>
		/// ACM_FORMATSUGGESTF_WFORMATTAG
		/// </summary>
		FormatTag = 0x10000,
		/// <summary>
		/// ACM_FORMATSUGGESTF_NCHANNELS
		/// </summary>
		Channels = 0x20000,
		/// <summary>
		/// ACM_FORMATSUGGESTF_NSAMPLESPERSEC
		/// </summary>
		SamplesPerSecond = 0x40000,
		/// <summary>
		/// ACM_FORMATSUGGESTF_WBITSPERSAMPLE
		/// </summary>
		BitsPerSample = 0x80000,
		/// <summary>
		/// ACM_FORMATSUGGESTF_TYPEMASK
		/// </summary>
		TypeMask = 0xFF0000
	}

	/// <summary>
	/// ACM Format Tag
	/// </summary>
	public class AcmFormatTag
	{
		private AcmFormatTagDetails formatTagDetails;

		/// <summary>
		/// Format Tag Index
		/// </summary>
		public int FormatTagIndex => formatTagDetails.formatTagIndex;

		/// <summary>
		/// Format Tag
		/// </summary>
		public WaveFormatEncoding FormatTag => (WaveFormatEncoding)formatTagDetails.formatTag;

		/// <summary>
		/// Format Size
		/// </summary>
		public int FormatSize => formatTagDetails.formatSize;

		/// <summary>
		/// Support Flags
		/// </summary>
		public AcmDriverDetailsSupportFlags SupportFlags => formatTagDetails.supportFlags;

		/// <summary>
		/// Standard Formats Count
		/// </summary>
		public int StandardFormatsCount => formatTagDetails.standardFormatsCount;

		/// <summary>
		/// Format Description
		/// </summary>
		public string FormatDescription => formatTagDetails.formatDescription;

		internal AcmFormatTag(AcmFormatTagDetails formatTagDetails)
		{
			this.formatTagDetails = formatTagDetails;
		}
	}

	internal struct AcmFormatTagDetails
	{
		/// <summary>
		/// DWORD cbStruct; 
		/// </summary>
		public int structureSize;

		/// <summary>
		/// DWORD dwFormatTagIndex; 
		/// </summary>
		public int formatTagIndex;

		/// <summary>
		/// DWORD dwFormatTag; 
		/// </summary>
		public int formatTag;

		/// <summary>
		/// DWORD cbFormatSize; 
		/// </summary>
		public int formatSize;

		/// <summary>
		/// DWORD fdwSupport;
		/// </summary>
		public AcmDriverDetailsSupportFlags supportFlags;

		/// <summary>
		/// DWORD cStandardFormats; 
		/// </summary>
		public int standardFormatsCount;

		/// <summary>
		/// TCHAR szFormatTag[ACMFORMATTAGDETAILS_FORMATTAG_CHARS]; 
		/// </summary>
		[MarshalAs(UnmanagedType.ByValTStr, SizeConst = 48)]
		public string formatDescription;

		/// <summary>
		/// ACMFORMATTAGDETAILS_FORMATTAG_CHARS
		/// </summary>
		public const int FormatTagDescriptionChars = 48;
	}

	/// <summary>
	/// Interop definitions for Windows ACM (Audio Compression Manager) API
	/// </summary>
	internal class AcmInterop
	{
		public delegate bool AcmDriverEnumCallback(IntPtr hAcmDriverId, IntPtr instance, AcmDriverDetailsSupportFlags flags);

		public delegate bool AcmFormatEnumCallback(IntPtr hAcmDriverId, ref AcmFormatDetails formatDetails, IntPtr dwInstance, AcmDriverDetailsSupportFlags flags);

		public delegate bool AcmFormatTagEnumCallback(IntPtr hAcmDriverId, ref AcmFormatTagDetails formatTagDetails, IntPtr dwInstance, AcmDriverDetailsSupportFlags flags);

		/// <summary>
		/// http://msdn.microsoft.com/en-us/library/dd742910%28VS.85%29.aspx
		/// UINT ACMFORMATCHOOSEHOOKPROC acmFormatChooseHookProc(
		///   HWND hwnd,     
		///   UINT uMsg,     
		///   WPARAM wParam, 
		///   LPARAM lParam  
		/// </summary>        
		public delegate bool AcmFormatChooseHookProc(IntPtr windowHandle, int message, IntPtr wParam, IntPtr lParam);

		[DllImport("msacm32.dll")]
		public static extern MmResult acmDriverAdd(out IntPtr driverHandle, IntPtr driverModule, IntPtr driverFunctionAddress, int priority, AcmDriverAddFlags flags);

		[DllImport("msacm32.dll")]
		public static extern MmResult acmDriverRemove(IntPtr driverHandle, int removeFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmDriverClose(IntPtr hAcmDriver, int closeFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmDriverEnum(AcmDriverEnumCallback fnCallback, IntPtr dwInstance, AcmDriverEnumFlags flags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmDriverDetails(IntPtr hAcmDriver, ref AcmDriverDetails driverDetails, int reserved);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmDriverOpen(out IntPtr pAcmDriver, IntPtr hAcmDriverId, int openFlags);

		[DllImport("Msacm32.dll", EntryPoint = "acmFormatChooseW")]
		public static extern MmResult acmFormatChoose(ref AcmFormatChoose formatChoose);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmFormatEnum(IntPtr hAcmDriver, ref AcmFormatDetails formatDetails, AcmFormatEnumCallback callback, IntPtr instance, AcmFormatEnumFlags flags);

		[DllImport("Msacm32.dll", EntryPoint = "acmFormatSuggest")]
		public static extern MmResult acmFormatSuggest2(IntPtr hAcmDriver, IntPtr sourceFormatPointer, IntPtr destFormatPointer, int sizeDestFormat, AcmFormatSuggestFlags suggestFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmFormatTagEnum(IntPtr hAcmDriver, ref AcmFormatTagDetails formatTagDetails, AcmFormatTagEnumCallback callback, IntPtr instance, int reserved);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmMetrics(IntPtr hAcmObject, AcmMetrics metric, out int output);

		/// <summary>
		/// A version with pointers for troubleshooting
		/// </summary>
		[DllImport("Msacm32.dll", EntryPoint = "acmStreamOpen")]
		public static extern MmResult acmStreamOpen2(out IntPtr hAcmStream, IntPtr hAcmDriver, IntPtr sourceFormatPointer, IntPtr destFormatPointer, [In] WaveFilter waveFilter, IntPtr callback, IntPtr instance, AcmStreamOpenFlags openFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamClose(IntPtr hAcmStream, int closeFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamConvert(IntPtr hAcmStream, [In][Out] AcmStreamHeaderStruct streamHeader, AcmStreamConvertFlags streamConvertFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamPrepareHeader(IntPtr hAcmStream, [In][Out] AcmStreamHeaderStruct streamHeader, int prepareFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamReset(IntPtr hAcmStream, int resetFlags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamSize(IntPtr hAcmStream, int inputBufferSize, out int outputBufferSize, AcmStreamSizeFlags flags);

		[DllImport("Msacm32.dll")]
		public static extern MmResult acmStreamUnprepareHeader(IntPtr hAcmStream, [In][Out] AcmStreamHeaderStruct streamHeader, int flags);
	}

	/// <summary>
	/// AcmStream encapsulates an Audio Compression Manager Stream
	/// used to convert audio from one format to another
	/// </summary>
	public class AcmStream : IDisposable
	{
		private IntPtr streamHandle;

		private IntPtr driverHandle;

		private AcmStreamHeader streamHeader;

		private readonly WaveFormat sourceFormat;

		/// <summary>
		/// Returns the Source Buffer. Fill this with data prior to calling convert
		/// </summary>
		public byte[] SourceBuffer => streamHeader.SourceBuffer;

		/// <summary>
		/// Returns the Destination buffer. This will contain the converted data
		/// after a successful call to Convert
		/// </summary>
		public byte[] DestBuffer => streamHeader.DestBuffer;

		/// <summary>
		/// Creates a new ACM stream to convert one format to another. Note that
		/// not all conversions can be done in one step
		/// </summary>
		/// <param name="sourceFormat">The source audio format</param>
		/// <param name="destFormat">The destination audio format</param>
		public AcmStream(WaveFormat sourceFormat, WaveFormat destFormat)
		{
			try
			{
				streamHandle = IntPtr.Zero;
				this.sourceFormat = sourceFormat;
				int num = Math.Max(65536, sourceFormat.AverageBytesPerSecond);
				num -= num % sourceFormat.BlockAlign;
				IntPtr intPtr = WaveFormat.MarshalToPtr(sourceFormat);
				IntPtr intPtr2 = WaveFormat.MarshalToPtr(destFormat);
				try
				{
					MmException.Try(AcmInterop.acmStreamOpen2(out streamHandle, IntPtr.Zero, intPtr, intPtr2, null, IntPtr.Zero, IntPtr.Zero, AcmStreamOpenFlags.NonRealTime), "acmStreamOpen");
				}
				finally
				{
					Marshal.FreeHGlobal(intPtr);
					Marshal.FreeHGlobal(intPtr2);
				}
				int destBufferLength = SourceToDest(num);
				streamHeader = new AcmStreamHeader(streamHandle, num, destBufferLength);
				driverHandle = IntPtr.Zero;
			}
			catch
			{
				Dispose();
				throw;
			}
		}

		/// <summary>
		/// Creates a new ACM stream to convert one format to another, using a 
		/// specified driver identifier and wave filter
		/// </summary>
		/// <param name="driverId">the driver identifier</param>
		/// <param name="sourceFormat">the source format</param>
		/// <param name="waveFilter">the wave filter</param>
		public AcmStream(IntPtr driverId, WaveFormat sourceFormat, WaveFilter waveFilter)
		{
			int num = Math.Max(16384, sourceFormat.AverageBytesPerSecond);
			this.sourceFormat = sourceFormat;
			num -= num % sourceFormat.BlockAlign;
			MmException.Try(AcmInterop.acmDriverOpen(out driverHandle, driverId, 0), "acmDriverOpen");
			IntPtr intPtr = WaveFormat.MarshalToPtr(sourceFormat);
			try
			{
				MmException.Try(AcmInterop.acmStreamOpen2(out streamHandle, driverHandle, intPtr, intPtr, waveFilter, IntPtr.Zero, IntPtr.Zero, AcmStreamOpenFlags.NonRealTime), "acmStreamOpen");
			}
			finally
			{
				Marshal.FreeHGlobal(intPtr);
			}
			streamHeader = new AcmStreamHeader(streamHandle, num, SourceToDest(num));
		}

		/// <summary>
		/// Returns the number of output bytes for a given number of input bytes
		/// </summary>
		/// <param name="source">Number of input bytes</param>
		/// <returns>Number of output bytes</returns>
		public int SourceToDest(int source)
		{
			if (source == 0)
			{
				return 0;
			}
			MmException.Try(AcmInterop.acmStreamSize(streamHandle, source, out var outputBufferSize, AcmStreamSizeFlags.Source), "acmStreamSize");
			return outputBufferSize;
		}

		/// <summary>
		/// Returns the number of source bytes for a given number of destination bytes
		/// </summary>
		/// <param name="dest">Number of destination bytes</param>
		/// <returns>Number of source bytes</returns>
		public int DestToSource(int dest)
		{
			if (dest == 0)
			{
				return 0;
			}
			MmException.Try(AcmInterop.acmStreamSize(streamHandle, dest, out var outputBufferSize, AcmStreamSizeFlags.Destination), "acmStreamSize");
			return outputBufferSize;
		}

		/// <summary>
		/// Suggests an appropriate PCM format that the compressed format can be converted
		/// to in one step
		/// </summary>
		/// <param name="compressedFormat">The compressed format</param>
		/// <returns>The PCM format</returns>
		public static WaveFormat SuggestPcmFormat(WaveFormat compressedFormat)
		{
			WaveFormat waveFormat = new WaveFormat(compressedFormat.SampleRate, 16, compressedFormat.Channels);
			IntPtr intPtr = WaveFormat.MarshalToPtr(waveFormat);
			IntPtr intPtr2 = WaveFormat.MarshalToPtr(compressedFormat);
			try
			{
				MmResult result = AcmInterop.acmFormatSuggest2(IntPtr.Zero, intPtr2, intPtr, Marshal.SizeOf(waveFormat), AcmFormatSuggestFlags.FormatTag);
				waveFormat = WaveFormat.MarshalFromPtr(intPtr);
				MmException.Try(result, "acmFormatSuggest");
				return waveFormat;
			}
			finally
			{
				Marshal.FreeHGlobal(intPtr);
				Marshal.FreeHGlobal(intPtr2);
			}
		}

		/// <summary>
		/// Report that we have repositioned in the source stream
		/// </summary>
		public void Reposition()
		{
			streamHeader.Reposition();
		}

		/// <summary>
		/// Converts the contents of the SourceBuffer into the DestinationBuffer
		/// </summary>
		/// <param name="bytesToConvert">The number of bytes in the SourceBuffer
		/// that need to be converted</param>
		/// <param name="sourceBytesConverted">The number of source bytes actually converted</param>
		/// <returns>The number of converted bytes in the DestinationBuffer</returns>
		public int Convert(int bytesToConvert, out int sourceBytesConverted)
		{
			if (bytesToConvert % sourceFormat.BlockAlign != 0)
			{
				bytesToConvert -= bytesToConvert % sourceFormat.BlockAlign;
			}
			return streamHeader.Convert(bytesToConvert, out sourceBytesConverted);
		}

		/// <summary>
		/// Converts the contents of the SourceBuffer into the DestinationBuffer
		/// </summary>
		/// <param name="bytesToConvert">The number of bytes in the SourceBuffer
		/// that need to be converted</param>
		/// <returns>The number of converted bytes in the DestinationBuffer</returns>
		[Obsolete("Call the version returning sourceBytesConverted instead")]
		public int Convert(int bytesToConvert)
		{
			int sourceBytesConverted;
			int result = Convert(bytesToConvert, out sourceBytesConverted);
			if (sourceBytesConverted != bytesToConvert)
			{
				throw new MmException(MmResult.NotSupported, "AcmStreamHeader.Convert didn't convert everything");
			}
			return result;
		}

		/// <summary>
		/// Frees resources associated with this ACM Stream
		/// </summary>
		public void Dispose()
		{
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}

		/// <summary>
		/// Frees resources associated with this ACM Stream
		/// </summary>
		protected virtual void Dispose(bool disposing)
		{
			if (disposing && streamHeader != null)
			{
				streamHeader.Dispose();
				streamHeader = null;
			}
			if (streamHandle != IntPtr.Zero)
			{
				MmResult mmResult = AcmInterop.acmStreamClose(streamHandle, 0);
				streamHandle = IntPtr.Zero;
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "acmStreamClose");
				}
			}
			if (driverHandle != IntPtr.Zero)
			{
				AcmInterop.acmDriverClose(driverHandle, 0);
				driverHandle = IntPtr.Zero;
			}
		}

		/// <summary>
		/// Frees resources associated with this ACM Stream
		/// </summary>
		~AcmStream()
		{
			Dispose(disposing: false);
		}
	}

	internal class AcmStreamHeader : IDisposable
	{
		private AcmStreamHeaderStruct streamHeader;

		private GCHandle hSourceBuffer;

		private GCHandle hDestBuffer;

		private IntPtr streamHandle;

		private bool firstTime;

		private bool disposed;

		public byte[] SourceBuffer { get; private set; }

		public byte[] DestBuffer { get; private set; }

		public AcmStreamHeader(IntPtr streamHandle, int sourceBufferLength, int destBufferLength)
		{
			streamHeader = new AcmStreamHeaderStruct();
			SourceBuffer = new byte[sourceBufferLength];
			hSourceBuffer = GCHandle.Alloc(SourceBuffer, GCHandleType.Pinned);
			DestBuffer = new byte[destBufferLength];
			hDestBuffer = GCHandle.Alloc(DestBuffer, GCHandleType.Pinned);
			this.streamHandle = streamHandle;
			firstTime = true;
		}

		private void Prepare()
		{
			streamHeader.cbStruct = Marshal.SizeOf(streamHeader);
			streamHeader.sourceBufferLength = SourceBuffer.Length;
			streamHeader.sourceBufferPointer = hSourceBuffer.AddrOfPinnedObject();
			streamHeader.destBufferLength = DestBuffer.Length;
			streamHeader.destBufferPointer = hDestBuffer.AddrOfPinnedObject();
			MmException.Try(AcmInterop.acmStreamPrepareHeader(streamHandle, streamHeader, 0), "acmStreamPrepareHeader");
		}

		private void Unprepare()
		{
			streamHeader.sourceBufferLength = SourceBuffer.Length;
			streamHeader.sourceBufferPointer = hSourceBuffer.AddrOfPinnedObject();
			streamHeader.destBufferLength = DestBuffer.Length;
			streamHeader.destBufferPointer = hDestBuffer.AddrOfPinnedObject();
			MmResult mmResult = AcmInterop.acmStreamUnprepareHeader(streamHandle, streamHeader, 0);
			if (mmResult != 0)
			{
				throw new MmException(mmResult, "acmStreamUnprepareHeader");
			}
		}

		public void Reposition()
		{
			firstTime = true;
		}

		public int Convert(int bytesToConvert, out int sourceBytesConverted)
		{
			Prepare();
			try
			{
				streamHeader.sourceBufferLength = bytesToConvert;
				streamHeader.sourceBufferLengthUsed = bytesToConvert;
				AcmStreamConvertFlags streamConvertFlags = (firstTime ? (AcmStreamConvertFlags.BlockAlign | AcmStreamConvertFlags.Start) : AcmStreamConvertFlags.BlockAlign);
				MmException.Try(AcmInterop.acmStreamConvert(streamHandle, streamHeader, streamConvertFlags), "acmStreamConvert");
				firstTime = false;
				sourceBytesConverted = streamHeader.sourceBufferLengthUsed;
			}
			finally
			{
				Unprepare();
			}
			return streamHeader.destBufferLengthUsed;
		}

		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		protected virtual void Dispose(bool disposing)
		{
			if (!disposed)
			{
				SourceBuffer = null;
				DestBuffer = null;
				hSourceBuffer.Free();
				hDestBuffer.Free();
			}
			disposed = true;
		}

		~AcmStreamHeader()
		{
			Dispose(disposing: false);
		}
	}

	[Flags]
	internal enum AcmStreamHeaderStatusFlags
	{
		/// <summary>
		/// ACMSTREAMHEADER_STATUSF_DONE
		/// </summary>
		Done = 0x10000,
		/// <summary>
		/// ACMSTREAMHEADER_STATUSF_PREPARED
		/// </summary>
		Prepared = 0x20000,
		/// <summary>
		/// ACMSTREAMHEADER_STATUSF_INQUEUE
		/// </summary>
		InQueue = 0x100000
	}

	/// <summary>
	/// Interop structure for ACM stream headers.
	/// ACMSTREAMHEADER 
	/// http://msdn.microsoft.com/en-us/library/dd742926%28VS.85%29.aspx
	/// </summary>    
	[StructLayout(LayoutKind.Sequential, Size = 128)]
	internal class AcmStreamHeaderStruct
	{
		public int cbStruct;

		public AcmStreamHeaderStatusFlags fdwStatus;

		public IntPtr userData;

		public IntPtr sourceBufferPointer;

		public int sourceBufferLength;

		public int sourceBufferLengthUsed;

		public IntPtr sourceUserData;

		public IntPtr destBufferPointer;

		public int destBufferLength;

		public int destBufferLengthUsed;

		public IntPtr destUserData;
	}

	[Flags]
	internal enum AcmStreamOpenFlags
	{
		/// <summary>
		/// ACM_STREAMOPENF_QUERY, ACM will be queried to determine whether it supports the given conversion. A conversion stream will not be opened, and no handle will be returned in the phas parameter. 
		/// </summary>
		Query = 1,
		/// <summary>
		/// ACM_STREAMOPENF_ASYNC, Stream conversion should be performed asynchronously. If this flag is specified, the application can use a callback function to be notified when the conversion stream is opened and closed and after each buffer is converted. In addition to using a callback function, an application can examine the fdwStatus member of the ACMSTREAMHEADER structure for the ACMSTREAMHEADER_STATUSF_DONE flag. 
		/// </summary>
		Async = 2,
		/// <summary>
		/// ACM_STREAMOPENF_NONREALTIME, ACM will not consider time constraints when converting the data. By default, the driver will attempt to convert the data in real time. For some formats, specifying this flag might improve the audio quality or other characteristics.
		/// </summary>
		NonRealTime = 4,
		/// <summary>
		/// CALLBACK_TYPEMASK, callback type mask
		/// </summary>
		CallbackTypeMask = 0x70000,
		/// <summary>
		/// CALLBACK_NULL, no callback
		/// </summary>
		CallbackNull = 0,
		/// <summary>
		/// CALLBACK_WINDOW, dwCallback is a HWND
		/// </summary>
		CallbackWindow = 0x10000,
		/// <summary>
		/// CALLBACK_TASK, dwCallback is a HTASK
		/// </summary>
		CallbackTask = 0x20000,
		/// <summary>
		/// CALLBACK_FUNCTION, dwCallback is a FARPROC
		/// </summary>
		CallbackFunction = 0x30000,
		/// <summary>
		/// CALLBACK_THREAD, thread ID replaces 16 bit task
		/// </summary>
		CallbackThread = 0x20000,
		/// <summary>
		/// CALLBACK_EVENT, dwCallback is an EVENT Handle
		/// </summary>
		CallbackEvent = 0x50000
	}

	internal enum AcmStreamSizeFlags
	{
		/// <summary>
		/// ACM_STREAMSIZEF_SOURCE
		/// </summary>
		Source,
		/// <summary>
		/// ACM_STREAMSIZEF_DESTINATION
		/// </summary>
		Destination
	}

	/// <summary>
	/// Summary description for WaveFilter.
	/// </summary>
	[StructLayout(LayoutKind.Sequential)]
	public class WaveFilter
	{
		/// <summary>
		/// cbStruct
		/// </summary>
		public int StructureSize = Marshal.SizeOf(typeof(WaveFilter));

		/// <summary>
		/// dwFilterTag
		/// </summary>
		public int FilterTag;

		/// <summary>
		/// fdwFilter
		/// </summary>
		public int Filter;

		/// <summary>
		/// reserved
		/// </summary>
		[MarshalAs(UnmanagedType.ByValArray, SizeConst = 5)]
		public int[] Reserved;
	}
}

namespace NAudio.Gui
{
	using NAudio.Wave;
	using System.Drawing;
	using System.Windows.Forms;
	using System.ComponentModel;
	using System.Drawing.Drawing2D;
	
	/// <summary>
	/// Summary description for Fader.
	/// </summary>
	public class Fader : Control
	{
		private int minimum;

		private int maximum;

		private float percent;

		private Orientation orientation;

		/// <summary>
		/// Required designer variable.
		/// </summary>
		private Container components;

		private readonly int SliderHeight = 30;

		private readonly int SliderWidth = 15;

		private Rectangle sliderRectangle;

		private bool dragging;

		private int dragY;

		/// <summary>
		/// Minimum value of this fader
		/// </summary>
		public int Minimum
		{
			get
			{
				return minimum;
			}
			set
			{
				minimum = value;
			}
		}

		/// <summary>
		/// Maximum value of this fader
		/// </summary>
		public int Maximum
		{
			get
			{
				return maximum;
			}
			set
			{
				maximum = value;
			}
		}

		/// <summary>
		/// Current value of this fader
		/// </summary>
		public int Value
		{
			get
			{
				return (int)(percent * (float)(maximum - minimum)) + minimum;
			}
			set
			{
				percent = (float)(value - minimum) / (float)(maximum - minimum);
			}
		}

		/// <summary>
		/// Fader orientation
		/// </summary>
		public Orientation Orientation
		{
			get
			{
				return orientation;
			}
			set
			{
				orientation = value;
			}
		}

		/// <summary>
		/// Creates a new Fader control
		/// </summary>
		public Fader()
		{
			InitializeComponent();
			SetStyle(ControlStyles.UserPaint | ControlStyles.AllPaintingInWmPaint | ControlStyles.DoubleBuffer, value: true);
		}

		/// <summary> 
		/// Clean up any resources being used.
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		private void DrawSlider(Graphics g)
		{
			Brush brush = new SolidBrush(Color.White);
			Pen pen = new Pen(Color.Black);
			sliderRectangle.X = (base.Width - SliderWidth) / 2;
			sliderRectangle.Width = SliderWidth;
			sliderRectangle.Y = (int)((float)(base.Height - SliderHeight) * percent);
			sliderRectangle.Height = SliderHeight;
			g.FillRectangle(brush, sliderRectangle);
			g.DrawLine(pen, sliderRectangle.Left, sliderRectangle.Top + sliderRectangle.Height / 2, sliderRectangle.Right, sliderRectangle.Top + sliderRectangle.Height / 2);
			brush.Dispose();
			pen.Dispose();
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnPaint(System.Windows.Forms.PaintEventArgs)" />
		/// </summary>
		protected override void OnPaint(PaintEventArgs e)
		{
			Graphics graphics = e.Graphics;
			if (Orientation == Orientation.Vertical)
			{
				Brush brush = new SolidBrush(Color.Black);
				graphics.FillRectangle(brush, base.Width / 2, SliderHeight / 2, 2, base.Height - SliderHeight);
				brush.Dispose();
				DrawSlider(graphics);
			}
			base.OnPaint(e);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseDown(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		protected override void OnMouseDown(MouseEventArgs e)
		{
			if (sliderRectangle.Contains(e.X, e.Y))
			{
				dragging = true;
				dragY = e.Y - sliderRectangle.Y;
			}
			base.OnMouseDown(e);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseMove(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		protected override void OnMouseMove(MouseEventArgs e)
		{
			if (dragging)
			{
				int num = e.Y - dragY;
				if (num < 0)
				{
					percent = 0f;
				}
				else if (num > base.Height - SliderHeight)
				{
					percent = 1f;
				}
				else
				{
					percent = (float)num / (float)(base.Height - SliderHeight);
				}
				Invalidate();
			}
			base.OnMouseMove(e);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseUp(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>        
		protected override void OnMouseUp(MouseEventArgs e)
		{
			dragging = false;
			base.OnMouseUp(e);
		}

		/// <summary>
		/// Required method for Designer support - do not modify
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.components = new System.ComponentModel.Container();
		}
	}

	/// <summary>
	/// Pan slider control
	/// </summary>
	public class PanSlider : UserControl
	{
		/// <summary>
		/// Required designer variable.
		/// </summary>
		private Container components;

		private float pan;

		/// <summary>
		/// The current Pan setting
		/// </summary>
		public float Pan
		{
			get
			{
				return pan;
			}
			set
			{
				if (value < -1f)
				{
					value = -1f;
				}
				if (value > 1f)
				{
					value = 1f;
				}
				if (value != pan)
				{
					pan = value;
					if (this.PanChanged != null)
					{
						this.PanChanged(this, EventArgs.Empty);
					}
					Invalidate();
				}
			}
		}

		/// <summary>
		/// True when pan value changed
		/// </summary>
		public event EventHandler PanChanged;

		/// <summary>
		/// Creates a new PanSlider control
		/// </summary>
		public PanSlider()
		{
			InitializeComponent();
		}

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			base.Name = "PanSlider";
			base.Size = new System.Drawing.Size(104, 16);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnPaint(System.Windows.Forms.PaintEventArgs)" />
		/// </summary>
		protected override void OnPaint(PaintEventArgs pe)
		{
			StringFormat stringFormat = new StringFormat();
			stringFormat.LineAlignment = StringAlignment.Center;
			stringFormat.Alignment = StringAlignment.Center;
			string s;
			if ((double)pan == 0.0)
			{
				pe.Graphics.FillRectangle(Brushes.Orange, base.Width / 2 - 1, 1, 3, base.Height - 2);
				s = "C";
			}
			else if (pan > 0f)
			{
				pe.Graphics.FillRectangle(Brushes.Orange, base.Width / 2, 1, (int)((float)(base.Width / 2) * pan), base.Height - 2);
				s = $"{pan * 100f:F0}%R";
			}
			else
			{
				pe.Graphics.FillRectangle(Brushes.Orange, (int)((float)(base.Width / 2) * (pan + 1f)), 1, (int)((float)(base.Width / 2) * (0f - pan)), base.Height - 2);
				s = $"{pan * -100f:F0}%L";
			}
			pe.Graphics.DrawRectangle(Pens.Black, 0, 0, base.Width - 1, base.Height - 1);
			pe.Graphics.DrawString(s, Font, Brushes.Black, base.ClientRectangle, stringFormat);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseMove(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		protected override void OnMouseMove(MouseEventArgs e)
		{
			if (e.Button == MouseButtons.Left)
			{
				SetPanFromMouse(e.X);
			}
			base.OnMouseMove(e);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseDown(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		/// <param name="e"></param>
		protected override void OnMouseDown(MouseEventArgs e)
		{
			SetPanFromMouse(e.X);
			base.OnMouseDown(e);
		}

		private void SetPanFromMouse(int x)
		{
			Pan = (float)x / (float)base.Width * 2f - 1f;
		}
	}

	/// <summary>
	/// Control that represents a potentiometer
	/// TODO list:
	/// Optional Log scale
	/// Optional reverse scale
	/// Keyboard control
	/// Optional bitmap mode
	/// Optional complete draw mode
	/// Tooltip support
	/// </summary>
	public class Pot : UserControl
	{
		private double minimum;

		private double maximum = 1.0;

		private double value = 0.5;

		private int beginDragY;

		private double beginDragValue;

		private bool dragging;

		/// <summary> 
		/// Required designer variable.
		/// </summary>
		private IContainer components;

		/// <summary>
		/// Minimum Value of the Pot
		/// </summary>
		public double Minimum
		{
			get
			{
				return minimum;
			}
			set
			{
				if (value >= maximum)
				{
					throw new ArgumentOutOfRangeException("Minimum must be less than maximum");
				}
				minimum = value;
				if (Value < minimum)
				{
					Value = minimum;
				}
			}
		}

		/// <summary>
		/// Maximum Value of the Pot
		/// </summary>
		public double Maximum
		{
			get
			{
				return maximum;
			}
			set
			{
				if (value <= minimum)
				{
					throw new ArgumentOutOfRangeException("Maximum must be greater than minimum");
				}
				maximum = value;
				if (Value > maximum)
				{
					Value = maximum;
				}
			}
		}

		/// <summary>
		/// The current value of the pot
		/// </summary>
		public double Value
		{
			get
			{
				return value;
			}
			set
			{
				SetValue(value, raiseEvents: false);
			}
		}

		/// <summary>
		/// Value changed event
		/// </summary>
		public event EventHandler ValueChanged;

		/// <summary>
		/// Creates a new pot control
		/// </summary>
		public Pot()
		{
			SetStyle(ControlStyles.UserPaint | ControlStyles.AllPaintingInWmPaint | ControlStyles.DoubleBuffer, value: true);
			InitializeComponent();
		}

		private void SetValue(double newValue, bool raiseEvents)
		{
			if (value != newValue)
			{
				value = newValue;
				if (raiseEvents && this.ValueChanged != null)
				{
					this.ValueChanged(this, EventArgs.Empty);
				}
				Invalidate();
			}
		}

		/// <summary>
		/// Draws the control
		/// </summary>
		protected override void OnPaint(PaintEventArgs e)
		{
			int num = Math.Min(base.Width - 4, base.Height - 4);
			Pen pen = new Pen(ForeColor, 3f);
			pen.LineJoin = LineJoin.Round;
			GraphicsState gstate = e.Graphics.Save();
			e.Graphics.TranslateTransform(base.Width / 2, base.Height / 2);
			e.Graphics.SmoothingMode = SmoothingMode.AntiAlias;
			e.Graphics.DrawArc(pen, new Rectangle(num / -2, num / -2, num, num), 135f, 270f);
			double num2 = (value - minimum) / (maximum - minimum);
			double num3 = 135.0 + num2 * 270.0;
			double num4 = (double)num / 2.0 * Math.Cos(Math.PI * num3 / 180.0);
			double num5 = (double)num / 2.0 * Math.Sin(Math.PI * num3 / 180.0);
			e.Graphics.DrawLine(pen, 0f, 0f, (float)num4, (float)num5);
			e.Graphics.Restore(gstate);
			base.OnPaint(e);
		}

		/// <summary>
		/// Handles the mouse down event to allow changing value by dragging
		/// </summary>
		protected override void OnMouseDown(MouseEventArgs e)
		{
			dragging = true;
			beginDragY = e.Y;
			beginDragValue = value;
			base.OnMouseDown(e);
		}

		/// <summary>
		/// Handles the mouse up event to allow changing value by dragging
		/// </summary>
		protected override void OnMouseUp(MouseEventArgs e)
		{
			dragging = false;
			base.OnMouseUp(e);
		}

		/// <summary>
		/// Handles the mouse down event to allow changing value by dragging
		/// </summary>
		protected override void OnMouseMove(MouseEventArgs e)
		{
			if (dragging)
			{
				int num = beginDragY - e.Y;
				double num2 = (maximum - minimum) * ((double)num / 150.0);
				double num3 = beginDragValue + num2;
				if (num3 < minimum)
				{
					num3 = minimum;
				}
				if (num3 > maximum)
				{
					num3 = maximum;
				}
				SetValue(num3, raiseEvents: true);
			}
			base.OnMouseMove(e);
		}

		/// <summary> 
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary> 
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			base.SuspendLayout();
			base.AutoScaleDimensions = new System.Drawing.SizeF(6f, 13f);
			base.AutoScaleMode = System.Windows.Forms.AutoScaleMode.Font;
			base.Name = "Pot";
			base.Size = new System.Drawing.Size(32, 32);
			base.ResumeLayout(false);
		}
	}

	/// <summary>
	/// Implements a rudimentary volume meter
	/// </summary>
	public class VolumeMeter : Control
	{
		private Brush foregroundBrush;

		private float amplitude;

		/// <summary>
		/// Required designer variable.
		/// </summary>
		private IContainer components;

		/// <summary>
		/// Current Value
		/// </summary>
		[DefaultValue(-3.0)]
		public float Amplitude
		{
			get
			{
				return amplitude;
			}
			set
			{
				amplitude = value;
				Invalidate();
			}
		}

		/// <summary>
		/// Minimum decibels
		/// </summary>
		[DefaultValue(-60.0)]
		public float MinDb { get; set; }

		/// <summary>
		/// Maximum decibels
		/// </summary>
		[DefaultValue(18.0)]
		public float MaxDb { get; set; }

		/// <summary>
		/// Meter orientation
		/// </summary>
		[DefaultValue(Orientation.Vertical)]
		public Orientation Orientation { get; set; }

		/// <summary>
		/// Basic volume meter
		/// </summary>
		public VolumeMeter()
		{
			SetStyle(ControlStyles.UserPaint | ControlStyles.AllPaintingInWmPaint | ControlStyles.OptimizedDoubleBuffer, value: true);
			MinDb = -60f;
			MaxDb = 18f;
			Amplitude = 0f;
			Orientation = Orientation.Vertical;
			InitializeComponent();
			OnForeColorChanged(EventArgs.Empty);
		}

		/// <summary>
		/// On Fore Color Changed
		/// </summary>
		protected override void OnForeColorChanged(EventArgs e)
		{
			foregroundBrush = new SolidBrush(ForeColor);
			base.OnForeColorChanged(e);
		}

		/// <summary>
		/// Paints the volume meter
		/// </summary>
		protected override void OnPaint(PaintEventArgs pe)
		{
			pe.Graphics.DrawRectangle(Pens.Black, 0, 0, base.Width - 1, base.Height - 1);
			double num = 20.0 * Math.Log10(Amplitude);
			if (num < (double)MinDb)
			{
				num = MinDb;
			}
			if (num > (double)MaxDb)
			{
				num = MaxDb;
			}
			double num2 = (num - (double)MinDb) / (double)(MaxDb - MinDb);
			int num3 = base.Width - 2;
			int num4 = base.Height - 2;
			if (Orientation == Orientation.Horizontal)
			{
				num3 = (int)((double)num3 * num2);
				pe.Graphics.FillRectangle(foregroundBrush, 1, 1, num3, num4);
			}
			else
			{
				num4 = (int)((double)num4 * num2);
				pe.Graphics.FillRectangle(foregroundBrush, 1, base.Height - 1 - num4, num3, num4);
			}
		}

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.components = new System.ComponentModel.Container();
		}
	}

	/// <summary>
	/// VolumeSlider control
	/// </summary>
	public class VolumeSlider : UserControl
	{
		/// <summary>
		/// Required designer variable.
		/// </summary>
		private Container components;

		private float volume = 1f;

		private float MinDb = -48f;

		/// <summary>
		/// The volume for this control
		/// </summary>
		[DefaultValue(1f)]
		public float Volume
		{
			get
			{
				return volume;
			}
			set
			{
				if (value < 0f)
				{
					value = 0f;
				}
				if (value > 1f)
				{
					value = 1f;
				}
				if (volume != value)
				{
					volume = value;
					if (this.VolumeChanged != null)
					{
						this.VolumeChanged(this, EventArgs.Empty);
					}
					Invalidate();
				}
			}
		}

		/// <summary>
		/// Volume changed event
		/// </summary>
		public event EventHandler VolumeChanged;

		/// <summary>
		/// Creates a new VolumeSlider control
		/// </summary>
		public VolumeSlider()
		{
			InitializeComponent();
		}

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			base.Name = "VolumeSlider";
			base.Size = new System.Drawing.Size(96, 16);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnPaint(System.Windows.Forms.PaintEventArgs)" />
		/// </summary>
		protected override void OnPaint(PaintEventArgs pe)
		{
			StringFormat stringFormat = new StringFormat();
			stringFormat.LineAlignment = StringAlignment.Center;
			stringFormat.Alignment = StringAlignment.Center;
			pe.Graphics.DrawRectangle(Pens.Black, 0, 0, base.Width - 1, base.Height - 1);
			float num = 20f * (float)Math.Log10(Volume);
			float num2 = 1f - num / MinDb;
			pe.Graphics.FillRectangle(Brushes.LightGreen, 1, 1, (int)((float)(base.Width - 2) * num2), base.Height - 2);
			string s = $"{num:F2} dB";
			pe.Graphics.DrawString(s, Font, Brushes.Black, base.ClientRectangle, stringFormat);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseMove(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		protected override void OnMouseMove(MouseEventArgs e)
		{
			if (e.Button == MouseButtons.Left)
			{
				SetVolumeFromMouse(e.X);
			}
			base.OnMouseMove(e);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnMouseDown(System.Windows.Forms.MouseEventArgs)" />
		/// </summary>
		protected override void OnMouseDown(MouseEventArgs e)
		{
			SetVolumeFromMouse(e.X);
			base.OnMouseDown(e);
		}

		private void SetVolumeFromMouse(int x)
		{
			float num = (1f - (float)x / (float)base.Width) * MinDb;
			if (x <= 0)
			{
				Volume = 0f;
			}
			else
			{
				Volume = (float)Math.Pow(10.0, num / 20f);
			}
		}
	}

	/// <summary>
	/// Windows Forms control for painting audio waveforms
	/// </summary>
	public class WaveformPainter : Control
	{
		private Pen foregroundPen;

		private List<float> samples = new List<float>(1000);

		private int maxSamples;

		private int insertPos;

		/// <summary>
		/// Required designer variable.
		/// </summary>
		private IContainer components;

		/// <summary>
		/// Constructs a new instance of the WaveFormPainter class
		/// </summary>
		public WaveformPainter()
		{
			SetStyle(ControlStyles.UserPaint | ControlStyles.AllPaintingInWmPaint | ControlStyles.OptimizedDoubleBuffer, value: true);
			InitializeComponent();
			OnForeColorChanged(EventArgs.Empty);
			OnResize(EventArgs.Empty);
		}

		/// <summary>
		/// On Resize
		/// </summary>
		protected override void OnResize(EventArgs e)
		{
			maxSamples = base.Width;
			base.OnResize(e);
		}

		/// <summary>
		/// On ForeColor Changed
		/// </summary>
		/// <param name="e"></param>
		protected override void OnForeColorChanged(EventArgs e)
		{
			foregroundPen = new Pen(ForeColor);
			base.OnForeColorChanged(e);
		}

		/// <summary>
		/// Add Max Value
		/// </summary>
		/// <param name="maxSample"></param>
		public void AddMax(float maxSample)
		{
			if (maxSamples != 0)
			{
				if (samples.Count <= maxSamples)
				{
					samples.Add(maxSample);
				}
				else if (insertPos < maxSamples)
				{
					samples[insertPos] = maxSample;
				}
				insertPos++;
				insertPos %= maxSamples;
				Invalidate();
			}
		}

		/// <summary>
		/// On Paint
		/// </summary>
		protected override void OnPaint(PaintEventArgs pe)
		{
			base.OnPaint(pe);
			for (int i = 0; i < base.Width; i++)
			{
				float num = (float)base.Height * GetSample(i - base.Width + insertPos);
				float num2 = ((float)base.Height - num) / 2f;
				pe.Graphics.DrawLine(foregroundPen, i, num2, i, num2 + num);
			}
		}

		private float GetSample(int index)
		{
			if (index < 0)
			{
				index += maxSamples;
			}
			if ((index >= 0) & (index < samples.Count))
			{
				return samples[index];
			}
			return 0f;
		}

		/// <summary>
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.components = new System.ComponentModel.Container();
		}
	}

	/// <summary>
	/// Control for viewing waveforms
	/// </summary>
	public class WaveViewer : UserControl
	{
		/// <summary> 
		/// Required designer variable.
		/// </summary>
		private Container components;

		private WaveStream waveStream;

		private int samplesPerPixel = 128;

		private long startPosition;

		private int bytesPerSample;

		/// <summary>
		/// sets the associated wavestream
		/// </summary>
		public WaveStream WaveStream
		{
			get
			{
				return waveStream;
			}
			set
			{
				waveStream = value;
				if (waveStream != null)
				{
					bytesPerSample = waveStream.WaveFormat.BitsPerSample / 8 * waveStream.WaveFormat.Channels;
				}
				Invalidate();
			}
		}

		/// <summary>
		/// The zoom level, in samples per pixel
		/// </summary>
		public int SamplesPerPixel
		{
			get
			{
				return samplesPerPixel;
			}
			set
			{
				samplesPerPixel = value;
				Invalidate();
			}
		}

		/// <summary>
		/// Start position (currently in bytes)
		/// </summary>
		public long StartPosition
		{
			get
			{
				return startPosition;
			}
			set
			{
				startPosition = value;
			}
		}

		/// <summary>
		/// Creates a new WaveViewer control
		/// </summary>
		public WaveViewer()
		{
			InitializeComponent();
			DoubleBuffered = true;
		}

		/// <summary> 
		/// Clean up any resources being used.
		/// </summary>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary>
		/// <see cref="M:System.Windows.Forms.Control.OnPaint(System.Windows.Forms.PaintEventArgs)" />
		/// </summary>
		protected override void OnPaint(PaintEventArgs e)
		{
			if (waveStream != null)
			{
				waveStream.Position = 0L;
				byte[] array = new byte[samplesPerPixel * bytesPerSample];
				waveStream.Position = startPosition + e.ClipRectangle.Left * bytesPerSample * samplesPerPixel;
				for (float num = e.ClipRectangle.X; num < (float)e.ClipRectangle.Right; num += 1f)
				{
					short num2 = 0;
					short num3 = 0;
					int num4 = waveStream.Read(array, 0, samplesPerPixel * bytesPerSample);
					if (num4 == 0)
					{
						break;
					}
					for (int i = 0; i < num4; i += 2)
					{
						short num5 = BitConverter.ToInt16(array, i);
						if (num5 < num2)
						{
							num2 = num5;
						}
						if (num5 > num3)
						{
							num3 = num5;
						}
					}
					float num6 = ((float)num2 - -32768f) / 65535f;
					float num7 = ((float)num3 - -32768f) / 65535f;
					e.Graphics.DrawLine(Pens.Black, num, (float)base.Height * num6, num, (float)base.Height * num7);
				}
			}
			base.OnPaint(e);
		}

		/// <summary> 
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.components = new System.ComponentModel.Container();
		}
	}
}

namespace NAudio.Utils
{
	using System.Drawing;
	using System.Windows.Forms;
	using System.ComponentModel;
	
	/// <summary>
	/// A thread-safe Progress Log Control
	/// </summary>
	public class ProgressLog : UserControl
	{
		private delegate void LogMessageDelegate(Color color, string message);

		private delegate void ClearLogDelegate();

		/// <summary> 
		/// Required designer variable.
		/// </summary>
		private IContainer components;

		private RichTextBox richTextBoxLog;

		/// <summary>
		/// The contents of the log as text
		/// </summary>
		public new string Text => richTextBoxLog.Text;

		/// <summary>
		/// Creates a new progress log control
		/// </summary>
		public ProgressLog()
		{
			InitializeComponent();
		}

		/// <summary>
		/// Log a message
		/// </summary>
		public void LogMessage(Color color, string message)
		{
			if (richTextBoxLog.InvokeRequired)
			{
				Invoke(new LogMessageDelegate(LogMessage), color, message);
			}
			else
			{
				richTextBoxLog.SelectionStart = richTextBoxLog.TextLength;
				richTextBoxLog.SelectionColor = color;
				richTextBoxLog.AppendText(message);
				richTextBoxLog.AppendText(Environment.NewLine);
			}
		}

		/// <summary>
		/// Clear the log
		/// </summary>
		public void ClearLog()
		{
			if (richTextBoxLog.InvokeRequired)
			{
				Invoke(new ClearLogDelegate(ClearLog), new object[0]);
			}
			else
			{
				richTextBoxLog.Clear();
			}
		}

		/// <summary> 
		/// Clean up any resources being used.
		/// </summary>
		/// <param name="disposing">true if managed resources should be disposed; otherwise, false.</param>
		protected override void Dispose(bool disposing)
		{
			if (disposing && components != null)
			{
				components.Dispose();
			}
			base.Dispose(disposing);
		}

		/// <summary> 
		/// Required method for Designer support - do not modify 
		/// the contents of this method with the code editor.
		/// </summary>
		private void InitializeComponent()
		{
			this.richTextBoxLog = new System.Windows.Forms.RichTextBox();
			base.SuspendLayout();
			this.richTextBoxLog.BorderStyle = System.Windows.Forms.BorderStyle.None;
			this.richTextBoxLog.Dock = System.Windows.Forms.DockStyle.Fill;
			this.richTextBoxLog.Location = new System.Drawing.Point(1, 1);
			this.richTextBoxLog.Name = "richTextBoxLog";
			this.richTextBoxLog.ReadOnly = true;
			this.richTextBoxLog.Size = new System.Drawing.Size(311, 129);
			this.richTextBoxLog.TabIndex = 0;
			this.richTextBoxLog.Text = "";
			base.AutoScaleDimensions = new System.Drawing.SizeF(6f, 13f);
			base.AutoScaleMode = System.Windows.Forms.AutoScaleMode.Font;
			this.BackColor = System.Drawing.SystemColors.ControlDarkDark;
			base.Controls.Add(this.richTextBoxLog);
			base.Name = "ProgressLog";
			base.Padding = new System.Windows.Forms.Padding(1);
			base.Size = new System.Drawing.Size(313, 131);
			base.ResumeLayout(false);
		}
	}
}

namespace NAudio.Wave
{
	using NAudio.Mixer;
	using System.Windows.Forms;
	
	/// <summary>
	/// Wave Callback Info
	/// </summary>
	public class WaveCallbackInfo
	{
		private WaveWindow waveOutWindow;

		private WaveWindowNative waveOutWindowNative;

		/// <summary>
		/// Callback Strategy
		/// </summary>
		public WaveCallbackStrategy Strategy { get; private set; }

		/// <summary>
		/// Window Handle (if applicable)
		/// </summary>
		public IntPtr Handle { get; private set; }

		/// <summary>
		/// Sets up a new WaveCallbackInfo for function callbacks
		/// </summary>
		public static WaveCallbackInfo FunctionCallback()
		{
			return new WaveCallbackInfo(WaveCallbackStrategy.FunctionCallback, IntPtr.Zero);
		}

		/// <summary>
		/// Sets up a new WaveCallbackInfo to use a New Window
		/// IMPORTANT: only use this on the GUI thread
		/// </summary>
		public static WaveCallbackInfo NewWindow()
		{
			return new WaveCallbackInfo(WaveCallbackStrategy.NewWindow, IntPtr.Zero);
		}

		/// <summary>
		/// Sets up a new WaveCallbackInfo to use an existing window
		/// IMPORTANT: only use this on the GUI thread
		/// </summary>
		public static WaveCallbackInfo ExistingWindow(IntPtr handle)
		{
			if (handle == IntPtr.Zero)
			{
				throw new ArgumentException("Handle cannot be zero");
			}
			return new WaveCallbackInfo(WaveCallbackStrategy.ExistingWindow, handle);
		}

		private WaveCallbackInfo(WaveCallbackStrategy strategy, IntPtr handle)
		{
			Strategy = strategy;
			Handle = handle;
		}

		internal void Connect(WaveInterop.WaveCallback callback)
		{
			if (Strategy == WaveCallbackStrategy.NewWindow)
			{
				waveOutWindow = new WaveWindow(callback);
				waveOutWindow.CreateControl();
				Handle = waveOutWindow.Handle;
			}
			else if (Strategy == WaveCallbackStrategy.ExistingWindow)
			{
				waveOutWindowNative = new WaveWindowNative(callback);
				waveOutWindowNative.AssignHandle(Handle);
			}
		}

		internal MmResult WaveOutOpen(out IntPtr waveOutHandle, int deviceNumber, WaveFormat waveFormat, WaveInterop.WaveCallback callback)
		{
			if (Strategy == WaveCallbackStrategy.FunctionCallback)
			{
				return WaveInterop.waveOutOpen(out waveOutHandle, (IntPtr)deviceNumber, waveFormat, callback, IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackFunction);
			}
			return WaveInterop.waveOutOpenWindow(out waveOutHandle, (IntPtr)deviceNumber, waveFormat, Handle, IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackWindow);
		}

		internal MmResult WaveInOpen(out IntPtr waveInHandle, int deviceNumber, WaveFormat waveFormat, WaveInterop.WaveCallback callback)
		{
			if (Strategy == WaveCallbackStrategy.FunctionCallback)
			{
				return WaveInterop.waveInOpen(out waveInHandle, (IntPtr)deviceNumber, waveFormat, callback, IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackFunction);
			}
			return WaveInterop.waveInOpenWindow(out waveInHandle, (IntPtr)deviceNumber, waveFormat, Handle, IntPtr.Zero, WaveInterop.WaveInOutOpenFlags.CallbackWindow);
		}

		internal void Disconnect()
		{
			if (waveOutWindow != null)
			{
				waveOutWindow.Close();
				waveOutWindow = null;
			}
			if (waveOutWindowNative != null)
			{
				waveOutWindowNative.ReleaseHandle();
				waveOutWindowNative = null;
			}
		}
	}

	/// <summary>
	/// Allows recording using the Windows waveIn APIs
	/// Events are raised as recorded buffers are made available
	/// </summary>
	public class WaveIn : IWaveIn, IDisposable
	{
		private IntPtr waveInHandle;

		private volatile bool recording;

		private WaveInBuffer[] buffers;

		private readonly WaveInterop.WaveCallback callback;

		private WaveCallbackInfo callbackInfo;

		private readonly SynchronizationContext syncContext;

		private int lastReturnedBufferIndex;

		/// <summary>
		/// Returns the number of Wave In devices available in the system
		/// </summary>
		public static int DeviceCount => WaveInterop.waveInGetNumDevs();

		/// <summary>
		/// Milliseconds for the buffer. Recommended value is 100ms
		/// </summary>
		public int BufferMilliseconds { get; set; }

		/// <summary>
		/// Number of Buffers to use (usually 2 or 3)
		/// </summary>
		public int NumberOfBuffers { get; set; }

		/// <summary>
		/// The device number to use
		/// </summary>
		public int DeviceNumber { get; set; }

		/// <summary>
		/// WaveFormat we are recording in
		/// </summary>
		public WaveFormat WaveFormat { get; set; }

		/// <summary>
		/// Indicates recorded data is available 
		/// </summary>
		public event EventHandler<WaveInEventArgs> DataAvailable;

		/// <summary>
		/// Indicates that all recorded data has now been received.
		/// </summary>
		public event EventHandler<StoppedEventArgs> RecordingStopped;

		/// <summary>
		/// Prepares a Wave input device for recording
		/// </summary>
		public WaveIn()
			: this(WaveCallbackInfo.NewWindow())
		{
		}

		/// <summary>
		/// Creates a WaveIn device using the specified window handle for callbacks
		/// </summary>
		/// <param name="windowHandle">A valid window handle</param>
		public WaveIn(IntPtr windowHandle)
			: this(WaveCallbackInfo.ExistingWindow(windowHandle))
		{
		}

		/// <summary>
		/// Prepares a Wave input device for recording
		/// </summary>
		public WaveIn(WaveCallbackInfo callbackInfo)
		{
			syncContext = SynchronizationContext.Current;
			if ((callbackInfo.Strategy == WaveCallbackStrategy.NewWindow || callbackInfo.Strategy == WaveCallbackStrategy.ExistingWindow) && syncContext == null)
			{
				throw new InvalidOperationException("Use WaveInEvent to record on a background thread");
			}
			DeviceNumber = 0;
			WaveFormat = new WaveFormat(8000, 16, 1);
			BufferMilliseconds = 100;
			NumberOfBuffers = 3;
			callback = Callback;
			this.callbackInfo = callbackInfo;
			callbackInfo.Connect(callback);
		}

		/// <summary>
		/// Retrieves the capabilities of a waveIn device
		/// </summary>
		/// <param name="devNumber">Device to test</param>
		/// <returns>The WaveIn device capabilities</returns>
		public static WaveInCapabilities GetCapabilities(int devNumber)
		{
			WaveInCapabilities waveInCaps = default(WaveInCapabilities);
			int waveInCapsSize = Marshal.SizeOf(waveInCaps);
			MmException.Try(WaveInterop.waveInGetDevCaps((IntPtr)devNumber, out waveInCaps, waveInCapsSize), "waveInGetDevCaps");
			return waveInCaps;
		}

		private void CreateBuffers()
		{
			int num = BufferMilliseconds * WaveFormat.AverageBytesPerSecond / 1000;
			if (num % WaveFormat.BlockAlign != 0)
			{
				num -= num % WaveFormat.BlockAlign;
			}
			buffers = new WaveInBuffer[NumberOfBuffers];
			for (int i = 0; i < buffers.Length; i++)
			{
				buffers[i] = new WaveInBuffer(waveInHandle, num);
			}
		}

		/// <summary>
		/// Called when we get a new buffer of recorded data
		/// </summary>
		private void Callback(IntPtr waveInHandle, WaveInterop.WaveMessage message, IntPtr userData, WaveHeader waveHeader, IntPtr reserved)
		{
			if (message != WaveInterop.WaveMessage.WaveInData || !recording)
			{
				return;
			}
			WaveInBuffer waveInBuffer = (WaveInBuffer)((GCHandle)waveHeader.userData).Target;
			if (waveInBuffer != null)
			{
				lastReturnedBufferIndex = Array.IndexOf(buffers, waveInBuffer);
				RaiseDataAvailable(waveInBuffer);
				try
				{
					waveInBuffer.Reuse();
				}
				catch (Exception e)
				{
					recording = false;
					RaiseRecordingStopped(e);
				}
			}
		}

		private void RaiseDataAvailable(WaveInBuffer buffer)
		{
			this.DataAvailable?.Invoke(this, new WaveInEventArgs(buffer.Data, buffer.BytesRecorded));
		}

		private void RaiseRecordingStopped(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.RecordingStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}

		private void OpenWaveInDevice()
		{
			CloseWaveInDevice();
			MmException.Try(callbackInfo.WaveInOpen(out waveInHandle, DeviceNumber, WaveFormat, callback), "waveInOpen");
			CreateBuffers();
		}

		/// <summary>
		/// Start recording
		/// </summary>
		public void StartRecording()
		{
			if (recording)
			{
				throw new InvalidOperationException("Already recording");
			}
			OpenWaveInDevice();
			EnqueueBuffers();
			MmException.Try(WaveInterop.waveInStart(waveInHandle), "waveInStart");
			recording = true;
		}

		private void EnqueueBuffers()
		{
			WaveInBuffer[] array = buffers;
			foreach (WaveInBuffer waveInBuffer in array)
			{
				if (!waveInBuffer.InQueue)
				{
					waveInBuffer.Reuse();
				}
			}
		}

		/// <summary>
		/// Stop recording
		/// </summary>
		public void StopRecording()
		{
			if (!recording)
			{
				return;
			}
			recording = false;
			MmException.Try(WaveInterop.waveInStop(waveInHandle), "waveInStop");
			for (int i = 0; i < buffers.Length; i++)
			{
				int num = (i + lastReturnedBufferIndex + 1) % buffers.Length;
				WaveInBuffer waveInBuffer = buffers[num];
				if (waveInBuffer.Done)
				{
					RaiseDataAvailable(waveInBuffer);
				}
			}
			RaiseRecordingStopped(null);
		}

		/// <summary>
		/// Gets the current position in bytes from the wave input device.
		/// it calls directly into waveInGetPosition)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			MmTime mmTime = default(MmTime);
			mmTime.wType = 4u;
			MmException.Try(WaveInterop.waveInGetPosition(waveInHandle, out mmTime, Marshal.SizeOf(mmTime)), "waveInGetPosition");
			if (mmTime.wType != 4)
			{
				throw new Exception($"waveInGetPosition: wType -> Expected {4}, Received {mmTime.wType}");
			}
			return mmTime.cb;
		}

		/// <summary>
		/// Dispose pattern
		/// </summary>
		protected virtual void Dispose(bool disposing)
		{
			if (disposing)
			{
				if (recording)
				{
					StopRecording();
				}
				CloseWaveInDevice();
				if (callbackInfo != null)
				{
					callbackInfo.Disconnect();
					callbackInfo = null;
				}
			}
		}

		private void CloseWaveInDevice()
		{
			if (waveInHandle == IntPtr.Zero)
			{
				return;
			}
			WaveInterop.waveInReset(waveInHandle);
			if (buffers != null)
			{
				for (int i = 0; i < buffers.Length; i++)
				{
					buffers[i].Dispose();
				}
				buffers = null;
			}
			WaveInterop.waveInClose(waveInHandle);
			waveInHandle = IntPtr.Zero;
		}

		/// <summary>
		/// Microphone Level
		/// </summary>
		public MixerLine GetMixerLine()
		{
			if (waveInHandle != IntPtr.Zero)
			{
				return new MixerLine(waveInHandle, 0, MixerFlags.WaveInHandle);
			}
			return new MixerLine((IntPtr)DeviceNumber, 0, MixerFlags.WaveIn);
		}

		/// <summary>
		/// Dispose method
		/// </summary>
		public void Dispose()
		{
			Dispose(disposing: true);
			GC.SuppressFinalize(this);
		}
	}

	/// <summary>
	/// Represents a wave out device
	/// </summary>
	public class WaveOut : IWavePlayer, IDisposable, IWavePosition
	{
		private IntPtr hWaveOut;

		private WaveOutBuffer[] buffers;

		private IWaveProvider waveStream;

		private volatile PlaybackState playbackState;

		private readonly WaveInterop.WaveCallback callback;

		private readonly WaveCallbackInfo callbackInfo;

		private readonly object waveOutLock;

		private int queuedBuffers;

		private readonly SynchronizationContext syncContext;

		/// <summary>
		/// Returns the number of Wave Out devices available in the system
		/// </summary>
		public static int DeviceCount => WaveInterop.waveOutGetNumDevs();

		/// <summary>
		/// Gets or sets the desired latency in milliseconds
		/// Should be set before a call to Init
		/// </summary>
		public int DesiredLatency { get; set; }

		/// <summary>
		/// Gets or sets the number of buffers used
		/// Should be set before a call to Init
		/// </summary>
		public int NumberOfBuffers { get; set; }

		/// <summary>
		/// Gets or sets the device number
		/// Should be set before a call to Init
		/// This must be between -1 and <see>DeviceCount</see> - 1.
		/// -1 means stick to default device even default device is changed
		/// </summary>
		public int DeviceNumber { get; set; } = -1;


		/// <summary>
		/// Gets a <see cref="T:NAudio.Wave.WaveFormat" /> instance indicating the format the hardware is using.
		/// </summary>
		public WaveFormat OutputWaveFormat => waveStream.WaveFormat;

		/// <summary>
		/// Playback State
		/// </summary>
		public PlaybackState PlaybackState => playbackState;

		/// <summary>
		/// Volume for this device 1.0 is full scale
		/// </summary>
		public float Volume
		{
			get
			{
				return WaveOutUtils.GetWaveOutVolume(hWaveOut, waveOutLock);
			}
			set
			{
				WaveOutUtils.SetWaveOutVolume(value, hWaveOut, waveOutLock);
			}
		}

		/// <summary>
		/// Indicates playback has stopped automatically
		/// </summary>
		public event EventHandler<StoppedEventArgs> PlaybackStopped;

		/// <summary>
		/// Retrieves the capabilities of a waveOut device
		/// </summary>
		/// <param name="devNumber">Device to test</param>
		/// <returns>The WaveOut device capabilities</returns>
		public static WaveOutCapabilities GetCapabilities(int devNumber)
		{
			WaveOutCapabilities waveOutCaps = default(WaveOutCapabilities);
			int waveOutCapsSize = Marshal.SizeOf(waveOutCaps);
			MmException.Try(WaveInterop.waveOutGetDevCaps((IntPtr)devNumber, out waveOutCaps, waveOutCapsSize), "waveOutGetDevCaps");
			return waveOutCaps;
		}

		/// <summary>
		/// Creates a default WaveOut device
		/// Will use window callbacks if called from a GUI thread, otherwise function
		/// callbacks
		/// </summary>
		public WaveOut()
			: this((SynchronizationContext.Current == null) ? WaveCallbackInfo.FunctionCallback() : WaveCallbackInfo.NewWindow())
		{
		}

		/// <summary>
		/// Creates a WaveOut device using the specified window handle for callbacks
		/// </summary>
		/// <param name="windowHandle">A valid window handle</param>
		public WaveOut(IntPtr windowHandle)
			: this(WaveCallbackInfo.ExistingWindow(windowHandle))
		{
		}

		/// <summary>
		/// Opens a WaveOut device
		/// </summary>
		public WaveOut(WaveCallbackInfo callbackInfo)
		{
			syncContext = SynchronizationContext.Current;
			DesiredLatency = 300;
			NumberOfBuffers = 2;
			callback = Callback;
			waveOutLock = new object();
			this.callbackInfo = callbackInfo;
			callbackInfo.Connect(callback);
		}

		/// <summary>
		/// Initialises the WaveOut device
		/// </summary>
		/// <param name="waveProvider">WaveProvider to play</param>
		public void Init(IWaveProvider waveProvider)
		{
			waveStream = waveProvider;
			int bufferSize = waveProvider.WaveFormat.ConvertLatencyToByteSize((DesiredLatency + NumberOfBuffers - 1) / NumberOfBuffers);
			MmResult result;
			lock (waveOutLock)
			{
				result = callbackInfo.WaveOutOpen(out hWaveOut, DeviceNumber, waveStream.WaveFormat, callback);
			}
			MmException.Try(result, "waveOutOpen");
			buffers = new WaveOutBuffer[NumberOfBuffers];
			playbackState = PlaybackState.Stopped;
			for (int i = 0; i < NumberOfBuffers; i++)
			{
				buffers[i] = new WaveOutBuffer(hWaveOut, bufferSize, waveStream, waveOutLock);
			}
		}

		/// <summary>
		/// Start playing the audio from the WaveStream
		/// </summary>
		public void Play()
		{
			if (playbackState == PlaybackState.Stopped)
			{
				playbackState = PlaybackState.Playing;
				EnqueueBuffers();
			}
			else if (playbackState == PlaybackState.Paused)
			{
				EnqueueBuffers();
				Resume();
				playbackState = PlaybackState.Playing;
			}
		}

		private void EnqueueBuffers()
		{
			for (int i = 0; i < NumberOfBuffers; i++)
			{
				if (!buffers[i].InQueue)
				{
					if (!buffers[i].OnDone())
					{
						playbackState = PlaybackState.Stopped;
						break;
					}
					Interlocked.Increment(ref queuedBuffers);
				}
			}
		}

		/// <summary>
		/// Pause the audio
		/// </summary>
		public void Pause()
		{
			if (playbackState == PlaybackState.Playing)
			{
				playbackState = PlaybackState.Paused;
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutPause(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutPause");
				}
			}
		}

		/// <summary>
		/// Resume playing after a pause from the same position
		/// </summary>
		public void Resume()
		{
			if (playbackState == PlaybackState.Paused)
			{
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutRestart(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutRestart");
				}
				playbackState = PlaybackState.Playing;
			}
		}

		/// <summary>
		/// Stop and reset the WaveOut device
		/// </summary>
		public void Stop()
		{
			if (playbackState != 0)
			{
				playbackState = PlaybackState.Stopped;
				MmResult mmResult;
				lock (waveOutLock)
				{
					mmResult = WaveInterop.waveOutReset(hWaveOut);
				}
				if (mmResult != 0)
				{
					throw new MmException(mmResult, "waveOutReset");
				}
				if (callbackInfo.Strategy == WaveCallbackStrategy.FunctionCallback)
				{
					RaisePlaybackStoppedEvent(null);
				}
			}
		}

		/// <summary>
		/// Gets the current position in bytes from the wave output device.
		/// (n.b. this is not the same thing as the position within your reader
		/// stream - it calls directly into waveOutGetPosition)
		/// </summary>
		/// <returns>Position in bytes</returns>
		public long GetPosition()
		{
			return WaveOutUtils.GetPositionBytes(hWaveOut, waveOutLock);
		}

		/// <summary>
		/// Closes this WaveOut device
		/// </summary>
		public void Dispose()
		{
			GC.SuppressFinalize(this);
			Dispose(disposing: true);
		}

		/// <summary>
		/// Closes the WaveOut device and disposes of buffers
		/// </summary>
		/// <param name="disposing">True if called from <see>Dispose</see></param>
		protected void Dispose(bool disposing)
		{
			Stop();
			if (disposing && buffers != null)
			{
				for (int i = 0; i < buffers.Length; i++)
				{
					if (buffers[i] != null)
					{
						buffers[i].Dispose();
					}
				}
				buffers = null;
			}
			lock (waveOutLock)
			{
				WaveInterop.waveOutClose(hWaveOut);
			}
			if (disposing)
			{
				callbackInfo.Disconnect();
			}
		}

		/// <summary>
		/// Finalizer. Only called when user forgets to call <see>Dispose</see>
		/// </summary>
		~WaveOut()
		{
			Dispose(disposing: false);
		}

		private void Callback(IntPtr hWaveOut, WaveInterop.WaveMessage uMsg, IntPtr dwInstance, WaveHeader wavhdr, IntPtr dwReserved)
		{
			if (uMsg != WaveInterop.WaveMessage.WaveOutDone)
			{
				return;
			}
			WaveOutBuffer waveOutBuffer = (WaveOutBuffer)((GCHandle)wavhdr.userData).Target;
			Interlocked.Decrement(ref queuedBuffers);
			Exception e = null;
			if (PlaybackState == PlaybackState.Playing)
			{
				lock (waveOutLock)
				{
					try
					{
						if (waveOutBuffer.OnDone())
						{
							Interlocked.Increment(ref queuedBuffers);
						}
					}
					catch (Exception ex)
					{
						e = ex;
					}
				}
			}
			if (queuedBuffers == 0 && (callbackInfo.Strategy != 0 || playbackState != 0))
			{
				playbackState = PlaybackState.Stopped;
				RaisePlaybackStoppedEvent(e);
			}
		}

		private void RaisePlaybackStoppedEvent(Exception e)
		{
			EventHandler<StoppedEventArgs> handler = this.PlaybackStopped;
			if (handler == null)
			{
				return;
			}
			if (syncContext == null)
			{
				handler(this, new StoppedEventArgs(e));
				return;
			}
			syncContext.Post(delegate
			{
				handler(this, new StoppedEventArgs(e));
			}, null);
		}
	}

	internal class WaveWindow : Form
	{
		private WaveInterop.WaveCallback waveCallback;

		public WaveWindow(WaveInterop.WaveCallback waveCallback)
		{
			this.waveCallback = waveCallback;
		}

		protected override void WndProc(ref Message m)
		{
			WaveInterop.WaveMessage msg = (WaveInterop.WaveMessage)m.Msg;
			switch (msg)
			{
			case WaveInterop.WaveMessage.WaveOutDone:
			case WaveInterop.WaveMessage.WaveInData:
			{
				IntPtr wParam = m.WParam;
				WaveHeader waveHeader = new WaveHeader();
				Marshal.PtrToStructure(m.LParam, waveHeader);
				waveCallback(wParam, msg, IntPtr.Zero, waveHeader, IntPtr.Zero);
				break;
			}
			case WaveInterop.WaveMessage.WaveOutOpen:
			case WaveInterop.WaveMessage.WaveOutClose:
			case WaveInterop.WaveMessage.WaveInOpen:
			case WaveInterop.WaveMessage.WaveInClose:
				waveCallback(m.WParam, msg, IntPtr.Zero, null, IntPtr.Zero);
				break;
			default:
				base.WndProc(ref m);
				break;
			}
		}
	}

	internal class WaveWindowNative : NativeWindow
	{
		private WaveInterop.WaveCallback waveCallback;

		public WaveWindowNative(WaveInterop.WaveCallback waveCallback)
		{
			this.waveCallback = waveCallback;
		}

		protected override void WndProc(ref Message m)
		{
			WaveInterop.WaveMessage msg = (WaveInterop.WaveMessage)m.Msg;
			switch (msg)
			{
			case WaveInterop.WaveMessage.WaveOutDone:
			case WaveInterop.WaveMessage.WaveInData:
			{
				IntPtr wParam = m.WParam;
				WaveHeader waveHeader = new WaveHeader();
				Marshal.PtrToStructure(m.LParam, waveHeader);
				waveCallback(wParam, msg, IntPtr.Zero, waveHeader, IntPtr.Zero);
				break;
			}
			case WaveInterop.WaveMessage.WaveOutOpen:
			case WaveInterop.WaveMessage.WaveOutClose:
			case WaveInterop.WaveMessage.WaveInOpen:
			case WaveInterop.WaveMessage.WaveInClose:
				waveCallback(m.WParam, msg, IntPtr.Zero, null, IntPtr.Zero);
				break;
			default:
				base.WndProc(ref m);
				break;
			}
		}
	}
}

namespace NAudio.WinForms.Gui
{
	using System.Resources;
	using System.ComponentModel;
	
	
	/// <summary>
	///   A strongly-typed resource class, for looking up localized strings, etc.
	/// </summary>
	[System.CodeDom.Compiler.GeneratedCode("System.Resources.Tools.StronglyTypedResourceBuilder", "16.0.0.0")]
	[System.Diagnostics.DebuggerNonUserCode]
	[System.Runtime.CompilerServices.CompilerGenerated]
	internal class Fader
	{
		private static ResourceManager resourceMan;

		private static CultureInfo resourceCulture;

		/// <summary>
		///   Returns the cached ResourceManager instance used by this class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static ResourceManager ResourceManager
		{
			get
			{
				if (resourceMan == null)
				{
					resourceMan = new ResourceManager("NAudio.WinForms.Gui.Fader", typeof(Fader).Assembly);
				}
				return resourceMan;
			}
		}

		/// <summary>
		///   Overrides the current thread's CurrentUICulture property for all
		///   resource lookups using this strongly typed resource class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static CultureInfo Culture
		{
			get
			{
				return resourceCulture;
			}
			set
			{
				resourceCulture = value;
			}
		}

		internal Fader()
		{
		}
	}

	/// <summary>
	///   A strongly-typed resource class, for looking up localized strings, etc.
	/// </summary>
	[System.CodeDom.Compiler.GeneratedCode("System.Resources.Tools.StronglyTypedResourceBuilder", "16.0.0.0")]
	[System.Diagnostics.DebuggerNonUserCode]
	[System.Runtime.CompilerServices.CompilerGenerated]
	internal class PanSlider
	{
		private static ResourceManager resourceMan;

		private static CultureInfo resourceCulture;

		/// <summary>
		///   Returns the cached ResourceManager instance used by this class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static ResourceManager ResourceManager
		{
			get
			{
				if (resourceMan == null)
				{
					resourceMan = new ResourceManager("NAudio.WinForms.Gui.PanSlider", typeof(PanSlider).Assembly);
				}
				return resourceMan;
			}
		}

		/// <summary>
		///   Overrides the current thread's CurrentUICulture property for all
		///   resource lookups using this strongly typed resource class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static CultureInfo Culture
		{
			get
			{
				return resourceCulture;
			}
			set
			{
				resourceCulture = value;
			}
		}

		internal PanSlider()
		{
		}
	}

	/// <summary>
	///   A strongly-typed resource class, for looking up localized strings, etc.
	/// </summary>
	[System.CodeDom.Compiler.GeneratedCode("System.Resources.Tools.StronglyTypedResourceBuilder", "16.0.0.0")]
	[System.Diagnostics.DebuggerNonUserCode]
	[System.Runtime.CompilerServices.CompilerGenerated]
	internal class VolumeSlider
	{
		private static ResourceManager resourceMan;

		private static CultureInfo resourceCulture;

		/// <summary>
		///   Returns the cached ResourceManager instance used by this class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static ResourceManager ResourceManager
		{
			get
			{
				if (resourceMan == null)
				{
					resourceMan = new ResourceManager("NAudio.WinForms.Gui.VolumeSlider", typeof(VolumeSlider).Assembly);
				}
				return resourceMan;
			}
		}

		/// <summary>
		///   Overrides the current thread's CurrentUICulture property for all
		///   resource lookups using this strongly typed resource class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static CultureInfo Culture
		{
			get
			{
				return resourceCulture;
			}
			set
			{
				resourceCulture = value;
			}
		}

		internal VolumeSlider()
		{
		}
	}

	/// <summary>
	///   A strongly-typed resource class, for looking up localized strings, etc.
	/// </summary>
	[System.CodeDom.Compiler.GeneratedCode("System.Resources.Tools.StronglyTypedResourceBuilder", "16.0.0.0")]
	[System.Diagnostics.DebuggerNonUserCode]
	[System.Runtime.CompilerServices.CompilerGenerated]
	internal class WaveViewer
	{
		private static ResourceManager resourceMan;

		private static CultureInfo resourceCulture;

		/// <summary>
		///   Returns the cached ResourceManager instance used by this class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static ResourceManager ResourceManager
		{
			get
			{
				if (resourceMan == null)
				{
					resourceMan = new ResourceManager("NAudio.WinForms.Gui.WaveViewer", typeof(WaveViewer).Assembly);
				}
				return resourceMan;
			}
		}

		/// <summary>
		///   Overrides the current thread's CurrentUICulture property for all
		///   resource lookups using this strongly typed resource class.
		/// </summary>
		[EditorBrowsable(EditorBrowsableState.Advanced)]
		internal static CultureInfo Culture
		{
			get
			{
				return resourceCulture;
			}
			set
			{
				resourceCulture = value;
			}
		}

		internal WaveViewer() { }
	}
}